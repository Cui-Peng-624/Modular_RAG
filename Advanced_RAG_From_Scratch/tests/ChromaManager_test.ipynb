{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学习Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\VSCode\\VSCode仓库\\RAG\\Advanced_RAG_From_Scratch\\tests\\..\\ChromaVDB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 获取当前目录\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# 设置persist_directory为Advanced_RAG_From_Scratch文件夹\n",
    "persist_directory = os.path.join(current_directory, '..', 'ChromaVDB')\n",
    "print(persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv # type: ignore\n",
    "\n",
    "# 设置代理\n",
    "os.environ[\"http_proxy\"] = \"127.0.0.1:7890\"\n",
    "os.environ[\"https_proxy\"] = \"127.0.0.1:7890\"\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv('ZETATECHS_API_KEY')\n",
    "base_url = os.getenv('ZETATECHS_API_BASE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings # type: ignore\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", api_key=api_key, base_url=base_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma # type: ignore\n",
    "\n",
    "# 获取当前目录\n",
    "current_directory = os.getcwd()\n",
    "# 设置persist_directory为Advanced_RAG_From_Scratch文件夹\n",
    "persist_directory = os.path.join(current_directory, '..', 'ChromaVDB')\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_directory,  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 添加新的文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader # type: ignore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # type: ignore\n",
    "\n",
    "file_path = \"../files/UnderstandingDeepLearning-ZH-CN-240721.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(file_path) # 创建 PyPDFLoader 实例\n",
    "documents = loader.load() # 加载 PDF 文件并转换为文本数据\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap  = 100)\n",
    "documents_chunks = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 0}, page_content='理解深度学习\\nSimon J.D. Prince\\nFebruary 15, 2024'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 1}, page_content='ii'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 2}, page_content='目录\\n1介绍 1\\n1.1监督学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\\n1.1.1回归和分类问题 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\n1.1.2输入. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\n1.1.3机器学习模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.1.4深度神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n1.1.5结构化输出 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n1.2无监督学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n1.2.1生成式模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n1.2.2潜变量. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n1.2.3结合监督学习与无监督学习 . . . . . . . . . . . . . . . . . . . . . . 9\\n1.2.4强化学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n1.2.5两个例子 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\n1.3伦理. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 2}, page_content='1.3伦理. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n1.4本书结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n1.5其他书籍 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n1.6如何阅读本书 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\n2监督学习 15\\n2.1监督学习介绍 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\n2.2线性回归示例 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n2.2.1一维线性回归模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n2.2.2损失（Loss）. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\\n2.2.3训练. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\\n2.2.4测试. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n2.3总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n2.4笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 2}, page_content='2.4笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n2.5习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\niii'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 3}, page_content='iv 目录\\n3浅层神经网络 23\\n3.1神经网络示例 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n3.1.1神经网络直观理解 . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\n3.1.2描绘神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n3.2通用逼近定理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n3.3多变量输入与输出 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n3.4多变量输入和输出 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n3.4.1可视化多变量输出 . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n3.4.2可视化多变量输入 . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n3.5浅层神经网络：一般情况 . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\n3.6术语. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\n3.7总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\\n3.8笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 3}, page_content='3.8笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\\n3.9习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\\n4深度神经网络 39\\n4.1组合神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\\n4.2从组合网络到深层网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\\n4.3深度神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\\n4.3.1超参数. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\n4.4矩阵表示法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\n4.4.1通用公式 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\n4.5浅层网络与深层网络的比较 . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\n4.5.1逼近不同函数的能力 . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\n4.5.2每个参数产生的线性区域数量 . . . . . . . . . . . . . . . . . . . . . 47\\n4.5.3深度效率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 3}, page_content='4.5.3深度效率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\n4.5.4大型结构化输入 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\n4.5.5训练和泛化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\n4.6总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\n4.7笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\n4.8习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\\n5损失函数 53\\n5.1最大似然 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\\n5.1.1计算输出的分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\\n5.1.2最大似然准则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\n5.1.3最大化对数似然 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\n5.1.4最小化负对数似然 . . . . . . . . . . . . . . . . . . . . . . . . . . . 56'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 4}, page_content='目录 v\\n5.1.5推断. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\\n5.2构建损失函数的步骤 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\\n5.3示例1：单变量回归 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\\n5.3.1最小平方损失函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\n5.3.2推断. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\n5.3.3估计方差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\n5.3.4异方差回归 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\n5.4示例2：二元分类 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\\n5.5示例3：多类别分类 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\n5.5.1预测其他数据类型 . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\\n5.6多输出预测 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\\n5.7交叉熵损失 (Cross-entropy loss) . . . . . . . . . . . . . . . . . . . . . . . . 65'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 4}, page_content='5.7交叉熵损失 (Cross-entropy loss) . . . . . . . . . . . . . . . . . . . . . . . . 65\\n5.8总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\\n5.9笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\\n5.10习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\\n6训练模型 73\\n6.1梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\n6.1.1线性回归示例 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\\n6.1.2 Gabor 模型示例 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\\n6.1.3局部最小值与鞍点 . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\\n6.2随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\\n6.2.1批次和周期 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\\n6.2.2随机梯度下降的特性 . . . . . . . . . . . . . . . . . . . . . . . . . . 80\\n6.3动量. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 4}, page_content='6.3动量. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\\n6.3.1 Nesterov 加速动量 . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\\n6.4 Adam . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82\\n6.5训练算法的超参数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\\n6.6总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\\n6.7笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\\n6.8习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\n7梯度和初始化 89\\n7.1问题定义 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\\n7.2计算导数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90\\n7.3示例. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91\\n7.4反向传播算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 4}, page_content='7.4反向传播算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\\n7.4.1反向传播算法概述 . . . . . . . . . . . . . . . . . . . . . . . . . . . 97'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 5}, page_content='vi 目录\\n7.4.2算法微分 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\\n7.4.3扩展至任意计算图 . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\\n7.5参数初始化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\\n7.5.1前向传播的初始化 . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\\n7.5.2反向传播的初始化 . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\n7.5.3正向传播和反向传播的初始化 . . . . . . . . . . . . . . . . . . . . . 103\\n7.6示例训练代码 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\\n7.7总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\\n7.8笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\\n7.9习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\\n8性能评估 109\\n8.1训练一个简单模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\\n8.2错误的来源 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 5}, page_content='8.2错误的来源 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110\\n8.2.1噪声、偏差与方差 . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\\n8.2.2测试误差的数学公式 . . . . . . . . . . . . . . . . . . . . . . . . . . 113\\n8.3降低误差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\n8.3.1减少方差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\n8.3.2减少偏差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\n8.3.3偏差-方差权衡 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\\n8.4双下降现象 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\\n8.4.1解释. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\n8.5超参数的选择 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119\\n8.6总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\\n8.7笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 5}, page_content='8.7笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\\n8.8习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\n9正则化 127\\n9.1显式正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\n9.2概率解释 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\\n9.3 L2正则化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\\n9.4隐式正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\n9.4.1梯度下降中的隐式正则化 . . . . . . . . . . . . . . . . . . . . . . . 130\\n9.4.2在随机梯度下降中的隐式正则化 . . . . . . . . . . . . . . . . . . . 131\\n9.5提升性能的启发式方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\n9.5.1早停. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\n9.5.2集成学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\\n9.5.3 Dropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 6}, page_content='目录 vii\\n9.5.4应用噪声 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135\\n9.5.5贝叶斯推理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\\n9.5.6迁移学习与多任务学习 . . . . . . . . . . . . . . . . . . . . . . . . 137\\n9.5.7自监督学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\\n9.5.8数据增强 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139\\n9.6总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139\\n9.7笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\\n9.8习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145\\n10卷积网络 147\\n10.1不变性与等变性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\n10.2适用于一维输入的卷积网络 . . . . . . . . . . . . . . . . . . . . . . . . . . 148\\n10.2.1一维卷积操作 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148\\n10.2.2填充. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 6}, page_content='10.2.2填充. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\\n10.2.3步长、核大小与扩张 . . . . . . . . . . . . . . . . . . . . . . . . . . 149\\n10.2.4卷积层. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\\n10.2.5 Channels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\\n10.2.6卷积网络与感受野 . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\\n10.2.7示例：MNIST-1D . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\\n10.3适用于二维输入的卷积网络 . . . . . . . . . . . . . . . . . . . . . . . . . . 153\\n10.4下采样与上采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156\\n10.4.1下采样. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156\\n10.4.2上采样. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156\\n10.4.3改变通道数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157\\n10.5应用. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 6}, page_content='10.5应用. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157\\n10.5.1图像分类 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158\\n10.5.2对象检测 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160\\n10.5.3语义分割 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160\\n10.6总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162\\n10.7笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162\\n10.8习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\n11残差网络 169\\n11.1顺序处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169\\n11.1.1顺序处理方式的限制 . . . . . . . . . . . . . . . . . . . . . . . . . . 170\\n11.2残差连接与残差块 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\\n11.2.1残差块中的操作顺序 . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\n11.2.2采用残差连接的更深网络 . . . . . . . . . . . . . . . . . . . . . . . 174'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 7}, page_content='viii 目录\\n11.3残差网络的梯度爆炸问题 . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\n11.4批量归一化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\n11.4.1批量归一化的代价与好处 . . . . . . . . . . . . . . . . . . . . . . . 176\\n11.5常用残差架构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176\\n11.5.1 ResNet （残差网络） . . . . . . . . . . . . . . . . . . . . . . . . . . 176\\n11.5.2 DenseNet （密集网络） . . . . . . . . . . . . . . . . . . . . . . . . 178\\n11.5.3 U-Net 和沙漏型网络 . . . . . . . . . . . . . . . . . . . . . . . . . . 178\\n11.6残差连接网络性能优异的原因是什么？ . . . . . . . . . . . . . . . . . . . . 179\\n11.7总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180\\n11.8笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182\\n11.9习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185\\n12 T ransformers 187\\n12.1文本数据处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 7}, page_content='12.1文本数据处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187\\n12.2点积自注意力 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\n12.2.1值的计算与加权 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\n12.2.2注意力权重的计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\\n12.2.3自注意力机制概述 . . . . . . . . . . . . . . . . . . . . . . . . . . . 191\\n12.2.4矩阵表示法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191\\n12.3点乘自注意力的扩展 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191\\n12.3.1位置编码 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192\\n12.3.2缩放点积自注意力 . . . . . . . . . . . . . . . . . . . . . . . . . . . 192\\n12.3.3多头自注意力 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193\\n12.4 Transformer 层. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\\n12.5面向自然语言处理的 Transformers . . . . . . . . . . . . . . . . . . . . . . 195'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 7}, page_content='12.5面向自然语言处理的 Transformers . . . . . . . . . . . . . . . . . . . . . . 195\\n12.5.1分词. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\\n12.5.2嵌入. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\\n12.5.3 Transformer 模型. . . . . . . . . . . . . . . . . . . . . . . . . . . . 197\\n12.6 Encoder 模型案例 : BERT . . . . . . . . . . . . . . . . . . . . . . . . . . . 197\\n12.6.1预训练. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197\\n12.6.2微调. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\n12.7 Decoder 模型案例 : GPT3 . . . . . . . . . . . . . . . . . . . . . . . . . . . 199\\n12.7.1语言模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199\\n12.7.2遮掩自注意力 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200\\n12.7.3利用解码器生成文本 . . . . . . . . . . . . . . . . . . . . . . . . . . 200\\n12.7.4 GPT-3 与少样本学习 . . . . . . . . . . . . . . . . . . . . . . . . . 201'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 7}, page_content='12.7.4 GPT-3 与少样本学习 . . . . . . . . . . . . . . . . . . . . . . . . . 201\\n12.8编码器-解码器模型案例：机器翻译 . . . . . . . . . . . . . . . . . . . . . . 202\\n12.9面向长序列的 Transformers . . . . . . . . . . . . . . . . . . . . . . . . . . 204'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 8}, page_content='目录 ix\\n12.10面向图像的 Transformers . . . . . . . . . . . . . . . . . . . . . . . . . . . 204\\n12.10.1ImageGPT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\\n12.10.2视觉Transformer (ViT) . . . . . . . . . . . . . . . . . . . . . . . . 205\\n12.10.3多尺度视觉 Transformers . . . . . . . . . . . . . . . . . . . . . . . 206\\n12.11总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207\\n12.12笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208\\n12.13习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 214\\n13图神经网络 215\\n13.1什么是图 ?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215\\n13.1.1图的类型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\n13.2图的表示方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\n13.2.1邻接矩阵的特性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217\\n13.2.2节点索引的置换 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 8}, page_content='13.2.2节点索引的置换 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218\\n13.3图神经网络、应用任务及损失函数 . . . . . . . . . . . . . . . . . . . . . . 219\\n13.3.1任务与损失函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219\\n13.4图卷积网络 (GCN). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220\\n13.4.1等变性与不变性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\\n13.4.2参数共享 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\\n13.4.3 GCN 层的实例 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223\\n13.5案例分析：图形分类 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\n13.5.1批量训练方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\n13.6归纳式vs.转导式模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\n13.7案例分析：节点分类 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225\\n13.7.1选择批次 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226\\n13.8图卷积网络的构建层 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 8}, page_content='13.8图卷积网络的构建层 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227\\n13.8.1结合当前节点与累积邻居 . . . . . . . . . . . . . . . . . . . . . . . 228\\n13.8.2残差连接 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229\\n13.8.3 Mean aggregation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229\\n13.8.4 Kipf 归一化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229\\n13.8.5最大池化聚合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229\\n13.8.6通过注意力机制聚合 . . . . . . . . . . . . . . . . . . . . . . . . . . 230\\n13.9边图. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230\\n13.10总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\n13.11笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\n13.12习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 9}, page_content='x 目录\\n14无监督学习 239\\n14.1无监督学习模型的分类 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239\\n14.2如何定义一个优秀的生成模型？ . . . . . . . . . . . . . . . . . . . . . . . 241\\n14.3性能量化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\\n14.4总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243\\n14.5笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\\n15生成对抗网络 245\\n15.1将鉴别作为信号 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\\n15.1.1 GAN 损失函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246\\n15.1.2训练GANs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247\\n15.1.3深度卷积生成式对抗网络（ DCGAN）. . . . . . . . . . . . . . . . 248\\n15.1.4训练GAN的困难 . . . . . . . . . . . . . . . . . . . . . . . . . . . 248\\n15.2提高稳定性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249\\n15.2.1 GAN 损失函数的分析 . . . . . . . . . . . . . . . . . . . . . . . . . 250'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 9}, page_content='15.2.1 GAN 损失函数的分析 . . . . . . . . . . . . . . . . . . . . . . . . . 250\\n15.2.2梯度消失 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251\\n15.2.3 Wasserstein 距离. . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\\n15.2.4离散分布的 Wasserstein 距离. . . . . . . . . . . . . . . . . . . . . 252\\n15.2.5连续分布的 Wasserstein 距离. . . . . . . . . . . . . . . . . . . . . 253\\n15.2.6 Wasserstein GAN 损失函数 . . . . . . . . . . . . . . . . . . . . . . 254\\n15.3渐进式增长、小批量判别和截断 . . . . . . . . . . . . . . . . . . . . . . . 255\\n15.4条件生成 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255\\n15.4.1条件GAN. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255\\n15.4.2辅助分类器 GAN. . . . . . . . . . . . . . . . . . . . . . . . . . . . 256\\n15.4.3 InfoGAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256\\n15.5图像翻译 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 9}, page_content='15.5图像翻译 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258\\n15.5.1 Pix2Pix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\\n15.5.2对抗性损失 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\\n15.5.3 CycleGAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\\n15.6 StyleGAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\\n15.7总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263\\n15.8笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264\\n16标准化流 269\\n16.1一维示例 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269\\n16.1.1测量概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\n16.1.2正向与逆向映射 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\n16.1.3学习. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 10}, page_content='目录 xi\\n16.2通用案例 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271\\n16.2.1深度神经网络的正向映射 . . . . . . . . . . . . . . . . . . . . . . . 272\\n16.2.2网络层设计要求 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273\\n16.3可逆网络层 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273\\n16.3.1线性流. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273\\n16.3.2逐元素流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\\n16.3.3耦合流. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275\\n16.3.4自回归流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275\\n16.3.5逆自回归流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277\\n16.3.6残差流： iRevNet . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277\\n16.3.7残差流与收缩映射： iResNet . . . . . . . . . . . . . . . . . . . . . 278\\n16.4多尺度流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 10}, page_content='16.4多尺度流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\n16.5应用. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\n16.5.1建模密度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\n16.5.2图像合成 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281\\n16.5.3近似其他密度模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . 281\\n16.6总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283\\n16.7笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283\\n16.8习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\n17变分自编码器 289\\n17.1潜在变量模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\n17.1.1示例：高斯混合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\\n17.2非线性潜在变量模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\\n17.2.1生成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 10}, page_content='17.2.1生成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291\\n17.3训练. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292\\n17.3.1证据下界 (ELBO) . . . . . . . . . . . . . . . . . . . . . . . . . . . 292\\n17.3.2詹森不等式 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292\\n17.3.3导出下界 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293\\n17.4 ELBO 特性. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 294\\n17.4.1界限紧密性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 295\\n17.4.2 ELBO 为重构损失与先验的 KL距离之差 . . . . . . . . . . . . . . 296\\n17.5变分近似 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296\\n17.6变分自编码器（ VAE）. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297\\n17.6.1 VAE 算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298\\n17.7重参数化技巧 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 10}, page_content='17.7重参数化技巧 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298\\n17.8应用. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299\\n17.8.1样本概率的近似 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 11}, page_content='xii 目录\\n17.8.2生成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301\\n17.8.3重新合成 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302\\n17.8.4解耦. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302\\n17.9总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303\\n17.10笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304\\n17.11习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\\n18扩散模型 309\\n18.1概览. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309\\n18.2编码器（前向过程） . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310\\n18.2.1 Diffusion kernel q(zt|x). . . . . . . . . . . . . . . . . . . . . . . . 311\\n18.2.2边缘分布q(zt). . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312\\n18.2.3条件分布q(zt−1|zt). . . . . . . . . . . . . . . . . . . . . . . . . . 313'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 11}, page_content='18.2.3条件分布q(zt−1|zt). . . . . . . . . . . . . . . . . . . . . . . . . . 313\\n18.2.4条件扩散分布 q(zt−1|zt,x). . . . . . . . . . . . . . . . . . . . . . 313\\n18.3解码器模型（反向过程） . . . . . . . . . . . . . . . . . . . . . . . . . . . 315\\n18.4训练. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315\\n18.4.1证据下界（ ELBO）. . . . . . . . . . . . . . . . . . . . . . . . . . 316\\n18.4.2简化ELBO. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\n18.4.3分析ELBO. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 318\\n18.4.4扩散损失函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 318\\n18.4.5训练过程 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 318\\n18.5损失函数的重新参数化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319\\n18.5.1目标的重参数化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 320\\n18.5.2网络的重参数化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 11}, page_content='18.5.2网络的重参数化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321\\n18.6实现. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\\n18.6.1应用于图像 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\\n18.6.2提高生成速度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323\\n18.6.3条件生成 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323\\n18.6.4提高生成质量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324\\n18.7总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 326\\n18.8笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 326\\n18.9习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329\\n19深度强化学习 331\\n19.1马尔可夫决策过程、回报与策略 . . . . . . . . . . . . . . . . . . . . . . . 331\\n19.1.1马尔科夫过程 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332\\n19.1.2马尔可夫奖励过程 . . . . . . . . . . . . . . . . . . . . . . . . . . . 332'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 11}, page_content='19.1.2马尔可夫奖励过程 . . . . . . . . . . . . . . . . . . . . . . . . . . . 332\\n19.1.3马尔科夫决策过程 . . . . . . . . . . . . . . . . . . . . . . . . . . . 333'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 12}, page_content='目录 xiii\\n19.1.4部分可观测马尔可夫决策过程 . . . . . . . . . . . . . . . . . . . . . 333\\n19.1.5策略. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 334\\n19.2预期回报 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335\\n19.2.1状态与动作价值 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335\\n19.2.2最优策略 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 336\\n19.2.3贝尔曼方程 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337\\n19.3表格式强化学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338\\n19.3.1动态规划 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 338\\n19.3.2蒙特卡洛方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 339\\n19.3.3时序差分学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 340\\n19.4拟合Q-learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341\\n19.4.1深度Q-网络在ATARI游戏中的应用 . . . . . . . . . . . . . . . . . 342'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 12}, page_content='19.4.1深度Q-网络在ATARI游戏中的应用 . . . . . . . . . . . . . . . . . 342\\n19.4.2双Q-学习与双深度 Q-网络. . . . . . . . . . . . . . . . . . . . . . 343\\n19.5策略梯度方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344\\n19.5.1梯度更新推导 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344\\n19.5.2 REINFORCE 算法. . . . . . . . . . . . . . . . . . . . . . . . . . . 346\\n19.5.3 Baselines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\n19.5.4依赖当前状态的 baselines . . . . . . . . . . . . . . . . . . . . . . . 348\\n19.6 Actor-Critic 方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 348\\n19.7离线强化学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\n19.8总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350\\n19.9笔记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350\\n19.10习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 354\\n20为什么深度学习有效？ 357'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 12}, page_content='20为什么深度学习有效？ 357\\n20.1深度学习的质疑 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 357\\n20.1.1训练. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 357\\n20.1.2泛化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 358\\n20.1.3深度学习的不合理效果 . . . . . . . . . . . . . . . . . . . . . . . . 358\\n20.2影响拟合性能的因素 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 358\\n20.2.1数据集. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 358\\n20.2.2正则化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359\\n20.2.3随机训练算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359\\n20.2.4过参数化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n20.2.5激活函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\n20.2.6初始化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\n20.2.7网络深度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 362'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 12}, page_content='20.2.7网络深度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 362\\n20.3损失函数的属性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 362'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 13}, page_content='xiv 目录\\n20.3.1多个全局最小值 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 363\\n20.3.2到达最小值的路径 . . . . . . . . . . . . . . . . . . . . . . . . . . . 363\\n20.3.3极小值间的关联 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 364\\n20.3.4损失表面的曲率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 364\\n20.4决定泛化能力的因素 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365\\n20.4.1训练算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366\\n20.4.2极小点的平坦性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366\\n20.4.3架构. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 368\\n20.4.4权重的范数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 368\\n20.4.5过参数化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 369\\n20.4.6超出数据流形 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 369\\n20.5真的需要这么多参数吗？ . . . . . . . . . . . . . . . . . . . . . . . . . . . 370'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 13}, page_content='20.5真的需要这么多参数吗？ . . . . . . . . . . . . . . . . . . . . . . . . . . . 370\\n20.5.1剪枝. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 371\\n20.5.2知识蒸馏 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 371\\n20.5.3讨论. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 372\\n20.6网络必须深吗？ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 372\\n20.6.1建模函数的复杂度 . . . . . . . . . . . . . . . . . . . . . . . . . . . 373\\n20.6.2训练的可行性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373\\n20.6.3归纳偏见 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373\\n20.7 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374\\n20.8习题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374\\n21深度学习与伦理 375\\n21.1价值观对齐 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 375\\n21.1.1偏见和不公正 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 13}, page_content='21.1.1偏见和不公正 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377\\n21.1.2人工道德代理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378\\n21.1.3透明与不透明 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 379\\n21.1.4可解释性与可解读性 . . . . . . . . . . . . . . . . . . . . . . . . . . 379\\n21.2故意误用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 380\\n21.2.1人脸识别与分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 380\\n21.2.2军事化与政治干涉 . . . . . . . . . . . . . . . . . . . . . . . . . . . 381\\n21.2.3欺诈. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 381\\n21.2.4数据隐私 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 381\\n21.3其它社会、伦理及专业议题 . . . . . . . . . . . . . . . . . . . . . . . . . . 382\\n21.3.1知识产权 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382\\n21.3.2自动化偏见与道德技能退化 . . . . . . . . . . . . . . . . . . . . . . 382\\n21.3.3环境影响 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 13}, page_content='21.3.3环境影响 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382\\n21.3.4就业与社会 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 14}, page_content='目录 xv\\n21.3.5权力集中 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383\\n21.4案例研究 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383\\n21.5科学的价值中立理想 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 384\\n21.6将负责任的 AI研究视为集体行动的问题 . . . . . . . . . . . . . . . . . . . 385\\n21.6.1科学交流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385\\n21.6.2多样性和异质性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385\\n21.7前行之道 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 386\\n21.8总结. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 387'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 15}, page_content='xvi 目录'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 16}, page_content='Chapter 1\\n介绍\\n人工智能（ AI）旨在打造模仿智能行为的系统。它覆盖了众多方法，涵盖了基于逻\\n辑、搜索和概率推理的技术。机器学习是 AI的一个分支，它通过对观测数据进行数学\\n模型拟合来学习决策制定。这个领域近年来迅猛发展，现在几乎（虽不完全准确）与 AI\\n同义。\\n深度神经网络是一类机器学习模型，将其应用到数据上的过程称为深度学习。目前，\\n深度网络是最强大和最实用的机器学习模型之一，常见于日常生活中。我们常常用自\\n然语言处理（ Natural Language Processing ）算法翻译文本、用计算机视觉（ Computer\\nVision）系统搜索特定对象的图片，或通过语音识别（ Speech Recognition ）界面与数字\\n助理交谈，这些都是深度学习的实际应用。\\n正如本书标题所示，它旨在帮助初学者理解深度学习的基本原理。本书既非理论性\\n质太重（没有证明） ，也不过分侧重实践（几乎不包含代码） 。其目的在于阐释深度学习\\n的核心思想；读者在阅读完这本书后，将能够在没有现成成功方案的新情境中应用深度\\n学习。机器学习方法大体上分为三大类：监督学习（ Supervised Learning ） 、无监督学习\\n（Unsupervised Learning ）和强化学习（ Reinforcement Learning ） 。目前，这三大类的前\\n沿方法均依赖于深度学习（见图 1.1） 。本书的开篇章节从高层次上介绍了这三大类，并\\n且这种分类也在书的结构中得到了体现。无论我们是否乐见，深度学习都将改变我们的\\n世界，而这种改变并非全都是积极的。因此，本章还简要介绍了人工智能伦理的基本概\\n念。最后，我们提出了一些建议，帮助读者更好地利用这本书。\\n1.1监督学习\\n监督学习模型建立了一种从输入数据到输出预测的关系。在后续几节中，我们会详\\n细探讨输入、输出、模型本身，以及“训练”模型所指的含义。\\n1'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 17}, page_content='2 CHAPTER 1. 介绍\\n图 1.1:机器学习是人工智能的一个分支，它专注于将数学模型应用于观测数据。它主要分为三\\n个类别：监督学习、非监督学习和强化学习。深度神经网络在这三个领域中均发挥着重要作用。\\n1.1.1回归和分类问题\\n图1.2展示了几个回归和分类问题的例子。在每个例子中，都有一个与现实世界相\\n关的输入（如一个句子、一段声音文件、一幅图片等） ，这些输入被转换成数字向量。这\\n个向量就是模型的输入。模型把这个输入映射到一个输出向量，随后这个输出向量被再\\n次转换，变成一个具有现实意义的预测。目前，我们主要关注输入和输出，并把模型当\\n作一个黑盒子，它接受一个数字向量并输出另一个数字向量。\\n图1.2a中的模型基于如房屋的平方米数和卧室数量等输入特征来预测房价。这是\\n一个回归问题，因为模型返回的是一个连续数值（而非某个类别） 。而图 1.2b中的模型\\n则以分子的化学结构为输入，预测其熔点和沸点。由于预测了多个数值，这是一个多变\\n量回归问题。\\n图1.2c中的模型接收包含餐厅评论的文本字符串作为输入，并预测评论是正面的\\n还是负面的。这是一个二元分类问题，因为模型试图将输入分配到两个不同的类别中。\\n输出向量包含输入属于每个类别的概率。图 1.2d和1.2e则展示了多类别分类问题。在\\n这里，模型将输入分配到多于两个的类别中。第一个例子中，输入是一个音频文件，模\\n型预测它包含的音乐类型。第二个例子中，输入是一幅图片，模型预测图片中包含的对\\n象。在这些例子中，模型均返回一个包含各类别概率的大小为 N的向量。\\n1.1.2输入\\n图1.2中的输入数据类型各异。在房价预测例子中，输入是一个固定长度的向量，\\n包含了描述房产特征的值。这是一种表格数据，它没有内在结构；如果我们改变输入值\\n的顺序再构建一个新模型，预期模型的预测结果不会改变。\\n另一方面，在餐厅评论的例子中，输入是一段文本。这可能根据评论中的单词数而\\n长度不同，且输入顺序很重要；例如， “我的妻子吃了鸡肉”与“鸡肉吃了我的妻子”意'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 18}, page_content='1.1.监督学习 3\\n图 1.2: a）这个回归模型使用描述房产特征的数字向量来预测其价格。 b）这个多变量回归模型\\n以化学分子的结构为输入， 预测其熔点和沸点。 c）这个二元分类模型接收餐厅评论， 并将其划分\\n为正面或负面。 d）这个多类别分类问题将一段音频片段归类为 N种音乐类型中的一种。 e）第\\n二个多类别分类问题中，模型根据图片可能包含的 N种物体之一来分类图片。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 19}, page_content='4 CHAPTER 1. 介绍\\n图 1.3:机器学习模型。该模型表示一系列关系，将输入（儿童年龄）与输出（儿童身高）联系\\n起来。通过训练数据（橙色点，包括输入 /输出对）来选定具体的关系。在训练模型过程中，我\\n们寻找能够很好描述数据的关系。这里，经过训练的模型是青色曲线，可以用来计算任何年龄的\\n儿童身高。\\n义截然不同。在传递给模型之前，文本必须被编码为数字形式。这里，我们使用一个包\\n含10,000个词的固定词汇表，并将单词索引简单拼接起来。\\n在音乐分类的例子中，输入向量可能是固定大小的（比如 10秒音频片段） ，但其维\\n度非常高。数字音频通常以 44.1 kHz 采样并以 16位整数表示，因此一个 10秒的音频\\n片段包含 441,000个整数。显然，监督学习模型必须能够处理大量输入。图像分类例子\\n中的输入（由每个像素的 RGB值串联起来的）也非常庞大。而且，它的结构本质上是\\n二维的；即使在输入向量中不相邻，上下相邻的两个像素也紧密相关。\\n最后，考虑预测分子熔点和沸点的模型的输入。一个分子可能包含不同数量且连接\\n方式各异的原子。在这种情况下，模型需要同时考虑分子的几何结构和组成原子。\\n1.1.3机器学习模型\\n到目前为止，我们把机器学习模型当作一个黑盒子，它接受输入向量并返回输出向\\n量。但这个黑盒子里面究竟是什么呢？考虑一个根据孩子年龄来预测身高的模型（见图\\n1.3） 。机器学习模型其实是一个数学方程，描述了平均身高如何随年龄变化（图 1.3中\\n的青色曲线） 。当我们把年龄输入这个方程，它就会返回相应的身高。例如，如果年龄是\\n10岁，我们预测身高为 139厘米。\\n更精确地说，这个模型代表了一系列方程，用于将输入映射到输出（即不同的青色\\n曲线） 。特定的方程（曲线）是根据训练数据（输入和输出对的示例）来选择的。在图\\n1.3中，这些对由橙色点表示，我们可以看到模型（青色线条）合理地描述了这些数据。\\n当我们谈到训练或拟合一个模型时，我们的意思是在可能的方程（青色曲线）中寻找一\\n个最能准确描述训练数据的关系。\\n因此，图 1.2中的模型需要标记好的输入 /输出对来进行训练。例如，音乐分类模型\\n需要大量音频片段，这些片段已由人类专家确定了各自的音乐类型。这些输入 /输出对\\n在训练过程中起到了教师或监督者的作用，这就是“监督学习”这个术语的由来。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 20}, page_content='1.2.无监督学习 5\\n1.1.4深度神经网络\\n这本书着重讨论深度神经网络，这是一种特别有效的机器学习模型。它们是方程，\\n能够代表输入和输出之间极其广泛的关系，并且在这些关系中寻找描述训练数据的关系\\n特别容易。\\n深度神经网络可以处理非常大、变化多端的输入，并且能够包含各种内部结构。它\\n们能输出单个实数（回归） 、多个数值（多变量回归）或两个或更多类别的概率（分别对\\n应二元和多类别分类） 。正如我们在下一节中将看到的，它们的输出也可能非常大、变\\n长，并且包含内部结构。想象具有这些特性的方程可能很困难，读者应努力暂时搁置怀\\n疑。\\n1.1.5结构化输出\\n图1.4a展示了一个用于语义分割的多变量二元分类模型。在这里，输入图像的每个\\n像素都被分配一个二元标签，指示它是属于牛还是背景。图 1.4b展示了一个多变量回\\n归模型，输入是街景图像，输出是每个像素的深度。在这两种情况下，输出都是高维且\\n有结构的。然而，这种结构与输入紧密相关，可以被利用；如果一个像素被标记为“牛” ，\\n那么具有相似 RGB值的邻近像素可能有相同的标签。\\n图1.4c-e描述了三个输出具有与输入不太紧密相关的复杂结构的模型。图 1.4c展\\n示了一个模型，输入是音频文件，输出是文件中的转录词。图 1.4d是一个翻译模型，输\\n入是英文文本，输出是法文翻译。图 1.4e描述了一个极具挑战性的任务，输入是描述性\\n文本，模型需要生成与这个描述匹配的图像。\\n原则上，这三个后续任务可以在标准监督学习框架下解决，但它们更为困难，原因\\n有二。首先，输出可能确实模糊不清；从英语到法语有多种有效翻译，任何描述都可能\\n对应多种图像。其次，输出包含大量结构；并非所有单词串都能构成有效的英语和法语\\n句子，也不是所有 RGB值的组合都能构成合理的图像。除了学习映射，我们还必须遵\\n循输出的“语法” 。\\n幸运的是，这种“语法”可以在不需要输出标签的情况下学习。例如，我们可以通\\n过学习大量文本数据的统计信息来学习构建有效的英语句子。这为本书接下来讨论的无\\n监督学习模型部分提供了一个联系。\\n1.2无监督学习\\n从没有对应输出标签的输入数据中构建模型被称为无监督学习；缺乏输出标签意味\\n着不存在“监督” 。无监督学习的目标不是学习输入到输出的映射，而是描述或理解数\\n据的结构。就像监督学习一样，数据可能具有非常不同的特点；它可能是离散或连续的，'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 20}, page_content='着不存在“监督” 。无监督学习的目标不是学习输入到输出的映射，而是描述或理解数\\n据的结构。就像监督学习一样，数据可能具有非常不同的特点；它可能是离散或连续的，\\n低维或高维的，长度固定或变化的。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 21}, page_content='6 CHAPTER 1. 介绍\\n图 1.4:具有结构化输出的监督学习任务。 a)这个语义分割模型把 RGB图像映射到一个二元图\\n像，用于指示每个像素是属于背景还是牛（改编自 Noh等人， 2015年） 。 b)这个单目深度估计\\n模型将 RGB图像映射到一个输出图像，每个像素代表深度（改编自 Cordts等人， 2016年） 。 c)\\n这个音频转录模型将音频样本映射到音频中所说话语的文字转录。 d)这个翻译模型将英语文本\\n字符串映射到其对应的法语翻译。 e)这个图像合成模型将文字描述映射到一幅图像（示例来自\\nhttps://openai.com/dal l-e-2/ ） 。在每个案例中，输出都具有复杂的内部结构或语法。在某些情\\n况下，与输入相兼容的输出可能有多个。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 22}, page_content='1.2.无监督学习 7\\n图 1.5:图像生成式模型。左图：两幅图像由训练有素的猫图模型生成。这些不是真正的猫，而\\n是概率模型生成的样本。右图：两幅图像由专门训练的建筑图模型生成。改编自 Karras等人\\n(2020b)。\\n图 1.6:文本数据生成式模型合成的短篇故事。该模型描述了一个为每个输出字符串分配概率的\\n概率分布。通过从模型中抽样，可以创造出遵循训练数据（这里是短篇故事）统计特性的字符串，\\n这些字符串之前从未出现过。\\n1.2.1生成式模型\\n本书着重介绍生成式无监督模型，这类模型学习如何合成新的数据实例，使其在统\\n计上与训练数据难以区分。一些生成式模型明确描述了输入数据的概率分布，并通过从\\n这个分布中抽样来生成新实例。其他模型则仅学习生成新实例的机制，而不直接描述其\\n分布。\\n最先进的生成式模型能够合成极为逼真但与训练实例不同的实例。它们在生成图像\\n（见图1.5）和文本（见图 1.6）方面特别成功。这些模型还可以在某些输出预先确定的\\n约束下合成数据（称为条件生成） 。例如，包括图像修复（见图 1.7）和文本补全（见图\\n1.8）在内的应用。事实上，现代文本生成模型非常强大，以至于它们看起来几乎具有智\\n能。给定一段文本后接一个问题，模型通常能通过生成文档最可能的补全来“填补”缺\\n失的答案。然而，实际上，模型只了解语言的统计特性，并不真正理解其答案的含义。\\n图 1.7:图像修复。原始图像（左图）中，男孩被金属缆绳遮挡。不需要的区域（中图）被移除，\\n生成式模型在其余像素保持不变的约束下合成了新图像（右图） 。改编自 Saharia等人 (2022a)。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 23}, page_content='8 CHAPTER 1. 介绍\\n图 1.8:条件性文本合成。给定一段初始文本（第一段） ，文本生成式模型可以通过合成“缺失”\\n的剩余部分来合理地继续这段文字。由 GPT3生成（ Brown等人， 2020） 。\\n图 1.9:人脸的变化。人脸大约包含 42块肌肉，因此可以用大约 42个数字来描述同一个人在\\n相同光照条件下的图像中的大部分变化。一般而言，图像、音乐和文本的数据集可以用相对较少\\n的潜在变量来描述，尽管通常更难将这些变量与特定的物理机制联系起来。图像来自 Dynamic\\nF ACES数据库（ Hol land 等人， 2019） 。\\n1.2.2潜变量\\n一些生成式模型（但不是所有）利用了这样一个观点：数据的维度可以比原始观测\\n变量的数量更小。例如，有效且有意义的英语句子的数量远少于随机组合单词形成的字\\n符串数量。同样，真实世界的图像只占通过随机赋予每个像素 RGB值能创建的图像的\\n一小部分。这是因为图像是由物理过程生成的（见图 1.9） 。\\n这就引出了一个想法，即我们可以使用较少的潜在变量来描述每个数据实例。在这\\n里，深度学习的作用是描述这些潜变量与数据之间的映射关系。这些潜变量通常被设计\\n为具有简单的概率分布。通过从这个分布中抽样并将结果通过深度学习模型传递，我们\\n可以创造新的样本（见图 1.10） 。\\n这些模型为操纵真实数据提供了新的方法。例如，考虑找出支持两个真实实例的潜\\n图 1.10:潜变量。潜变量在许多生成模型中扮演关键角色，这些模型利用深度学习来揭示低维潜\\n变量与观测到的高维数据之间的联系。潜变量按设计拥有简易的概率分布。因此，通过从这些潜\\n变量的简单分布中采样，再利用深度学习模型将采样结果映射到观测数据空间，我们便能创造出\\n新的样本。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 24}, page_content='1.2.无监督学习 9\\n图 1.11:图像插值。图像插值是一种有趣的应用。在每一行的图像中，左右两侧为真实图像，中\\n间三张则是生成模型创造的插值序列。这些生成模型学习到了所有图像均可通过一组潜在变量\\n来生成的原理。通过确定这两张真实图像的潜变量，对它们的值进行插值，然后用这些中间变量\\n生成新图像，我们能创造出既视觉上合理，又融合了两张原始图像特征的中间图像。上排图片改\\n编自 Sauer等人 (2022)，下排图片改编自 Ramesh等人 (2022)。\\n图 1.12:从“时代广场上的滑板泰迪熊”这个标题出发， DALL·E-2（Ramesh等人， 2022）生\\n成了多张图片。\\n变量。我们可以通过在它们的潜在表示之间插值，并将中间位置映射回数据空间，从而\\n在这些实例之间进行插值（见图 1.11） 。\\n1.2.3结合监督学习与无监督学习\\n具有潜变量的生成式模型也可以促进输出具有结构的监督学习模型的发展（见图\\n1.4） 。例如，考虑学习如何预测与描述相对应的图像。我们可以学习文本的潜变量与图\\n像的潜变量之间的关系，而不是直接将文本输入映射到图像上。\\n这种方法有三个优点。首先，由于输入和输出维度较低，我们可能需要更少的文\\n本/图像对来学习这种映射。其次，我们更有可能生成看起来合理的图像；潜变量的任\\n何合理值都应该产生像是一个可信的示例。第三，如果我们在两组潜变量之间的映射或\\n潜变量到图像的映射中引入随机性，那么我们可以生成多个都与描述相匹配的图像（见\\n图1.12） 。\\n1.2.4强化学习\\n机器学习的最后一个领域是强化学习。这个范畴引入了代理（ agent）的概念，代理\\n生活在一个世界中，在每个时间步骤中可以执行特定行动。行动会改变系统的状态，但'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 25}, page_content='10 CHAPTER 1. 介绍\\n图 1.13:在强化学习中使用策略网络是一种创新。通过深度神经网络，我们可以定义从状态（例\\n如棋盘上的位置）到动作（可能的移动）的映射。这种映射即为所谓的“策略” 。\\n这种改变不一定是确定性的。执行行动还可能产生奖励，强化学习的目标是让代理学会\\n选择能够平均获得高奖励的行动。\\n一个复杂点是奖励可能在行动后一段时间才出现，因此把奖励与特定行动关联起来\\n并不直接。这被称为时间性信用分配问题。在学习过程中，代理必须在探索（寻找新的\\n可能性）和利用（使用已知的策略）之间做出平衡；也许代理已经学会了如何获得适度\\n的奖励，它应该继续遵循这个策略（利用现有知识） ，还是尝试不同的行动以寻找改进\\n的机会（探索新的可能性） ？\\n1.2.5两个例子\\n考虑教一个类人机器人如何行走。机器人在特定时间可以执行有限的行动（如移动\\n各种关节） ，这些行动会改变世界的状态（即它的姿态） 。我们可以通过设立障碍赛道上\\n的检查点来奖励机器人。为了到达每个检查点，它必须执行许多行动，但当收到奖励时，\\n很难确定哪些行动对奖励有贡献，哪些是无关紧要的。这就是时间性信用分配问题的一\\n个实例。\\n第二个例子是学习下棋。同样，代理在任何时刻都有一组有效的行动（棋子移动） 。\\n然而，这些行动以非确定性的方式改变系统状态；对于任何行动选择，对手可能以多种\\n不同的方式回应。这里，我们可以根据捕获棋子来设定奖励结构，或者在游戏结束时赢\\n得比赛来获得单一奖励。在后者情况下，时间性信用分配问题非常严重；系统必须学习\\n在众多走法中哪些是成功或失败的关键。\\n探索与利用的权衡在这两个例子中也很明显。机器人可能已经发现，通过侧躺并用\\n一条腿推动可以前进。这种策略虽然能让机器人移动并获得奖励，但比最优解——站立\\n行走——要慢得多。因此，它面临一个选择，是利用已知的策略（沿地面滑行）还是探\\n索其他可能的行动（可能实现更快的移动） 。在下棋例子中也是如此，代理可能学到了\\n一系列合理的开局走法。它应该利用这些知识，还是探索不同的开局序列？\\n深度学习如何融入强化学习框架可能不那么明显。有几种可能的方法，其中一种是\\n使用深度网络构建从观察到的世界状态到行动的映射。这被称为策略网络。在机器人的\\n例子中，策略网络会学习从传感器测量到关节运动的映射。在下棋的例子中，网络将学'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 25}, page_content='使用深度网络构建从观察到的世界状态到行动的映射。这被称为策略网络。在机器人的\\n例子中，策略网络会学习从传感器测量到关节运动的映射。在下棋的例子中，网络将学\\n习从棋盘的当前状态到走法选择的映射（见图 1.13） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 26}, page_content='1.3.伦理 11\\n1.3伦理\\n如果不讨论人工智能的伦理影响就撰写本书，将是不负责任的。这种强大技术将至\\n少在与电力、内燃机、晶体管或互联网相同的程度上改变世界。在医疗保健、设计、娱\\n乐、交通、教育以及几乎所有商业领域的潜在益处都是巨大的。然而，科学家和工程师\\n对其工作成果的影响常常过于乐观，造成的潜在伤害同样巨大。以下几点突出了五个关\\n注点。\\n偏见与公平性 ：如果我们训练一个系统基于历史数据来预测个人的薪酬水平，那么\\n这个系统将重现历史偏见；例如，它可能会预测女性应获得比男性更低的薪酬。已有几\\n个此类案例成为国际新闻：一个用于超分辨率人脸图像的 AI系统使非白人看起来更白；\\n一个用于生成图像的系统在被要求合成律师图片时只产生了男性的图片。不慎使用 AI\\n进行算法决策可能会加剧现有偏见。有关更多讨论，请参阅 Binns（2018） 。\\n解释性：深度学习系统做出决策，但我们通常不知道其基于何种信息或如何做出\\n的。它们可能包含数十亿个参数，我们无法仅通过检查来理解它们的工作原理。这导致\\n了可解释 AI的子领域的形成。一个中等成功的领域是产生局部解释；我们无法解释整\\n个系统，但可以提供为何做出特定决策的可解释描述。然而，目前尚不清楚是否有可能\\n构建对其用户甚至其创建者完全透明的复杂决策系统。更多信息请参见 Grennan 等人\\n（2022） 。\\n武器化 AI：所有重要技术都被直接或间接地用于战争。可悲的是，暴力冲突似乎\\n是人类行为的不可避免特征。 AI可能是有史以来构建的最强大的技术，并且无疑会在\\n军事背景中得到广泛部署。事实上，这已经在发生（参见 Heikkilä，2022） 。\\n集中权力 ：世界上最强大的公司之所以大力投资人工智能，并非出于改善人类命运\\n的善意兴趣。他们意识到这些技术将使他们获得巨大利润。与任何先进技术一样，深度\\n学习可能会使权力集中在掌握它的少数组织手中。将目前由人类完成的工作自动化，将\\n改变经济环境，对薪资较低、技能较少的工人的生计产生不成比例的影响。乐观主义者\\n认为，工业革命期间也发生了类似的变革，导致工作时间缩短。但事实是，我们不知道\\nAI的大规模应用将对社会产生何种影响（参见 David，2015） 。\\n存在风险 ：人类面临的主要存在风险都来自技术。气候变化是由工业化推动的。核'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 26}, page_content='AI的大规模应用将对社会产生何种影响（参见 David，2015） 。\\n存在风险 ：人类面临的主要存在风险都来自技术。气候变化是由工业化推动的。核\\n武器源于物理学研究。由于交通、农业和建筑的创新，使得人口更大、更密集、更相互连\\n接，疫情因此更易发生且传播更快。人工智能带来新的存在风险。我们应该非常谨慎地\\n构建比人类更有能力和可扩展性的系统。在最乐观的情况下，它会将巨大的权力集中在\\n少数拥有者手中。在最悲观的情况下，我们可能无法控制它，甚至无法理解其动机（参\\n见Tegmark ，2018） 。\\n这份列表远非完整。 AI还可能助长监控、虚假信息、隐私侵犯、欺诈和金融市场操\\n纵的现象，而且培训 AI系统所需的能源也会对气候变化产生影响。此外，这些担忧并\\n非无的放矢； AI的伦理问题已有许多实例（参见 Dao，2021年的部分列表） 。互联网的\\n近期历史展示了新技术可能以意想不到的方式造成伤害。 80年代和90年代初的在线社'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 27}, page_content='12 CHAPTER 1. 介绍\\n区几乎无法预见假新闻、垃圾邮件、网络骚扰、欺诈、网络欺凌、极端单身文化、政治\\n操纵、个人信息泄露、网络激进化和网络报复色情的泛滥。\\n研究或学习（或撰写关于） AI的每个人都应思考科学家对其技术使用的责任程度。\\n我们应该认识到，资本主义是推动 AI发展的主要动力，法律进步和社会利益的实施可\\n能会大大落后。我们应反思作为科学家和工程师，是否有可能控制这个领域的进展，以\\n减少潜在的伤害。我们还应考虑愿意为哪种组织工作。他们在减少 AI潜在危害方面的\\n承诺有多认真？他们是否只是为了减少声誉风险而进行“伦理洗白” ，还是真正实施机\\n制来停止伦理上可疑的项目？\\n鼓励所有读者进一步探索这些问题。在线课程\\nhttps://ethics-of-ai.mooc.fi/ 是一个有用的入门资源。如果您是使用本书进行教\\n学的教授，建议您与学生讨论这些问题。如果您是在未进行此类讨论的课程中学习的学\\n生，请敦促您的教授实现这一点。如果您在企业环境中部署或研究 AI，建议您审视雇主\\n的价值观，并帮助改变它们（或离开） ，如果它们不尽人意。\\n1.4本书结构\\n本书的结构遵循本导言的框架。第 2至9章详细介绍监督学习流程。我们描述了浅\\n层和深层神经网络，并讨论了如何训练它们、如何衡量和提高它们的性能。第 10至13\\n章讲述了深度神经网络的常见架构变化，包括卷积网络、残差连接和变压器，这些架构\\n在监督学习、无监督学习和强化学习中都有应用。\\n第14至18章聚焦通过深度神经网络进行的无监督学习。我们专门为四种现代深度\\n生成模型各写了一章：生成对抗网络、变分自编码器、规范化流和扩散模型。第 19章\\n简要介绍深度强化学习。这个主题本可以轻易成为一本书的核心，因此本书的处理相对\\n浅显。然而，这一部分旨在为不熟悉这一领域的读者提供一个良好的起点。\\n尽管本书标题为“深度学习” ，但深度学习的某些方面仍然缺乏充分理解。第 20章\\n提出了一些基础问题：为什么深度网络易于训练？为什么它们泛化能力如此强？为什么\\n需要如此多的参数？它们是否需要深度？在此过程中，我们探讨了一些意外现象，如损\\n失函数的结构、双重下降、理解和彩票。书籍以第 21章结尾，讨论伦理和深度学习。\\n1.5其他书籍\\n这本书是自成体系的， 但主要聚焦于深度学习领域。 它旨在成为 《深度学习》 （ Good-'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 27}, page_content='失函数的结构、双重下降、理解和彩票。书籍以第 21章结尾，讨论伦理和深度学习。\\n1.5其他书籍\\n这本书是自成体系的， 但主要聚焦于深度学习领域。 它旨在成为 《深度学习》 （ Good-\\nfellow等人，2016年）的精神续作，后者是一本极佳的资源，但没有涵盖近期的进展。\\n对于更广泛的机器学习领域，最新且百科全书式的资源是《概率机器学习》 （ Murphy，\\n2022年、2023年） 。然而， 《模式识别与机器学习》 （ Bishop，2006年）仍是一本优秀且\\n相关的书籍。\\n如果你喜欢本书，那么我之前的作品《计算机视觉：模型、学习与推理》 （ Prince，'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 28}, page_content='1.6.如何阅读本书 13\\n2012年）也值得一读。尽管部分内容已显陈旧，但它包含了对概率的全面介绍，包括\\n贝叶斯方法，以及潜变量模型、计算机视觉的几何学、高斯过程和图形模型的良好初步\\n覆盖。它使用与本书相同的符号，并可以在网上找到。关于图形模型的详细处理可以在\\n《概率图形模型：原理与技术》 （ Koller & Friedman ，2009年）中找到，而高斯过程则由\\n《机器学习中的高斯过程》 （ Williams & Rasmussen ，2006年）涵盖。\\n对于背景数学，可以参考《机器学习的数学》 （ Deisenroth 等人，2020年） 。更注重\\n编程的方法可以参考《深入深度学习》 （ Zhang等人，2023年） 。计算机视觉最佳概述是\\nSzeliski（2022年） ，还有即将出版的《计算机视觉基础》 （ Torralba 等人，2024年） 。学\\n习图神经网络的好起点是《图表示学习》 （ Hamilton ，2020年） 。关于强化学习的权威著\\n作是《强化学习导论》 （ Sutton & Barto ，2018年） 。一个很好的入门资源是《深度强化\\n学习基础》 （ Graesser & Keng ，2019年） 。\\n1.6如何阅读本书\\n本书的大多数剩余章节包含主要正文、注释部分和一组问题。主要正文旨在自成体\\n系，可在不参考章节其他部分的情况下阅读。尽可能地，背景数学被纳入正文中。但对\\n于那些可能会分散主要论点注意力的更大主题，背景材料被放在附录中，并在页边提供\\n参考。本书中的大多数符号是标准的。但一些约定使用得不太广泛，鼓励读者在继续之\\n前查阅附录 A。\\n正文包括许多深度学习模型和结果的新颖插图和可视化。我努力提供现有观点的新\\n解释，而不仅仅是整理他人的工作。深度学习是一个新领域，有时现象理解不足。我试\\n图明确指出在哪些情况下是这样，以及何时我的解释应该谨慎对待。\\n只有在描述结果的章节主体中才包含参考文献。相反，它们可以在章节末尾的注释\\n部分找到。我在主文中通常不尊重历史先例；如果当前技术的祖先已不再有用，我将不\\n会提及它。然而，该领域的历史发展在注释部分有所描述，并希望公平地分配了功劳。\\n注释被组织成段落，并提供了进一步阅读的指引。它们应该帮助读者在子领域内定位自\\n己，并理解它与机器学习的其他部分的关系。注释部分不像正文那样自成体系。根据您'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 28}, page_content='注释被组织成段落，并提供了进一步阅读的指引。它们应该帮助读者在子领域内定位自\\n己，并理解它与机器学习的其他部分的关系。注释部分不像正文那样自成体系。根据您\\n的背景知识和兴趣水平，您可能会觉得这些部分更有用或更没用。\\n每章都有一些相关的问题。它们在主文的边栏中被引用，应在相应的点尝试解答。\\n正如乔治·波利亚所指出的， “你看，数学不是一项观赏运动。 ”他是正确的，我强烈建\\n议你在阅读时尝试解决问题。在某些情况下，它们提供了将帮助您理解正文的洞察。在\\n相关网站上提供答案的问题用星号标记。此外，帮助您理解本书中观点的 Python笔记\\n本也可通过网站获得，并在正文的边栏中引用。事实上，如果您感到生疏，现在可能值\\n得通读一下有关背景数学的笔记本。\\n不幸的是， AI研究的进展速度使得这本书不可避免地成为一项持续的工作。如果\\n有您觉得难以理解的部分、值得注意的遗漏或看似多余的部分，请通过相关网站与我联\\n系。我们可以一起让下一版更好。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 29}, page_content='14 CHAPTER 1. 介绍'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 30}, page_content='Chapter 2\\n监督学习\\n监督学习模型就是将一个或多个输入转化为一个或多个输出的方式。比如，我们可\\n以将某部二手丰田普锐斯的车龄和行驶里程作为输入，预估的车辆价格则是输出。\\n这个模型其实只是个数学公式；当我们把输入放入这个公式进行计算，我们得到的\\n结果就是所谓的“推理” 。这个公式还包含一些参数。改变参数值会改变计算的结果；这\\n个公式其实描述了输入和输出之间所有可能关系的“家族” ，而参数则定义了其中的特\\n定关系。\\n每当我们训练或学习模型时，我们其实是在寻找可以真实反映输入与输出关系的参\\n数。学习算法收集一组输入 /输出对，然后调整这些参数，使得输入数据能够尽可能准\\n确地预测出其相应的输出。如果对于这些训练数据，模型的预测效果不错，那么我们就\\n会寄希望于它能在未来遇到新的未知输出的情况下，依然能做出好的预测。\\n本章的目标是深入探讨这些观点。我们会首先对这个框架进行更详细的描述，并引\\n入一些专业的符号。然后，我们会用一个简单的范例来展示如何使用一条直线来描述输\\n入与输出间的关系。这个线性模型比较容易理解且直观，却恰好包含了所有有监督学习\\n的关键概念。\\n2.1监督学习介绍\\n在监督学习中，我们的目标是建立一个模型，这个模型能够接收输入 x并给出预测\\n结果y。简单来说，我们假设输入 x和输出y都是预先定义且大小固定的向量，并且\\n这些向量中的元素排列顺序始终一致。举个例子，如普锐斯汽车的例子，输入 x总是先\\n包含汽车的年龄，然后是行驶里程，按照这个顺序。这种数据被称为结构化或表格数据\\n（structured or tabular data ） 。\\n为了进行预测，我们需要一个函数模型 f[•]，它以x为输入并返回预测结果 y，即：\\ny=f[x] (2.1)\\n当我们根据输入 x来计算预测结果 y时，这个过程称为推理（ inference ） 。\\n15'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 31}, page_content='16 CHAPTER 2. 监督学习\\n这个模型实际上是一个具有固定形式的数学方程，代表了输入和输出之间各种不同\\n的关系。模型中也包含一些参数 ϕ。这些参数的选择决定了输入和输出之间具体的关系。\\n更准确地说，我们应该这样表达这个关系：\\ny=f[x,ϕ] (2.2)\\n当我们谈及学习或训练模型时，意味着我们在尝试找出能够根据输入合理预测输出\\n的参数ϕ。我们通过一组包含 I对输入和输出样本 xi,yi的训练数据集来学习这些参数。\\n我们的目标是选取能够尽可能准确地将每一个训练输入映射到它对应的输出的参数。我\\n们通过损失函数 L来衡量这种映射的准确程度。损失函数是一个标量值，它概括了模型\\n基于当前参数 ϕ预测训练数据输出与实际输入的不匹配程度。\\n我们可以把损失函数视为参数的函数 L[ϕ]。在训练模型时，我们的目标是寻找一组\\n参数 ˆϕ，这组参数能够使损失函数的值最小：\\nˆϕ=argmin\\nϕL[ϕ] (2.3)\\n如果在这个最小化过程之后损失很小，说明我们找到了一组能够从训练输入 xi准\\n确预测训练输出 yi的模型参数。\\n在训练模型之后，我们接下来需要评估它的性能。我们会在一组独立的测试数据上\\n运行模型，以评估它对于训练过程中未曾见过的示例的泛化能力。如果模型的性能达到\\n预期，那么我们就可以开始部署这个模型了。\\n2.2线性回归示例\\n让我们通过一个简单的实例，将这些理论概念具体化。假设有一个模型 y=f[x,ϕ]，\\n它能够根据某个输入 x，预测出单一的输出 y。接着，我们将构建一个损失函数，并就\\n如何训练这个模型进行讨论。\\n2.2.1一维线性回归模型\\n一维线性回归模型以一条直线的形式，展现了输入 x和输出y之间的关系：\\ny=f[x,ϕ]\\n=ϕ0+ϕ1x (2.4)\\n这个模型有两个参数 ϕ= [ϕ0,ϕ1]T，ϕ0和ϕ1分别代表直线的截距和斜率。调整截\\n距和斜率的值，可以改变输入和输出之间的关系（如图 2.1所示） 。因此，我们可以认为\\n方程2.4描述的是一族可能的输入 -输出关系（即：所有可能的线） 。而具体选择哪个参\\n数，就能确定这一族关系中的特定成员（也就是特定的一条直线） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 32}, page_content='2.2.线性回归示例 17\\n图 2.1:线性回归模型。在我们确定了参数 ϕ= [ϕ0, ϕ1]T的选择后，该模型就可以依据输入值\\n（x轴位置）来预测输出值（ y轴位置） 。通过调整 y轴截距 ϕ0和直线斜率 ϕ1的值，我们的预\\n测结果（代表为青色、橙色以及灰色线）也就有所不同。所以，线性回归模型（公式 2.4）实际\\n上就定义了一个输入 /输出关系的集合（代表为多条直线） ，而模型的参数则用来确定我们将使\\n用的具体一条直线（即集合中的一个成员） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 33}, page_content='18 CHAPTER 2. 监督学习\\n2.2.2损失（ Loss）\\n对于这个模型，训练数据集（见图 2.2a）由I对输入/输出数据对 xi,yi组成。图\\n2.2b–d展示了三组不同参数定义下的三条线。图 2.2d中的绿色线条比其他两条更准确\\n地描述了数据，因为它更接近于数据点。然而，我们需要一种系统的方法来判断哪一组\\n参数ϕ比其他参数更优。为了做到这一点，我们给每一组参数赋予一个数值，这个数值\\n表示模型与数据之间不匹配的程度。我们称这个值为损失；损失越低，表示模型拟合得\\n越好。\\n这种不匹配是通过模型预测 f[xi,ϕ]（线在xi处的高度）和真实输出 yi之间的差异\\n来表示的。在图 2.2b–d中，这些差异以橙色虚线显示。我们通过计算所有 I对训练数\\n据对中这些差异的平方和来量化总的不匹配、训练误差或损失：\\nL(ϕ) =IX\\ni=1(f(xi;ϕ)−yi)2\\n=IX\\ni=1(ϕ0+ϕ1xi−yi)2(2.5)\\n由于最佳参数是使这个表达式最小化的参数，我们称之为最小二乘损失。平方操作\\n意味着偏差的方向（即线是在数据点上方还是下方）不重要。我们将在第 5章回到这个\\n选择的理论原因。\\n损失L是参数ϕ的函数；当模型拟合较差时（如图 2.2b,c） ，损失会较大；而拟合\\n良好时（如图 2.2d） ，损失则较小。从这个角度来看，我们称 L[ϕ]为损失函数或成本函\\n数。目标是找到能最小化这个量的参数 ˆϕ：\\nˆϕ=argmin\\nϕL(ϕ)\\n=argmin\\nϕ\"IX\\ni=1(f(xi;ϕ)−yi)2#\\n=argmin\\nϕ\"IX\\ni=1(ϕ0+ϕ1xi−yi)2#\\n(2.6)\\n由于模型只有两个参数（ y截距ϕ0和斜率ϕ1） ，我们可以为每一组参数值的组合计\\n算损失，并将损失函数以表面的形式进行可视化（见图 2.3） 。”最佳”参数则位于这个\\n表面的最低点。\\n2.2.3训练\\n寻找使损失最小化的参数的过程称为模型拟合、训练或学习。这个过程的基本方法\\n是首先随机选择初始参数，然后通过不断“下降”损失函数，直到找到最低点（参见图'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 34}, page_content='2.2.线性回归示例 19\\n图 2.2:线性回归中的训练数据，模型和损失的展示。 a）我们的训练数据（标注为橙色的点）包\\n含着 I = 12个输入输出对 xi, yi。b–d）每一部分都展示了一个具有不同参数的线性回归模型。\\n根据我们选择的截距和斜率参数 ϕ= [ϕ0, ϕ1]T，模型的预测结果（表示为橙色的虚线）的误差可\\n能会变大或变小。这里的损失 L实际上就是这些误差的平方和。如果你看一下图表 b和 c，你\\n会发现其线条拟合的并不是很好，这使得它们的损失 L分别为 7.07和 10.28，这是相当大的损\\n失。而在图表 d中，该模型拟合得相当好，导致其损失 L仅为 0.20；实际上，这就是所有可能\\n的线条中损失最小的那一条，可以认为这些参数是最优的。\\n图 2.3:线性回归模型的损失函数，使用图 2.2a中的数据集。 a)每个参数组合 Φ = [ ϕ0, ϕ1]T都\\n有一个对应的损失。结果损失函数 L[Φ]可以被可视化为一个表面。三个圆圈代表图 2.2b-d中\\n的直线。 b)损失也可以被可视化为一个热图，其中较亮的区域代表较大的损失；这里我们从上\\n方看 (a)中的表面，灰色椭圆表示等高线。最佳拟合直线（图 2.2d）具有最小损失的参数（绿色\\n圆圈） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 35}, page_content='20 CHAPTER 2. 监督学习\\n图 2.4:线性回归训练。目标是找到对应于最小损失的 y截距和斜率参数。 a)迭代训练算法随机\\n初始化参数，然后通过“下山”来改进参数，直到不能再改进为止。这里，我们从位置 0开始，\\n向下移动一定距离（垂直于等高线）到位置 1。然后我们重新计算下山方向并移动到位置 2。最\\n终，我们到达函数的最小值（位置 4） 。 b)面板 (a)中的每个位置 0-4对应于不同的 y截距和斜\\n率，因此表示不同的直线。随着损失的减少，直线与数据的拟合度更高。\\n2.4） 。具体做法是，测量当前位置损失函数表面的梯度，然后朝最陡峭的下坡方向迈出\\n一步。接着不断重复这个过程，直到梯度变平，无法再进一步优化。\\n2.2.4测试\\n当模型训练完成后，我们想知道它在实际应用中的表现。这可以通过在一组独立的\\n测试数据上计算损失来实现。模型预测的准确性在多大程度上能泛化到测试数据，一方\\n面取决于训练数据的代表性和完整性；另一方面，则取决于模型的表达能力。例如，简\\n单的模型如直线可能无法完全捕捉输入和输出之间的真实关系，这就是所谓的欠拟合。\\n相反，表达能力过强的模型可能会描述训练数据中的一些不典型的统计特性，导致不正\\n常的预测结果，这被称为过拟合。\\n2.3总结\\n监督学习模型是一个函数 y=f[x,ϕ]，它将输入 x与输出y关联起来。这种特定\\n的关系由参数 ϕ决定。为了训练模型，我们在训练数据集 xi,yi上定义了损失函数 L[ϕ]，\\n以量化模型预测 f[xi,ϕ]与实际观测输出 yi之间的不匹配程度。然后我们寻找能够最小\\n化这个损失的参数。我们通过在不同的测试数据集上评估模型，来检查它对新输入的泛\\n化能力。\\n接下来的第 3-9章将进一步深入这些概念。首先，我们将探讨模型本身。 1D线性\\n回归的明显限制是，它只能以直线形式描述输入和输出之间的关系。第 3章介绍的浅层\\n神经网络虽然比线性回归稍复杂，但能描述更广泛的输入 /输出关系。第 4章的深度神'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 36}, page_content='2.4.笔记 21\\n经网络在保持表达能力的同时，能用更少的参数描述复杂函数，且在实际应用中表现更\\n佳。\\n第5章将探讨不同任务下的损失函数及其理论基础，特别是最小二乘损失。第 6章\\n和第7章将讨论训练过程，第 8章将讨论如何衡量模型性能，而第 9章将考察旨在提\\n高性能的正则化技术。\\n2.4笔记\\n损失函数（ loss F unction ）与成本函数（ cost function ）：在机器学习领域，尤其\\n是在本书中， “损失函数”和“成本函数”这两个术语通常可以互换使用。但更准确地\\n说，损失函数是指与单个数据点相关的具体项（例如，方程 2.5中每个平方项） ，而成本\\n函数是指需要被最小化的整体量（即方程 2.5中的整个右侧部分） 。成本函数可能还包\\n含与单个数据点无关的其他项（详见第 9.1节） 。更广义上，目标函数指的是任何需要\\n最大化或最小化的函数。\\n生成 (Generative) 模型与判别 (Discriminative) 模型：本章中提到的模型 y=\\nf[x,ϕ]属于判别模型。这类模型基于实际测量的数据 x来预测输出 y。另一种方法是构\\n建生成模型 x=g[y,ϕ]，在这种模型中，实际测量的数据 x被看作是输出 y的函数。虽\\n然生成模型的缺点是它们不直接预测 y，但它们的优势在于能够融入关于数据生成方式\\n的先验知识。比如，如果我们要预测图像 x中汽车的三维位置和方向 y，我们可以在函\\n数x=g[y,ϕ]中加入关于汽车形状、三维几何和光传输的知识。尽管这听起来是个好主\\n意，但实际上，在现代机器学习中，判别模型更为主流。这是因为在生成模型中利用先\\n验知识所带来的优势通常不及利用大量训练数据来学习灵活的判别模型所获得的优势。\\n2.5习题\\n问题 2.1为了在损失函数（方程 2.5）上实现“ downhill” ，我们需要计算它对参数\\nϕ0和ϕ1的梯度。请计算出这两个参数的梯度值 ∂L/∂ϕ0和∂L/∂ϕ1的具体表达式。\\n问题 2.2请证明我们可以通过将问题 2.1中的导数设置为零，然后求解 ϕ0和ϕ1，\\n以闭合形式找到损失函数的最小值。需要注意的是，这种方法适用于线性回归，但不适\\n用于更复杂的模型；这就是为什么我们通常会使用迭代的模型拟合方法，例如梯度下降\\n（参见图 2.4） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 36}, page_content='以闭合形式找到损失函数的最小值。需要注意的是，这种方法适用于线性回归，但不适\\n用于更复杂的模型；这就是为什么我们通常会使用迭代的模型拟合方法，例如梯度下降\\n（参见图 2.4） 。\\n问题 2.3考虑将线性回归改造为生成模型，形式为 x=g[y,ϕ] =ϕ0+ϕ1y。请问这\\n种情况下的新损失函数是什么？请找出进行推理所需的逆函数 y=g−1[x,ϕ]的表达式。\\n对于一个给定的训练数据集 xi,yi，这个模型是否会做出与判别模型版本相同的预测？一\\n种验证方法是编写程序，使用这两种方法对三个数据点进行线性拟合，看结果是否一致。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 37}, page_content='22 CHAPTER 2. 监督学习'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 38}, page_content='Chapter 3\\n浅层神经网络\\n第二章我们学习了使用一维线性回归的监督学习方法，但这种模型只能表示出输入\\n与输出之间简单的线性关系。在这一章里，我们将接触到浅层神经网络。这种网络可以\\n表达分段线性函数，并且能力强大到足以近似任何复杂度的多维输入和输出之间的关\\n系。\\n3.1神经网络示例\\n浅层神经网络是带有参数 ϕ的函数y=f[x,ϕ]，它将多变量输入 x映射成多变量\\n输出y。关于浅层神经网络的全面定义将在第 3.4节中给出。首先，我们通过一个示例\\n网络f[x,ϕ]来介绍核心概念。这个网络能够将单一变量输入 x转化为单一变量输出 y，\\n并包含十个参数 ϕ={ϕ0,ϕ1,ϕ2,ϕ3,θ10,θ11,θ20,θ21,θ30,θ31}：\\ny=f[x,ϕ]\\n=ϕ0+ϕ1a[θ10+θ11x] +ϕ2a[θ20+θ21x] +ϕ3a[θ30+θ31x] (3.1)\\n这个计算过程可以分成三个步骤：首先，计算输入数据 x的三个线性函数（ θ10+\\nθ11x,θ 20+θ21x,θ 30+θ31x） 。接着，将这三个函数的结果通过激活函数 a[·]处理。最后，\\n用ϕ1,ϕ2,ϕ3对这三个激活结果进行加权，求和，并加上一个偏移量 ϕ0。\\n接下来，我们需要定义激活函数（ activation function ）a[·]。虽然有很多选择，但最\\n常用的是整流线性单元（ ReLU） ：\\na[z] =ReLU [z] =8\\n<\\n:0ifz <0\\nzifz≥0(3.2)\\n这个函数在输入为正时返回输入值，否则返回零（参见图 3.1） 。\\n方程3.1描述了哪一类输入 /输出关系可能不是一目了然的。但是，前一章节提到\\n的所有概念都适用于这里。方程 3.1表示了一个函数族，具体的函数取决于 ϕ中的十个\\n23'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 39}, page_content='24 CHAPTER 3. 浅层神经网络\\n图 3.1:整流线性单元 (Rectified Linear Unit, ReLU) 。这种激活函数在输入小于零时输出为零，\\n否则保持输入值不变。简而言之，它将所有负数输入值变为零。需要注意的是，虽然有许多其他\\n激活函数可供选择（参见图 3.13） ，但 ReLU由于其简单易懂，成为最常用的选择。\\n参数。如果我们知道这些参数，就可以通过对给定输入 x计算该方程来进行推断（预测\\ny） 。给定一个训练数据集 {xi,yi}I\\ni=1，我们可以定义一个最小二乘损失函数 L[ϕ]，用它\\n来评估对于任意参数值 ϕ，模型描述该数据集的效果。为了训练这个模型，我们要找出\\n能够最小化这个损失的参数值 ˆϕ。\\n3.1.1神经网络直观理解\\n事实上，方程 3.1描述了一个连续分段线性函数族（见图 3.2） ，这个函数族最多包\\n含四个线性区域。下面我们解析这个方程，阐释它是如何描绘出这样一个函数族的。为\\n了便于理解，我们将这个函数拆分为两个部分。首先，我们定义几个中间量：\\nh1 =a[θ10+θ11x]\\nh2 =a[θ20+θ21x]\\nh3 =a[θ30+θ31x] (3.3)\\n这里的h1,h2,h3被称为隐藏单元。然后，我们通过将这些隐藏单元与一个线性函\\n数结合来计算输出：\\ny=ϕ0+ϕ1h1 +ϕ2h2 +ϕ3h3 (3.4)\\n图3.3展示了形成图 3.2a中函数的计算流程。每个隐藏单元内包含了一个关于输\\n入的线性函数 θ0+θ1x，该线性函数在零点以下被 ReLU函数a[·]截断。这三条线在零'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 40}, page_content='3.2.通用逼近定理 25\\n点交叉的位置形成了最终输出函数的三个“拐点” 。然后，分别用 ϕ1,ϕ2,ϕ3对这三条被\\n截断的线加权。最后，加上偏移量 ϕ0来控制最终函数的整体高度。\\n图 3.2:由方程 3.1定义的函数族。 a-c)展示了三种不同参数 ϕ的选择下的函数。在这些函数\\n中，输入与输出的关系均为分段线性。不过，各个拐点的位置、拐点间线段的斜率，以及整体高\\n度各不相同。\\n在图3.3j中，每个线性区域对应于隐藏单元中的一种不同激活模式。当一个单元在\\nReLU函数下被截断时，我们称其为不活跃状态；相反，如果没有被截断，则处于活跃\\n状态。例如，在阴影区域内，得到 h1和h3（处于活跃状态）的贡献，但没有 h2（处于\\n不活跃状态）的贡献。每个线性区域的斜率取决于两个因素： （ i）这个区域内活跃输入\\n的原始斜率 θ1和（ii）随后应用的权重 ϕ。例如，在阴影区域（参见问题 3.3） ，斜率是\\nϕ1θ11+θ31ϕ3，其中第一项是图中（ g）面板的斜率，第二项是（ i）面板的斜率。\\n由于每个隐藏单元贡献了一个拐点，所以有三个隐藏单元时，可以形成四个线性区\\n域。但是，这些区域的斜率只有三个是相互独立的；第四个斜率要么是零（如果在这个\\n区域所有隐藏单元都处于不活跃状态） ，要么是其他区域斜率的总和。\\n3.1.2描绘神经网络\\n我们此前一直探讨的是一种神经网络，它由一个输入层、一个输出层和三个隐藏单\\n元组成。在图 3.4a中，我们将这个网络形象化。图中，最左边的是输入层，中间部分\\n是隐藏单元，右边则是输出层。图中的每一条连接线代表了这个神经网络的十个参数中\\n的一个。而为了图像表示的简洁，我们通常不会特别标出截距参数，所以大多数情况下，\\n这个网络的表达方式如图 3.4b所示。\\n3.2通用逼近定理\\n在上一节中，我们介绍了一个只有一个输入、一个输出、使用 ReLU激活函数，并\\n配备了三个隐藏单元的神经网络示例。现在，让我们稍微扩展这个概念，考虑一个拥有\\nD个隐藏单元的网络，其中第 dth个隐藏单元表示为：\\nhd=a[θd0+θd1x], (3.5)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 41}, page_content='26 CHAPTER 3. 浅层神经网络\\n图 3.3:展示图 3.2a中函数的计算过程。 a-c)输入 x分别经过三个具有不同 y截距 θ•0和斜率\\nθ•1的线性函数处理。 d-f)每个线性函数的输出再经过 ReLU激活函数处理，将所有负数输出\\n值变为零。 g-i)接着，这三个处理过的输出分别乘以权重 ϕ1, ϕ2, ϕ3进行加权。 j)最后，将这些\\n加权后的输出相加，并加上一个控制整体高度的偏移量 ϕ0。每个线性段代表了隐层单元中的一\\n种不同激活模式。在阴影区域， h2处于非激活状态（被剪切） ，而 h1和 h3保持激活状态。\\n这些隐藏单元通过线性方式结合，共同产生输出：\\ny=ϕ0+DX\\nd=1ϕdhd. (3.6)\\n在浅层网络中，隐藏单元的数量是衡量网络“容量” （即其处理复杂性的能力）的\\n一个指标。当使用 ReLU激活函数时，具有 D个隐藏单元的网络输出最多有 D个拐点，\\n因此它是一个最多有 D+ 1个线性区域的分段线性函数。随着增加更多的隐藏单元，模\\n型能够逼近更为复杂的函数。\\n实际上，如果网络有足够的“容量” （即足够多的隐藏单元） ，它就能够以任意精度\\n描述定义在实数线某个紧凑子集上的任何连续一维函数。这是因为，每当我们增加一个\\n隐藏单元，就会在函数中增加一个新的线性区域。随着这些线性区域的增多，它们代表'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 42}, page_content='3.3.多变量输入与输出 27\\n图 3.4:描述神经网络结构。 a)输入变量 x位于左侧，隐层单元 h1 , h2 , 和 h3位于中间，输出\\n变量 y位于右侧。计算过程从左向右进行。输入变量用于计算隐层单元的值，这些隐层单元的\\n组合进而生成输出值。图中的十个箭头分别代表一个参数，橙色代表截距，黑色代表斜率。每个\\n参数将其来源的值乘以自己，然后将结果加到其目标上。例如，我们将参数 ϕ1与来源于 h1的\\n值相乘，再将结果加到 y上。为了将偏移量纳入这一计算框架，引入了值为 1的额外节点（橙\\n色圆圈） ，例如我们将 ϕ0乘以 1（实际上无变化）后加到 y上。 ReLU函数被应用于隐层单元。\\nb)通常情况下，网络图中会省略截距、 ReLU函数和参数名称的显示；这种简化后的表示方式实\\n际上描述了同一个网络。\\n了函数中越来越小的部分，这些部分可以被一条线越来越精确地逼近（参见图 3.5） 。通\\n用逼近定理证明了，对于任何连续函数，都存在一个浅层网络，它能以任意设定的精度\\n逼近这个函数。\\n3.3多变量输入与输出\\n在前述例子中， 网络仅有一个单变量标量输入 x和一个单变量标量输出 y。 然而， 对\\n于网络将多变量输入 x= [x1,x2,...,x Di]T（其中“T”表示转置）映射到多变量输出预测\\ny= [y1,y2,...,y Do]T的更广泛情况，通用逼近定理 (universal approximation theorem)\\n依然成立。我们首先探讨如何改进模型以预测多变量输出。接着，我们将讨论多变量输\\n入的处理方式。最后，在第 3.4节，我们会提出浅层神经网络的通用定义。\\n3.4多变量输入和输出\\n在前面的例子中，网络有一个单变量输入 x和一个单变量输出 y。然而，通用逼\\n近定理也同样适用于网络将多变量输入 x= [x1,x2,...,x Di]T映射到多变量输出 y=\\n[y1,y2,...,y Do]T的更一般情况。我们首先探索如何将模型扩展到预测多变量输出。然后\\n我们会考虑多变量输入。最后，在第 3.4节中，我们将提出浅层神经网络的通用定义。\\n3.4.1可视化多变量输出\\n为了将网络扩展到能产生多变量输出 y，我们可以简单地为每个输出使用隐藏单元\\n的不同线性函数。例如，一个具有单变量输入 x、四个隐藏单元 h1,h2,h3,h4和一个二'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 42}, page_content='3.4.1可视化多变量输出\\n为了将网络扩展到能产生多变量输出 y，我们可以简单地为每个输出使用隐藏单元\\n的不同线性函数。例如，一个具有单变量输入 x、四个隐藏单元 h1,h2,h3,h4和一个二\\n维多变量输出 y= [y1,y2]T的网络可以定义为：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 43}, page_content='28 CHAPTER 3. 浅层神经网络\\nh1=a[θ10+θ11x]\\nh2=a[θ20+θ21x]\\nh3=a[θ30+θ31x]\\nh4=a[θ40+θ41x] (3.7)\\n以及\\ny1 =ϕ10+ϕ11h1 +ϕ12h2 +ϕ13h3 +ϕ14h4\\ny2 =ϕ20+ϕ21h1 +ϕ22h2 +ϕ23h3 +ϕ24h4. (3.8)\\n这两个输出是隐藏单元的两种不同线性组合。\\n如图3.3所示，分段函数的“接点”取决于隐藏单元处的 ReLU函数a[·]截断的初\\n始线性函数 θ0+θ1x。由于y1和y2都是相同四个隐藏单元的不同线性函数，因此它们\\n各自的四个“接点”位置必须相同。然而，这些线性区域的斜率和整体的垂直偏移可能\\n不同（参见图 3.6） 。\\n图 3.5:用分段线性模型近似一维函数（虚线表示） 。 a-c)随着分段区域的数量增加，该模型逐\\n渐趋近于连续函数。一个只有单一输入的神经网络会为每个隐层单元新增一个线性区域。根据\\n通用近似定理（ Universal Approximation Theorem ） ，只要隐层单元足够多，就能构建一个浅层\\n神经网络，该网络能够以任意精度近似定义在 RDi紧凑子集上的任何连续函数。\\n3.4.2可视化多变量输入\\n为了应对多变量输入 x，我们扩展了输入与隐藏单元之间的线性关联。例如，一个\\n有两个输入 x= [x1,x2]T和一个标量输出 y的网络（参见图 3.7）可能由三个隐藏单元\\n构成，定义如下：\\nh1 =a[θ10+θ11x1+θ12x2]\\nh2 =a[θ20+θ21x1+θ22x2]\\nh3 =a[θ30+θ31x1+θ32x2] (3.9)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 44}, page_content='3.4.多变量输入和输出 29\\n图 3.6:展示了一个具有一个输入、四个隐层单元和两个输出的网络。 a)网络结构的可视化展示。\\nb)该网络产生两个分段线性函数， y1[x]和 y2[x]。由于这些函数共享相同的隐层单元，它们的四\\n个“关节” （位于垂直虚线处）位置是固定的，但它们的斜率和整体高度可能有所不同。\\n图 3.7:展示了具有二维多变量输入 x= [x1, x2]T和单一输出 y的神经网络的可视化。\\n这里，每个输入都对应一个斜率参数。隐藏单元以通常的方式结合，形成输出：\\ny=ϕ0+ϕ1h1 +ϕ2h2 +ϕ3h3 (3.10)\\n图3.8展示了这个网络的处理过程。每个隐藏单元接收两个输入的线性组合，这在\\n三维输入 /输出空间中形成了一个有方向的平面。激活函数将这些平面的负值剪切为零。\\n接着，这些被剪切的平面在第二个线性函数（方程 3.10）中被重新组合，形成了一个由\\n凸多边形区域组成的连续分段线性表面（见图 3.8j） 。每个区域代表了一种不同的激活\\n模式。例如，在中央的三角形区域中，第一个和第三个隐藏单元处于激活状态，而第二\\n个则未激活。当模型有超过两个输入时，可视化变得更加困难。不过，其基本原理是相\\n似的：输出将是输入的连续分段线性函数，其中线性区域在多维输入空间中呈现为凸多\\n面体。\\n需要注意的是，随着输入维度的增加，线性区域的数量迅速增长（参见图 3.9） 。为\\n了更好地理解这种增长速度，考虑每个隐藏单元定义了一个超平面，区分了单元活跃和\\n不活跃的空间部分（见图 3.8d-f中的青色线条） 。如果我们的隐藏单元数量与输入维度\\nDi相等，我们可以将每个超平面与一个坐标轴对齐（见图 3.10） 。对于两个输入维度，\\n这会将空间划分为四个象限。对于三个维度，这会形成八个八分区，而对于 Di维度，则\\n会形成 2Di个正交空间。由于浅层神经网络通常比输入维度有更多的隐藏单元，它们通\\n常会创造出超过 2Di个线性区域。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 45}, page_content='30 CHAPTER 3. 浅层神经网络\\n图 3.8:在一个具有两个输入 x= [x1, x2]T、三个隐层单元 h1, h2, h3和一个输出 y的网络中的\\n处理过程。 a-c)每个隐层单元的输入是两个输入变量的线性函数，对应于一个方向性平面。亮度\\n代表函数的输出，例如，在面板 (a)中，亮度表示 θ10 +θ11x1+θ12x2。细线代表等值线。 d-f)\\nReLU (Rectified Linear Unit) 激活函数对每个平面进行剪切处理（青色线相当于图 3.3d-f中的\\n“关节” ） 。 g-i)这些被剪切的平面随后被加权， j)然后和一个决定表面整体高度的偏移量相加。\\n最终得到的是一个由凸的分段线性多边形区域构成的连续表面。\\n3.5浅层神经网络：一般情况\\n我们已经通过几个示例来展示浅层网络的工作原理。现在我们定义一个浅层神经网\\n络的通用方程 y=f[x,ϕ]，它利用h∈RDh个隐藏单元将多维输入 x∈RDi映射到多维\\n输出y∈RDo。每个隐藏单元的计算方式如下：\\nhd=a\"\\nθd0+DiX\\ni=1θdixi#\\n(3.11)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 46}, page_content='3.5.浅层神经网络：一般情况 31\\n图 3.9:隐层单元与线性区域的关系。 a)对于五种不同输入维度 Di= 1,5,10,50,100，展示了隐\\n层单元数与其能够产生的最大线性区域数之间的关系。在高维度下，线性区域的数量迅速增加；\\n例如，在 D = 500 单元和输入维度 Di = 100 的情况下，线性区域的数量可以超过 10107（实心\\n圆所示） 。 b)将相同的数据以参数数量作为函数进行绘制。实心圆表示与 a)面板中相同的模型，\\n拥有 D = 500 隐层单元。这个网络有 51,001个参数，在现代标准下被认为非常小。\\n这些隐藏单元被线性方式组合，以产生输出：\\nyj=ϕj0+DhX\\nd=1ϕjdhd (3.12)\\n其中a[·]是一种非线性激活函数。该模型的参数为 ϕ={θ·,ϕ·}。图3.11展示了一\\n个包含三个输入、三个隐藏单元和两个输出的示例。\\n激活函数使得模型能描述输入与输出之间的非线性关系，因此它本身必须是非线性\\n的；如果没有激活函数，或使用线性激活函数，从输入到输出的映射将被限制为线性映\\n射。已尝试了多种不同的激活函数（见图 3.13） ，但最常用的选择是 ReLU（见图3.1） ，\\n它具有易于理解的优点。使用 ReLU激活的网络将输入空间划分为由 ReLU函数中的\\n“接点”计算出的超平面交叉定义的凸多面体。每个凸多面体内包含一个不同的线性函\\n数。尽管每个输出的多面体都相同，但它们包含的线性函数可能会有所不同。\\n图 3.10:输入维度与线性区域数量的关系。 a)对于单输入维度的模型，一个隐层单元可以创建\\n一个分割点，将输入轴分为两个线性区域。 b)在两个输入维度的模型中，两个隐层单元可以使用\\n两条线（此处与坐标轴对齐）划分输入空间，形成四个区域。 c)在三个输入维度的模型中，三个\\n隐层单元可以用三个平面（同样与坐标轴对齐）划分输入空间，形成八个区域。延伸这一逻辑，\\n一个具有 Di输入维度和 Di隐层单元的模型可以用 Di超平面来划分输入空间，从而形成 2Di\\n个线性区域。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 47}, page_content='32 CHAPTER 3. 浅层神经网络\\n图 3.11:展示了一个具有三个输入和两个输出的神经网络的可视化。该网络共有二十个参数，包\\n括十五个斜率（由箭头指示）和五个偏移（未显示） 。\\n图 3.12:术语 :一个浅层网络由一个输入层、一个隐层和一个输出层构成。每一层都通过前向连\\n接（箭头所示）与下一层相连， 因此这类模型被称为前向网络（ feed-forward networks ） 。 当每一层\\n中的每个变量都与下一层的每个变量相连时，我们称之为全连接网络（ ful ly connected network ） 。\\n每个连接代表了底层方程中的斜率参数，这些参数称为权重（ weights） 。隐层中的变量被称为神\\n经元（ neurons）或隐层单元（ hidden units ） 。进入隐层单元的值称为激活前值（ pre-activations ） ，\\n而隐层单元上的值（即应用 ReLU函数后的值）称为激活值（ activations ） 。\\n3.6术语\\n在本章的结尾，我们来介绍一些术语。神经网络领域有很多专业术语。通常情况下，\\n它们是通过层来描述的。在图 3.12中，左边是输入层，中间是隐藏层，右边是输出层。\\n我们可以说图 3.12中的网络有一个包含四个隐藏单元的隐藏层。隐藏单元本身有时也\\n被称为神经元。当数据通过网络传输时，隐藏层输入的值（即在应用 ReLU函数之前的\\n值）被称为预激活值。隐藏层的值（即在应用 ReLU函数之后的值）被称为激活值。\\n由于历史原因， 任何至少有一个隐藏层的神经网络也被称为多层感知器（ MLP） 。本\\n章所述的具有一个隐藏层的网络有时被称为浅层神经网络。具有多个隐藏层的网络（将\\n在下一章中描述）被称为深度神经网络。其中连接形成一个无环图（即没有循环的图，\\n如本章中的所有示例）的神经网络被称为前馈网络。如果一个层中的每个元素都连接到\\n下一个层中的每个元素（如本章中的所有示例） ，则该网络被称为全连接网络。这些连\\n接代表了基础方程中的斜率参数，并被称为网络权重。偏移参数（在图 3.12中未显示）\\n被称为偏置。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 48}, page_content='3.7.总结 33\\n3.7总结\\n浅层神经网络包含一个隐藏层。它们的工作过程包括： (i)计算输入的多个线性函\\n数，(ii)将这些函数结果通过激活函数处理，然后 (iii)将这些激活后的结果线性组合以\\n产生输出。浅层神经网络通过将输入空间划分成连续的、由分段线性区域组成的表面来\\n根据输入 x进行预测 y。只要拥有足够多的隐藏单元（神经元） ，浅层神经网络能够以\\n任意精度逼近任何连续函数。\\n第4章将讨论深度神经网络，这些网络通过增加更多隐藏层来扩展本章所述的模\\n型。第5至7章将描述如何训练这些模型。\\n3.8笔记\\n”神经 ”网络：如果本章中的模型仅仅是函数，为什么它们被称为“神经网络”呢？\\n这个连接实际上是比较脆弱的。像图 3.12中的可视化包括节点（输入、隐藏单元和输\\n出） ，它们之间有密集的连接。这与哺乳动物大脑中密集连接的神经元在表面上有相似\\n之处。然而，几乎没有证据表明大脑计算的方式与神经网络相同，而且从生物学角度来\\n考虑这一点是没有帮助的。\\n神经网络的历史 ：1943年，McCulloch 和Pitts首次提出了人工神经元的概念， 这种\\n神经元能够将输入信号组合以产生输出，但缺乏有效的学习算法。 1958年，Rosenblatt\\n开发出了感知机（ Perceptron ） ，一种通过线性组合输入信号并设定阈值来做出是 /否决\\n策的模型，并为其设计了一种从数据中学习权重的算法。 1969年，Minsky和Papert指\\n出，仅用线性函数处理一般分类问题是不够的。他们认为，通过增加带有非线性激活函\\n数的隐藏层（由此产生了“多层感知机（ Multi-layer Perceptron ） ”这一术语） ，可以学\\n习到更广泛的输入 /输出关系。不过，他们也指出， Rosenblatt 的算法无法学习这些模型\\n的参数。直到 20世纪80年代，一个有效的学习算法——反向传播（ Backpropagation ，\\n详见第7章）才被发明，此后神经网络的研究才重新获得显著发展。关于神经网络历史\\n的详细记载可参见 Kurenkov (2020) 、Sejnowski (2018) 和Schmidhuber (2022) 的著作。\\n激活函数 ：ReLU（Rectified Linear Unit ）函数最早在 1969年由Fukushima 提出并'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 48}, page_content='激活函数 ：ReLU（Rectified Linear Unit ）函数最早在 1969年由Fukushima 提出并\\n使用。然而，在神经网络的早期阶段，更常见的激活函数是逻辑 S形（Logistic Sigmoid ）\\n或双曲正切（ Tanh）函数（见图 3.13a） 。2009年以后，由 Jarrett et al. 、Nair & Hinton\\n和Glorot et al. 等人的工作重新推广， ReLU成为现代神经网络成功故事的重要组成部\\n分。ReLU的一个显著特性是，对于大于零的输入值，其输出相对于输入的导数恒为 1，\\n这有助于提高训练的稳定性和效率（详见第 7章） 。这与逻辑 S形激活函数形成鲜明对\\n比，后者的导数在大的正输入和负输入下会趋近于零，即发生饱和现象。\\n然而，ReLU函数存在一个明显的不足：当输入为负值时，它的导数为零。这意味\\n着如果所有训练样本对某个 ReLU函数都产生负输入，那么在训练过程中就无法改进该\\nReLU的输入参数。因为相对于输入权重的梯度在局部呈平坦状态，我们无法通过梯度'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 49}, page_content='34 CHAPTER 3. 浅层神经网络\\n下降法“下坡” 。这种现象被称为 ReLU消亡问题。为解决这一问题，提出了多种 ReLU\\n的改进版本（见图 3.13b） ， 包括(i)渗漏ReLU（Leaky ReLU ，Maas et al., 2013 ） ， 即使对\\n负输入值也有一定的线性输出，其斜率较小，大约为 0.1；(ii)参数化ReLU（Parametric\\nReLU，He et al., 2015 ） ，将负值部分的斜率作为一个可学习的参数；以及 (iii)连接型\\nReLU（Concatenated ReLU ，Shang et al., 2016 ） ，它生成两个输出，一个在零以下截断\\n（类似于标准 ReLU） ，另一个在零以上截断。\\n此外，还研究了多种平滑函数（见图 3.13c–d），例如 soft-plus 函数（Glorot et\\nal., 2011 ）、高斯误差线性单元（ Gaussian Error Linear Unit ，Hendrycks & Gimpel,\\n2016） 、S形线性单元（ Sigmoid Linear Unit ，Hendrycks & Gimpel, 2016 ）和指数线性\\n单元（Exponential Linear Unit ，Clevert et al., 2015 ） 。这些函数大多旨在避免 ReLU消\\n亡问题，同时限制负值的梯度过大。 Klambauer et al. (2017) 提出了缩放指数线性单元\\n（Scaled Exponential Linear Unit ， 见图3.13e） ， 这一激活函数特别有趣， 因为当输入方差\\n在有限范围内时， 它能帮助稳定激活值的方差（详见第 7.5节） 。2017年，Ramachandran\\net al.采用了一种经验方法来选择激活函数。他们在可能的函数空间中寻找，在各种监\\n督学习任务上表现最佳的函数。他们找到的最佳函数是 a[x] =x/(1 +exp[−βx])，其中\\nβ是一个可学习的参数（见图 3.13f） 。他们将这个函数命名为 Swish。有趣的是， Swish\\n实际上是对 Hendrycks & Gimpel (2016) 和Elfwing et al. (2018) 之前提出的激活函数'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 49}, page_content='实际上是对 Hendrycks & Gimpel (2016) 和Elfwing et al. (2018) 之前提出的激活函数\\n的再发现。 2019年，Howard et al. 提出了HardSwish 函数，它近似于 Swish，形状非常\\n相似，但计算速度更快：\\nHardSwish [z] =8\\n>>><\\n>>>:0forz <−3\\nz(z+3)\\n6for−3≤z≤3\\nzforz >3\\n尽管这些激活函数各有特点，但目前尚无定论哪种在实际应用中明显优于其他。不\\n过，渗漏 ReLU、参数化 ReLU和许多连续函数在特定情况下相比 ReLU确实表现出了\\n轻微的性能提升。在本书剩余部分，我们主要关注使用基本 ReLU函数的神经网络，因\\n为它们创建的函数更容易根据线性区域数量进行刻画。\\n通用逼近定理 ：该定理的宽度版本指出，存在一个单隐藏层且隐藏单元数量有限的\\n网络，能够在 Rn的紧凑子集上以任意精度逼近任何特定的连续函数。这一理论最初由\\nCybenko (1989) 针对S形激活函数类别证明，并后由 Hornik (1991) 扩展到更广泛的非\\n线性激活函数。\\n线性区域数量 ：考虑一个拥有 Di≥2维输入和 D个隐藏单元的浅层网络。其线\\n性区域的数量取决于由 ReLU函数的转折点所形成的 D个超平面的相交情况（如图\\n3.8d-f所示） 。每个区域由 ReLU函数对输入的剪切或不剪切的不同组合产生。 Zaslavsky\\n(1975)指出，在Di≤D维输入空间内，由 D个超平面所创造的区域数量最多可以达到\\nPDi\\nj=0\\x00D\\nj\\x01\\n（即二项式系数之和） 。一般而言，浅层神经网络的隐藏单元数 D几乎总是大\\n于输入维度 Di，并能在 2Di到2D之间创造多个线性区域。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 50}, page_content='3.9.习题 35\\n线性、 仿射与非线性函数 ： 严格定义下， 线性变换 f[·]是遵循叠加原理的任何函数， 即\\nf[a+b] =f[a]+f[b]。 根据这个定义， f[2a] = 2f[a]。 加权和f[h1,h2,h3] =ϕh1+ϕh2+ϕh3\\n是线性的，但加上偏移（偏置）后， f[h1,h2,h3] =ϕ0+ϕh1+ϕh2+ϕh3，就不再是线性\\n的。例如，当我们加倍前一个函数的参数时，输出也加倍，但后一个函数不是这样。后者\\n更恰当地被称为仿射函数。在机器学习领域，这些术语常常混用。在本书中，我们也将\\n遵循这一习惯，把这两种函数都称为线性。我们将遇到的所有其他函数都是非线性的。\\n图 3.13:激活函数（ Activation functions ） 。 a) Logistic sigmoid 函数和 tanh函数。 b) Leaky\\nReLU函数和参数为 0.25的 Parametric ReLU 函数。 c) SoftPlus 函数、高斯误差线性激活函\\n数（ Gaussian error linear unit ）和 sigmoid 线性激活函数（ sigmoid linear unit ） 。 d)参数为\\n0.5和 1.0的指数线性激活函数（ Exponential Linear Unit ） 。 e)按比例调整的指数线性激活函\\n数（ Scaled Exponential Linear Unit ） 。 f)参数为 0.4，1.0，和 1.4的 Swish函数。\\n图 3.14:针对问题 3.4,描述了一个网络的处理过程，该网络具有一个输入，三个隐藏单元，以\\n及一个输出。 a-c)所示的是，每个隐藏单元接受的输入来源是原输入的线性转换。前两个隐藏单\\n元接收到的输入与图 3.3中的一样，但是最后一个与它们不同。\\n3.9习题\\n问题 3.1若方程3.1中的激活函数是线性的，即 a[z] =ϕ0+ϕ1z，则输入到输出的\\n映射将是怎样的？如果移除激活函数，使 a[z] =z，又将产生何种映射？'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 51}, page_content='36 CHAPTER 3. 浅层神经网络\\n问题 3.2在图3.3j的四个线性区域中，分别指出哪些隐藏单元是活跃的，哪些是不\\n活跃的（即剪切或不剪切输入的隐藏单元） 。\\n问题 3.3导出图3.3j函数中“关节”位置的表达式，用十个参数 ϕ和输入x表示。\\n同时，导出四个线性区域斜率的表达式。\\n问题 3.4绘制图3.3的一个版本，其中第三个隐藏单元的截距和斜率发生变化，如\\n图3.14c所示，假定其他参数保持不变。\\n问题 3.5证明以下性质对于 α∈R+成立：\\nReLU [α·z] =α·ReLU [z] (3.13)\\n这是ReLU函数的非负齐次性质。\\n问题 3.6继续问题 3.5，当我们将方程 3.3和3.4中定义的浅层网络的参数 θ10和\\nθ11乘以一个正常数 α并将斜率ϕ1除以同一参数 α时，会发生什么？如果 α是负数呢？\\n问题 3.7考虑使用最小二乘损失函数拟合方程 3.1中的模型。这个损失函数是否有\\n唯一的最小值？即，是否存在一组“最佳”参数？\\n问题 3.8考虑将ReLU激活函数替换为 (i)海维赛德阶跃函数 heaviside [z]，(ii)双\\n曲正切函数 tanh [z]，以及(iii)矩形函数rect[z]。为每种激活函数重绘图 3.3，并简要描\\n述使用一个输入、三个隐藏单元和一个输出的神经网络，对于每种激活函数所能创造的\\n函数族。\\nheaviside [z] =8\\n<\\n:0z <0\\n1z≥0(3.14)\\nrect[z] =8\\n>>><\\n>>>:0z <0\\n1 0≤z≤1\\n0z >1(3.15)\\n请针对以下每一个函数，重新绘制一份图 3.3。原始的参数为：\\nϕ= [ϕ0,ϕ1,ϕ2,ϕ3,θ10,θ20,θ30,θ31]\\n= [−0.23,−1.3,1.3,0.66,−0.2,0.4,−0.9,0.9,1.1,−0.7] (3.16)\\n对于每个激活函数，尝试用通俗的语言解释一下，对于那些神经网络来说，它们只\\n有一个输入，三个隐藏单元和一个输出，可以创造出什么样的函数族。\\n问题 3.9证明图3.3中第三个线性区域的斜率是第一个和第四个线性区域斜率之\\n和。\\n问题 3.10考虑一个有一个输入、一个输出和三个隐藏单元的神经网络。图 3.3展\\n示了如何形成四个线性区域。在什么情况下，这个网络会产生少于四个线性区域的分段\\n线性函数？'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 51}, page_content='和。\\n问题 3.10考虑一个有一个输入、一个输出和三个隐藏单元的神经网络。图 3.3展\\n示了如何形成四个线性区域。在什么情况下，这个网络会产生少于四个线性区域的分段\\n线性函数？\\n问题 3.11和问题 3.12图3.7中的模型包含多少个参数？'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 52}, page_content='3.9.习题 37\\n问题 3.13在图3.8的七个区域中，每个区域的激活模式分别是什么？也就是说，在\\n每个区域中，哪些隐藏单元是激活状态（传递输入） ，哪些是非激活状态（剪切输入） ？\\n问题 3.14描述图3.11中网络的方程。需要三个方程从输入计算出三个隐藏单元的\\n值，以及两个方程从隐藏单元计算输出。\\n问题 3.15图3.11中的网络最多能创建多少个三维线性区域？\\n问题 3.16描述一个具有两个输入、四个隐藏单元和三个输出的网络的方程，并按\\n照图3.11的风格绘制这个网络模型。\\n问题 3.17方程3.11和3.12定义了一个具有 Di个输入、Dh个隐藏单元的隐藏层\\n以及Do个输出的通用神经网络。求出模型参数数量的表达式，以 Di、Dh和Do作为\\n变量。\\n问题 3.18证明一个只有 Di= 2维输入、Do= 1维输出和D= 3个隐藏单元的\\n浅层网络所能创建的最大区域数是七个，如图 3.8j所示。根据 Zaslavsky (1975) 的结果，\\n即用D个超平面划分 Di维空间时创造的最大区域数是PDi\\nj=0\\x00D\\nj\\x01\\n。如果在这个模型中\\n增加两个隐藏单元，使 D= 5，那么最大区域数将是多少？'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 53}, page_content='38 CHAPTER 3. 浅层神经网络'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 54}, page_content='Chapter 4\\n深度神经网络\\n前面一章我们讨论了只有一个隐藏层的浅层神经网络。本章，我们将转向深度神经\\n网络，这种网络拥有多个隐藏层。无论是浅层还是深层网络，当使用 ReLU (Rectified\\nLinear Unit) 激活函数时，它们都能实现从输入到输出的分段直线式的变换。\\n浅层神经网络的能力随着隐藏单元数量的增加而提升。实际上，如果隐藏单元足够\\n多，这些网络甚至能够模拟高维空间中极其复杂的函数。但是，对于某些特定的函数，\\n所需的隐藏单元数量可能非常庞大，以至于实际应用变得不现实。相比之下，深度神经\\n网络能够在相同数量的参数条件下创造出更多的线性判断区域。因此，从实际应用的角\\n度来看，深度网络能够描述更加广泛的函数类型。\\n4.1组合神经网络\\n为了更深入地理解深度神经网络的行为特征，我们首先考虑将两个浅层网络进行组\\n合，使得第一个网络的输出成为第二个网络的输入。设想两个各有三个隐藏单元的浅层\\n网络（见图 4.1a） 。第一个网络接收输入 x，并产生输出 y，其定义如下：\\nh1=a[θ10+θ11x]\\nh2=a[θ20+θ21x]\\nh3=a[θ30+θ31x] (4.1)\\n以及\\ny=ϕ0+ϕ1h1+ϕ2h2+ϕ3h3 (4.2)\\n第二个网络以 y作为输入，产生输出 y′，定义如下：\\n39'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 55}, page_content='40 CHAPTER 4. 深度神经网络\\nh′\\n1=a[θ′\\n10+θ′\\n11y]\\nh′\\n2=a[θ′\\n20+θ′\\n21y]\\nh′\\n3=a[θ′\\n30+θ′\\n31y] (4.3)\\n以及\\ny′=ϕ′\\n0+ϕ′\\n1h′\\n1+ϕ′\\n2h′\\n2+ϕ′\\n3h′\\n3 (4.4)\\n在使用ReLU（线性整流单元）激活函数的情况下，该模型描述了一系列分段线性函数。\\n然而，与拥有六个隐藏单元的浅层网络相比，这种组合网络的线性区域数量潜在地更多。\\n例如，若第一个网络产生三个正负斜率交替的区域（见图 4.1b） ，这意味着三个不同范\\n围的x值被映射到同一输出范围 y∈[−1,1]。接下来，从该 y范围到y′的映射被重复\\n应用三次。最终的效果是，第二个网络定义的函数被复制三次，从而形成九个线性区域。\\n这一原理在更高维度同样适用（见图 4.2） 。\\n组合网络的另一种思考方式是，第一个网络将输入空间 x折叠回自身，使得多个输\\n入产生相同的输出。随后，第二个网络在所有重叠点上应用同一函数，实现了函数在这\\n些点上的复制（见图 4.3） 。\\n4.2从组合网络到深层网络\\n上一节我们展示了通过将一个浅层神经网络的输出传递给另一个网络，可以创建复\\n杂的函数。现在我们将说明，这实际上是一个包含两个隐藏层的深层网络的特例。\\n第一个网络的输出（ y=ϕ0+ϕ1h1+ϕ2h2+ϕ3h3）是隐藏单元激活值的线性组合。\\n第二个网络的初始操作（根据方程 4.3，我们计算 θ′\\n10+θ′\\n11y,θ′\\n20+θ′\\n21y,andθ′\\n30+θ′\\n31y）是\\n对第一个网络输出的线性函数。将一个线性函数应用于另一个线性函数，结果仍然是线\\n性函数。将 y的表达式代入方程 4.3，可以得到：\\nh′\\n1=a[ψ0+θ11ψ1] =a[ψ0+θ11ϕ0+θ11ϕ1h1+θ11ϕ2h2+θ11ϕ3h3]\\nh′\\n2=a[ψ0+θ21ψ1] =a[ψ0+θ21ϕ0+θ21ϕ1h1+θ21ϕ2h2+θ21ϕ3h3]\\nh′\\n3=a[ψ0+θ31ψ1] =a[ψ0+θ31ϕ0+θ31ϕ1h1+θ31ϕ2h2+θ31ϕ3h3](4.5)\\n进一步重写为：\\nh′\\n1=a[ψ0+ψ11h1+ψ12h2+ψ13h3]\\nh′\\n2=a[ψ0+ψ21h1+ψ22h2+ψ23h3]\\nh′\\n3=a[ψ0+ψ31h1+ψ32h2+ψ33h3], (4.6)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 56}, page_content='4.3.深度神经网络 41\\n图 4.1:结合了各含三个隐藏单元的两个单层网络。 a)第一个网络的输出 y成为第二个网络的\\n输入。 b)第一个网络通过一个包含三个线性区域的函数，将输入 x（取值范围为 [−1, 1]）映射\\n到输出 y（取值范围为 [−1, 1]） 。这些线性区域的设计目的是让它们的斜率符号交替出现。因此，\\n多个输入 x（以灰色圆圈表示）可以被映射到同一个输出 y（以青色圆圈表示） 。 c)第二个网络\\n定义了一个包含三个线性区域的函数，它将输入 y转换为输出 y′（即将青色圆圈映射到棕色圆\\n圈） 。 d)当这两个函数结合后，它们共同作用的结果是： (i)第一个网络能将三个不同的输入 x\\n映射到任意一个特定的输出 y，以及 ((ii)第二个网络以相同的方式处理这些输出；这导致第二\\n个网络在面板 (c)中定义的函数被重复三次，并根据面板 (b)中各区域的斜率不同，进行了相应\\n的翻转和缩放处理。\\n其中ψ10=θ′\\n10+θ′\\n11ψ0,ψ11=θ′\\n11ψ1,ψ12=θ′\\n11ψ2等等。这样的结果就是一个拥有两\\n个隐藏层的网络（见图 4.4） 。\\n因此，一个含有两层的网络能够表示那些通过将单层网络的输出传递给另一个网\\n络而创建的函数族。实际上，它能表示一个更广泛的函数族，因为在方程 4.6中，九\\n个斜率参数 ψ11,psi 21,...,psi 33可以取任意值。而在方程 4.5中，这些参数受限于外积\\n[θ′\\n11,θ′\\n21,θ′\\n31]T[ψ1,ψ2,ψ3]。\\n4.3深度神经网络\\n在上一节中，我们展示了将两个浅层网络组合起来可以形成一个有两个隐藏层的特\\n殊深度网络。现在，我们将探讨一个一般情况下的深度网络，它具有两个隐藏层，每层'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 57}, page_content='42 CHAPTER 4. 深度神经网络\\n图 4.2:结合了两个神经网络，输入为二维。 a)第一个网络（源自图 3.8）包含三个隐藏单元，它\\n接收两个输入 x1和 x2，并输出一个标量 y。这个输出随后被送入一个含有两个隐藏单元的第二\\n网络，生成输出 y′。b)第一个网络构建的函数包含七个线性区域，其中一个区域保持水平。 c)\\n第二个网络定义了一个在 y∈[−1,1]范围内包含两个线性区域的函数。 d)当这两个网络结合时，\\n第一个网络中的六个非平坦区域每个都被第二网络划分为两个新的区域，总共形成了 13个线性\\n区域。\\n图 4.3:深层网络用于折叠输入空间。 a)对于图 4.1中的第一个网络，一种理解方式是它把输入\\n空间折叠，使其叠加在自身之上。 b)第二个网络则在这个已被折叠的空间上施加其功能。 c)最\\n终的输出结果，是在再次展开这些折叠后得到的。\\n含有三个隐藏单元（见图 4.4） 。\\n图 4.4:一个神经网络，它有一个输入，一个输出，并包含两个隐藏层，每层有三个隐藏单元。\\n第一层由以下公式定义：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 58}, page_content='4.3.深度神经网络 43\\n图 4.5:深层网络的计算过程。 a–c)第二隐藏层接收的输入（即预激活值）是三个分段线性函数，\\n这些函数在相同的位置连接（参见图 3.6） 。 d–f) ReLU 激活函数将每个分段线性函数的值截断\\n为零。 g–i)接着，这些被截断的函数分别以参数 ϕ′1, ϕ′2andϕ′3进行加权处理。 j)最终，这些被\\n截断且加权的函数被相加，并加上一个调节总体高度的偏移 ϕ′0。\\nh1=a[θ10+θ11x]\\nh2=a[θ20+θ21x]\\nh3=a[θ30+θ31x] (4.7)\\n接着是第二层：\\nh′\\n1=a[ψ10+ψ11h1+ψ12h2+ψ13h3]\\nh′\\n2=a[ψ20+ψ21h1+ψ22h2+ψ23h3]\\nh′\\n3=a[ψ30+ψ31h1+ψ32h2+ψ33h3] (4.8)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 59}, page_content='44 CHAPTER 4. 深度神经网络\\n以及输出层：\\ny′=ϕ0+ϕ1h′\\n1+ϕ2h′\\n2+ϕ3h′\\n3 (4.9)\\n基于这些方程，我们可以用另一种方式思考网络是如何构建出越来越复杂的函数\\n（见图4.5） ：\\n1.第一层的三个隐藏单元 h1,h2,h3通过对输入形成线性函数，然后通过 ReLU激\\n活函数来计算（参见方程 4.7） 。2.第二层的激活前状态是通过对这些隐藏单元形成三\\n个新的线性函数来计算的（参见方程 4.8） 。此时，我们实际上构建了一个有三个输出的\\n浅层网络，计算了三个具有相同转折点位置的分段线性函数（参见图 3.6） 。3.在第二隐\\n藏层，我们对每个函数应用另一个 ReLU函数a[·]（参见方程 4.8） ，这会对函数进行裁\\n剪并在每个函数中添加新的转折点。 4.最终的输出是这些隐藏单元的线性组合（参见方\\n程4.9） 。\\n总的来说，我们可以从两个角度来理解每一层的作用：一是将输入空间进行“折叠”\\n处理，二是创造新的函数，这些函数经过剪切（形成新的区域）后被重新组合。前者强\\n调了输出函数的依赖关系，但没有突出剪切如何创造新的转折点；而后者则侧重于剪切\\n和转折点的产生，但忽视了输出函数中的依赖性。最终，这两种描述都只能提供对深度\\n神经网络运作方式的部分理解。然而，重要的是不要忘记，这些都只是描述输入 x与输\\n出y′之间关系的方程式。实际上，我们可以将方程式 4.7到4.9结合起来，得到一个更\\n全面的表达式：\\ny′=ϕ′\\n0+ϕ′\\n1a[ψ10+ψ11a[θ10+θ11x]] +ψ12a[ψ20+ψ21a[θ20+θ21x]]\\n+ψ13a[ψ30+ψ31a[θ30+θ31x]] +ψ′\\n2a[ψ20+ψ21a[θ10+θ11x]]\\n+ψ22a[ψ20+ψ21a[θ20+θ21x]] +ψ23a[ψ30+ψ31a[θ30+θ31x]]\\n+ψ′\\n3a[ψ30+ψ31a[θ10+θ11x]] +ψ32a[ψ20+ψ21a[θ20+θ21x]]\\n+ψ33a[ψ30+ψ31a[θ30+θ31x]] (4.10)\\n尽管这个表达式确实有些难以理解，但它提供了对深度神经网络内部操作更加全面\\n的视角。\\n4.3.1超参数\\n我们可以将深度网络的结构扩展到不止两个隐藏层；现代的网络可能包含超过一百'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 59}, page_content='尽管这个表达式确实有些难以理解，但它提供了对深度神经网络内部操作更加全面\\n的视角。\\n4.3.1超参数\\n我们可以将深度网络的结构扩展到不止两个隐藏层；现代的网络可能包含超过一百\\n层，每层拥有数千个隐藏单元。每层隐藏单元的数量称为网络的 *宽度*，而隐藏层的\\n数量则称为网络的 *深度*。隐藏单元的总数量是衡量网络 *容量*的重要指标。\\n我们用K来代表层数， D1,D2,...,D K来表示每层的隐藏单元数量。这些都是 *\\n超参数*的典型例子。它们是在学习模型参数（即斜率和截距项）之前确定的量。对于\\n给定的超参数（比如， K= 2层，每层有 Dk= 3个隐藏单元） ，模型就定义了一个函数'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 60}, page_content='4.4.矩阵表示法 45\\n族，而具体的参数则确定了这个族中的特定函数。因此，当我们考虑到超参数时，可以\\n把神经网络看作是一系列函数族，这些函数族将输入与输出相联系。\\n4.4矩阵表示法\\n我们已经了解到深度神经网络是由线性变换和激活函数交替构成的。我们也可以用\\n矩阵表示法来等效地描述方程式 4.7到4.9：\\n2\\n664h′\\n1\\nh′\\n2\\nh′\\n33\\n775=a0\\nBB@2\\n664θ10\\nθ20\\nθ303\\n775+2\\n664θ11θ12\\nθ21θ22\\nθ31θ323\\n775\"\\nx1\\nx2#1\\nCCA, (4.11)\\n2\\n664h′\\n1\\nh′\\n2\\nh′\\n33\\n775=a0\\nBB@2\\n664ψ10\\nψ20\\nψ303\\n775+2\\n664ψ11ψ12ψ13\\nψ21ψ22ψ23\\nψ31ψ32ψ333\\n7752\\n664h1\\nh2\\nh33\\n7751\\nCCA, (4.12)\\n以及\\ny′=ϕ′\\n0+h\\nϕ′\\n1ϕ′\\n2ϕ′\\n3i2\\n664h′\\n1\\nh′\\n2\\nh′\\n33\\n775, (4.13)\\n或者更简洁地用矩阵表示法表示为：\\nh=a[θ0+ Θx]\\nh′=a[ψ0+ Ψh]\\ny′=ϕ′\\n0+ϕ′Th′(4.14)\\n在每种情况下，函数 a[·]都是将激活函数独立地应用于其向量输入的每个元素上。\\n4.4.1通用公式\\n对于层数众多的网络，上述的表示方法可能显得过于复杂。因此，我们从现在开始\\n将第k层的隐藏单元向量记作 hk，对第k+ 1层产生影响的偏置（截距）向量记作 βk，\\n以及作用于第 k层并影响第 (k+ 1)层的权重（斜率）矩阵记作 Ωk。这样，一个包含 K\\n层的通用深度网络 y=f[x,ϕ]可以表示为：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 61}, page_content='46 CHAPTER 4. 深度神经网络\\nh1=a[β0+ Ω 0x]\\nh2=a[β1+ Ω 1h1]\\nh3=a[β2+ Ω 2h2]\\n...\\nhK=a[βK−1+ Ω K−1hK−1]\\ny=βK+ Ω KhK. (4.15)\\n这个模型的参数 ϕ包括了所有的权重矩阵和偏置向量，表示为 ϕ={βk,Ωk}K\\nk=0。\\n如果第k层有Dk个隐藏单元，那么偏置向量 βk−1的维度就是 Dk。最后一个偏置\\n向量βK的维度是输出的 D0。第一个权重矩阵 Ω0的维度是D1×Di，其中Di是输入的\\n维度。最后一个权重矩阵 ΩK的维度是D0×DK，其余的矩阵 Ωk的维度是Dk+1×Dk\\n（参见图 4.6） 。\\n图 4.6:描述一个具有 Di= 3维输入 x，Do= 2维输出 y以及 K = 3个隐藏层 h1, h2, h3的\\n网络的矩阵表示法，这些隐藏层的维度分别是 D1= 4, D2= 2和D3= 3。权重以矩阵 Ωk的\\n形式存储，通过与前一层的激活值相乘来为下一层生成预激活值。例如， Ω1是一个 2 × 4的矩\\n阵，用于计算从第一层的激活值到第二层的预激活值。这个矩阵作用于第一层的四个隐藏单元，\\n并为第二层的两个隐藏单元生成输入。偏置则以向量 βk的形式存储，其维度与其输入的层相对\\n应。比如，偏置向量 β2长度为三，因为 h3层包含三个隐藏单元。\\n我们也可以将整个网络等效地表示为一个单一函数：\\ny=βK+ Ω K[βK−1+ Ω K−1[...a[β2+ Ω 2[a[β1+ Ω 1[a[β0+ Ω 0x]]...]].(4.16)\\n4.5浅层网络与深层网络的比较\\n第3章讨论了单隐藏层的浅层网络，而本章我们讨论了多隐藏层的深层网络。现在，\\n我们来比较这两种模型。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 62}, page_content='4.5.浅层网络与深层网络的比较 47\\n4.5.1逼近不同函数的能力\\n在第3.2节，我们提出了一个观点：具备足够容量（隐藏单元）的浅层神经网络能\\n够极其接近地模拟任何连续函数。本章我们了解到，一个包含两个隐藏层的深层网络能\\n够实现两个浅层网络的功能组合。如果其中一个网络执行恒等函数，那么这个深层网络\\n就等同于一个浅层网络。因此，它也能在拥有足够容量的情况下非常接近地逼近任何连\\n续函数。\\n4.5.2每个参数产生的线性区域数量\\n一个有一个输入、一个输出和 D > 2个隐藏单元的浅层网络能够创造最多 D+ 1个\\n线性区域，由 3D+ 1个参数定义。相比之下，一个有一个输入、一个输出和 K层D > 2\\n个隐藏单元的深层网络能够使用 3D+ 1 + (K−1)D(D+ 1)个参数创造最多 (D+ 1)K\\n个线性区域的函数。\\n图4.7a展示了对于将标量输入 x映射到标量输出 y的网络，最大线性区域数量随\\n参数数量增加而增加的趋势。深层神经网络在固定参数预算下可以创造出更复杂的函\\n数。当输入维度 Di增加时，这种效果更加显著（参见图 4.7b） ，尽管计算最大区域数量\\n的方法更加复杂。\\n图 4.7:随着网络深度的增加，神经网络能够产生的线性区域数量急剧增加。 a)输入为 Di= 1\\n的网络。每条曲线代表在不同隐藏层 K数量下，变化每层隐藏单元 D数量的情况。在相同参数\\n限制（水平位置）下，较深的网络能比较浅的网络产生更多线性区域。例如，一个 K = 5层、每\\n层 D = 10隐藏单元的网络有 471个参数（突出显示的点） ，可以产生 161,051 个区域。 b)输\\n入为 Di= 10的网络。曲线上的每个点代表增加了十个隐藏单元。在这种情况下，一个 K = 5\\n层、每层 D = 50隐藏单元的模型拥有 10,801个参数（突出显示的点） ，能创建超过 10134个\\n线性区域。\\n尽管这听起来很吸引人，但函数的灵活性仍然受到参数数量的限制。深度网络能够\\n创建大量的线性区域，但这些区域中存在着复杂的依赖性和对称性。我们在之前讨论过\\n深层网络如何通过“折叠”输入空间来实现这一点（参见图 4.3） 。因此，除非我们希望\\n逼近的现实世界函数中存在相似的对称性，或者我们有理由相信输入到输出的映射真的\\n涉及到简单函数的组合，否则更多的区域数量并不一定是一个优势。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 63}, page_content='48 CHAPTER 4. 深度神经网络\\n4.5.3深度效率\\n深层和浅层网络都能模拟任意函数，但某些函数使用深层网络进行逼近会更有效\\n率。事实上，已经发现某些函数需要浅层网络有指数级更多的隐藏单元才能与深层网络\\n实现同等水平的逼近。这种现象被称为神经网络的“深度效率” 。虽然这听起来很有吸\\n引力，但目前尚不清楚我们想要逼近的真实世界函数是否符合这种特性。\\n4.5.4大型结构化输入\\n我们讨论了每一层的每个元素都与下一层的每个元素相连的完全连接网络。但这种\\n网络对于像图像这样的大型结构化输入来说并不实际，因为输入可能包含大约 106个像\\n素。参数数量会非常庞大，而且我们希望图像的不同部分以类似的方式进行处理；没有\\n必要在图像的每个可能位置都独立学习识别同一对象。\\n解决方案是并行处理图像的局部区域，然后逐步整合来自更大区域的信息。这种由\\n局部到全局的处理方式在没有多层结构的情况下很难实现（参见第 10章） 。\\n4.5.5训练和泛化\\n深层网络相比于浅层网络的另一个潜在优势是它们更容易训练；通常训练中等深度\\n的网络比浅层网络要容易（参见图 20.2） 。这可能是因为过度参数化的深层模型存在许\\n多大致相同且易于找到的解决方案。然而，随着隐藏层的增加，训练又变得更加困难，\\n尽管已经发展了许多缓解这一问题的方法（参见第 11章） 。\\n深度神经网络在泛化到新数据方面似乎也比浅层网络表现更佳。在实际应用中，大\\n多数任务的最佳结果是通过使用数十甚至数百层的网络实现的。这两种现象都尚未被充\\n分理解，我们将在第 20章中进一步探讨这些主题。\\n4.6总结\\n本章首先探讨了组合两个浅层网络时所发生的情况。我们认为，第一个网络对输入\\n空间进行了“折叠” ，随后第二个网络应用了一个分段线性函数。在输入空间被折叠到\\n其自身时，第二个网络的效果得到了复制。\\n接着，我们证明了这种浅层网络组合实际上是具有两个隐藏层的深层网络的一种特\\n例。我们解释了每一层中的 ReLU函数如何在多个位置剪切输入函数，并在输出函数中\\n创建更多的“关节” 。我们引入了超参数的概念，对于我们目前讨论的网络而言，它包\\n括了隐藏层的数量和每层中隐藏单元的数量。\\n最后，我们对浅层和深层网络进行了比较。我们发现： (i)给定足够容量，两种网络\\n都能逼近任何函数； (ii)相比之下，深层网络每个参数能产生更多的线性区域； (iii)某'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 63}, page_content='最后，我们对浅层和深层网络进行了比较。我们发现： (i)给定足够容量，两种网络\\n都能逼近任何函数； (ii)相比之下，深层网络每个参数能产生更多的线性区域； (iii)某\\n些函数可以通过深层网络更有效率地逼近； (iv)像图像这样的大型结构化输入更适合通\\n过多阶段处理； (v)实践中，大多数任务使用多层的深层网络能达到最佳效果。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 64}, page_content='4.7.笔记 49\\n了解了深层和浅层网络模型后，我们接下来将关注它们的训练过程。在下一章，我\\n们将讨论损失函数，它对于任何给定的参数值 ϕ，提供了一个指标，显示模型输出与训\\n练数据集中的真实预测之间的差异。在第 6章和第7章中，我们将深入训练过程本身，\\n探索如何寻找使损失最小化的参数值。\\n4.7笔记\\n深度学习 ：长期以来人们已经理解，通过组合浅层神经网络或发展具有多个隐藏层\\n的网络，可以构建更复杂的函数。事实上， “深度学习”这个术语最早由 Dechter在1986\\n年使用。然而，由于实际问题，人们对此的兴趣有限；无法很好地训练这些网络。深度\\n学习的现代时代是由 Krizhevsky 等人在2012年报告的图像分类方面的惊人改进所启动\\n的。这一突破性进展可以说是由四个因素的汇聚造成的：更大的训练数据集、训练时更\\n强大的处理能力、使用 ReLU激活函数和使用随机梯度下降（见第 6章） 。LeCun等人\\n在2015年提供了现代深度学习早期进展的概览。\\n线性区域数量 ：对于使用总共 D个隐藏单元和 ReLU激活的深度网络，区域数量\\n的上限是 2D（Montufar 等人，2014） 。同样的作者展示了一个具有 Di维输入和K层、\\n每层包含D≥Di个隐藏单元的深度 ReLU网络，具有 O\\x12\\x10\\nD\\nDi\\x11(K−1)DiDD i\\x13\\n个线性\\n区域。Montufar （2017） 、Arora等人（2016）和Serra等人（2018）都提供了考虑到每\\n层有不同数量隐藏单元的可能性的更紧密的上限。 Serra等人（2018）提供了一个计算\\n神经网络中线性区域数量的算法，尽管它只适用于非常小的网络。\\n如果K层中的每层隐藏单元数量 D相同，并且 D是输入维度 Di的整数倍，则最\\n大线性区域数量 Nr可以精确计算，为：\\nNr=\\x12D\\nDi+ 1\\x13Di(K−1)\\n·DiX\\nj=0\\x12D\\nj\\x13\\n(4.17)\\n这个表达式中的第一项对应于网络的前 K−1层，可以被认为是反复折叠输入空\\n间。然而，我们现在需要将D\\nDi个\\n隐藏单元分配给每个输入维度以创建这些折叠。这个方程中的最后一项（二项式系\\n数之和） 是浅层网络可以创建的区域数量， 归因于最后一层。 更多信息， 请参考 Montufar\\n等人（2014） 、Pascanu 等人（2013）和Montufar （2017） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 64}, page_content='数之和） 是浅层网络可以创建的区域数量， 归因于最后一层。 更多信息， 请参考 Montufar\\n等人（2014） 、Pascanu 等人（2013）和Montufar （2017） 。\\n通用逼近定理 ： 我们在 4.5.1节中讨论了一个观点， 即如果深度网络的各层包含足够\\n多的隐藏单元，那么宽度版本的通用逼近定理将适用。这意味着存在一种网络结构，它\\n能够在RDi的一个紧凑子集上，以任意精度逼近任何给定的连续函数。 Lu et al. (2017)\\n证实，只要层数足够，每层至少包含 Di+ 4个隐藏单元的带有 ReLU激活函数的网络，\\n能够以任意精度逼近任何指定的 Di维勒贝格（ Lebesgue ）可积函数。这被称作通用逼\\n近定理的 深度版本 。\\n深度效率 ：近期研究显示，某些函数可以被深度网络实现，但无法被容量上限呈指'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 65}, page_content='50 CHAPTER 4. 深度神经网络\\n数级增长的浅层网络所表达。换言之，浅层网络要准确描述这些函数，需要指数级增加\\n其单元数量。这种现象被称为神经网络的 深度效率 。\\nTelgarsky (2016) 指出，对于任意整数 k，可以构建一个具有单一输入、单一输出，\\n并且包含O[k3]层恒定宽度的网络，这样的网络不能用少于 2k宽度的O[k]层来实现。\\n更令人惊讶的是， Eldan & Shamir (2016) 发现，当涉及到多变量输入时，某些三层网络\\n无法由任何两层网络实现，前提是两层网络的容量低于输入维度的亚指数级。 Cohen et\\nal. (2016) 、Safran & Shamir (2017. 和Poggio et al. (2017) 同样展示了深层网络能够有\\n效逼近的函数，而这些函数对于浅层网络却难以做到。 Liang & Srikant (2016) 则表明，\\n在一定的逼近误差上限条件下，对于包括单变量函数在内的广泛函数类别，浅层网络需\\n要远比深层网络多的指数级隐藏单元。\\n宽度效率 ：Lu et al. (2017) 探讨了这样一个问题：是否存在宽而浅的网络（即，隐\\n藏单元众多的浅层网络） ，而这些网络却无法通过深度不显著增加的窄网络来实现。他\\n们发现，确实存在一类宽而浅的网络，只有通过深度为多项式级别的窄网络才能表达。\\n这被称为神经网络的宽度效率。相对于深度的指数级下界限制，宽度的多项式级下界限\\n制显得更为宽松，这表明在网络设计中，深度比宽度更为重要。 Vardi et al. (2022) 进一\\n步证明，对于带有 ReLU激活函数的网络，减小宽度的代价仅是网络深度的线性增加。\\n4.8习题\\n问题 4.1考虑组合图 4.8中的两个神经网络。请绘制一张图， 展示当输入 x在[-1,1]\\n范围内变化时，输出 y′的变化关系。\\n图 4.8:针对问题 4.1，展示了两个网络的组合。 a)第一个网络的输出 y转化为第二个网络的\\n输入。 b)第一个网络在输出值 y∈[−1,1]的范围内计算该函数。 c)第二个网络则在输入范围\\ny∈[−1,1]内计算该函数。\\n问题 4.2请确定图 4.6中的四个超参数。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 66}, page_content='4.8.习题 51\\n问题 4.3利用ReLU（修正线性单元）函数的非负同质性质（见问题 3.5） ，证明以\\n下等式：\\nReLU [β1+λ1·Ω1ReLU [β0+λ0·Ω0x]] =λ0λ1·ReLU [1\\nλ0λ1β1+ Ω 1ReLU [1\\nλ0β0+ Ω 0x]]\\n(4.18)\\n其中λ0和λ1是非负数值标量。由此可见，只要同时调整偏置，并在网络末端重新\\n应用这些缩放因子，就可以任意缩放权重矩阵。\\n问题 4.4编写一个深度神经网络的方程，该网络有 Di= 5个输入、Do= 4个输出，\\n并且有三个隐藏层，其大小分别为 D1= 20,D2= 10和D3= 7。使用方程式 4.15和\\n4.16的形式表示。每个权重矩阵（ Weight Matrix ）Ω和偏置向量（ Bias Vector ）β的大\\n小分别是多少？\\n问题 4.5考虑一个深度神经网络，它有 Di= 5个输入、Do= 1个输出，以及\\nK= 20个隐藏层，每层含有 D= 30个隐藏单元。请问这个网络的深度和宽度分别是\\n多少？\\n问题 4.6考虑一个网络，它有 Di= 1个输入、Do= 1个输出，并且有 K= 10层，\\n每层包含D= 10个隐藏单元。如果我们增加一层深度或增加每层的单元数量，哪种情\\n况下权重的数量会增加更多？请给出你的理由。\\n问题 4.7为方程3.1中的浅层神经网络选择参数\\nϕ=ϕ0,ϕ1,ϕ2,ϕ3,θ10,θ11,θ20,θ21,θ30,θ31\\n的值，使得该网络在有限范围 x∈[a,b]上定义一个恒等函数。\\n问题 4.8*图4.9展示了一个浅层网络（如图 3.3所示）中三个隐藏单元的激活情\\n况。隐藏单元的斜率分别为 1.0, 1.0和-1.0，隐藏单元的“关节”位置分别在 1/6, 2/6\\n和4/6。找出ϕ0,ϕ1,ϕ2和ϕ3的值，使得隐藏单元激活的组合为 ϕ0+ϕ1h1+ϕ2h2+ϕ3h3，\\n以创建一个具有四个线性区域的函数，这些区域的输出值在零和一之间摆动。最左边区\\n域的斜率应该是正的，下一个是负的，依此类推。如果我们将这个网络与自身组合，将\\n会创建多少个线性区域？如果我们将其与自身组合 K次，将会创建多少个？\\n图 4.9:针对问题 4.8的隐藏单元激活情况。 a)第一个隐藏单元在 x = 1/6 的位置形成一个拐'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 66}, page_content='会创建多少个线性区域？如果我们将其与自身组合 K次，将会创建多少个？\\n图 4.9:针对问题 4.8的隐藏单元激活情况。 a)第一个隐藏单元在 x = 1/6 的位置形成一个拐\\n点，其激活区域的斜率为正一。 b)第二个隐藏单元在 x = 2/6 的位置形成一个拐点，其激活区\\n域的斜率同样为正一。 c)第三个隐藏单元在 x = 4/6 的位置形成一个拐点，但其激活区域的斜\\n率为负一。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 67}, page_content='52 CHAPTER 4. 深度神经网络\\n问题 4.9*继续问题 4.8，使用一个有两个隐藏单元的浅层网络，能否创建一个具有\\n三个线性区域的函数，其输出值在零和一之间来回摆动？使用一个有四个隐藏单元的浅\\n层网络，能否创建一个以同样方式摆动的具有五个线性区域的函数？\\n问题 4.10考虑一个深度神经网络，它有一个输入、一个输出，以及 K个隐藏层，\\n每层包含D个隐藏单元。展示这个网络总共有 3D+ 1 + (K−1)D(D+ 1)个参数。\\n问题 4.11*考虑两个将标量输入 x映射到标量输出 y的神经网络。第一个网络是\\n浅层的，有 D= 95个隐藏单元。第二个是深层的，有 K= 10层，每层包含 D= 5个隐\\n藏单元。每个网络有多少参数？每个网络可以制造多少个线性区域？哪个运行得更快？'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 68}, page_content='Chapter 5\\n损失函数\\n前三章分别介绍了线性回归、浅层神经网络和深度神经网络。这些都属于函数家族，\\n能够实现从输入到输出的映射，其具体的函数取决于模型参数 ϕ。在训练这些模型时，\\n我们的目标是找到能够为特定任务提供最优输入输出映射的参数。本章将详细阐述“最\\n优映射”的含义。\\n要定义“最优映射” ，首先需要一组训练数据集 {xi,yi}，即输入和输出的配对。损\\n失函数（ Loss Function ）L[ϕ]能够返回一个数值，这个数值描述了模型预测 f(xi,ϕ)与\\n其对应的真实输出 yi之间的不匹配程度。在训练过程中，我们追求的是能最小化损失\\n的参数值ϕ，以使训练输入尽可能准确地映射到输出。例如，在第 2章中，我们见到了\\n一种损失函数——最小平方损失函数，适用于目标是实数 y∈R的单变量回归问题。该\\n函数通过计算模型预测 f(xi,ϕ)与真实值yi之间差异的平方和来进行计算。\\n本章还提出了一个框架，不仅证明了在实值输出场景下选择最小平方准则的适用\\n性，还指导我们为其他类型的预测问题构建损失函数。我们将讨论包括二元分类（其中\\n预测结果y∈{0,1}属于两个类别中的一个）和多类别分类（预测结果 y∈{1,2,...,K}\\n属于K个类别中的一个）在内的多种情形。在接下来的两章中，我们将探讨模型训练\\n的过程，目标是找到能最小化这些损失函数的参数值。\\n5.1最大似然\\n在本节中，我们将介绍构建损失函数的具体方法。设想一个计算输入 x到输出的模\\n型f(x,ϕ)， 其中ϕ是模型的参数。之前， 我们认为模型直接输出预测结果 y。现在， 我们\\n改变思路， 将模型视为计算给定输入 x时， 可能的输出 y的条件概率分布 Pr(y|x)。 这种\\n损失函数的设计目的是使得每个训练输出 yi在由对应输入 xi计算得到的分布 Pr(yi|xi)\\n中具有较高的概率（见图 5.1） 。\\n53'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 69}, page_content='54 CHAPTER 5. 损失函数\\n图 5.1: a)回归任务中，目标是基于训练数据 xi, yi（橙色点）从输入 x预测出一个实数输出 y。\\n对于每个输入值 x，机器学习模型预测输出 y∈R的分布 P(y|x)（青色曲线展示了 x = 2.0和\\nx = 7.0时的分布） 。损失函数的目的是使根据相应输入 xi预测出的分布最大化观测到的训练输\\n出yi的概率。 b)在分类任务中，为预测离散类别 y∈1,2,3,4，我们采用离散概率分布，模型\\n因此针对 xi的每个值预测 yi的四个可能值的概率分布直方图。 c)在预测计数 y∈0,1,2, ...和\\nd)预测方向 y∈(−π, π]的任务中，我们分别采用定义在正整数集和圆周域上的分布。\\n5.1.1计算输出的分布\\n这引出了一个问题：模型 f(x,ϕ)如何转化为计算概率分布的形式。答案很简单。首\\n先，我们需要选定一个定义在输出域 Y上的参数化概率分布 Pr(y|θ)。接着，我们利用\\n神经网络来计算该分布的一个或多个参数 θ。\\n例如，假设预测域是实数集，即 y∈R。在这种情况下，我们可能选择单变量正态\\n分布，它在 R上有定义。该分布由均值 µ和方差σ2所决定，因此 θ={µ,σ2}。机器学\\n习模型可以用来预测均值 µ，而方差σ2则可以视为一个待定的常数。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 70}, page_content='5.1.最大似然 55\\n5.1.2最大似然准则\\n模型现在针对每个训练输入 xi计算不同的分布参数 θi=f(xi,ϕ)。我们的目标是使\\n每个训练输出 yi在其相应的分布 Pr(yi|θi)下具有较高概率。因此，我们选择模型参数\\nϕ，以最大化所有 I个训练样本的联合概率：\\nˆϕ=argmax ϕ\"IY\\ni=1Pr(yi|xi)#\\n=argmax ϕ\"IY\\ni=1Pr(yi|θi)#\\n=argmax ϕ\"IY\\ni=1Pr(yi|f(xi,ϕ))#\\n(5.1)\\n这个联合概率项反映的是参数的似然（ Likelihood ） ，因此方程 5.1称为最大似然准\\n则（Maximum Likelihood Criterion ）[1]。\\n这里我们基于两个假设。首先，我们假设所有数据点的输出 yi都服从相同的概率\\n分布，即数据是同分布的。其次，我们认为给定输入的输出的条件分布 Pr(yi|xi)是相\\n互独立的，因此整个训练数据集的似然可以表示为：\\nPr(y1,y2,...,y I|x1,x2,...,x I) =IY\\ni=1Pr(yi|xi) (5.2)\\n换言之，我们假定数据是独立同分布（ i.i.d.）的。\\n图 5.2:对数变换。 a)对数函数是单调递增的，即若 z > z′，则 logz > logz′。因此，任何函数\\ng(z)的最大值位置与 log g(z)的最大值位置相同。 b)函数 g(z)。c)该函数的对数 log g(z)。g(z)\\n上所有正斜率的位置在经过对数变换后依然保持正斜率，负斜率的位置同样保持负斜率。最大\\n值位置不变。\\n5.1.3最大化对数似然\\n尽管最大似然准则（方程 5.1）理论上有效，但在实际应用中并不方便。每个项\\nPr(yi|f(xi,ϕ))的值可能很小，导致这些项的乘积极小，难以用有限精度算法精确表示。\\n幸运的是，我们可以通过最大化似然的对数来解决这个问题：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 71}, page_content='56 CHAPTER 5. 损失函数\\nˆϕ=argmax ϕ\"IY\\ni=1Pr(yi|f(xi,ϕ))#\\n=argmax ϕ\"\\nlogIY\\ni=1Pr(yi|f(xi,ϕ))#\\n=argmax ϕ\"IX\\ni=1logPr(yi|f(xi,ϕ))#\\n(5.3)\\n由于对数是单调递增函数，对数似然准则与原始最大似然准则在数学上是等价的。\\n这意味着，提高对数似然准则的同时，也就提高了最大似然准则。因此，两种准则的最\\n大值位置是相同的，最优的模型参数 ˆϕ在两种情况下都是一致的。同时，对数似然准则\\n通过求和而非乘积，避免了精度问题。\\n5.1.4最小化负对数似然\\n通常，模型拟合问题是以最小化损失的方式来定义的。为了将最大对数似然准则转\\n换为一个最小化问题，我们通过乘以负一得到负对数似然准则：\\nˆϕ=argmin ϕ\"\\n−IX\\ni=1logPr(yi|f(xi,ϕ))#\\n=argmin ϕ[L[ϕ]] (5.4)\\n这就构成了最终的损失函数 L[ϕ]。\\n5.1.5推断\\n如今，网络不再直接预测输出 y，而是确定了一个关于 y的概率分布。在进行推断\\n时，我们一般需要一个具体的估计值而不是整个分布，因此我们选择分布的最大值作为\\n预测：\\nˆy=argmax y[Pr(y|f(x,ϕ))] (5.5)\\n我们通常可以根据模型预测的分布参数 θ来确定这个估计值。例如，在单变量正态\\n分布中，最大值出现在均值 µ处。\\n5.2构建损失函数的步骤\\n根据最大似然方法，针对训练数据 {xi,yi}构建损失函数的步骤如下：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 72}, page_content='5.3.示例 1：单变量回归 57\\n1.选定一个适合预测结果 y的概率分布 Pr(y|θ)，并确定其分布参数 θ。2.设\\n定机器学习模型 f(x,ϕ)来预测这些参数中的一个或多个，即 θ=f(x,ϕ)，Pr(y|θ) =\\nPr(y|f(x,ϕ))。3.为训练模型，寻找最小化负对数似然损失函数的模型参数 ϕ：\\nˆϕ=argmin ϕ[L[ϕ]] =argmin ϕ\"\\n−IX\\ni=1logPr(yi|f(xi,ϕ))#\\n(5.6)\\n4.对于新的测试样例 x，返回完整分布 Pr(y|f(x,ϕ))或此分布的最大值。\\n本章其余部分主要讨论如何使用这种方法为常见的预测类型构建损失函数。\\n图 5.3:单变量正态分布（也被称为高斯分布）是在实数轴 z∈R上定义的，其主要由两个参数\\nµ和σ2决定。其中，均值 µ决定了分布的峰值位置，而方差 σ2的标准差（即方差的正平方根）\\n则决定了分布的宽度。因为整个概率密度的总和为一，所以当方差减小，分布变得更加集中时，\\n其峰值也相应地变得更高。\\n5.3示例 1：单变量回归\\n首先考虑单变量回归模型。这里的目标是用带有参数 ϕ的模型f(x,ϕ)，从输入x\\n预测单一实数输出 y∈R。遵循上述步骤，我们为输出域 y选择一个概率分布。我们选\\n用单变量正态分布（见图 5.3） ，它定义在 y∈R上。该分布有两个参数（均值 µ和方\\n差σ2） ，并具有概率密度函数：\\nPr(y|µ,σ2) =1√\\n2πσ2exp\\x14\\n−(y−µ)2\\n2σ2\\x15\\n(5.7)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 73}, page_content='58 CHAPTER 5. 损失函数\\n接着，我们让机器学习模型 f(x,ϕ)计算这个分布的一个或多个参数。在这里，我\\n们只计算均值 µ=f(x,ϕ)：\\nPr(y|f(x,ϕ),σ2) =1√\\n2πσ2exp\\x14\\n−(y−f(x,ϕ))2\\n2σ2\\x15\\n(5.8)\\n我们的目标是找到使训练数据 {xi,yi}在此分布下尽可能概率最高的参数 ϕ（参见图\\n5.4） 。为此，我们选择了基于负对数似然的损失函数 L[ϕ]：\\nL[ϕ] =−IX\\ni=1log\\x02\\nPr(yi|f(xi,ϕ),σ2)\\x03\\n=−IX\\ni=1log\\x141√\\n2πσ2exp\\x14\\n−(yi−f(xi,ϕ))2\\n2σ2\\x15\\x15\\n(5.9)\\n在训练模型时，我们的目标是找到最小化这一损失的参数 ˆϕ。\\n5.3.1最小平方损失函数\\n我们对损失函数进行一系列代数操作，目的是寻找：\\nˆϕ=argmin\\nϕ\"\\n−IX\\ni=1log\\x141√\\n2πσ2exp\\x14\\n−(yi−f[xi,ϕ])2\\n2σ2\\x15\\x15#\\n=argmin\\nϕ\"\\n−IX\\ni=1\\x12\\nlog\\x141√\\n2πσ2\\x15\\n−(yi−f[xi,ϕ])2\\n2σ2\\x13#\\n=argmin\\nϕ\"\\n−IX\\ni=1\\x12\\n−(yi−f[xi,ϕ])2\\n2σ2\\x13#\\n=argmin\\nϕ\"IX\\ni=1(yi−f[xi,ϕ])2\\n2σ2#\\n=argmin\\nϕ\"IX\\ni=1(yi−f[xi,ϕ])2#\\n(5.10)\\n在这里，我们去除了与 ϕ无关的项，并忽略了常数缩放因子，因为它不影响最小值\\n的位置。\\n通过这些操作，我们得到了最小平方损失函数，这是我们在第 2章讨论线性回归时\\n首次提出的：\\nL[ϕ] =IX\\ni=1(yi−f(xi,ϕ))2(5.11)\\n最小平方损失函数的自然来源于两个假设：预测误差（ i）是独立的，并且（ ii）遵循均\\n值为µ=f(xi,ϕ)的正态分布（参见图 5.4） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 74}, page_content='5.3.示例 1：单变量回归 59\\n5.3.2推断\\n网络现在不直接预测 y，而是预测 y的正态分布均值 µ=f(x,ϕ)。在进行推断时，\\n我们通常寻求一个最佳的单点估计，因此我们选择预测分布的最大值：\\nˆy=argmax\\ny[Pr(y|f(x,ϕ))] (5.12)\\n在单变量正态分布中，最大值位置由均值参数 µ决定（参见图 5.3） 。这正是模型所\\n计算的，因此 ˆy=f(x,ϕ)。\\n5.3.3估计方差\\n在制定最小平方损失函数时，我们假定网络预测了正态分布的均值。有趣的是，方\\n程5.11中的最终表达式并不依赖于方差 σ2。但我们可以将 σ2视为模型的参数之一，并\\n对模型参数 ϕ和分布的方差 σ2一起最小化方程 5.9：\\nˆϕ,ˆσ2=argmin\\nϕ,σ2\"\\n−IX\\ni=1log\\x141√\\n2πσ2exp\\x12\\n−(yi−f(xi;ϕ))2\\n2σ2\\x13\\x15#\\n(5.13)\\n在推断阶段，模型从输入中预测均值 µ=f[x,ˆϕ]，同时我们在训练过程中得到了方\\n差ˆσ2的估计。均值是最优预测，而方差反映了预测的不确定性。\\n5.3.4异方差回归\\n先前的模型假定数据方差是固定的，但这可能不太现实。当模型的不确定性随输入\\n数据变化时，我们称之为异方差（与同方差相对，后者不确定性是固定的） 。\\n一种处理这种情况的简单方法是训练一个神经网络 f(x,ϕ)来同时计算均值和方差。\\n举个例子，考虑一个输出两个值的浅层网络，其中第一个输出 f1(x,ϕ)预测均值，第二\\n个输出f2(x,ϕ)预测方差。\\n为了确保计算的方差始终为正，我们需要对网络的第二个输出应用一个能映射到正\\n数的函数。一个好的选择是使用平方函数，得到：\\nµ=f1(x,ϕ)\\nσ2=f2(x,ϕ)2(5.14)\\n这样就得到了以下损失函数：\\nˆϕ=argmin ϕ\"\\n−IX\\ni=1log\"\\n1p\\n2πf2(xi,ϕ)2exp\\x14\\n−(yi−f1(xi,ϕ))2\\n2f2(xi,ϕ)2\\x15##\\n(5.15)\\n图5.5对比了同方差和异方差模型。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 75}, page_content='60 CHAPTER 5. 损失函数\\n图 5.4:最小二乘法与正态分布最大似然损失的等效性。 a)参照图 2.2中的线性模型。最小二乘\\n法通过最小化模型预测值 f[xi, ϕ]（绿线）与真实输出值 yi（橙色点）之间差异（虚线表示）的\\n平方和来进行优化。在此例中，模型拟合非常准确，因此这些差异非常小（比如，对于被特别标\\n出的两个点） 。 b)当参数设置不当时，模型拟合效果较差，导致平方差异显著增加。 c)最小二乘\\n法的原理是假设模型预测的是输出值的正态分布的平均值，并且我们通过最大化概率来优化它。\\n在第一种情况下，由于模型拟合得很好，所以数据的概率 P r(yi|xi)（水平橙色虚线）较高（相\\n应的负对数概率较小） 。 d)在第二种情况下，由于模型拟合效果差，因此概率较低，负对数概率\\n较高。\\n5.4示例 2：二元分类\\n在二元分类任务中，我们的目标是根据数据 x将其划分为两个离散类别之一 y∈\\n{0,1}。这里的y被称为标签。二元分类的例子包括： （ i）根据文本数据 x判断餐厅评论\\n是正面（y= 1）还是负面（ y= 0） ； （ii）根据MRI扫描x判断肿瘤是否存在（ y= 1）\\n或不存在（ y= 0） 。\\n我们再次按照第 5.2节的步骤构建损失函数。首先，我们为输出空间 y∈{0,1}选\\n择了伯努利分布，这个分布定义在 {0,1}上。它有一个参数 λ∈[0,1]，表示y取值为1\\n的概率（见图 5.6） ：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 76}, page_content='5.4.示例 2：二元分类 61\\n图 5.5:同方差回归与异方差回归比较。 a)在同方差回归中，一个简单的神经网络模型根据输入\\nx预测输出分布的平均值 µ。b)这种情况下，尽管输出的均值（用蓝线表示）随输入 x呈分段线\\n性变化，方差却始终保持不变（通过箭头和灰色区域表示的 ±2标准差来展示） 。 c)异方差回归\\n的浅层神经网络除了预测均值外，还会预测输出的方差 σ2（更精确地说，是计算方差的平方根，\\n然后再平方） 。 d)如此一来，标准差也随输入 x呈分段线性变化。\\n图 5.6:伯努利分布。伯努利分布是定义在仅包含 0,1的域上的分布，它由单一参数 λ定义， λ\\n表示观测到结果为 1的概率。相应地，结果为 0的概率则为 1−λ。\\nPr(y|λ) =8\\n<\\n:1−λify= 0\\nλify= 1(5.16)\\n也可以写成：\\nPr(y|λ) = (1−λ)1−y·λy(5.17)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 77}, page_content='62 CHAPTER 5. 损失函数\\n图 5.7:逻辑 Sigmoid 函数。该函数把实数 z映射到 0到 1之间的值，因此 sig[z]的范围是 [0,\\n1]。当输入为 0时，输出值为 0.5。负数输入对应于小于 0.5的输出值，而正数输入对应于大于\\n0.5的输出值。\\n然后，我们设置机器学习模型 f(x,ϕ)来预测单一参数 λ。但由于λ只能在[0, 1]范围\\n内取值，我们需要通过一个函数将网络输出映射到这个范围内。一个合适的函数是逻辑\\n斯蒂sigmoid函数（见图 5.7） ：\\nsig[z] =1\\n1 +exp[−z](5.18)\\n因此，我们预测的分布参数为 λ=sig[f(x,ϕ)]。现在的似然表达式为：\\nPr(y|x) = (1−sig[f(x,ϕ)])1−y·sig[f(x,ϕ)]y(5.19)\\n这在图5.8中展示了一个浅层神经网络模型。损失函数是训练集的负对数似然：\\nL[ϕ] =IX\\ni=1−[(1−yi)log[1−sig[f(xi,ϕ)]] +yilog[sig[f(xi,ϕ)]]] (5.20)\\n由于第5.7节将会解释的原因，这称为二元交叉熵损失。\\n变换后的模型输出 sig[f(x,ϕ)]预测了伯努利分布的参数 λ。这代表y= 1的概率，\\n所以 1−λ代表y= 0的概率。在进行推断时，如果我们需要 y的具体估计，那么当\\nλ>0.5时我们设定 y= 1，否则设定 y= 0。\\n5.5示例 3：多类别分类\\n多类别分类的目标是将输入数据 x分配给K > 2个类别中的一个，即 y∈\\n{1,2,...,K}。现实中的例子包括： （ i）预测手写数字图像 x中的哪一个数字 y'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 78}, page_content='5.5.示例 3：多类别分类 63\\n图 5.8:二元分类模型。 a)网络的输出是一个分段线性函数，能够接受任意实数值。 b)这些值\\n通过逻辑 Sigmoid 函数转换，被压缩到 [0,1]的区间内。 c)转换后的输出用来预测概率 λ，即 y\\n= 1的可能性（用实线表示） 。因此， y = 0的可能性就是 1−λ（用虚线表示） 。对任一固定的\\nx（通过垂直切片展示） ，我们能得到一个与图 5.6类似的伯努利分布的两种概率值。损失函数倾\\n向于优化模型参数，使得在与正例 yi = 1关联的 xi位置上 λ的值较大，而在与负例 yi = 0关\\n联的位置上 λ的值较小。\\n图 5.9:分类分布。分类分布为超过两个的 K类别分配概率值，相应的概率为 λ1, λ2, ..., λ K.这\\n里有五个类别，因此 K= 5。为保证其为一个有效的概率分布，每个参数 λk都应处于 [0, 1]的\\n范围内，并且所有 K个参数的总和必须等于 1。\\n（K= 10） ； （ii）预测不完整句子 x后面跟随的哪一个词汇 y（K个可能词汇） 。\\n我们再次遵循第 5.2节的步骤。首先，对于输出空间 y∈{1,2,...,K}，我们选择\\n分类分布（见图 5.9） 。这个分布有 K个参数λ1,λ2,...,λ K，它们确定每个类别的概率：\\nPr(y=k) =λk (5.21)\\n参数被限制在零和一之间，并且总和必须为一，以形成有效的概率分布。\\n然后，我们利用具有 K个输出的网络 f(x,ϕ)来从输入x计算这K个参数。为了\\n确保网络输出符合约束，我们通过一个函数处理这 K个输出，这个函数是 *softmax*\\n函数（见图 5.10） 。softmax函数接受长度为 K的任意向量，并返回一个同样长度的向'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 79}, page_content='64 CHAPTER 5. 损失函数\\n图 5.10:针对 K = 3类别的多类别分类。 a)该网络输出三个可以任意取值的分段线性函数。 b)\\n通过 softmax函数处理后，这些输出值被限制为非负数，且它们的总和必须为一。因此，对于任\\n何给定的输入 x，我们都能得到有效的分类分布参数：图中任意垂直切片所产生的三个值的总和\\n为一，这些值代表在类似图 5.9的分类分布条形图中各条的高度。\\n量，其元素位于 [0, 1]范围内且总和为一。 softmax函数的第k个输出是：\\nsoftmax k[z] =exp[zk]PK\\nk′=1exp[zk′](5.22)\\n指数函数确保输出为正，分母的求和则保证这 K个数的总和为一。\\n因此，输入 x有标签y的似然（见图 5.10）是：\\nPr(y=k|x) =softmax k[f(x,ϕ)] (5.23)\\n损失函数是训练数据的负对数似然：\\nL[ϕ] =−IX\\ni=1log[softmax yi[f(xi,ϕ)]]\\n=−IX\\ni=1\"\\nfyi[xi,ϕ]−log KX\\nk′=1exp[fk′[xi,ϕ]]!#\\n, (5.24)\\n其中fk[x,ϕ]是神经网络的第 k个输出。由于将在第 5.7节中解释的原因，这被称\\n为多类别交叉熵损失。\\n模型输出的变换代表了 y∈{1,2,...,K}可能类别的分类分布。作为点估计，我们\\n选择最可能的类别 ˆy=argmax k[Pr(y=k|f(x,ϕ))]，这对应于图 5.10中对于该x值最\\n高的曲线。\\n5.5.1预测其他数据类型\\n本章主要关注回归和分类，因为这些问题非常普遍。然而，为了预测不同类型的数\\n据，我们只需选择适合该领域的分布，并应用第 5.2节中的方法。图 5.11列出了一系列\\n概率分布及其预测领域。其中一些将在本章末尾的问题中进行探讨。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 80}, page_content='5.6.多输出预测 65\\n5.6多输出预测\\n在许多情况下，我们需要使用同一个模型进行多个预测，因此目标输出 y是向量形\\n式。例如，我们可能想同时预测分子的熔点和沸点（多变量回归问题） ，或者预测图像\\n中每个点的物体类别（多变量分类问题） 。虽然可以定义多变量概率分布，并利用神经\\n网络模拟它们作为输入的函数参数，但更常见的做法是将每个预测视为独立的。\\n独立性意味着我们把概率 Pr(y|f(x,ϕ))看作是对于每个元素 yd∈y的单变量项的\\n乘积：\\nPr(y|f(x,ϕ)) =Y\\ndPr(yd|fd[x,ϕ]) (5.25)\\n其中fd[x,ϕ]是网络对于 yd分布参数的第 d组输出。例如，对于预测多个连续变量\\nyd∈R，我们对每个 yd使用正态分布，并由网络输出 fd[x,ϕ]预测这些分布的均值。对\\n于预测多个离散变量 yd∈{1,2,...,K}，我们对每个 yd使用分类分布。在这种情况下，\\n每组网络输出 fd[x,ϕ]预测对yd分类分布的贡献值。\\n最小化负对数概率时，这个乘积变为各项的求和：\\nL[ϕ] =−IX\\ni=1log[Pr(yi|f(xi,ϕ))] =−IX\\ni=1X\\ndlog[Pr(yid|fd[xi,ϕ])](5.26)\\n其中yid是第i个训练样本的第 d个输出。\\n为了同时进行两种或更多类型的预测，我们同样假设每种错误是独立的。比如，为\\n了同时预测风向和风力，我们可能分别选择定义在圆形域的 von Mises 分布预测风向，\\n以及定义在正实数上的指数分布预测风力。独立性假设意味着这两个预测的联合似然是\\n单独似然的乘积。在计算负对数似然时，这些项会转化为加和形式。\\n5.7交叉熵损失 (Cross-entropy loss)\\n在本章中， 我们开发了旨在最小化负对数似然 (negative log-likelihood) 的损失函数。\\n然而，术语“交叉熵损失 (cross-entropy loss) ”也广为流传。在本节中，我们将解释交\\n叉熵损失，并证明它与使用负对数似然是等价的。\\n交叉熵损失的核心思想是寻找参数 θ，以最小化观测数据 y的经验分布 q(y)与模\\n型分布Pr(y|θ)（见图5.12）之间的差距。可以用 Kullback-Leibler (KL) 散度来衡量两\\n个概率分布 q(z)和p(z)之间的距离：\\nDKL(q||p) =Z∞'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 80}, page_content='型分布Pr(y|θ)（见图5.12）之间的差距。可以用 Kullback-Leibler (KL) 散度来衡量两\\n个概率分布 q(z)和p(z)之间的距离：\\nDKL(q||p) =Z∞\\n−∞q(z)log[q(z)]dz−Z∞\\n−∞q(z)log[p(z)]dz (5.27)\\n设想我们在点集{yi}I\\ni=1观测到了一组经验数据分布。这可以表示为点质量的加权总和：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 81}, page_content='66 CHAPTER 5. 损失函数\\n图 5.11:不同预测类型下损失函数的分布。\\n图 5.12:交叉熵方法。 a)训练样本的实证分布（箭头标示了 Dirac delta 函数） 。 b)模型分布（参\\n数为 θ=µ, σ2的正态分布） 。通过交叉熵方法，我们尝试最小化这两个分布之间的距离（即 KL\\n散度） ，这个距离是模型参数 θ的函数。\\nq(y) =1\\nIIX\\ni=1δ[y−yi] (5.28)\\n这里的δ[·]是Dirac delta 函数。我们的目标是最小化模型分布 Pr(y|θ)与这一经验\\n分布之间的 KL散度：\\nˆθ=argmin θ\\x14Z∞\\n−∞q(y)log[q(y)]dy−Z∞\\n−∞q(y)log[Pr(y|θ)]dy\\x15\\n=argmin θ\\x14\\n−Z∞\\n−∞q(y)log[Pr(y|θ)]dy\\x15\\n, (5.29)\\n由于第一项与 θ无关， 因此消失了。 剩下的第二项被称为 *交叉熵(cross-entropy)* 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 82}, page_content='5.8.总结 67\\n它可以理解为在考虑到另一个分布已知信息后，一个分布中剩余的不确定性量。接下来，\\n我们将方程 5.28中的q(y)定义代入：\\nˆθ=argmin θ\"Z∞\\n−∞ \\n1\\nIIX\\ni=1δ[y−yi]!\\nlog[Pr(y|θ)]dy#\\n=argmin θ\"\\n−IX\\ni=1log[Pr(yi|θ)]#\\n, (5.30)\\n第一行的两项相乘，对应于图 5.12a中点质量与图 5.12b中分布的对数进行逐点乘\\n积。最终我们得到一组集中在数据点上的有限加权概率质量。在最后一行，我们去掉了\\n不影响最小值位置的常数缩放因子 1/I。\\n在机器学习领域，分布参数 θ由模型f[xi,ϕ]计算得出。因此，我们有：\\nˆϕ=argmin ϕ\"\\n−IX\\ni=1log[Pr(yi|f[xi,ϕ])]#\\n(5.31)\\n这正是第 5.2节提到的负对数似然准则。由此可见，负对数似然准则（即最大化数据似\\n然）与交叉熵准则（即最小化模型与经验数据分布间的距离）是等价的。\\n5.8总结\\n在前面的章节中， 我们考虑神经网络是如何直接从数据 x预测输出 y的。 在本章， 我\\n们改变了观点， 把神经网络视为计算输出空间概率分布 Pr(y|θ)上的参数θ。 这引领我们\\n采用了一种原理性方法构建损失函数。我们选择了能够使观测数据在这些分布下的似然\\n最大化的模型参数 ϕ。我们发现，这等同于最小化负对数似然 (negative log-likelihood) 。\\n这种方法的自然结果是，回归的最小二乘准则；它基于假设 y符合正态分布，并且\\n我们正在预测其均值。我们还探讨了如何 (1)扩展回归模型以估计对预测的不确定性，\\n以及(2)扩展模型使不确定性依赖于输入（ heteroscedastic model ） 。我们将同样的方法\\n应用于二元分类和多类分类，为每种情况推导出了损失函数。我们讨论了如何处理更加\\n复杂的数据类型以及如何处理多个输出。最后，我们指出交叉熵是另一种等效的考虑模\\n型拟合方式。\\n在之前的章节中，我们开发了神经网络模型。在本章，我们为决定模型如何根据一\\n组给定参数描述训练数据的效果，开发了损失函数。下一章将考虑模型训练，我们的目\\n标是找到能使这种损失最小化的模型参数。\\n5.9笔记\\n基于正态分布的损失函数 ：Nix & Weigend (1994) 和Williams (1996) 研究了异方'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 82}, page_content='标是找到能使这种损失最小化的模型参数。\\n5.9笔记\\n基于正态分布的损失函数 ：Nix & Weigend (1994) 和Williams (1996) 研究了异方\\n差非线性回归 (heteroscedastic nonlinear regression) ，其中输出的均值和方差都是输入'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 83}, page_content='68 CHAPTER 5. 损失函数\\n的函数。在无监督学习的背景下， Burda等人(2016)使用了基于具有对角协方差的多变\\n量正态分布的损失函数，而 Dorta等人(2018)使用了基于具有完全协方差的正态分布\\n的损失函数。\\n稳健回归 ：Qi等人(2020)研究了最小化平均绝对误差而非平均平方误差的回归模\\n型特性。这种损失函数基于对输出采用拉普拉斯分布的假设，并估计给定输入的中位数\\n输出，而非均值。 Barron (2019) 提出了一种参数化稳健度的损失函数。在概率背景下解\\n释时，它产生了一个包括正态分布和柯西分布作为特例的单变量概率分布族。\\n估计分位数 ：有时，我们可能不想在回归任务中估计均值或中位数，而是希望预测\\n一个分位数。例如，这对风险模型很有用，我们希望知道真实值在 90%的时间内会小\\n于预测值。这被称为分位数回归 (Koenker & Hallock, 2001) 。这可以通过拟合一个异方\\n差回归模型，然后基于预测的正态分布估计分位数来完成。或者，分位数可以直接使用\\n分位数损失（也称为弹球损失）来估计。在实践中，这最小化了数据与模型的绝对偏差，\\n但在一个方向上对偏差的权重比另一个方向更大。最近的研究探索了同时预测多个分位\\n数以获得整体分布形状的概念（ Rodrigues & Pereira, 2020 ） 。\\n类别不平衡和焦点损失 ：Lin等人(2017c)讨论了分类问题中的数据不平衡问题。如\\n果某些类别的示例数量远大于其他类别，则标准的最大似然损失就不再适用；模型可能\\n会专注于提高对主导类别中已分类良好示例的信心，而对代表性较差的类别分类不佳。\\nLin等人(2017c)引入了焦点损失，该损失添加了一个额外的参数，用于减弱分类良好\\n示例的影响，以提高性能。\\n学习排名 ：Cao等人(2007)，Xia等人(2008)，和Chen等人(2009)都在学习排名\\n数据的损失函数中使用了 Plackett-Luce 模型。这是学习排名的列表式方法，因为模型\\n一次性处理整个待排名的对象列表。其他方法包括点式方法，其中模型处理单个对象，\\n以及对式方法，其中模型处理对象对。 Chen等人(2009)总结了学习排名的不同方法。\\n其他数据类型 ：Fan等人(2020)使用基于贝塔分布的损失来预测 0到1之间的值。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 83}, page_content='以及对式方法，其中模型处理对象对。 Chen等人(2009)总结了学习排名的不同方法。\\n其他数据类型 ：Fan等人(2020)使用基于贝塔分布的损失来预测 0到1之间的值。\\nJacobs等人(1991)和Bishop (1994) 研究了适用于多模态数据的混合密度网络。这些模\\n型将输出建模为基于输入的高斯混合（见图 5.14） 。Prokudin 等人(2018)使用了von\\nMises分布来预测方向（见图 5.13） 。Fallah等人(2009)使用泊松分布构建了预测计数\\n的损失函数（见图 5.15） 。Ng等人(2017)使用基于伽马分布的损失函数来预测持续时\\n间。\\n图5.13冯·米塞斯分布定义在圆周上，范围是 (−π,π]。它由两个参数构成：平均\\n值µ决定了分布峰值的位置；浓度参数 K（大于0）起着类似于方差倒数的作用，因此\\n1√κ可以大致看作是与正态分布的标准差相对应的量。\\n非概率方法 ：采用本章讨论的概率方法并不是严格必要的，但这在近年来已成为默\\n认方法；任何旨在减少模型输出与训练输出之间距离的损失函数都是足够的，距离可\\n以用任何看似合理的方式定义。有几种著名的非概率机器学习模型用于分类，包括支\\n持向量机 (Vapnik, 1995; Cristianini & Shawe-Taylor, 2000) ，它们使用铰链损失，以及\\nAdaBoost (Freund & Schapire, 1997) ，它们使用指数损失。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 84}, page_content='5.10.习题 69\\n图 5.13: Figure5.13\\n5.10习题\\n问题 5.1证明逻辑 sigmoid函数sig[z]将z=−∞映射到0，z= 0映射到0.5，\\nz=∞映射到1，其中：\\nsig[z] =1\\n1 +exp[−z](5.32)\\n问题 5.2对于单个训练对{x,y}的二元分类，损失 L为：\\nL=−(1−y)log[1−sig[f[x,ϕ]]]−ylog[sig[f[x,ϕ]]] (5.33)\\n其中sig[·]在方程5.32中定义。将这种损失作为变换后的网络输出\\nsig[f[x,ϕ]]∈[0,1]\\n的函数绘制出来。 (i)当训练标签 y= 0时 (ii)当y= 1时\\n问题 5.3*假设我们想构建一个模型，基于本地气压 x的测量来预测占主导地位的\\n风向y（以弧度表示） 。适用于圆形域的分布是 von Mises distribution （见图5.13） ：\\nPr(y|µ,κ) =exp[κcos(y−µ)]\\n2π·Bessel 0[κ](5.34)\\n其中µ是平均方向的度量， κ是集中度的度量（即方差的倒数） 。\\nBessel 0[κ]是阶数为 0的修改过的贝塞尔函数。使用第 5.2节的配方来开发用于学\\n习模型f[x,ϕ]参数µ的损失函数，以预测最有可能的风向。你的解决方案应将集中度\\nκ视为常数。你会如何进行推理？'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 85}, page_content='70 CHAPTER 5. 损失函数\\n问题 5.4*有时， 对于输入 x的输出y是多模态的 （见图 5.14a） ； 对于给定输入， 有多\\n个有效的预测。 在这里， 我们可能使用正态分量的加权和作为输出的分布。 这被称为高斯\\n混合(Gaussian Mixture) 模型。例如，两个高斯的混合具有参数 Θ ={λ,µ 1,σ2\\n1,µ2,σ2\\n2}：\\nPr(y|µ1,µ2,σ2\\n1,σ2\\n2) =λp\\n2πσ2\\n1exp\\x14\\n−(y−µ1)2\\n2σ2\\n1\\x15\\n+1−λp\\n2πσ2\\n2exp\\x14\\n−(y−µ2)2\\n2σ2\\n2\\x15\\n(5.35)\\n其中λ∈[0,1]控制两个分量的相对权重，它们分别具有均值 µ1,µ2和方差σ2\\n1,σ2\\n2。这\\n个模型可以表示具有两个峰的分布（见图 5.14b）或具有更复杂形状的单峰分布（见图\\n5.14c） 。使用第 5.2节的配方构建一个训练模型 f[x,ϕ]的损失函数，该模型接收输入 x，\\n具有参数ϕ，并预测两个高斯的混合。损失应基于 I训练数据对{xi,yi}。在进行推理\\n时，你预见会遇到什么问题？\\n图 5.14:多模态数据及其高斯混合密度。 a)在示例训练数据中，当输入 x的值处于中间范围时，\\n相应的输出 y会沿着两种可能的路径之一变化。例如，在 x = 0的情况下，输出 y的值可能接\\n近 −2或 +3，但不太可能是介于这两个值之间。 b)高斯混合模型非常适合描述这种数据，它通\\n过将两个或更多具有不同均值和方差的正态分布（此处为两个分布， 分别用虚线蓝色和橙色曲线\\n表示）进行加权求和（用实线青色曲线表示）来构建。当各个正态分布的均值相差较远时，便形\\n成了多模态分布。 c)当这些均值较为接近时，这种混合模型能够描述单峰但非正态的密度分布。\\n问题 5.5考虑扩展问题 5.3中的模型，使用两个 von Mises distribution 的混合来预\\n测风向。为这个模型写出似然 Pr(y|θ)的表达式。网络需要产生多少个输出？\\n问题 5.6考虑构建一个模型，预测接下来一分钟内将有多少行人 y∈{0,1,2,...}\\n经过城市中给定的点，这是基于包含一天中的时间、经纬度和社区类型等信息的数据 x。\\n适用于模拟计数的分布是泊松分布（见图 5.15） 。它有一个称为速率的单一参数 λ > 0，\\n代表分布的均值。该分布的概率密度函数为：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 85}, page_content='适用于模拟计数的分布是泊松分布（见图 5.15） 。它有一个称为速率的单一参数 λ > 0，\\n代表分布的均值。该分布的概率密度函数为：\\nPr(y=k) =λke−λ\\nk!(5.36)\\n假设我们可以访问 I个训练对{xi,yi}，为这个模型设计一个损失函数。\\n问题 5.7考虑一个多变量回归问题，我们预测十个输出，因此 y∈R10，并且用独\\n立的正态分布对每个进行建模，其中均值 µd由网络预测，方差 σ2是常数。写出似然'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 86}, page_content='5.10.习题 71\\n图 5.15:泊松分布是定义在非负整数上的离散分布，具有一个参数 λ（正实数） ，称为分布的率，\\n它代表了分布的平均值。 a–c)分别展示了当率为 1.4、2.8和 6.0时的泊松分布，展示了不同率\\n值下分布形态的变化。\\nPr(y|f[x,ϕ])的表达式。展示如果我们不估计方差 σ2，最小化这个模型的负对数似然仍\\n然等价于最小化一系列平方项。\\n问题 5.8*构建一个损失函数，用于基于独立正态分布进行多变量预测 y∈RD\\ni，每\\n个维度有不同的方差 σ2\\nd。假设一个异方差模型，使得均值 µd和方差σ2\\nd都随数据而变\\n化。\\n问题 5.9*考虑一个多变量回归问题，我们从数据 x预测一个人的身高（以米为单\\n位）和体重（以千克为单位） 。这里，单位的范围差异较大。你认为这会导致什么问题？\\n提出两个解决这些问题的方案。\\n问题 5.10扩展问题 5.3中的模型，预测风向和风速，并定义相关的损失函数。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 87}, page_content='72 CHAPTER 5. 损失函数'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 88}, page_content='Chapter 6\\n训练模型\\n第3章和第4章详细讨论了浅层和深层神经网络，它们构成了分段线性函数族，函\\n数的具体形式由各自的参数确定。第 5章引入了损失概念——一个反映网络预测与训练\\n集真实值差异的单个数值。损失与网络参数有关，本章着重于探讨如何确定能使损失最\\n小化的参数值。这个过程称为网络参数的学习，或更通俗地说，是模型的训练或拟合。\\n该过程首先是选取一组初始参数值，随后重复执行两个步骤： (i)计算损失函数关于参数\\n的导数（梯度） ； (ii)根据梯度调整参数，以期减少损失。多次迭代后，目标是使损失函\\n数达到其全局最小值。本章重点讨论参数调整步骤，即采用何种算法来减少损失。第 7\\n章将介绍如何为神经网络初始化参数并计算梯度。\\n6.1梯度下降\\n为了拟合模型，我们需要一组输入 /输出对的训练集{xi,yi}。我们寻求模型 f(xi,ϕ)\\n的参数ϕ，使得这些参数能够尽可能准确地将输入 xi映射到输出 yi。为此目的，我们\\n定义了一个损失函数 L(ϕ)，它通过返回一个数值来量化映射中的误差。优化算法的目标\\n是找到一组参数 ˆϕ，使得这个损失函数达到最小值：\\nˆϕ=argmin\\nϕL(ϕ) (6.1)\\n虽然存在多种优化算法，但训练神经网络通常采用迭代方法。这些方法首先启发式\\n地设定初始参数值，然后反复调整参数以降低损失值。\\n这个过程中最基本的方法称为梯度下降。它从初始参数 ϕ= [ϕ0,ϕ1,...,ϕ N]T开始，\\n并分两步迭代：\\n步骤 1.计算损失相对于参数的导数：\\n∂L\\n∂ϕ=2\\n666664∂L\\n∂ϕ0\\n∂L\\n∂ϕ1...\\n∂L\\n∂ϕN3\\n777775(6.2)\\n73'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 89}, page_content='74 CHAPTER 6. 训练模型\\n步骤 2.根据以下规则更新参数：\\nϕ←ϕ−α·∂L\\n∂ϕ(6.3)\\n其中，正数 α确定了调整的幅度。\\n第一步计算当前位置上损失函数的梯度，确定了损失增加的方向。第二步则是向相\\n反方向（即下降方向）小幅移动。参数 α可以固定（此时称之为学习率） ，或者通过线\\n性搜索尝试多个 α值，以找到能最大程度降低损失的值。\\n当损失函数达到最小值时，其表面必须是平坦的（否则，我们还能通过继续下降来\\n进一步改进） 。因此，梯度将变为零，参数也随之停止改变。在实践中，我们会监测梯度\\n的大小，并在其变得过小时停止算法。\\n6.1.1线性回归示例\\n考虑将梯度下降方法应用于第 2章介绍的一维线性回归模型。该模型 f(x,ϕ)把一\\n个标量输入 x映射到一个标量输出 y，具有参数 ϕ= [ϕ0,ϕ1]T，分别代表了 y轴截距和\\n斜率：\\ny=f(x,ϕ) =ϕ0+ϕ1x (6.4)\\n给定一个数据集{xi,yi}，包含I对输入/输出数据，我们采用最小二乘法作为损失\\n函数：\\nL(ϕ) =IX\\ni=1ei=IX\\ni=1(f(xi,ϕ)−yi)2=IX\\ni=1(ϕ0+ϕ1xi−yi)2(6.5)\\n这里的ei= (ϕ0+ϕ1xi−yi)2表示第i个训练样本对损失的单独贡献。\\n损失函数对参数的导数可以表示为各个贡献导数的总和：\\n∂L\\n∂ϕ=∂\\n∂ϕIX\\ni=1ei=IX\\ni=1∂ei\\n∂ϕ(6.6)\\n具体计算方式如下：\\n∂ei\\n∂ϕ=\"\\n∂ei\\n∂ϕ0\\n∂ei\\n∂ϕ1#\\n=\"\\n2(ϕ0+ϕ1xi−yi)\\n2xi(ϕ0+ϕ1xi−yi)#\\n(6.7)\\n图6.1通过迭代地根据方程 6.6和6.7计算导数，接着依据方程 6.3的规则更新参\\n数，展示了算法的逐步进展。在此示例中，我们采用了线搜索技术，在每次迭代中找到\\n能够最大限度减少损失的 α值。\\n6.1.2 Gabor 模型示例\\n线性回归问题的损失函数（参见图 6.1c）总是有一个清晰定义的全局最小值。更形\\n式化地说，这些函数是凸函数，意味着曲面上任意两点连线（即弦）不会穿过函数图像。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 90}, page_content='6.1.梯度下降 75\\n图 6.1:线性回归模型的梯度下降。 a)训练集由 12对输入 /输出数据对 xi, yi组成。 b)损失函数\\n图展示了梯度下降的迭代过程。从点 0出发，我们沿最陡峭的下降方向前进，直至无法进一步\\n降低损失，从而到达点 1。然后，我们重复此过程，测量点 1的梯度并继续下降到点 2，以此类\\n推。 c)通过热图可以更直观地展示这一过程，图中的亮度代表了损失大小。仅经过四轮迭代，我\\n们已经非常接近最小损失值。 d)点 0处参数（线条最浅）的模型对数据的描述非常不准确，但\\n随着每轮迭代，模型的拟合度都有所提升。点 4处参数（线条最深）的模型已能合理描述训练\\n数据。\\n凸性保证了无论参数初始化在何处，只要我们不断地“下坡” ，最终都能找到最小值；这\\n样的训练过程是不会失败的。\\n然而，大部分非线性模型（包括浅层和深层网络）的损失函数都是非凸的。由于参\\n数众多，使得神经网络损失函数的可视化变得极具挑战性。因此，我们首先研究一个参\\n数较少的简单非线性模型，以深入理解非凸损失函数的特性：\\nf(x,ϕ) =sin[ϕ0+ 0.06·ϕ1x]·exp\\x12\\n−(ϕ0+ 0.06·ϕ1x)2\\n32.0\\x13\\n(6.8)\\n这个Gabor模型将标量输入 x映射到标量输出 y，并且由一个正弦分量（产生振\\n荡效果）和一个负指数分量（使得振幅随离中心距离增加而减小）相乘构成。模型具有\\n两个参数ϕ= [ϕ0,ϕ1]T，ϕ0∈R控制函数的拉伸或压缩，而 ϕ1∈R+则决定沿 x轴的拉\\n伸或压缩（见图 6.2） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 91}, page_content='76 CHAPTER 6. 训练模型\\n考虑一个包含 I个样本{xi,yi}的训练集。定义 I个训练样本的最小二乘损失函数\\n为：\\nL(ϕ) =IX\\ni=1(f(xi,ϕ)−yi)2(6.9)\\n目标再次是找到能够最小化这个损失的参数 ˆϕ。\\n图 6.2: Gabor 模型。 这个非线性模型将单一输入 x映射到单一输出 y， 拥有参数组 ϕ= [ϕ0, ϕ1]T。\\n它描述了一个振幅随距离中心增加而减小的正弦波函数。 ϕ0参数决定了波峰的位置，随 ϕ0增\\n大，波形向左移动。 ϕ1参数控制波形相对于中心的压缩程度， ϕ1增大时，波形变得更窄。 a–c)\\n展示了具有不同参数的模型。\\n图 6.3:用于拟合 Gabor模型的训练数据。训练集包含了 28组输入 /输出样本 xi,yi。这些样本\\n是通过在区间 [−15, 15] 内均匀采样 xi，然后将样本值通过参数设为 ϕ= [0.0,16.6]T 的 Gabor\\n模型处理，并加入正态分布的噪声生成的。\\n6.1.3局部最小值与鞍点\\n图6.4展示了这个数据集的 Gabor模型损失函数。存在众多局部最小值（标记为青\\n色圆圈） 。在这些位置，梯度为零，无论向哪个方向移动，损失都会增加，然而这些并不'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 92}, page_content='6.1.梯度下降 77\\n代表函数的全局最小点。损失最小的点，即全局最小值，用灰色圆圈标出。\\n如果我们从随机位置出发，采用梯度下降法“下山” ，无法保证最终能够达到全局\\n最小值并找出最优参数（参见图 6.5a） 。算法很可能会停在某个局部最小值，而不是最\\n佳解。更重要的是，我们无法确定是否有更优的解存在于其他地方。\\n此外，损失函数中还存在鞍点（比如图 6.4中的蓝色十字处） 。在鞍点，虽然梯度为\\n零，但是函数值在某些方向上升，在其他方向下降。如果当前参数位置并非正好在鞍点\\n上，那么通过“下山”梯度下降法仍有可能逃脱。然而，鞍点附近的曲面几乎是平坦的，\\n这使得很难确定训练是否已经收敛。如果我们在梯度很小时就终止算法，可能会错误地\\n在鞍点附近停止，误以为找到了解决方案。\\n图 6.4: Gabor 模型的损失函数。 a)损失函数呈现非凸形状，除了一个全局最小值（灰色圆圈）\\n外，还存在多个局部最小值（青色圆圈） 。同时，该函数包含鞍点，即在这些点上，虽然梯度临\\n时为零，但函数值在某一方向上升，在另一方向下降。例如，蓝色叉号标识的鞍点，水平方向移\\n动导致函数值下降，而垂直方向移动则导致上升。 b–f)展示了对应于不同最小值点的模型状态。\\n在这些状态下，任何微小的调整都无法使损失值进一步降低。图 (c)中展示的全局最小值点，其\\n损失值为 0.64。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 93}, page_content='78 CHAPTER 6. 训练模型\\n图 6.5:梯度下降与随机梯度下降的比较。 a)使用线性搜索的梯度下降方法。只要初始设置正确，\\n位于损失函数的适当“谷底” （如点 1和 3） ，参数估计便会稳步向全局最小值靠拢。但如果初始\\n点设在这个谷底之外（如点 2） ，则可能会陷入局部最小值。 b)随机梯度下降通过引入噪声到优\\n化过程中，使得即便是从错误的“谷底” （如点 2）出发，也有可能跳出并最终找到全局最小值。\\n6.2随机梯度下降\\nGabor模型具有两个参数， 因此我们可以通过以下两种方式找到全局最小值： （ i）穷\\n尽地搜索参数空间或（ ii）重复从不同位置开始梯度下降， 并选择损失最低的结果。然而，\\n神经网络模型可能拥有数以百万计的参数，这使得上述两种方法都不现实。简言之，利\\n用梯度下降方法寻找高维损失函数的全局最优解颇具挑战性。我们能找到一个最小值，\\n但无法确定这是否为全局最小值或一个较优解。一个主要问题是，梯度下降算法的最终\\n结果完全取决于其起始点。随机梯度下降（ SGD）尝试通过在每一步中为梯度引入一些\\n噪声来解决这一问题。这样，解决方案在平均意义上仍向低处移动，但在任何给定的迭\\n代中，所选方向不必然是最陡峭的下坡方向。实际上，有时甚至可能不是向下的。 SGD\\n算法可能暂时向上移动，因此能够从损失函数的一个“谷”跳跃到另一个（见图 6.5b） 。\\n6.2.1批次和周期\\n引入随机性的机制很简单。在每次迭代时，算法随机选择训练数据的一个子集，并\\n仅根据这些示例计算梯度。这个子集称为 小批量（minibatch ）或简称 批次（batch） 。因\\n此，模型参数 ϕt在第t次迭代的更新规则为：\\nϕt+1←ϕt−α·X\\ni∈Bt∂L[ϕ]\\n∂ϕ(6.10)\\n其中Bt是当前批次中输入 /输出对索引的集合， ei是第i对导致的损失。 α是学习率，\\n与梯度大小一起，决定了每次迭代的移动距离。学习率在开始时确定，并不受函数局部\\n特性的影响。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 94}, page_content='6.2.随机梯度下降 79\\n图 6.6:针对 Gabor模型的随机梯度下降方法，采用的批处理大小为三。 a)针对全部训练数据\\n集的损失函数图。每一次迭代都对应一组可能的参数变化概率分布（小图展示了样本选择） 。这\\n些分布对应于选择的三个批处理元素的不同组合。 b)某一特定批处理的损失函数图。随机梯度\\n下降算法依据学习速率和当前梯度的大小，沿着损失函数下降方向移动一段距离。当前模型（小\\n图中的虚线表示）将调整以更好地符合这批数据（以实线表示） 。 c)另一批数据会生成不同的损\\n失函数，并导致不同的模型更新。 d)对这批数据，算法沿着批损失函数的下降方向移动，但相\\n对于图 (a)中的全局损失函数可能是上升的。这展示了随机梯度下降如何帮助模型跳出局部最\\n小值，寻找全局最优解。\\n通常，批次是从数据集中不重复抽取的。算法遍历所有训练样本直至全部使用完毕，\\n然后再次从完整训练数据集开始抽样。整个训练数据集的单次遍历称为一个 *周期*。\\n批次的大小可以从单一样本到整个数据集不等。后者被称为 *全批量梯度下降 *，与常\\n规（非随机）梯度下降相同。\\nSGD的另一解释是，它在每次迭代计算不同损失函数的梯度；由于损失函数依赖\\n于模型与训练数据，因此每个随机选择的批次都会不同。从这个角度看， SGD在一个不\\n断变化的损失函数上执行确定性梯度下降（见图 6.6） 。然而，尽管存在这种变异性，任\\n何点的期望损失和梯度与常规梯度下降保持一致。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 95}, page_content='80 CHAPTER 6. 训练模型\\n6.2.2随机梯度下降的特性\\nSGD具有几个吸引人的特点。首先，尽管它在路径上增加了噪声，但每次迭代都改\\n善了对数据子集的拟合，因此更新通常是合理的，即使不是最佳的。其次，通过无重复\\n抽取训练样本并遍历数据集，保证了所有训练样本的平等贡献。第三，仅使用训练数据\\n的一部分计算梯度在计算上更为高效。第四，它原则上能够逃离局部最小值。第五，它\\n减少了在鞍点附近停滞的几率；很可能至少有一些批次在损失函数的任何点上都有显著\\n梯度。最后，有证据表明， SGD找到的参数能使神经网络在实际中对新数据具有良好的\\n泛化能力（见第 9.2节） 。\\nSGD不一定按传统意义上“收敛” 。然而，我们希望当接近全局最小值时，所有数\\n据点都能被模型很好地描述，这样无论选择哪个批次，梯度都将很小，参数变化不大。\\n实践中， SGD常配合学习率调度使用。学习率 α起始于一个较高值，并每经过 N个周\\n期以一个固定比例降低。这样做的逻辑是，在训练初期，我们希望算法能探索参数空间，\\n跨越不同的“谷”寻找合理的区域；而在后期，当我们大致处于正确位置时，更注重参\\n数的微调，因此通过降低 α来减小变化幅度。\\n6.3动量\\n在随机梯度下降法中，增加动量（ Momentum ）项是一种常见的改进方法。此方法\\n通过结合当前批次计算得到的梯度与上一步骤的移动方向的加权组合来更新参数：\\nmt+1←β·mt+ (1−β)X\\ni∈Bt∂L[ϕ]\\n∂ϕ\\nϕt+1←ϕt−α·mt+1, (6.11)\\n其中，mt表示动量项， β∈[0,1]用于控制随时间变化的平滑效果， α为学习率。\\n动量的递归计算方式导致梯度更新步骤成为所有先前梯度的无限加权和，其中随着\\n时间的推移，权重逐渐减少。若这些梯度在多个迭代中保持一致方向，则有效的学习速\\n率会增加；反之，如果梯度方向频繁变化，由于累加项之间的相互抵消，有效的学习速\\n率则会降低。这样能够使参数更新路径更加平滑，减少在优化过程中的震荡现象（参见\\n图6.7） 。\\n6.3.1 Nesterov 加速动量\\n动量项可视为对 SGD算法下一步移动位置的粗略预测。 Nesterov 加速动量（参见\\n图6.8）不是在当前位置，而是在预测的位置计算梯度：\\nmt+1←β·mt+ (1−β)X\\niinB∂L(ϕt−α·mt)\\n∂ϕ\\nϕt+1←ϕt−α·mt+1 (6.12)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 96}, page_content='6.3.动量 81\\n此处，梯度是在 ϕt−α·mt位置计算的。这种方式使得梯度项能够对仅靠动量确定\\n的路径进行修正。\\n图 6.7:带动量的随机梯度下降。 a)传统的随机梯度下降方法向最小值进发的路径曲折复杂。 b)\\n通过引入动量项，可以将当前步的更新设定为之前更新与当前批次梯度的加权混合，从而使路径\\n更平滑，加快收敛速度。\\n图 6.8: Nesterov 加速动量。该方法的解沿虚线前进至点 1。在传统动量更新中，先在点 1处\\n计算梯度，再按此方向移动至点 2，并添加前一次迭代的动量（即延虚线方向） ，最终到达点 3。\\nNesterov 动量先应用动量（从点 1至点 4） ，然后计算梯度并更新至点 5。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 97}, page_content='82 CHAPTER 6. 训练模型\\n6.4 Adam\\n传统的梯度下降方法采用固定步长，存在一个问题：它会对大梯度的参数做出较大\\n调整（在这些情况下我们可能需要更加小心） ，而对小梯度的参数调整较小（这里可能\\n需要进一步的探索） 。当损失函数表面的梯度在一个方向比另一个方向更陡峭时，很难\\n选择一个同时能（ i）在两个方向上有效进展且（ ii）保持稳定的学习率（见图 6.9a–b） 。\\n一个简便的方法是对梯度进行标准化处理，使得在每个方向上都能按固定距离（由\\n学习率决定）前进。首先，我们计算梯度 mt+1和逐点平方梯度 vt+1：\\nmt+1←∂L(ϕt)\\n∂ϕ\\nvt+1←\\x12∂L(ϕt)\\n∂ϕ\\x132\\n(6.13)\\n接下来应用更新规则：\\nϕt+1←ϕt−α·mt+1√vt+1+ϵ(6.14)\\n其中，平方根和除法均为逐点执行， α表示学习率， ϵ是一个小常量，用于防止当\\n梯度大小为零时除以零的情况。 vt+1为平方梯度，通过其正平方根来标准化梯度，使得\\n最终只剩下每个坐标方向上的符号。算法因此沿每个坐标方向移动固定距离 α，方向由\\n下坡方向确定（见图 6.9c） 。这种简单的算法虽然能在两个方向上取得进展，但除非刚\\n好到达最小值点，否则不会收敛。它会在最小值周围反复跳动。\\n自适应矩估计（ Adaptive Moment Estimation ，简称 Adam）在这一思路基础上，对\\n梯度估计和平方梯度都引入了动量：\\nmt+1←β·mt+ (1−β)∂L(ϕt)\\n∂ϕ\\nvt+1←γ·vt+ (1−γ)\\x12∂L(ϕt)\\n∂ϕ\\x132\\n(6.15)\\n其中β和γ分别是两种统计量的动量系数。\\n使用动量相当于对这些统计量的历史数据进行加权平均。在开始时，所有之前的测\\n量基本上都是零，这会导致估计值过小。因此，我们通过以下规则对这些统计量进行调\\n整：\\nˆmt+1←mt+1\\n1−βt+1\\nˆvt+1←vt+1\\n1−γt+1(6.16)\\n由于β和γ的取值范围是 [0,1]，随着时间步进，指数项 t+ 1逐渐减小，分母趋近\\n于一，这种调整的效果逐渐变小。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 98}, page_content='6.4. ADAM 83\\n最终，我们按之前的方式更新参数，但使用调整后的项：\\nϕt+1←ϕt−α·ˆmt+1p\\nˆvt+1+ϵ(6.17)\\n这一算法能够朝整体最小值收敛，并在参数空间的每个方向上都取得良好进展。注\\n意，Adam通常在一个随机环境下使用，其中梯度及其平方基于小批量数据计算：\\nmt+1←β·mt+ (1−β)X\\ni∈B∂L(ϕt)\\n∂ϕ\\nvt+1←γ·vt+ (1−γ)X\\niinB\\x12∂L(ϕt)\\n∂ϕ\\x132\\n(6.18)\\n因此，实际的轨迹会有噪声。\\n图 6.9:自适应矩估计（ Adam） 。 a)该损失函数在垂直方向上迅速变化，在水平方向上变化缓慢。\\n若使用适合垂直进展的学习率进行全批梯度下降，算法达到最终水平位置需时甚久。 b)若学习\\n率设置利于水平进展，则会在垂直方向过冲，导致不稳定。 c)一个简单方法是每步沿每个轴固\\n定距离移动，以两个方向都下降。这需要通过归一化梯度大小并保留方向来完成。但这通常不会\\n精确收敛至最小值，而是在其周边振荡（如最后两点间） 。 d) Adam 算法利用动量优化梯度估计\\n和归一化，确保路径更平滑。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 99}, page_content='84 CHAPTER 6. 训练模型\\n如第7章所述，神经网络参数的梯度大小可能取决于它们在网络中的深度。 Adam\\n有助于补偿这一趋势，并在不同层之间平衡变化。实际上，由于它避免了图 6.9a–b中\\n描述的情况， Adam对初始学习率的敏感度较低，因此不需要复杂的学习率调整策略。\\n6.5训练算法的超参数\\n选择学习算法、批量大小（ Batch Size ） 、学习率调度（ Learning Rate Schedule ）和\\n动量系数（ Momentum Coeﬀicients ）都是训练算法的超参数；它们直接影响最终模型的\\n性能，但与模型的参数本身不同。挑选这些超参数更像是一门艺术而非精确科学，常见\\n的做法是训练多个带有不同超参数的模型，然后选出表现最佳的一个。这个过程称为超\\n参数搜索。我们将在第 8章深入讨论这一话题。\\n6.6总结\\n本章围绕模型训练进行了讨论。我们将问题定义为找到使损失函数 L[ϕ]达到最小\\n的参数ϕ。梯度下降法（ Gradient Descent ）通过测量当前参数下损失函数的梯度（即，\\n当我们微调参数时损失如何变化）来进行。接着，它会将参数向着能使损失最快减少的\\n方向调整。这个过程持续进行，直到达到收敛状态。\\n对于非线性函数，损失函数可能存在局部最小值（梯度下降可能会陷入这些点）和\\n鞍点（梯度下降可能似乎已收敛，但实际上并未真正收敛） 。随机梯度下降（ Stochastic\\nGradient Descent ）有助于缓解这些问题。每次迭代，我们都使用数据的一个不同随机\\n子集（一个批次）来计算梯度，为过程引入噪声，避免算法陷入参数空间的非最优区域。\\n此外，每次迭代计算成本更低，因为只利用了数据的一部分。我们还看到，引入动量项\\n可以使收敛过程更加高效。最后，我们介绍了 Adam算法（Adam Algorithm ） 。\\n本章内容适用于任何模型的优化。下一章将专门探讨与神经网络训练相关的两个问\\n题。首先是如何使用著名的反向传播算法（ Backpropagation Algorithm ）计算损失函数\\n相对于神经网络参数的梯度。其次是在优化开始之前如何正确初始化网络参数。如果初\\n始化不当，优化过程使用的梯度可能会异常大或小，从而妨碍训练进程。\\n6.7笔记\\n优化算法 ：优化算法在工程学中被广泛使用，一般倾向于使用“目标函数”而非损'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 99}, page_content='始化不当，优化过程使用的梯度可能会异常大或小，从而妨碍训练进程。\\n6.7笔记\\n优化算法 ：优化算法在工程学中被广泛使用，一般倾向于使用“目标函数”而非损\\n失函数或成本函数。梯度下降法由 Cauchy在1847年提出，而随机梯度下降的概念至\\n少可以追溯到 Robbins & Monro 的1951年工作。两者之间的一种现代中间方案是随机\\n方差减小下降（ Stochastic Variance-Reduced Descent, Johnson & Zhang, 2013 ） ，在该方\\n法中，全梯度定期计算，与随机更新交替进行。优化算法，特别是针对神经网络的，可'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 100}, page_content='6.7.笔记 85\\n以参考Ruder (2016) 、Bottou等(2018)以及Sun (2020) 的综述。 Bottou (2012) 探讨了\\nSGD的最佳实践，包括无重复的随机选择。\\n凸性、极小值与鞍点 ：如果函数上任意两点间的连线（弦）都不与函数相交，则该\\n函数是凸的。这可以通过分析海森矩阵（ Hessian Matrix ，即二阶导数矩阵）来验证：\\nH[ϕ] =2\\n666664∂2L\\n∂ϕ2\\n0∂2L\\n∂ϕ0∂ϕ1···∂2L\\n∂ϕ0∂ϕN\\n∂2L\\n∂ϕ1∂ϕ0∂2L\\n∂ϕ2\\n1···∂2L\\n∂ϕ1∂ϕN............\\n∂2L\\n∂ϕN∂ϕ0∂2L\\n∂ϕN∂ϕ1···∂2L\\n∂ϕ2\\nN3\\n777775(6.19)\\n如果海森矩阵在所有可能的参数值上都是正定的（具有正特征值） ，则该函数是凸\\n的；损失函数将呈现为光滑的碗状（如图 6.1c所示） ，使得训练过程相对简单。存在单\\n一的全局最小值，不会有局部最小值或鞍点。\\n对于任何损失函数，梯度为零的位置处海森矩阵的特征值能够帮助我们将该位置分\\n类为： （i）最小值（所有特征值均为正） ， （ ii）最大值（所有特征值均为负） ，或（ iii）鞍\\n点（正特征值与处于最小值的方向相关，负特征值与处于最大值的方向相关） 。\\n线搜索：梯度下降法使用固定步长可能效率不高，因为移动的距离完全由梯度的大\\n小决定。函数变化快时，它可能移动较长距离（可能应更谨慎） ，而函数变化慢时则移\\n动较短距离（可能应探索更远） 。因此，梯度下降通常与线搜索过程结合使用，通过在\\n期望方向上采样函数来尝试找到最优步长。一种方法是括号法（如图 6.10） 。梯度下降\\n在下降山谷时还可能导致低效的振荡行为（如图 6.5a的路径1） 。\\n图 6.10:利用夹逼法进行线性搜索。 a)当前的解在位置 a（橙色点） ，我们计划探索区间 [a, d]\\n（灰色阴影部分） 。在这个区间内，我们选取两个内部点 b和 c，评估这些点的损失函数值。发现\\nL[b]大于 L[c]，因此我们将区间 [a, b]从搜索范围中剔除。 b)接下来，在细化后的搜索区间重\\n复这一步骤，此次发现 L[b]小于 L[c]，因此我们剔除区间 [c, d]。c)通过不断重复这一过程，直\\n到我们能够紧密定位到最小值的位置。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 100}, page_content='复这一步骤，此次发现 L[b]小于 L[c]，因此我们剔除区间 [c, d]。c)通过不断重复这一过程，直\\n到我们能够紧密定位到最小值的位置。\\n超越梯度下降 ：已开发出许多算法解决梯度下降的问题。其中最著名的是牛顿法\\n（Newton Method ） ，它通过使用海森矩阵的逆矩阵（ Inverse of the Hessian Matrix ）来\\n考虑表面的曲率；如果函数梯度变化迅速，则会应用更谨慎的更新策略。这种方法使线\\n搜索变得不必要，且不会受到振荡行为的影响。然而，它在简单形式下向最近的极值移'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 101}, page_content='86 CHAPTER 6. 训练模型\\n动可能是一个缺点，特别是当我们接近山顶而非山谷底部时，可能会是一个最大值。此\\n外，对于参数众多的情况，如神经网络，计算海森矩阵的逆变得不切实际。\\nSGD的特性： 当学习率趋近于零时， SGD的极限是一种随机微分方程。 Jastrzebski\\n等（2018）指出，这一方程依赖于学习率与批量大小的比例，并发现学习率与批量大小\\n比例与找到的最小值的宽度有关。较宽的最小值被认为更为理想；如果测试数据的损失\\n函数相似，则参数估计的微小错误对测试性能的影响较小。 He等（2019）为SGD提出\\n了一个泛化界限，显示了批量大小与学习率比例的正相关性。通过在不同架构和数据集\\n上训练大量模型，他们找到了当批量大小与学习率比例较低时，测试准确率提高的实证\\n证据。Smith等（2018）和Goyal等（2018）也认为批量大小与学习率的比例对泛化至\\n关重要（参见图 20.10） 。\\n动量：Polyak在1964年提出使用动量加速优化的概念。 Goh（2017） 对动量的属性进\\n行了深入讨论。 Nesterov 加速梯度方法由 Nesterov 在1983年引入，并首次由 Sutskever\\n等人（2013）在随机梯度下降的背景下应用 Nesterov 动量。\\n自适应训练算法 ：AdaGrad （Duchi等人，2011年）是一种优化算法，它通过为每\\n个参数分配不同的学习率来应对某些参数可能需要移动更远距离的问题。 AdaGrad 使\\n用每个参数的累计平方梯度来降低其学习率。这样做的缺点是学习率会随时间降低，可\\n能在找到最小值之前停止学习。 RMSProp （Hinton等人，2012a）和AdaDelta （Zeiler，\\n2012）对该算法进行了改进，通过递归更新平方梯度项来避免这些问题。\\n目前最广泛使用的自适应训练算法是自适应矩估计优化（ Adaptive Moment Esti-\\nmation or Adam ，Kingma & Ba ，2015） 。它结合了动量（其中梯度向量随时间平均）和\\nAdaGrad 、AdaDelta 与RMSProp （其中使用平滑的平方梯度项为每个参数调整学习率）\\n的思想。尽管存在理论上的争议，原始的 Adam算法在实践中表现出色，广泛使用，主\\n要是因为它在广泛的超参数范围内都能良好工作，并且能够迅速取得初步进展。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 101}, page_content='的思想。尽管存在理论上的争议，原始的 Adam算法在实践中表现出色，广泛使用，主\\n要是因为它在广泛的超参数范围内都能良好工作，并且能够迅速取得初步进展。\\n自适应训练算法的一个潜在问题是学习率基于观察到的梯度的累积统计。在训练开\\n始阶段，由于样本量少，这些统计可能极为嘈杂。通过学习率热身（ Goyal等人，2018）\\n可以解决这一问题，其中在最初的几千次迭代中逐渐增加学习率。另一种解决方案是校\\n正Adam（Liu等人，2021a） ，它逐渐改变动量项，有助于避免高方差。 Dozat（2016）\\n将Nesterov 动量整合入 Adam算法中。\\nSGD与 Adam：关于SGD和Adam的相对优势一直存在激烈讨论。 Wilson等\\n人（2017）提供了证据表明，带动量的 SGD能找到比 Adam更低的极小值，从而在多\\n种深度学习任务中实现更好的泛化。然而，这是有些奇怪的，因为在特定条件下（当\\nβ=γ= 0时） ，SGD实际上是 Adam的一种特例。这表明，当使用 Adam的默认超参\\n数时，SGD可能会有更好的表现。 Loshchilov & Hutter （2019）提出的 AdamW，在存在\\nL2正则化时显著提升了 Adam的性能。 Choi等人（2019）的研究表明，如果寻找最佳\\n的Adam超参数，它与 SGD的表现相当且收敛更快。 Keskar & Socher （2017）提出了\\nSWATS方法，先使用 Adam快速进展，然后切换到 SGD以获得更好的最终泛化性能。\\n穷尽搜索 ：本章讨论的所有算法都是迭代的。一个完全不同的方法是对网络参数进'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 102}, page_content='6.8.习题 87\\n行量化，并使用 SAT解算器（ Mézard & Mora ，2009）穷尽搜索结果离散化的参数空间。\\n这种方法有可能找到全局最小值，并确保没有其他更低的损失存在，但只对非常小的模\\n型实用。\\n6.8习题\\n问题6.1证明方程 6.5中最小二乘损失函数的导数可以通过方程 6.7中的表达式给\\n出。\\n问题6.2若Hessian矩阵H[ϕ]的特征值在任何位置都是正值，则该表面为凸面。在\\n这种情况下，该表面存在一个唯一的最小值，使得优化变得简单。求线性回归模型（方\\n程6.5）的Hessian矩阵的代数表达式，\\nH[ϕ] =2\\n4∂2L\\n∂ϕ2\\n0∂2L\\n∂ϕ0∂ϕ1\\n∂2L\\n∂ϕ1∂ϕ0∂2L\\n∂ϕ2\\n13\\n5 (6.20)\\n通过证明其特征值始终为正来论证此函数的凸性。这可以通过证明矩阵的迹和行列\\n式均为正值来实现。\\n问题6.3对于Gabor模型（方程 6.8） ，计算参数 ϕ0和ϕ1对最小二乘损失 L[ϕ]的\\n导数。\\n问题6.4*逻辑回归模型通过线性函数将一个维度的输入 x分类到两个可能的类别\\ny∈{0,1}中。该模型具有两个参数， ϕ0和ϕ1，定义如下：\\nPr(y= 1|x) =sig[ϕ0+ϕ1x] (6.21)\\n其中sig[·]是逻辑sigmoid函数：\\nsig[z] =1\\n1 +exp[−z](6.22)\\n问题6.5*计算相对于方程 3.1中介绍的简单神经网络模型的十个参数的最小二乘损失\\n的导数：\\nf[x,z] =ϕ0+ϕ1a[θ0+θ1x] +ϕ2a[β0+β1x] +ϕ3a[γ0+γ1x] (6.23)\\n仔细考虑 ReLU函数a[·]的导数将如何表达。\\n问题6.6图6.11中哪些函数是凸函数？请给出你的论证。对每个点 1–7进行分类，\\n分别为（ i）局部最小值， （ ii）全局最小值，或（ iii）两者都不是。\\n问题6.7*图6.5a中的路径 1在向最小值方向下降时表现出来回摆动的低效率。特\\n别是，每一步都以直角转变方向。对这一现象给出定性解释，并提出一种可能的解决方\\n案，以避免此种行为。\\n问题6.8*固定学习率的（非随机）梯度下降法能否逃离局部最小值？'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 103}, page_content='88 CHAPTER 6. 训练模型\\n图 6.11:展示了问题 6.6中的三个一维损失函数。\\n问题6.9在数据集大小为 100，批量大小为 20的条件下，我们运行了 1,000次迭代\\n的随机梯度下降算法。模型被训练了多少个周期？\\n问题6.10证明动量项 mt（方程6.11）是先前迭代中梯度的无限加权和，并推导出\\n该总和中系数（权重）的表达式。\\n问题6.11如果模型有一百万个参数， Hessian矩阵将是什么维度？'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 104}, page_content='Chapter 7\\n梯度和初始化\\n第6章介绍了迭代优化算法，这是一类用于找到函数最小值的通用算法。在神经网\\n络的背景下，它们用于寻找能够最小化损失函数的参数，使模型能够根据输入准确预测\\n训练数据的输出。基本方法是随机选择一组初始参数，然后逐步进行微小调整，平均而\\n言这些调整会降低损失。每一次的调整都是基于当前参数位置对损失函数梯度的计算结\\n果。\\n本章将讨论两个神经网络特有的问题。首先，我们将探讨如何高效地计算梯度。这\\n是一个巨大的挑战，因为截至本文写作时，最大的模型拥有达到 1012的参数数量，且在\\n训练算法的每次迭代中都需要对每个参数计算梯度。其次，我们讨论如何进行参数的初\\n始化。如果初始化过程不被妥善处理，初始的损失及其梯度可能会非常大或非常小，这\\n在任何情况下都将阻碍训练过程。\\n7.1问题定义\\n考虑一个网络 f(x,ϕ)，它接受多变量输入 x，具有参数 ϕ，并包含三个隐藏层 h1,h2\\n和h3：\\nh1=a(β0+ Ω 0x)\\nh2=a(β1+ Ω 1h1)\\nh3=a(β2+ Ω 2h2)\\nf(x,ϕ) =β3+ Ω 3h3 (7.1)\\n其中激活函数 a[·]分别作用于输入的每个元素。模型参数\\nϕ={β0,Ω0,β1,Ω1,β2,Ω2,β3,Ω3}\\n包括每层之间的偏置向量 βk和权重矩阵 Ωk（见图7.1） 。\\n89'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 105}, page_content='90 CHAPTER 7. 梯度和初始化\\n此外，我们定义了单个损失项 li来返回基于模型预测 f(xi,ϕ)对训练输入 xi的真\\n实标签yi的负对数似然。例如，这可能是指最小平方损失 li= (f(xi,ϕ)−yi)2。总损失\\n是所有训练数据上这些损失项的和：\\nL(ϕ) =IX\\ni=1li (7.2)\\n对于训练神经网络，最常用的优化方法是随机梯度下降（ SGD） ，通过以下方式更\\n新参数：\\nϕt+1←ϕt−αX\\ni∈Bt∂L(i,ϕt)\\n∂ϕ(7.3)\\n其中α表示学习率， Bt为迭代t时的批次索引。要执行此更新，必须计算每个批\\n次中索引i对应的参数{βk,Ωk}在每一层k∈{0,1,...,K}的导数：\\n∂li\\n∂βk,and∂li\\n∂Ωk(7.4)\\n本章的首部分阐述了反向传播算法，该算法能够高效地计算上述导数。\\n在章节的第二部分，我们将讨论在训练开始前如何初始化网络参数。我们将介绍方\\n法来选择初始权重 Ωk和偏置βk，确保训练过程的稳定性。\\n7.2计算导数\\n损失函数的导数揭示了，当我们对模型参数进行细微调整时，损失值会如何变化。\\n优化算法借此信息调整参数，以减少损失值。反向传播算法负责计算这些导数。鉴于涉\\n及的数学细节较为复杂，我们先提出两个观点来帮助理解。\\n观察 1：每一个权重（属于 Ωk）都会乘上某个源隐藏单元的激活值，并将结果累加\\n到下一层的目标隐藏单元中。这意味着，权重的任意微小调整都会受到源隐藏单元激活\\n值的放大或衰减作用。因此，我们会对每批数据中的每个样本运行网络，并记录所有隐\\n藏单元的激活值。这个过程称为 *前向传播 *（图7.1） 。记录下来的激活值之后将用于\\n梯度的计算。\\n观察 2：对偏置或权重的微小调整会在后续网络中引发一系列变化，这种变化会修\\n改其目标隐藏单元的值。这又会导致下一层隐藏单元的值发生变化，接着是下下层，依\\n此类推，直至模型输出和最终的损失值发生变化。\\n因此，要了解参数变化如何影响损失值，我们还需要知道每个后续隐藏层的变化如\\n何进一步影响它们的后继层。这一逻辑同样适用于考虑同一或更早层次中的其他参数\\n时。这意味着，我们可以一次性计算这些量，并在需要时复用。例如，设想计算对输入\\n至隐藏层h3、h2、h1的权重进行微小调整的影响：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 106}, page_content='7.3.示例 91\\n图 7.1:反向传播过程中的正向传播阶段。目的是计算损失 l对于每个权重（用箭头表示）和偏\\n置（图中未展示）的导数。也就是说，我们希望了解每个参数的微小变化将如何影响损失。每个\\n权重将其源头的隐藏单元的激活值乘以权重值，并将结果传递给目标隐藏单元。因此，任何权重\\n的微小变化所产生的效果，都会根据源隐藏单元的激活水平而放大。比如，蓝色权重作用于第一\\n层的第二个隐藏单元；如果该单元的激活值增加一倍，那么对蓝色权重的微小变化产生的影响也\\n会相应增加一倍。因此，为了计算权重的导数，我们需要计算并记录下隐藏层的激活值。这一过\\n程称为正向传播，因为它包括了按顺序执行网络方程的过程。\\n•要计算对隐藏层 h3输入的权重或偏置的微小调整如何影响损失，我们需要知道\\n(i)h3层变化如何影响模型输出 f，以及(ii)模型输出的变化如何影响损失（图\\n7.2a） 。\\n•要计算对隐藏层 h2输入的权重或偏置的微小调整如何影响损失，我们需要知道\\n(i)h2层的变化如何影响 h3层，(ii)h3层的变化如何影响模型输出，以及 (iii)模\\n型输出的变化如何影响损失（图 7.2b） 。\\n•要计算对隐藏层 h1输入的权重或偏置的微小调整如何影响损失，我们需要知道\\n(i)h1层的变化如何影响 h2层，(ii)h2层的变化如何影响 h3层，(iii)h3层的变化\\n如何影响模型输出，以及 (iv)模型输出的变化如何影响损失（图 7.2c） 。\\n随着我们向网络的前端回溯，大部分必需的计算在前一步已经完成，因此无需重复\\n计算。这种沿网络反向进行的计算导数的过程称为 *反向传播 *。\\n虽然反向传播的概念相对容易理解，但其推导过程需要应用矩阵微积分，因为偏置\\n和权重分别以向量和矩阵的形式存在。为了更好地理解其底层机理，下一节将为一个参\\n数为标量的简化模型推导反向传播过程。之后，在第 7.4节，我们将这一方法应用于深\\n度神经网络。\\n7.3示例\\n考虑一个含有八个标量参数 ϕ= [β0,ω0,β1,ω1,β2,ω2,β3,ω3]的模型f(xi,ϕ)，该模\\n型是通过组合 sin[·]、exp[·]和cos[·]函数而构成的：\\nf(x,ϕ) =β3+ω3·cos[β2+ω2·exp[β1+ω1·sin[β0+ω0·x]]] (7.5)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 107}, page_content='92 CHAPTER 7. 梯度和初始化\\n图 7.2:反向传播过程中的反向传播阶段。 a)为了计算对第三层 h3（蓝色箭头指向的层）输入\\n权重的改变如何影响损失，我们需要知道 h3中的隐藏单元如何影响模型输出 f，以及 f如何影\\n响损失（橙色箭头指示的影响） 。 b)为了计算对第二层 h2（蓝色箭头指向的层）输入权重的微\\n小改变如何影响损失，我们需要了解 (i) h2中的隐藏单元如何影响 h3，(ii) h3如何影响 f，以\\n及 (iii) f如何影响损失（橙色箭头指示的影响） 。 c)类似地，为了计算对第一层 h1（蓝色箭头\\n指向的层）输入权重的微小改变如何影响损失，我们需要知道 h1如何影响 h2，以及这些变化\\n如何通过网络传递影响到损失（橙色箭头指示的影响） 。反向传播首先在网络末端计算导数，然\\n后逆向进行，以此利用这些计算过程中的固有重复性。\\n以及一个最小二乘损失函数 L[ϕ] =P\\niℓi，其中的每一项定义如下：\\nℓi= (f(xi,ϕ)−yi)2(7.6)\\n其中，按照惯例， xi表示第i个训练输入， yi表示第i个训练输出。可以把这看作\\n是一个简单的神经网络，它具有单个输入、单个输出、每层一个隐藏单元，并且每一层\\n之间采用了不同的激活函数 sin[·]、exp[·]和cos[·]。我们的目标是计算以下导数：\\n∂ℓi\\n∂ω0,∂ℓi\\n∂β1,∂ℓi\\n∂ω1,∂ℓi\\n∂β2,∂ℓi\\n∂ω2,∂ℓi\\n∂β3,和∂ℓi\\n∂ω3.\\n虽然我们理论上可以通过手工求解这些导数的表达式并直接计算它们，但是部分导\\n数表达式的复杂度相当高。举个例子：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 108}, page_content='7.3.示例 93\\n∂ℓi\\n∂ω0=−2 [(β3+ω3·cos[β2+ω2·exp[β1+ω1·sin[β0+ω0·xi]]]−yi)\\n·ω1ω2ω3·xi·cos[β0+ω0·xi]·exp[β1+ω1·sin[β0+ω0·xi]]\\n·sin[β2+ω2·exp[β1+ω1·sin[β0+ω0·xi]]]] (7.7)\\n这些表达式的推导和编码不仅容易出错，而且未能充分利用其中的重复性元素；值\\n得注意的是，三个指数函数项实际上是一致的。\\n图 7.3:反向传播过程中的正向传播阶段。我们依次计算并记录每一个中间变量，直至最终计算\\n出损失。\\n反向传播算法是一种同时计算所有这些导数的高效方法，它主要分为两个步骤： （ i）\\n前向传播，在此过程中我们计算并保存一系列中间值及网络的输出结果； （ ii）反向传播，\\n在此过程中我们从网络的输出层开始，逆向计算每个参数的导数，同时复用之前阶段的\\n计算结果。\\n前向传播： 我们把损失计算过程视作一连串的计算步骤：\\nf0=β0+ω0·xi\\nh1=sin[f0]\\nf1=β1+ω1·h1\\nh2=exp[f1]\\nf2=β2+ω2·h2\\nh3=cos[f2]\\nf3=β3+ω3·h3\\nℓi= (f3−yi)2. (7.8)\\n我们计算并存储了中间变量 fk和hk（图7.3）的值。\\n第一次反向传播： 接下来，我们计算损失函数 ℓi对这些中间变量的偏导数，计算顺\\n序与它们被计算出来的顺序相反：\\n∂ℓi\\n∂f′\\n3,∂ℓi\\n∂h′\\n3,∂ℓi\\n∂f′\\n2,∂ℓi\\n∂h′\\n2,∂ℓi\\n∂f′\\n1,∂ℓi\\n∂h′\\n1,and∂ℓi\\n∂f′\\n0(7.9)\\n首先计算的这个导数相对简单直接：\\n∂ℓi\\n∂f3= 2(f3−yi) (7.10)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 109}, page_content='94 CHAPTER 7. 梯度和初始化\\n接下来的导数可以通过应用链式法则进行计算：\\n∂ℓi\\n∂h3=∂f3\\n∂h3∂ℓi\\n∂f3(7.11)\\n这里探讨的是当 h3发生变化时， ℓi会如何变化。我们可以将这个问题分解为两部\\n分：(i)h3发生变化导致 f3如何变化；以及 (ii)f3发生变化导致 ℓi如何变化。根据原始\\n方程，h3的变化引起 f3的变化，进一步影响 ℓi，这些导数体现了这一连锁反应的效应。\\n值得注意的是，我们已经计算出了这些导数中的第二个，而另一个导数是 β3+ω3·h3对\\nh3的导数，即 ω3。我们继续这样做，计算出输出相对于这些中间量的导数（图 7.4） ：\\n∂ℓi\\n∂f2=∂h3\\n∂f2\\x12∂f3\\n∂h3∂ℓi\\n∂f3\\x13\\n,\\n∂ℓi\\n∂h2=∂f2\\n∂h2\\x12∂h3\\n∂f2∂f3\\n∂h3∂ℓi\\n∂f3\\x13\\n,\\n∂ℓi\\n∂f1=∂h2\\n∂f1\\x12∂f2\\n∂h2∂h3\\n∂f2∂f3\\n∂h3∂ℓi\\n∂f3\\x13\\n,\\n∂ℓi\\n∂h1=∂f1\\n∂h1\\x12∂h2\\n∂f1∂f2\\n∂h2∂h3\\n∂f2∂f3\\n∂h3∂ℓi\\n∂f3\\x13\\n,\\n∂ℓi\\n∂f0=∂h1\\n∂f0\\x12∂f1\\n∂h1∂h2\\n∂f1∂f2\\n∂h2∂h3\\n∂f2∂f3\\n∂h3∂ℓi\\n∂f3\\x13\\n(7.12)\\n在每个案例中，我们已经在上一步骤计算出了括号内的值，最后一项则有一个简洁\\n的公式。这些建立在先前章节观察 2（图7.2）的基础上；通过倒序计算这些导数，我们\\n能够复用先前计算得到的导数。\\n第二次反向传播： 最终，我们分析改变参数 β和ω时，损失ℓi如何相应变化。我\\n们再次应用链式法则（图 7.5） ：\\n∂ℓi\\n∂βk=∂fk\\n∂βk∂ℓi\\n∂fk,\\n∂ℓi\\n∂ωk=∂fk\\n∂ωk∂ℓi\\n∂fk(7.13)\\n对于每个案例，右侧的第二项已在方程式 7.12中计算得出。当 k > 0，我们得到\\nfk=βk+ωk·hk，因此：\\n∂fk\\n∂βk= 1and∂fk\\n∂ωk=hk (7.14)\\n这与上一节的第一观察点一致； ωk的改变对效果与源变量 hk的值呈正比（该值在\\n前向传播中已被记录） 。从项 f0=β0+ω·xi得到的最终导数为：\\n∂f0\\n∂β0= 1and∂f0\\n∂ω0=xi (7.15)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 110}, page_content='7.4.反向传播算法 95\\n反向传播不仅过程简化，相较于单独计算每个导数（如方程 7.7.1）的方式，效率更\\n高。\\n7.4反向传播算法\\n现在我们针对一个三层网络重复这一过程（图 7.1） 。尽管直觉和大部分的代数处理\\n相似，但主要的不同在于中间变量 fk,hk是向量形式，偏置 βk也是向量，权重 Ωk是矩\\n阵，并且我们采用的是 ReLU函数而不是如 cos[·]这类简单的代数函数。\\n前向传播过程： 我们将网络描述为一系列连续的计算步骤：\\nf0=β0+ Ω 0xi\\nh1=a[f0]\\nf1=β1+ Ω 1h1\\nh2=a[f1]\\nf2=β2+ Ω 2h2\\nh3=a[f2]\\nf3=β3+ Ω 3h3\\nℓi=l[f3,yi], (7.16)\\n这里fk−1指的是第kth隐藏层的预激活值（即在 ReLU函数a[l]应用之前的值） ，\\nhk包含了第kth隐藏层的激活值（即在 ReLU函数应用之后的值） 。项 lf3,y表示损失函\\n数（如最小二乘损失或二元交叉熵损失） 。在前向传播阶段，我们按顺序完成这些计算\\n并记录所有中间结果。\\n第一次反向传播过程： 现在，我们探讨修改预激活 f0,f1,f2时，损失如何变化。通\\n过应用链式法则，我们得到了损失 ℓi相对于f2的偏导数的表达方式：\\n∂ℓi\\n∂f2=∂h3\\n∂f2∂f3\\n∂h3∂ℓi\\n∂f3(7.17)\\n右侧的三个项的维度分别是 D3×D3,D3×Df和Df×1，这里D3表示第三层隐\\n藏单元的数目， Df表示模型输出 f3的维度。\\n图 7.4:反向传播过程中的反向传播第一阶段。我们从函数的最末端开始逆向进行，计算损失 l\\n对于各个中间变量的导数 ∂li/∂f •和∂li/∂h •。每个导数的计算都是基于前一个导数，并乘以\\n形如 ∂fk/∂hk或∂hk/∂fk −1的项进行的。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 111}, page_content='96 CHAPTER 7. 梯度和初始化\\n图 7.5:反向传播过程中的第二阶段。我们最终计算了导数 ∂li/∂β •和∂li/∂ω •。每个导数的\\n计算都是通过将 ∂li/∂fk项乘以适当的 ∂fk/∂∂βk或∂fk/∂ωk来实现的。\\n图 7.6:整流线性单元的导数。当输入小于零时，整流线性单元（橙色曲线）输出为零；当输入\\n大于零时，输出为输入值。其导数（青色曲线）在输入小于零时为零（因为此处斜率为零） ，在\\n输入大于零时为一（因为此处斜率为一） 。\\n类似地，我们也可以分析当改变 f1和f0时，损失的变化情况：\\n∂ℓi\\n∂f1=∂h2\\n∂f1∂f2\\n∂h2\\x12∂h3\\n∂f2∂f3\\n∂h3∂ℓi\\n∂f3\\x13\\n(7.18)\\n∂ℓi\\n∂f0=∂h1\\n∂f0∂f1\\n∂h1\\x12∂h2\\n∂f1∂f2\\n∂h2∂h3\\n∂f2∂f3\\n∂h3∂ℓi\\n∂f3\\x13\\n(7.19)\\n请注意，每种情况下，括号中的内容都已在前一步计算完成。通过反向遍历网络，\\n我们可以复用先前的计算结果。此外，这些计算项本身都相对简单。从方程 7.17的右侧\\n向前回溯时，我们得到：\\n•损失ℓi对网络输出 f3的偏导数∂ℓi/∂f3取决于损失函数，但它通常有一个简单的\\n公式形式。\\n•网络输出f3相对于隐藏层 h3的偏导数∂f3/∂h3为：\\n∂f3\\n∂h3=∂\\n∂h3(β3+ Ω 3h3) = ΩT\\n3 (7.20)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 112}, page_content='7.4.反向传播算法 97\\n如果你对矩阵微积分不够熟悉，这个结果可能不是很直观。这一问题在问题 7.6中\\n有所探讨。\\n-激活函数的输出 h3对其输入f2的偏导数∂h3/∂f2取决于激活函数的种类。它是\\n一个对角矩阵，因为每个激活值只与其对应的预激活值有关。对于 ReLU函数，当f2\\n小于零时对角项为零，否则为一（图 7.6） 。我们不直接进行矩阵乘法，而是将对角项提\\n取为向量 [f2>0]进行逐元素乘法，这种做法更为高效。\\n方程7.18和7.19中右侧的项具有相似的结构。随着我们逐步回退网络，我们将交\\n替执行(i)乘以权重矩阵 Ωk的转置和 (ii)根据隐藏层的输入 fk−1进行阈值判断。这些\\n输入值在前向传播时已经被记录下来。\\n第二次反向传播过程： 现在我们已经掌握了如何计算损失对于 fk的偏导数∂ℓi/∂fk，\\n我们可以集中注意力于计算损失对权重和偏置的导数。为了得到损失对偏置 βk的导数，\\n我们再次应用了链式法则：\\n∂ℓi\\n∂βk=∂fk\\n∂βk∂ℓi\\n∂fk\\n=∂\\n∂βk(βk+ Ω khk)∂ℓi\\n∂fk\\n=∂ℓi\\n∂fk(7.21)\\n这部分我们已在方程 7.17和7.18中完成了计算。\\n同样地，权重矩阵 Ωk的导数可以通过以下公式计算：\\n∂ℓi\\n∂Ωk=∂fk\\n∂Ωk∂ℓi\\n∂fk\\n=∂\\n∂Ωk(βk+ Ω khk)∂ℓi\\n∂fk\\n=∂ℓi\\n∂fkhT\\nk (7.22)\\n从第二行过渡到第三行的逻辑并不直观，这一点在问题 7.9中有所讨论。然而，这\\n个结果是合理的。最终得到的是一个与 Ωk尺寸相同的矩阵。这个结果与 hk线性相关，\\nhk在原表达式中与 Ωk相乘。这也验证了最初的直觉： Ωk中的权重导数将与它们乘的\\n隐藏单元的值成比例。回顾之前，我们已经在前向传播阶段完成了这些计算。\\n7.4.1反向传播算法概述\\n现在，让我们简要概述反向传播算法的最终形态。设想一个深度神经网络 fi,xi，它\\n接收输入xi， 包含K个隐藏层， 采用 ReLU激活函数， 并计算单个损失项 ℓi=l[fi,xi,yi]。\\n反向传播的目标是求出损失 ℓi对偏置βk和权重 Ωk的偏导数∂ℓi/∂βk和∂ℓi/∂Ωk。前\\n向传播过程： 我们计算并记录下列数据：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 113}, page_content='98 CHAPTER 7. 梯度和初始化\\nf0=β0+ Ω 0xi\\nhk=a[fk−1]k∈{1,2,...,K}\\nfk=βk+ Ω khk. k∈{1,2,...,K} (7.23)\\n反向传播过程： 我们从损失函数 ℓi相对于网络输出 fK的偏导数∂ℓi/∂fK开始，逆\\n向遍历网络：\\n∂ℓi\\n∂βk=∂ℓi\\n∂fk\\n∂ℓi\\n∂Ωk=∂ℓi\\n∂fkhT\\nk\\n∂ℓi\\n∂fk−1=1[fk−1>0]⊙\\x12\\nΩT\\nk∂ℓi\\n∂fk\\x13\\n(7.24)\\n这里，⊙代表逐元素乘法， 1[fk−1>0]是一个向量，其在 fk−1大于零的位置为 1，\\n其余为0。最终，我们求出第一组偏置和权重的偏导数：\\n∂ℓi\\n∂β0=∂ℓi\\n∂f0\\n∂ℓi\\n∂Ω0=∂ℓi\\n∂f0xT\\ni (7.25)\\n我们对批次中的每一个训练实例计算这些偏导数，并将它们累加起来，以便为 SGD\\n更新计算出梯度。\\n需要注意的是，反向传播算法极为高效；无论是前向还是反向传播，最计算密集的\\n步骤均为矩阵乘法（分别由 Ω和ΩT完成） ，仅涉及加法和乘法操作。然而，这种方法\\n在内存使用上并不高效；因为前向传播中的所有中间值都需保存，这可能限制我们能够\\n训练的模型规模。\\n7.4.2算法微分\\n虽然理解反向传播算法是重要的，但实际上你可能不需要自己编写这些代码。现代\\n深度学习框架，如 PyTorch 和TensorFlow ，能够根据模型的定义自动计算导数，这一\\n过程称为 *算法自动微分 *。\\n框架内的每个功能组件（如线性变换、 ReLU激活函数、损失函数）均能自行计算\\n其导数。例如， PyTorch 中的ReLU函数zout=relu(zin)能够计算出其输出 zout相对\\n于输入zin的导数。同理，一个线性函数 zout=β+ Σzin能够计算输出 zout相对于输入\\nzin，以及参数 β和Ω的导数。算法自动微分框架还掌握网络操作的顺序，因而具备执\\n行前向传播和反向传播所需的全部信息。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 114}, page_content='7.5.参数初始化 99\\n这些框架充分利用了现代图形处理单元（ GPU）的大规模并行处理能力。诸如矩阵\\n乘法之类的运算（在前向和反向传递过程中均非常重要）天生适合并行处理。此外，如\\n果模型和前向传播中的中间结果没有超出可用内存的限制，可以对整个批量数据的前向\\n和反向传递同时并行处理。\\n因为训练算法现在能够并行处理整个批次，所以输入变为了多维 *张量*。在此语\\n境下，张量可视为矩阵向任意维度的扩展。因此，向量是一维张量，矩阵是二维张量，\\n而三维张量则是一个三维数字网格。直到现在，训练数据都是一维的，所以反向传播的\\n输入会是一个二维张量，其中第一维索引批次元素，第二维索引数据维度。在接下来的\\n章节里，我们将探讨更为复杂的结构化输入数据。比如，在输入为 RGB图像的模型中，\\n原始数据样本是三维的（高 x宽x通道） 。这里，对学习框架的输入将是一个四维张量，\\n额外的维度用于索引批次元素。\\n7.4.3扩展至任意计算图\\n我们已经讨论了深度神经网络中自然顺序的反向传播过程，其中我们依次计算中间\\n量f0, f1, f2, ..., fk 。然而，模型并不局限于顺序计算。在本书的后续部分，我们将介绍\\n具有分支结构的模型。举例来说，我们可能会将隐藏层的值通过两个不同的子网络进行\\n处理，然后再次组合。\\n幸运的是，即使计算图是无环的，反向传播的概念依然适用。现代算法自动微分框\\n架，如PyTorch 和TensorFlow ，能够处理任意的无环计算图。\\n7.5参数初始化\\n反向传播算法计算的导数被随机梯度下降和 Adam算法用于训练模型。在我们开始\\n训练之前，如何初始化参数是一个关键问题。为了理解其重要性，考虑到在前向传播过\\n程中，每一组预激活值 fk是按照下面的方式计算的：\\nfk=βk+ Ω khk\\n=βk+ Ω ka[hk−1] (7.26)\\n其中a[·]代表应用 ReLU函数， Ωk和βk分别代表权重和偏置。假设我们将所有偏\\n置初始化为零，并且 Ωk的元素按照均值为零、方差为 σ2的正态分布进行初始化。设想\\n以下两种情况：\\n•如果方差σ2非常小（比如， 10−5） ，那么βk+ Ω khk的每个元素将是 hk的一个小\\n权重加权和；这样的结果可能会比输入值的幅度还小。此外，由于 ReLU函数会\\n将小于零的值设为零， hk的取值范围将是 fk−1的一半。因此，随着网络深入，隐'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 114}, page_content='权重加权和；这样的结果可能会比输入值的幅度还小。此外，由于 ReLU函数会\\n将小于零的值设为零， hk的取值范围将是 fk−1的一半。因此，随着网络深入，隐\\n藏层的预激活值的幅度会逐渐变小。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 115}, page_content='100 CHAPTER 7. 梯度和初始化\\n•如果方差σ2非常大（比如， 105） ，那么βk+ Ω khk的每个元素将是 hk的一个大\\n权重加权和；这样的结果可能会远大于输入值的幅度。尽管 ReLU函数会将输入\\n值的范围减半，但若 σ2足够大，预激活值的幅度在网络中逐层增加。\\n在这两种极端情况下，预激活值可能变得极小或极大，以至于无法用有限精度的浮\\n点数来表示。\\n即便前向传播过程可行，后向传播过程也面临同样的逻辑问题。每一次梯度更新\\n（如方程 7.24所示）涉及到乘以 ΩT。如果 Ω的值未能合理初始化，那么在后向传播过\\n程中，梯度的幅度可能会不受控制地减少或增加。这分别称为梯度消失问题和梯度爆炸\\n问题。在前者情况下，模型的更新量变得极小；在后者情况下，更新变得不稳定。\\n7.5.1前向传播的初始化\\n我们将展示该论点的数学表述。请考虑相邻预激活 f和f′之间的计算过程，它们\\n的维度分别是 Dh和Dh′：\\nh=a[f],\\nf′=β+ Ωh (7.27)\\n其中f代表神经网络中的预激活值， Ω和β分别代表网络的权重和偏置， a{·}表\\n示激活函数。\\n假设在输入层 f中，预激活值 fj的方差为σ2。将偏置βj初始化为 0，权重 Ωij按\\n照均值为 0、方差为α2\\nD的正态分布进行初始化。接下来，我们将推导出下一层预激活\\n值f′的平均值和方差的表达式。\\n中间预激活值 fi的期望（平均值） E[fi]为：\\nE[f′\\ni] =E\"\\nβi+DhX\\nj=1Ωijhj#\\n=E[βi] +DhX\\nj=1E[Ωijhj]\\n=E[βi] +DhX\\nj=1E[Ωij]E[hj]\\n= 0 +DhX\\nj=10·E[hj] = 0, (7.28)\\n其中Dh代表输入层 h的维度。我们应用了期望操作的规则，并假设在第二行与第\\n三行之间，隐藏单元 hj与网络权重 Ωij的分布互相独立。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 116}, page_content='7.5.参数初始化 101\\n基于这个结果，我们得出预激活值 f′\\ni的方差σ2\\nf′为：\\nσ2\\nf′=E[f′2\\ni]−E[f′\\ni]2\\n=E2\\n4 \\nβi+DhX\\nj=1Ωijhj!23\\n5−0\\n=E2\\n4 DhX\\nj=1Ωijhj!23\\n5\\n=DhX\\nj=1E[Ω2\\nij]E[h2\\nj]\\n=DhX\\nj=1σ2E[h2\\nj] =σ2DhX\\nj=1E[h2\\nj], (7.29)\\n我们应用了方差的定义 σ2=E[(x−E[x])2] =E[x2]−E[x]2。再次，我们假定权重\\nΩij和隐藏单元 hj在第三行与第四行之间的分布是相互独立的。\\n在假设预激活 fj的输入分布在零点对称的前提下，一半的预激活值会被 ReLU函\\n数设置为零，这意味着隐藏单元的第二矩 E[h2\\nj]将是fj的方差σ2的一半（参考问题\\n7.14） ：\\nσ2\\nf′=σ2\\nΩDhX\\nj=1σ2\\nf\\n2=1\\n2Dhσ2\\nΩσ2\\nf. (7.30)\\n这也就意味着，若我们想让后续预激活值 f′的方差σ2\\nf′在前向传播过程中保持与\\n原始预激活值 f的方差σ2\\nf相等，那么我们需要设定：\\nσ2\\nf′=2\\nDh(7.31)\\n其中Dh是应用权重的原始层的维度。这种初始化方法被称为 He初始化。\\n7.5.2反向传播的初始化\\n一个相似的论证说明了反向传播期间梯度∂l\\n∂fk的方差的变化情况。在反向传播过程\\n中，我们将其与权重矩阵的转置 ΩT相乘（见方程 7.24） ，因此相应的表达式变为：\\nσ2\\nn=2\\nDh′, (7.32)\\n其中Dh′表示权重作用的那一层的维度。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 117}, page_content='102 CHAPTER 7. 梯度和初始化\\n图 7.7:权重初始化。设想一个具有 50个隐藏层，每层有 Dh = 100 个隐藏单元的深度网络。该\\n网络的 100维输入 x从标准正态分布中初始化，设定单一固定目标 y = 0，并使用最小二乘损\\n失函数。偏置向量 βk初始化为零，权重矩阵 Ωk则采用均值为零的正态分布初始化，并设置五\\n种不同的方差 σΩ2∈{0.001,0.01,0.02,0.1,1.0}。a)正向传播计算出的隐藏单元激活方差随网络\\n层变化的函数图。对于 He初始化 (σΩ2= 2/Dh= 0.02)，激活方差保持稳定。但是，对于较大\\n的值，方差迅速增加；对于较小的值，方差迅速减少（注意此处使用了对数刻度） 。 b)反向传播\\n中梯度的方差（用实线表示）延续了这一趋势；如果初始化值大于 0.02，梯度大小会随着网络\\n反向传播而迅速增大。如果初始化值小于这个值，则梯度大小会减小。这两种情况分别被称为梯\\n度爆炸和梯度消失问题。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 118}, page_content='7.6.示例训练代码 103\\n7.5.3正向传播和反向传播的初始化\\n如果权重矩阵 Ω不是方阵（即，两个相邻层的隐藏单元数量不同，从而 Dh和Dh′\\n存在差异） ，则无法选择一个方差同时满足方程 7.31和7.32。一种可行的折衷方法是采\\n用平均数 (Dh+Dh′)/2作为项数，据此得到：\\nσ2\\nn=4\\nDh+Dh′(7.33)\\n图7.7通过实验数据表明，当参数进行适当的初始化后，正向传播过程中隐藏单元\\n的方差以及反向传播过程中梯度的方差均能保持稳定。\\n7.6示例训练代码\\n本书主要专注于科学研究；并非旨在指导实现深度学习模型。然而，在图 7.8中，我\\n们呈现了一段 PyTorch 代码，该代码实践了迄今为止本书探讨的理念。该代码定义了一\\n个神经网络并初始化了权重。它生成了随机的输入和输出数据集，并定义了一个最小二\\n乘损失函数。模型通过在大小为 10的批次中使用具有动量的 SGD在100轮次(epoch)\\n内进行训练，学习率从 0.01开始，并每 10轮次减半。\\n核心观点是，虽然深度学习的底层原理相当复杂，其实现过程却相对简单。比如，\\n反向传播的所有细节都封装在了一行代码 loss.backward() 中。\\n7.7总结\\n上一章引入了随机梯度下降（ SGD） ， 一个旨在找到函数最小值的迭代优化算法。在\\n神经网络的背景下，这一算法寻找能够最小化损失函数的参数。 SGD依赖于损失函数\\n相对于参数的梯度，这需要在优化前进行初始化。本章解决了深度神经网络面临的这两\\n大问题。\\n图 7.8:在随机数据上训练双层网络的示例代码。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 119}, page_content='104 CHAPTER 7. 梯度和初始化\\n梯度必须对大量参数进行评估，针对每个批次中的每一个样本，以及每一次 SGD\\n迭代。因此，高效的梯度计算显得至关重要，为此引入了反向传播算法。此外，谨慎的\\n参数初始化也极为关键。在正向传播过程中，隐藏单元激活的幅度可能会指数级地增加\\n或减少。反向传播过程中，梯度幅度的变化同样可能出现，这种现象被称为梯度消失和\\n梯度爆炸问题，它们都会阻碍训练过程，但可以通过恰当的初始化来避免。\\n至此，我们已经定义了模型及其损失函数，并可以针对特定任务训练模型。下一章\\n将讨论如何评估模型性能。\\n7.8笔记\\n反向传播 (Backpropagation) ： 在计算图中计算梯度时， 有效重复使用部分计算的\\n技术已多次被发现，包括 Werbos (1974) 、Bryson等人(1979)、LeCun (1985) 和Parker\\n(1985)的研究。然而，这一理念最为人称道的描述出现在 Rumelhart 等人(1985)和\\nRumelhart 等人(1986)的工作中，他们还首次提出了“反向传播”这一术语。这项后期\\n工作引发了 80年代和90年代神经网络研究的新浪潮；首次使得训练具有隐藏层的网\\n络成为可能。不过，由于训练数据的缺乏、计算能力的限制以及使用 Sigmoid激活函数，\\n进展最终陷入停滞（事后看来） 。直到 Krizhevsky 等人(2012)在图像分类方面取得显著\\n成果，自然语言处理和计算机视觉领域才开始依赖神经网络模型，开启了深度学习的现\\n代纪元。\\n在现代深度学习框架如 PyTorch 和TensorFlow 中实施的反向传播，是逆模式算法\\n微分(reverse-mode algorithmic differentiation) 的一个例子。这与在计算图前向传播过\\n程中累积链式法则导数的前向模式算法微分不同（参见问题 7.13） 。有关算法微分的更\\n多信息，请参阅 Griewank & Walther (2008) 和Baydin等人(2018)的工作。\\n初始化：He初始化最初由 He等人(2015)提出。它紧跟 Glorot或Xavier初始化\\n（Glorot & Bengio, 2010 ） ，非常相似，但未考虑 ReLU层的影响，因此有一定的差异。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 119}, page_content='（Glorot & Bengio, 2010 ） ，非常相似，但未考虑 ReLU层的影响，因此有一定的差异。\\n实际上， LeCun等人(2012)早期就提出了本质上相同的方法，但其动机略有不同；在\\n此，采用了 Sigmoid激活函数，这种函数自然地规范了每层输出的范围，从而帮助避免\\n隐藏单元幅度的指数级增长。然而，若预激活值过大，就会落入 Sigmoid函数的平坦区\\n域，导致梯度非常小。因此，合理地初始化权重仍然至关重要。 Klambauer 等人(2017)\\n引入了缩放指数线性单元 (SeLU)并显示，在一定范围的输入下，该激活函数倾向于使\\n网络层的激活自动趋向于零均值和单位方差。\\n完全不同的方法是通过网络传递数据后，根据实际观察到的方差进行规范化。层\\n序列单位方差初始化 (Layer-sequential unit variance initialization) （Mishkin & Matas,\\n2016）就是这种方法的一个例子， 其中权重矩阵以正交方式初始化。 GradInit (Zhu 等人，\\n2021)随机初始化权重，并在学习每个权重矩阵的非负缩放因子时暂时固定它们。这些\\n因子选取是为了在固定学习率的条件下最大化减少损失，同时限制最大梯度范数。激活\\n规范化或 ActNorm 在每个网络层的每个隐藏单元后添加一个可学习的缩放和偏移参数。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 120}, page_content='7.8.笔记 105\\n他们在网络上运行一个初始批次，然后调整偏移和比例，使得激活的平均值为零且方差\\n为一。此后，这些额外的参数将作为模型的一部分进行学习。\\n与这些方法紧密相关的是如 BatchNorm （Ioffe & Szegedy, 2015 ）等方案，其中网络\\n作为其每一步处理的一部分，规范化每批的方差。 BatchNorm 及其变种将在第 11章中\\n讨论。其他针对特定架构的初始化方案包括用于卷积网络的 ConvolutionOrthogonal 初\\n始化器（ Xiao等人，2018a） 、残差网络的 Fixup（Zhang等人，2019a）以及Transformer\\n的TFixup（Huang等人，2020a）和DTFixup （Xu等人，2021b） 。\\n减少内存需求：训练神经网络是一个内存密集型的过程。我们必须存储批次中每\\n个成员的模型参数和隐藏单元的预激活值。减少内存需求的两种方法包括梯度检查点\\n（Chen等人，2016a）和微批处理（ Huang等人，2019） 。在梯度检查点技术中，激活仅\\n在前向传播的每 N层存储一次。在反向传递期间，中间缺失的激活从最近的检查点重新\\n计算。这样，我们可以在计算成本上执行前向传播两次的情况下大幅减少内存需求（参\\n见问题7.11） 。在微批处理中，将批次细分为更小的部分，并在应用到网络之前聚合每\\n个子批次的梯度更新。构建可逆网络（例如， Gomez等人，2017）是一种完全不同的方\\n法，在这种网络中，可以从当前层的激活计算出上一层的激活，因此在前向传播期间无\\n需缓存任何内容（见第 16章） 。Sohoni等人(2019)回顾了减少内存需求的方法。\\n分布式训练：对于大型模型，内存需求或所需总时间可能对于单个处理器来说过多。\\n在这种情况下，我们必须采用分布式训练，训练过程在多个处理器上并行进行。并行方\\n法有几种。在数据并行中，每个处理器或节点包含模型的完整副本，但只运行批次的一\\n部分（参见 Xing等人，2015；Li等人，2020b） 。每个节点的梯度在中央聚合，然后重新\\n分配回每个节点，以确保模型保持一致。这称为同步训练。聚合和重新分配梯度所需的\\n同步可能成为性能瓶颈，这引出了异步训练的概念。例如，在 Hogwild! 算法（Recht等'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 120}, page_content='分配回每个节点，以确保模型保持一致。这称为同步训练。聚合和重新分配梯度所需的\\n同步可能成为性能瓶颈，这引出了异步训练的概念。例如，在 Hogwild! 算法（Recht等\\n人，2011）中，节点的梯度被用来更新中心模型，一旦准备好即可。更新后的模型随后\\n重新分配给该节点。这意味着每个节点可能在任何给定时间都有略微不同版本的模型，\\n因此梯度更新可能是陈旧的；然而，实践证明这种方法效果良好。也开发了其他去中心\\n化方案。例如，在 Zhang等人(2016a)的研究中，个别节点以环形结构互相更新。\\n数据并行方法仍然假设整个模型可以存储在单个节点的内存中。管道模型并行不需\\n要这样的前提，它将网络的不同层存储在不同节点上。在一种简单的实现中，第一个节\\n点对批次的前几层进行前向传播，并将结果传递给下一个节点，该节点继续对接下来的\\n几层进行前向传播，以此类推。在反向传递中，以相反的顺序更新梯度。这种方法的明\\n显缺点是，每台机器在大多数时间里处于闲置状态。已经提出了各种方案来减少这种低\\n效率，例如，让每个节点依次处理微批次（例如， Huang等人，2019；Narayanan 等人，\\n2021a） 。最后，在张量模型并行中，单个网络层的计算在节点之间分布（例如， Shoeybi\\n等人，2019） 。Narayanan 等人(2021b)提供了分布式训练方法的综述，他们结合张量、\\n管道和数据并行训练了一个具有一万亿参数的语言模型，在 3072个GPU上运行。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 121}, page_content='106 CHAPTER 7. 梯度和初始化\\n7.9习题\\n问题 7.1一个包含两个隐藏层，每层有两个隐藏单元的双层网络可以被定义为：\\ny=ϕ0+ϕ1a[ψ01+ψ11a[θ01+θ11x] +ψ21a[θ02+θ12x]]\\n+ϕ2a[ψ02+ψ12a[θ01+θ11x] +ψ22a[θ02+θ12x]] (7.34)\\n其中函数a[·]是线性整流函数（ ReLU函数） 。直接计算输出 y相对于各参数 ϕ·,θ··,\\n和ψ··的导数（即，不采用反向传播算法） 。线性整流函数（ ReLU函数）相对于其输入\\n的导数∂a(z)/∂z是指示函数 I[z >0]，如果参数大于零则返回一，否则返回零（图 7.6） 。\\n问题 7.2寻找等式 7.12中每个导数链五个最终项的表达式。\\n问题 7.3等式7.19中每个项的尺寸是多少？\\n问题 7.4对于最小平方损失函数，计算导数 ∂ℓi/∂f(xi,ϕ)：\\nℓi= (yi−f(xi,ϕ))2. (7.35)\\n问题 7.5对于二分类损失函数，计算导数 ∂ℓi/∂f(xi,ϕ)：\\nℓi=−(1−yi)log[1−sig[f(xi,ϕ)]]−yilog[sig[f(xi,ϕ)]] (7.36)\\n其中函数sig[]是逻辑Sigmoid 函数，并被定义为：\\nsig[z] =1\\n1 +exp[−z]. (7.37)\\n问题 7.6对于z=β+ Ωh证明：\\n∂z\\n∂h= ΩT,\\n其中∂z\\n∂h是一个矩阵，包含项∂zi\\n∂hj在其第i列和第j行。首先找出构成元素∂zi\\n∂hj的表达\\n式，然后确定矩阵∂z\\n∂h的形式。\\n问题 7.7当使用逻辑 Sigmoid函数 （参见等式 7.37） 作为激活函数时， 即 h=sig[f]，\\n计算此激活函数对 f的导数∂h\\n∂f。当输入值是 (i)一个很大的正数和 (ii)一个很大的负数\\n时，这个导数会怎样变化？\\n问题 7.8考虑使用 (i) Heaviside 函数和(ii)矩形函数作为激活函数：\\nHeaviside [z] =8\\n<\\n:0z <0\\n1z≥0(7.38)\\n和\\nrect[z] =8\\n>>><\\n>>>:0z <0\\n1 0≤z≤1\\n0z >1(7.39)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 122}, page_content='7.9.习题 107\\n讨论这些函数为何在使用基于梯度的优化方法训练神经网络时会产生问题。\\n问题 7.9考虑损失函数 ℓ[f]，其中f=β+ Ωh。我们想要找出当改变 Ω时，损失ℓ\\n如何变化，用一个包含导数 ∂ℓ/∂Ωij在第i行和第j列的矩阵来表示。找出 ∂ℓ/∂Ωij的\\n表达式，并使用链式法则证明：\\n∂ℓ\\n∂Ω=∂ℓ\\n∂hT. (7.40)\\n问题 7.10导出对于使用 leaky ReLU 激活函数的网络反向传播算法的反向传递方\\n程，定义为：\\na[z] =ReLU [z] =8\\n<\\n:α·z z < 0\\nz z≥0(7.41)\\n其中α是一个小的正值（通常为 0.1） 。\\n问题 7.11考虑训练一个含有五十层的网络，在正向传播过程中，我们只有足够的\\n内存来在每十个隐藏层保存一次预激活值。请解释在这种情况下如何利用梯度检查点技\\n术计算导数。\\n问题 7.12本题探索在一般的有向无环图计算图上计算导数。考虑下列函数：\\ny=exp[exp[x] +exp[x2]] +sin[exp[x] +exp[x2]]. (7.42)\\n我们可以将这个过程分解为以下几步中间计算：\\nf1=exp[x]\\nf2=f2\\n1\\nf3=f1+f2\\nf4=exp[f3]\\nf5=sin[f3]\\ny=f4+f5. (7.43)\\n相应的计算图展示在图 7.9中。通过反向传播法计算∂y\\n∂x的导数。也就是依次计算：\\n∂y\\n∂f5,∂y\\n∂f4,∂y\\n∂f3,∂y\\n∂f2,∂y\\n∂f1,∂y\\n∂x(7.44)\\n每一步均应用链式法则，以利用之前已计算出的导数。\\n图 7.9:针对问题 7.12和问题 7.13的计算图，根据 Domke (2010) 的研究进行了展示。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 123}, page_content='108 CHAPTER 7. 梯度和初始化\\n问题 7.13对于问题 7.42中相同的函数，通过正向传播法计算∂y\\n∂x的导数。即依次\\n计算：\\n∂f1\\n∂x,∂f2\\n∂x,∂f3\\n∂x,∂f4\\n∂x,∂f5\\n∂x,∂y\\n∂x(7.45)\\n每一步均应用链式法则，以利用之前已计算出的导数。为什么在计算深度网络的参\\n数梯度时，我们不采用正向传播法呢？\\n问题 7.14假设有一个随机变量 a，其方差 Var[a] =σ2，且其分布在均值 E[a] = 0\\n周围对称。证明如果我们将这个变量通过 ReLU函数处理：\\nb=ReLU [a] =8\\n<\\n:0a<0\\na a≥0,] (7.46)\\n那么，变换后变量的二阶矩（二次方期望）为 E[b2] =σ2/2。\\n问题 7.15如果我们将网络中所有的权重和偏置初始化为零，你认为会发生什么情\\n况？\\n问题 7.16使用PyTorch 实现图7.8中的代码，并绘制训练过程中的损失与迭代次\\n数的关系图。\\n问题 7.17修改图7.8中的代码以解决一个二元分类问题。你需要 (i)将目标y修\\n改为二元值， (ii)修改网络以预测介于 0和1之间的数值， (iii)适当修改损失函数。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 124}, page_content='Chapter 8\\n性能评估\\n前文介绍了神经网络模型、损失函数和训练算法。本章将探讨如何评估训练好的模\\n型性能。对于具备足够容量（即隐藏单元数量）的神经网络模型而言，它们在训练数据\\n上的表现往往是完美无瑕的。但这并不保证模型能够同样出色地适用于新的测试数据。\\n我们会发现， 测试误差主要由三种不同的原因造成， 它们各自的影响程度依赖于： （ i）\\n任务本身的固有不确定性， （ ii）训练数据的量，以及（ iii）模型选择。特别地，模型选\\n择引出了超参数搜索的议题。本章还将讨论如何确定模型超参数（如隐藏层的数目及每\\n层的隐藏单元数）和学习算法的超参数（如学习率和批次大小）的选择方法。\\n8.1训练一个简单模型\\n本节我们将通过 MNIST-1D 数据集（图 8.1）来分析模型的性能。该数据集包括十\\n个类别y∈{0,1,..., 9}，分别代表数字 0到9。这些数据是基于每个数字的一维模板，\\n通过随机变换这些模板并加入噪声生成的。训练数据集 {xi,yi}共有4000个样本，每个\\n样本有40维，代表了 40个位置的水平偏移。在生成数据时，十个类别被等概率地抽取，\\n因此每个类别约有 400个样本。\\n我们采用了一个输入为 Di= 40，输出为Do= 10的网络，通过 softmax函数输出\\n类别概率（参见第 5.5节） 。该网络包含两个隐藏层，每层各有 100个隐藏单元。使用\\n批次大小为 100，学习率为 0.1的随机梯度下降法进行了 6000步（150个周期）的训练，\\n采用的是多类别交叉熵损失（公式 5.24） 。如图 8.2所示，训练误差随着训练的进行而\\n逐渐减少，训练数据在大约 4000步后完美分类，训 L练损失也逐渐降低至接近零。\\n但这并不表示我们的分类器完美无缺。可能存在过拟合现象，即模型仅记住了训练\\n数据，却无法准确预测新的样本。为准确评估模型性能，我们需要一个独立的测试集\\nxi,yi。因此，我们按照相同的过程生成了额外的 1000个样本。如图 8.2a所示，测试误\\n差随训练步骤增加而减少，但最终稳定在约 40%，虽然优于随机猜测的 90%误差率，但\\n与训练集相比差距甚远，说明模型对测试数据的泛化能力不佳。\\n测试损失在训练的前 1500步中下降，之后又有所上升。此时，测试误差率基本稳\\n109'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 125}, page_content='110 CHAPTER 8. 性能评估\\n定，模型以更高的自信度重复犯同样的错误。这降低了正确答案的概率，从而增加了负\\n对数似然值。这种增加的自信度是 softmax函数一个副作用，为了让训练数据的概率趋\\n向于1（参见图 5.10） ，预softmax激活值被推向越来越极端的值。\\n图 8.1: MNIST-1D 。a)以 0–9十个数字为基础构建的十类 (y∈0, ...,9)模板示例。 b)通过对\\n一个模板进行随机变换并 c)加入噪声，生成训练样本 x。d)接着，对变换后的模板在 40个垂\\n直位置进行水平偏移采样。据 (Greydanus, 2020) 改编。\\n图 8.2: MNIST-1D 结果。 a)随训练步骤变化的分类错误百分比。训练集的错误率能降至零，但\\n测试集的错误率无法降至 40%以下，显示出模型对新测试数据的泛化能力不强。 b)随训练步骤\\n变化的损失值。训练损失稳步降低至零，而测试损失初期下降后，随着模型对其错误预测的置信\\n度增加而开始上升。\\n8.2错误的来源\\n现在，让我们关注在模型泛化失败时产生错误的根本原因。为了便于理解，我们重\\n新考虑一个一维线性最小二乘回归问题，该问题中我们完全了解生成地面真实数据的过\\n程。如图 8.3所示，展示了一个近似正弦波形的函数；通过在 [0, 1]范围内采样输入值，\\n并经过此函数处理再加上固定方差的高斯噪声，生成了训练和测试数据。\\n我们对这些数据应用了一个简化的浅层神经网络模型（见图 8.4） 。该模型的输入层\\n到隐藏层的权重和偏置被适当选择，以确保在整个区间内函数的转折点均匀分布。若隐\\n藏单元为 D个，那么这些转折点将出现在 0, 1/D, 2/D,...,(D−1)/D 的位置。该模型能'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 126}, page_content='8.2.错误的来源 111\\n图 8.3:回归函数。实心黑线代表真实函数。为生成 I个训练样例 xi, yi，将输入空间 x∈[0,1]\\n等分为 I段，每段内按均匀分布抽取一个样本 xi，并在 xi点评估函数后加入高斯噪声得到对应\\n的yi值（灰色区域显示正负两个标准差） 。测试数据采用相同方式生成。\\n够表示[0, 1]范围内分为 D个等大部分的任意分段线性函数。这个模型不仅易于理解，\\n而且它还有一个优点，即可以通过封闭形式进行拟合，无需依赖随机优化算法（参见问\\n题8.3） 。因此，我们能够保证在训练过程中找到损失函数的全局最小值。\\n8.2.1噪声、偏差与方差\\n模型未能泛化时的错误可以来源于三个方面：噪声、偏差和方差（参见图 8.5） ：\\n噪声指的是在数据生成过程中引入的随机性，导致每个输入 x可能对应多个有效\\n的输出y（如图8.5a所示） 。这种类型的错误在处理测试数据时难以避免。值得注意的\\n是，这并不一定会影响训练性能；因为在训练过程中，相同的输入 x出现两次的可能性\\n极低，所以理论上可以完美拟合训练数据。\\n产生噪声的原因可能是数据生成过程本身具有随机性，或是部分数据标记错误，亦\\n或是存在未被观察到的解释变量。极少数情况下，噪声可能完全不存在，例如，网络可\\n能尝试近似一个确定性的、但计算量巨大的函数。然而，噪声通常是测试性能潜在的基\\n本限制因素。\\n偏差指模型由于不够灵活，无法完美拟合真实函数而可能出现的错误。举例来说，\\n即便参数经过最优选择，一个分为三区域的神经网络模型也不能精确描述一个近似正弦\\n波形的函数（如图 8.5b所示） ，这种现象称为偏差。\\n方差源于我们仅有有限的训练样本，不能区分数据中的系统性变化和随机噪声。因\\n此， 当我们拟合模型时， 不能得到对真实基础函数的最佳近似。实际上， 对于不同的训练\\n数据集，模型的结果每次都会略有不同。这种在拟合函数上的额外变异性称为方差（如'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 127}, page_content='112 CHAPTER 8. 性能评估\\n图 8.4:三隐藏单元的简化神经网络。 a)输入层与隐藏层之间的权重和偏置固定（表示为虚线箭\\n头） 。 b–d)权重和偏置被设定，使得隐藏单元激活函数的斜率为 1，且其断点在区间内等距分布，\\n分别位于 x = 0, x = 1/3, 和 x = 2/3。通过调整其余参数 ϕ=β, ω 1, ω2, ω3，可在 x∈[0,1]范\\n围内生成任何断点位于 1/3和 2/3的分段线性函数。 e–g)展示了三个参数 ϕ不同值下的示例\\n函数。\\n图 8.5:测试误差来源。 a)噪声。数据生成过程中存在较大噪声，因此即便模型完美复现了真实\\n底层函数（黑线） ，测试数据的噪声（灰点）也会导致一定误差（灰色区域表示正负两个标准差\\n的范围） 。 b)偏差。即使采用最佳参数，三区模型（青线）也无法完全拟合真实函数（黑线） ，这\\n种偏差是误差的另一个来源（灰色区域表示符号误差） 。 c)方差。实际中，我们仅有有限的噪声\\n训练数据（橙点） 。拟合模型时，并非恢复出最佳可能函数（如 b面板所示） ，而是得到了一个\\n略有不同、反映训练数据特异性的函数（青线） ，这也是误差的一个额外来源（灰色区域表示正\\n负两个标准差的范围） 。图 8.6展示了该区域的计算方式。\\n图8.5c所示） 。在实践中，随机学习算法本身的随机性也可能引入额外的方差，不一定\\n每次都能收敛到同一个解。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 128}, page_content='8.2.错误的来源 113\\n8.2.2测试误差的数学公式\\n我们现在以数学的方式精确定义噪声、偏差和方差。考虑一个具有加性噪声且方差\\n为σ2的一维回归问题（如图 8.3所示） ；对同一个输入 x，可能会观察到不同的输出 y，\\n因此对每个 x，存在一个期望值（均值）为 µ[x]的分布Pr(y|x)：\\nµ[x] =Ey[µ[x]] =Z\\ny[x]Pr(y|x)dy, (8.1)\\n和固定噪声 σ2=Ey[(µ[x]−y[x])2]。这里，y[x]表示在给定输入 x处的输出y。\\n现在考虑在输入位置 x，模型预测 f(x,ϕ)与观测值y[x]之间的最小二乘损失：\\nL[x] = (f(x,ϕ)−y[x])2\\n= ((f(x,ϕ)−µ[x]) + (µ[x]−y[x]))2\\n= (f(x,ϕ)−µ[x])2+ 2(f(x,ϕ)−µ[x])(µ[x]−y[x]) + (µ[x]−y[x])2,(8.2)\\n其中通过在第二行同时加上和减去基础函数的均值 µ[x]，并在第三行展开平方项。\\n由于基础函数具有随机性，损失取决于我们观测到的特定的 y[x]。期望损失为：\\nEy[L[x]] =Ey[(f(x,ϕ)−µ[x])2+ 2(f(x,ϕ)−µ[x])(µ[x]−y[x]) + (µ[x]−y[x])2]\\n= (f(x,ϕ)−µ[x])2+ 2(f(x,ϕ)−µ[x])(µ[x]−Ey[y[x]]) +Ey[(µ[x]−y[x])2]\\n= (f(x,ϕ)−µ[x])2+ 2(f(x,ϕ)−µ[x])·0 +Ey[(µ[x]−y[x])2]\\n= (f(x,ϕ)−µ[x])2+σ2, (8.3)\\n利用了期望操作的规则。在第四行，我们通过定义替换了固定噪声 σ2。因此，期望\\n损失分为两部分：模型与真实函数均值之间的平方偏差，以及噪声。\\n第一个部分进一步细分为偏差和方差。模型 f[x,ϕ]的参数ϕ取决于训练数据集\\nD={xi,yi}，因此，我们应表示为 f[x,ϕ[D]]。训练数据集是数据生成过程中的随机样\\n本，不同样本会导致不同的参数值。因此，对所有可能的数据集 D，期望模型输出 fµ[x]\\n为：\\nfµ[x] =ED[f[x,ϕ[D]]]. (8.4)\\n回到方程 8.3的第一项，我们加减 fµ[x]并展开：\\n(f[x,ϕ[D]]−µ[x])2'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 128}, page_content='为：\\nfµ[x] =ED[f[x,ϕ[D]]]. (8.4)\\n回到方程 8.3的第一项，我们加减 fµ[x]并展开：\\n(f[x,ϕ[D]]−µ[x])2\\n= ((f[x,ϕ[D]]−fµ[x]) + (fµ[x]−µ[x]))2\\n= (f[x,ϕ[D]]−fµ[x])2+ 2(f[x,ϕ[D]]−fµ[x])(fµ[x]−µ[x]) + (fµ[x]−mu[x])2.(8.5)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 129}, page_content='114 CHAPTER 8. 性能评估\\n对训练数据集 D取期望：\\nED[(f[x,ϕ[D]]−µ[x])2] =ED[(f[x,ϕ[D]]−fµ[x])2] + (fµ[x]−µ[x])2,(8.6)\\n采用与方程 8.3相似的简化步骤。最后，我们将此结果代入方程 8.3：\\nED[Ey[L[x]]] =ED[(f[x,ϕ[D]]−fµ[x])2] + (fµ[x]−µ[x])2+σ2. (8.7)\\n（等式右边三个部分分别表示方差、偏差和噪声）这表明，考虑到训练数据 D和测试数\\n据y的不确定性后，期望损失由三个加和项构成：方差、偏差和噪声。方差是由于特定\\n训练数据集样本导致的拟合模型的不确定性；偏差是模型与我们试图建模的函数均值之\\n间的系统性偏离；噪声是输入到输出的真实映射中固有的不确定性。这三种错误来源对\\n于任何任务都存在，并且在线性回归中以加和的形式出现，但在其他问题类型中，它们\\n的相互作用可能更复杂。\\n8.3降低误差\\n在前一节中，我们了解到测试误差源自三个方面：噪声、偏差和方差。噪声是一个\\n不可逾越的障碍；我们无法避开它，它设定了模型性能的基本极限。但是，我们可以减\\n少其他两个因素。\\n8.3.1减少方差\\n回顾一下，方差是由于训练数据的有限性和噪声引起的。用两个不同的训练集来训\\n练模型会得到略有差异的参数。因此，通过增加训练数据量可以减少方差。这有助于平\\n衡固有噪声并确保输入空间得到充分采样。\\n图8.6展示了使用 6、10和100个样本训练的效果。对于每种数据集大小，我们都\\n展示了三个训练数据集的最佳拟合模型。仅用六个样本时，每次拟合的函数都相差很大：\\n方差显著。随着样本数的增加，拟合模型变得越来越相似，方差也随之减少。总的来说，\\n增加训练数据几乎总能提升测试表现。\\n8.3.2减少偏差\\n偏差来源于模型无法准确描述真实底层函数。这意味着，我们可以通过提高模型的\\n灵活性来减少此类误差。通常，这是通过增加模型的容量来实现的。对于神经网络，这\\n意味着增加更多的隐藏单元和 /或隐藏层。\\n在简化的模型中，增加容量意味着增加更多的隐藏单元，使得区间 [0, 1]被划分成\\n更多的线性区域。图 8.7a–c显示，增加线性区域的数量到十，如预期那样，确实减少了\\n偏差；模型变得足够灵活，能够更紧密地拟合真实函数。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 130}, page_content='8.3.降低误差 115\\n图 8.6:通过增加训练数据以降低方差。 a–c)对三个不同的、随机选择的六点数据集进行的三区\\n域模型拟合，结果每次都大相径庭。 d)这个实验被多次重复，我们画出了模型预测的平均值（青\\n线）和预测的方差（灰色区域表示正负两个标准差） 。 e–h)进行同样的实验，但这次的数据集大\\n小为十，预测方差有所减小。 i–l)使用大小为 100的数据集重复实验，现在拟合模型几乎总是一\\n致的，且方差很小。\\n8.3.3偏差 -方差权衡\\n然而，图 8.7d–f揭示了增加模型容量的一个意外副作用。对于固定规模的训练数据\\n集，随着模型容量的提升，方差也会增加。因此，增加模型容量并不一定能降低测试误\\n差。这就是所谓的偏差 -方差权衡。\\n图8.8探讨了这一现象。在面板 a–c）中，我们将简化的三区域模型拟合到三个不\\n同的、各含十五点的数据集上。尽管数据集不同，但最终的模型大致相同；数据集中的\\n噪声在每个线性区域中大致被平均掉。在面板 d–f）中，我们用一个拥有十个区域的模\\n型拟合相同的三个数据集。这个模型更加灵活，但这其实是不利的；模型确实更好地拟\\n合了数据，训练误差也更低，但很大一部分额外的描述能力实际上用于了对噪声的建模。\\n这种现象被称为过拟合。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 131}, page_content='116 CHAPTER 8. 性能评估\\n图 8.7:模型容量与偏差和方差的关系。 a–c)随着我们增加玩具模型的隐藏单元数，线性区域的\\n数目增加，使得模型能够更紧密地拟合真实函数，偏差（灰色区域）减小。 d–f)然而，不幸的\\n是，增加模型容量也会增加方差项（灰色区域） ，这就是所谓的偏差 -方差权衡。\\n我们发现，随着模型容量的增加，偏差会减少，但对于固定规模的训练数据集，方\\n差却会增加。这表明存在一个最佳容量，在这一点上，偏差不过分而方差仍然相对较小。\\n图8.9通过使用图 8.8的数据展示了随着容量增加，这些项如何在数值上变化。对于回\\n归模型，总期望误差是偏差与方差的和，在模型容量为四（即有四个隐藏单元和四个线\\n性区域）时，这个和最小。\\n图 8.8:过拟合现象。 a–c)对每个包含十五个数据点的三个不同数据集，拟合了一个三区域模\\n型。所有三种情况下的结果都相似（即方差较低） 。 d–f)对相同的数据集拟合了一个十区域模型，\\n增加的灵活性并不一定能产生更好的预测。虽然这三个模型都更好地描述了训练数据，但它们\\n并不一定更接近于真实的底层函数（黑色曲线） 。相反，它们过度拟合了数据，只是描述了噪声，\\n而方差（拟合曲线之间的差异）更大。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 132}, page_content='8.4.双下降现象 117\\n图 8.9:偏差 -方差权衡。根据方程 8.7，模型容量（隐藏单元 /线性区域的数量）的变化绘制了偏\\n差和方差项。随着模型容量的增加，偏差（实线橙色线）减少，但方差（实线青色线）增加。这\\n两项的总和（灰色虚线）在模型容量为四时达到最小。\\n8.4双下降现象\\n在上一节中，我们探讨了随模型容量增加时偏差与方差之间的权衡关系。现在，让\\n我们重新关注 MNIST-1D 数据集，实际观察这种现象是否发生。我们采用了 10,000个\\n训练样本进行模型训练，并使用另外 5,000个样本进行测试，以此来观察随着模型中参\\n数数量（即模型容量）增加时，训练和测试性能的变化。模型的训练采用了 Adam优化\\n算法，步长设置为 0.005，通过对全部 10,000个样本进行 4000步的批量训练。\\n图8.10a展示了一个具有两个隐藏层的神经网络在隐藏单元数增加时，训练误差与\\n测试误差的变化情况。可以看到，随着模型容量的扩大，训练误差逐渐降低并迅速趋近\\n于零。图中的虚线表示模型的参数数量达到训练样本数的时刻，但值得注意的是，模型\\n在达到这一点之前就已经能够记忆整个数据集了。测试误差随着模型容量的增加而下\\n降，但与偏差 -方差权衡理论预测的不同，它并没有上升，而是持续下降。\\n在图8.10b中，我们重复了此实验，但这次我们随机更改了 15%训练标签的值。结\\n果再次显示，训练误差降至零。这一次，由于引入了更多的随机性，模型几乎需要与数\\n据点数量一样多的参数才能记住这些数据。测试误差确实展示出随着模型容量增加所期\\n望的偏差 -方差权衡特征，直至模型完美拟合训练数据。然而，接下来发生了意外；测试\\n误差再次开始下降。事实上，如果我们进一步增加模型容量，测试损失可以降至最初曲\\n线部分所达到的最低水平之下。\\n这种现象被称为“双下降”现象。对于某些数据集，如 MNIST，在原始数据中就已'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 133}, page_content='118 CHAPTER 8. 性能评估\\n经存在（见图 8.10c） 。而对于其他数据集，如 MNIST-1D 和CIFAR-100 （见图8.10d） ，\\n在我们向标签中添加噪声后，这种现象会显现出来或变得更加明显。曲线的前半部分被\\n认为是“经典”或“欠参数化”阶段，后半部分则被视为“现代”或“过参数化”阶段。\\n而在误差上升的中间部分，则被称为“临界”阶段。\\n图 8.10:双下降现象。 a)随着我们在每层增加隐藏单元（从而增加参数）数量，对 MNIST-1D\\n数据集进行两层隐藏层网络训练和测试损失的分析。当参数数量接近训练样本数量（垂直虚线\\n表示）时，训练损失降至零。测试误差并未展现出预期的偏差 -方差权衡，而是在模型记住数据\\n集之后继续下降。 b)使用更加嘈杂的训练数据重复相同的实验。尽管此时几乎需要与训练点数\\n量相等的参数来记住数据集，训练误差仍降至零。测试误差显示出预测的偏差 /方差权衡；随着\\n容量增加而减少，但在接近完全记住训练数据的点时再次增加，然而之后它再次下降，并最终达\\n到更优的性能水平。这称为双下降现象。根据损失、模型和数据中的噪声量，这种双下降模式在\\n许多数据集中都有不同程度的表现。 c) Belkin 等人 (2019)在无标签噪声的 MNIST数据集上使\\n用浅层神经网络的结果。 d) Nakkiran 等人 (2021)使用 ResNet18 网络在 CIF AR-100 上的结果\\n（见第 11章） 。详细信息见原始论文。\\n8.4.1解释\\n双下降的发现是近年来意料之外且有些令人困惑的新现象。它源于两个现象的交互\\n作用。首先，当模型刚好具有足够的容量记住数据时，测试性能会暂时恶化。其次，即\\n使在训练性能达到完美之后，随着容量的进一步增加，测试性能仍然会继续提升。第一\\n个现象正符合偏差 -方差权衡的预测。而第二个现象则更加令人迷惑；目前尚不清楚，为'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 134}, page_content='8.5.超参数的选择 119\\n什么在模型过度参数化的情况下，性能反而会更好，尽管这时已经没有足够的训练数据\\n点来唯一约束模型的参数了。\\n要理解为什么随着参数数量的增加，性能仍然能够得到改善，需要注意到一旦模型\\n拥有足够的容量将训练损失降至近乎零，模型便几乎完美地拟合了训练数据。这意味着\\n进一步增加容量无法使模型更好地拟合训练数据；任何改进都必须发生在训练数据点之\\n间。模型在数据点之间进行推断时倾向于选择某种解决方案而非另一种，这种倾向称为\\n模型的“归纳偏置” 。\\n因为在高维空间中，训练数据极其稀疏，模型在数据点之间的行为尤为关键。以 40\\n维的MNIST-1D 数据集为例，我们使用了 10,000个样本进行训练。如果将每个输入维\\n度划分为 10个区间，那么总共将有 1040个区间，但只有 105个样本点。即使是这样粗\\n略的划分，也意味着在每 1035个区间中仅有一个数据点！这种情况，即高维空间的广\\n阔程度远超训练数据点数，被称为“维度的诅咒” 。\\n因此，在高维中的问题可能更类似于图 8.11a所示；我们在输入空间的小区域内观\\n察到数据点，而这些数据点之间存在着显著的间隙。 “双下降”的一种解释是，随着模\\n型容量的增加，它在相邻数据点之间的插值变得更加平滑。在不知道训练点之间发生了\\n什么的情况下，假设平滑是合理的，并且可能会合理地推广到新数据上。\\n这个观点是有道理的。随着模型容量的增加，它确实能够构造出更平滑的函数。图\\n8.11b–f展示了随着隐藏单元数的增加，模型能够构建的尽可能平滑且仍然通过数据点\\n的函数。当参数数量接近训练数据量时（图 8.11b） ，模型不得不强行适应训练数据，导\\n致预测结果出现异常波动。这解释了双下降曲线中峰值异常显著的原因。随着我们增加\\n更多隐藏单元，模型能够构建出更平滑的函数，这些函数更有可能在新数据上表现出更\\n好的泛化能力。\\n然而，这并未解释为什么过参数化模型会产生平滑的函数。图 8.12展示了一个简\\n化模型（拥有 50个隐藏单元）可以创建的三种函数。在每种情况下，模型都完美拟合\\n了数据，因此损失为零。如果双下降的“现代”阶段是通过增加平滑性来解释的，那么\\n是什么驱使模型趋向于这种平滑性呢？\\n8.5超参数的选择\\n在上一节，我们探讨了模型容量如何影响测试性能。遗憾的是，在传统的模型阶段，'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 134}, page_content='是什么驱使模型趋向于这种平滑性呢？\\n8.5超参数的选择\\n在上一节，我们探讨了模型容量如何影响测试性能。遗憾的是，在传统的模型阶段，\\n我们既不能直接获得偏差信息（因为这需要对真实的底层函数有所了解） ，也无法准确\\n知道方差（因为这需要多个独立抽样的数据集来评估） 。而在现代模型阶段，预判增加\\n多少模型容量才能使测试误差停止改进变得更加困难。这就引出了一个实际问题：我们\\n该如何在实际应用中合理选择模型的容量。\\n对于深度网络而言，模型的容量不仅取决于隐藏层的数目和每层的单元数量，还包\\n括其它我们还未提及的架构特征。同时，所选择的学习算法及其参数（比如学习率等）\\n也会影响到测试性能。这些因素统一被称为超参数。寻找最优超参数的过程被称作超参'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 135}, page_content='120 CHAPTER 8. 性能评估\\n图 8.11:增加容量（隐藏单元）可以实现稀疏数据点之间更加平滑的插值。 a)在这个场景中，训\\n练数据（橙色圆圈）分布稀疏，中心区域没有数据来限制模型以模仿真实函数（黑色曲线） 。 b)\\n若我们拟合一个仅具有足够容量以适应训练数据的模型（青色曲线） ，模型必须调整自身以通过\\n训练点，导致输出预测缺乏平滑性。 c–f)但是，随着我们增加更多的隐藏单元，模型能够在点之\\n间进行更平滑的插值（每种情况下绘制了尽可能平滑的曲线） 。然而，值得注意的是，模型并非\\n一定要这样做。\\n图 8.12:正则化。 a–c)三个拟合曲线都恰好穿过了数据点，因此每个的训练损失都为零。但是，\\n我们可能期望 (a)面板中的平滑曲线比 (b)和 (c)面板中的波动曲线在泛化到新数据上时表现\\n得更好。任何倾向于使模型偏好于一组具有相似训练损失的解的因素都称为正则化器。人们认为\\n神经网络的初始化和 /或拟合过程具有隐式的正则化效果。因此，在参数过多的情况下，像 (a)\\n面板中那样更合理的解决方案受到鼓励。\\n数搜索，或者当专注于网络结构时，被称作神经架构搜索。\\n超参数的选择通常基于经验；我们会在同一个训练集上对多个不同超参数设置的模\\n型进行训练，评估它们的性能，并保留表现最佳的模型。但我们不会在测试集上评估它\\n们的性能，以避免选出的超参数仅仅是偶然适合于测试集而不具有普适性。因此，我们\\n引入了一个称为验证集的第三数据集。对每一组超参数配置，我们使用训练集来训练模\\n型，并在验证集上评估其性能。最终，我们选取在验证集上表现最佳的模型，并在测试\\n集上评估其性能。按理说，这种方法能够合理估计模型的真实性能。\\n尽管超参数空间通常比参数空间要小，但其范围仍然广泛，以至于无法穷尽所有组'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 136}, page_content='8.6.总结 121\\n合进行尝试。不幸的是，许多超参数是离散的（例如隐藏层的数目） ，有些则是相互依赖\\n的（比如，只有当存在十层或更多层时，我们才需要指定第十层的单元数目） 。因此，我\\n们无法依赖于梯度下降方法来进行学习，这种方法是我们在学习模型参数时所采用的。\\n超参数优化算法通过考虑之前的结果来对超参数空间进行智能采样。由于我们需要为每\\n一组超参数组合训练一个完整的模型并评估其在验证集上的性能，这个过程是计算成本\\n很高的。\\n8.6总结\\n为了评估模型性能，我们采用了独立的测试集。模型在这一测试集上的表现好坏反\\n映了其泛化能力。测试误差主要受三个因素影响：噪声、偏差和方差。在使用最小二乘\\n法的回归问题中，这些因素以加法形式共同作用。增加训练数据量能够有效降低方差。\\n当模型的容量不足以处理训练样本时，提升模型容量可以减少偏差，但同时会导致方差\\n增加。这种现象称为偏差 -方差权衡，存在一个最优的模型容量点，可以达到两者之间的\\n最佳平衡。\\n然而，值得注意的是，即使模型的参数数量超过训练样本，性能随容量的增加而提\\n高的趋势依然存在。这两种现象共同形成了所谓的双下降曲线。人们普遍认为，在参数\\n过剩的“现代”模型阶段，模型能够在训练数据点之间实现更平滑的插值，但目前尚不\\n清楚具体是什么因素推动了这一过程。为了确定模型容量及其他模型和训练算法的超参\\n数，我们需要训练多个模型，并借助独立的验证集来评估它们的表现。\\n8.7笔记\\n偏差与方差的权衡 ：我们证明了，对于使用最小二乘损失的回归问题，测试误差可\\n以分解为噪声、偏差及方差三者的总和。这些因素在采用其他损失函数的模型中同样存\\n在，但它们之间的相互作用往往更为复杂（ Friedman, 1997; Domingos, 2000 ） 。在分类问\\n题中，存在一些违反直觉的预测现象；例如，若模型在输入空间的某区域倾向于错误分\\n类，则增加方差有助于提高分类准确率，因为这样做能将部分预测值推过分类阈值，实\\n现正确分类。\\n交叉验证 ：通常的做法是将数据分为三部分：训练数据（用来学习模型参数） 、验\\n证数据（用来选择超参数）和测试数据（用来估计最终的性能） 。这种方法称为交叉验\\n证。然而，当可用的数据总量有限时，这种分法可能会带来问题；如果训练样本的数量\\n与模型的容量相近，则会导致较大的方差。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 136}, page_content='证数据（用来选择超参数）和测试数据（用来估计最终的性能） 。这种方法称为交叉验\\n证。然而，当可用的数据总量有限时，这种分法可能会带来问题；如果训练样本的数量\\n与模型的容量相近，则会导致较大的方差。\\n为缓解此问题，可以采用 k折交叉验证。训练和验证数据被分割成 K个互不重叠\\n的子集。比如，我们可以将数据分为五份，每次用其中四份进行训练，剩下一份进行验\\n证，如此针对五种可能的排列组合分别选择超参数，并基于平均验证性能做出选择。最\\n终测试性能是通过对选出的最佳超参数下五个模型在完全不同的测试集上的预测平均'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 137}, page_content='122 CHAPTER 8. 性能评估\\n值进行评估得出的。虽然这个方法有许多变种，但它们的共同目标都是利用更大比例的\\n数据进行模型训练，以此来降低方差。\\n模型容量 ：我们通常将“容量”一词非正式地用来描述模型中的参数或隐藏单元数\\n（从而间接地描述模型拟合日益复杂函数的能力） 。模型的表示容量是指在考虑所有可能\\n的参数值时，模型能够构造的函数空间。考虑到优化算法可能无法找到所有这些解，我\\n们所关注的便是有效容量。\\nVapnik-Chervonenkis (VC) 维度（Vapnik & Chervonenkis, 1971 ）是衡量容量的更\\n为正式的指标。它指的是一个二元分类器能够任意标记的最大训练样本数。 Bartlett 等\\n人（2019）从层数和权重的角度给出了 VC维度的上下界。 Rademacher 复杂度是另一\\n种衡量指标，预期的经验性能是指在随机标签数据上，采用最优参数的分类模型的表现。\\nNeyshabur 等人（2017）基于Rademacher 复杂度，给出了泛化误差的下界。\\n双下降现象 ：Belkin等人（2019）首次提出“双下降”这一术语，并证明了在过参\\n数化情况下，对于两层神经网络和随机特征，测试误差会再次下降。尽管 Buschjäger &\\nMorik (2021) 后来提供了相反的证据， 他们还声称决策树中也会发生这一现象。 Nakkiran\\n等人（2021）展示了双下降现象在不同的现代数据集（ CIFAR-10, CIFAR-100, IWSLT ’\\n14 de-en） 、架构（ CNNs, ResNets, transformers ）和优化器（ SGD, Adam ）中的存在。\\n当目标标签添加噪声（ Nakkiran 等人，2021）以及使用某些正则化技术（ Ishida等人，\\n2020）时，这种现象尤为明显。\\nNakkiran 等人（2021）还提供了实证证据，显示测试性能依赖于有效模型容量（即\\n给定模型和训练方法可以达到零训练误差的最大样本数） 。此时，模型开始专注于平滑\\n的插值。因此，测试性能不仅取决于模型本身，还取决于训练算法和训练时长。当研究\\n容量固定的模型并增加训练迭代次数时，他们观察到了同样的模式，称之为“按时代双\\n下降” 。Pezeshki 等人（2022）通过模型中不同特征以不同速度学习的情况，对这一现象'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 137}, page_content='容量固定的模型并增加训练迭代次数时，他们观察到了同样的模式，称之为“按时代双\\n下降” 。Pezeshki 等人（2022）通过模型中不同特征以不同速度学习的情况，对这一现象\\n进行了建模。\\n双下降现象提出了一个奇特的预测，即增加训练数据有时会导致测试性能下降。在\\n曲线的第二下降部分，对于一个过参数化模型，如果我们增加训练数据量以匹配模型容\\n量，那么我们现在将处于新测试误差曲线的关键区域，测试损失可能会增加。\\nBubeck & Sellke (2021) 证明了在高维情况下，过参数化是平滑插值数据的必要条\\n件。他们展示了模型参数数量与 Lipschitz 常数（模型输出对小输入变化的最快响应速\\n度）之间的权衡关系。 Dar等人（2021）对过参数化机器学习的理论进行了综述。\\n维度诅咒 ：随着维度增加，空间体积的增长速度极快，导致需要的数据量以指数形\\n式增长以实现密集采样。这种现象被称为维度诅咒。高维空间具有许多不可思议的属性，\\n在尝试用低维例子进行推理时应当小心。本书尝试将深度学习的多个方面在一维或二维\\n中进行可视化，但对这些可视化应持谨慎态度。\\n高维空间的一些惊奇属性包括： (i)两个从标准正态分布中随机选取的数据点很可\\n能与原点几乎正交。 (ii)从标准正态分布抽样的点到原点的距离大致是恒定的。 (iii)大\\n部分高维球体（超球体）的体积靠近其表面（常用的比喻是，大部分高维橙子的体积在'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 138}, page_content='8.7.笔记 123\\n皮里，而不是果肉中） 。 (iv)如果将单位直径的超球体放置在边长为单位长度的超立方\\n体内，随着维度的增加，超球体占超立方体体积的比例会逐渐减小。由于超立方体的体\\n积固定为 1，这意味着高维超球体的体积近乎为零。 (v)对于从高维超立方体中均匀抽\\n取的随机点，最近点与最远点之间的欧氏距离比接近于一。更多信息，可参考 Beyer等\\n人（1999）和Aggarwal 等人（2001） 。\\n实际性能 ：我们在本章中讨论了，通过留出测试集可以评估模型的性能。然而，如\\n果测试集的统计特征与实际世界数据的不一致，那么所得结果并不能真实反映实际性\\n能。更进一步，实际世界数据的统计特征可能随时间变化，导致模型逐渐过时，性能下\\n降。这种现象称为数据偏移，意味着部署的模型需要细致监控。\\n实际性能不如测试性能所示的原因主要有三个。首先，输入数据 x的统计特征可\\n能发生变化，我们可能遇到了训练期间采样稀少或未曾采样的函数部分，称为协变量偏\\n移。其次，输出数据 y的统计特征可能变化，若某些输出值在训练期间较为罕见，则模\\n型可能学习在不确定情况下不预测这些值，如果这些值在实际世界中变得更常见，则会\\n导致错误，这称为先验偏移。第三，输入与输出之间的关系可能发生变化，称为概念偏\\n移。Moreno-Torres 等人(2012)对这些问题进行了讨论。\\n超参数搜索 ：寻找最佳超参数是一个挑战性的优化任务。测试单一配置的超参数成\\n本高昂，需要训练完整模型并测量其性能。我们无法轻易获得性能变化的导数（即，对\\n超参数的微小改变） 。此外，许多超参数是离散的，无法应用梯度下降方法。存在多个局\\n部最小值，且无法确定是否接近全局最小值。由于每次训练 /验证周期都采用随机训练\\n算法，噪声水平高，相同超参数的模型训练两次可能得到不同结果。最后，某些变量是\\n条件性的，仅在设置了其他变量时存在，例如，仅当模型至少有三个隐藏层时，第三隐\\n藏层的隐藏单元数才有意义。\\n一种简单方法是随机采样空间（ Bergstra & Bengio, 2012 ） 。然而， 对于连续变量， 构\\n建一个将性能作为超参数函数的模型， 并利用此函数中的不确定性， 更为有效。 这可以用\\n来探索不确定性较大的区域或专注于性能表现有希望的区域。贝叶斯优化正是基于此思'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 138}, page_content='建一个将性能作为超参数函数的模型， 并利用此函数中的不确定性， 更为有效。 这可以用\\n来探索不确定性较大的区域或专注于性能表现有希望的区域。贝叶斯优化正是基于此思\\n想的高斯过程框架， 其在超参数搜索中的应用由 Snoek等人(2012)描述。Beta-Bernoulli\\nbandit（参见Lattimore & Szepesvári, 2020 ）为描述离散变量导致的结果不确定性提供\\n了一个类似的模型。\\n基于序列模型的配置（ SMAC）算法（ Hutter等人，2011）能够处理连续、离散和\\n条件参数。其基本方法是利用随机森林模拟目标函数，其中树预测的均值是对目标函数\\n最好的估计，它们的方差代表不确定性。完全不同的方法，也能处理连续、离散和条件\\n参数的组合，即 Tree-Parzen 估计器（ Bergstra 等人，2011） 。这些方法模拟了给定超参\\n数下模型性能的概率，与之相对， Tree-Parzen 估计器模拟了给定模型性能下超参数的\\n概率。\\nHyperband （Li等人，2017b）是一种针对超参数优化的多臂老虎机策略。它假设\\n存在计算成本低但近似的性能测量方法（例如，未完全训练完成）并且可以与预算关联\\n（例如，固定迭代次数训练） 。抽样若干随机配置并运行，直到预算耗尽。然后保留最佳'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 139}, page_content='124 CHAPTER 8. 性能评估\\n的一小部分 η运行，并将预算乘以 1/η。重复此过程直到达到最大预算。此方法的优势\\n在于效率；对于表现不佳的配置，无需将实验进行到底。然而，每个样本的选择都是随\\n机的，这种方式效率不高。 BOHB算法（Falkner等人，2018）结合了 Hyperband 的效\\n率和来自 Tree Parzen 估计器更合理的超参数选择，构建出了更优秀的方法。\\n8.8习题\\n问题 8.1在图8.2中，多类交叉熵（ multiclass cross-entropy ）训练损失能达到零吗？\\n请解释你的理由。\\n问题 8.2对于图8.4a中模型的第一层，我们应该如何选择三个权重和偏置的值，以\\n使得隐藏单元的响应符合图 8.4b-d所描绘的情况？\\n问题 8.3假设有一个训练数据集，包含 I个输入/输出对{xi;yi}，展示如何利用最\\n小二乘损失函数，为图 8.4a中的模型参数{β,ω 1,ω2,ω3}寻找闭式解。\\n问题 8.4考虑到图 8.10b中的曲线，在我们训练一个隐藏层规模为 200，参数总数\\n为50,410的模型时的情况。如果我们将训练样本数量从 10,000增加到50,410，你认为\\n训练和测试性能会怎样变化？\\n问题 8.5当模型容量超过训练数据点的数量，并且模型足够灵活以使训练损失降至\\n零时，这对于拟合一个异方差模型（ heteroscedastic model ）意味着什么？提出一种方法\\n来解决你发现的问题。\\n问题 8.6证明从一个 1000维标准高斯分布中随机选取的两个点，它们相对于原点\\n高概率正交。\\n问题 8.7在D维空间中，一个半径为 r的超球体的体积公式为：\\nVol[r] =rDπD/2\\nΓ[D/2 + 1], (8.8)\\n其中 Γ[·]代表伽马函数（ Gamma function ） 。利用斯特林公式（ Stirling’s formula ） ，\\n展示当维度增加时，直径为一（半径 r= 0.5）的超球体体积如何趋于零。\\n问题 8.8考虑半径r= 1的超球体。求出一个表达式来计算总体积中位于中心最外\\n层1%距离内的体积比（即，位于厚度为 0.01的最外壳层内的体积比） 。证明随着维数\\n的增加，这个比例趋于 1。\\n问题 8.9图8.13c显示了随维度增加，标准正态分布样本距离的分布情况。通过在'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 139}, page_content='层1%距离内的体积比（即，位于厚度为 0.01的最外壳层内的体积比） 。证明随着维数\\n的增加，这个比例趋于 1。\\n问题 8.9图8.13c显示了随维度增加，标准正态分布样本距离的分布情况。通过在\\n25、100和500维度下从标准正态分布采样并绘制距离中心的直方图来验证这一现象。\\n哪种闭式概率分布（ closed-form probability distribution ）描述了这些距离？'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 140}, page_content='8.8.习题 125\\n图 8.13:典型集合。 a)二维标准正态分布。圆圈代表从该分布中抽取的四个样本。随着距中心\\n的距离增加，概率降低，而在该半径处的空间体积（即相邻等距圆圈间的区域）增大。 b)这些因\\n素的权衡使得样本距中心的距离的直方图显示出明显的峰值。 c)在更高的维度中，这种效应变\\n得更加极端，接近均值的样本的概率极低。尽管分布的均值处是最可能的点，但典型样本实际上\\n位于一个相对狭窄的壳层内。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 141}, page_content='126 CHAPTER 8. 性能评估'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 142}, page_content='Chapter 9\\n正则化\\n第8章描述了如何测量模型的性能，并指出了训练数据与测试数据之间可能存在的\\n显著性能差异。这种差异可能的原因包括： （一）模型只描述了训练数据的统计特征，这\\n些特征并不代表从输入到输出的真实映射关系（即过拟合现象） ； （二）模型在没有训练\\n样本的区域内行为不受约束，导致预测结果不理想。\\n本章将讨论正则化技术，一系列旨在减少训练与测试性能之间泛化差距的方法。严\\n格来讲，正则化是指在损失函数中添加特定项以偏好某些参数选择的过程。然而，在机\\n器学习领域，这个概念通常被广泛用来指代任何能够改善泛化能力的策略。\\n文章首先从最严格的正则化概念入手，接着展示随机梯度下降算法本身是如何偏好\\n某些解决方案的，这种现象称为隐式正则化。随后，我们将探讨一系列启发式方法，旨\\n在提升测试性能，包括早停（ early stopping ） 、集成方法（ ensembling ） 、dropout、标签\\n平滑（label smoothing ）和迁移学习（ transfer learning ） 。\\n9.1显式正则化\\n考虑用一组输入 /输出对{xi,yi}来拟合模型 f(x,ϕ)，其中ϕ为模型参数。我们的\\n目标是找到损失函数 L[ϕ]的最小值：\\nˆϕ=argmin\\nϕ[L[ϕ]]\\n=argmin\\nϕ\"IX\\ni=1li(xi,yi)#\\n, (9.1)\\n这里，每个项 l(xi,yi)衡量了对每对训练数据，网络预测 f(xi,ϕ)与实际输出 yi之\\n间的误差。为了让这一最小化过程倾向于特定的解决方案，我们加入了一个附加项：\\nˆϕ=argmin\\nϕ\"IX\\ni=1li(xi,yi) +λ·g(ϕ)#\\n, (9.2)\\n127'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 143}, page_content='128 CHAPTER 9. 正则化\\n其中g(ϕ)是一个函数，用于返回一个标量值，该值在参数较不理想时会较大。系\\n数λ是一个正数，用于平衡原始损失函数和正则化项的贡献。采用正则化后的损失函数\\n通常会导致与原始损失函数不同的最小值，因此训练过程会收敛至不同的参数值（见图\\n9.1） 。\\n图 9.1:显式正则化。 a) Gabor 模型的损失函数（见 6.1.2节） 。青色圆圈代表局部最小值。灰色\\n圆圈代表全局最小值。 b)正则化项通过增加远离该点处的惩罚，倾向于选择接近图中心的参数。\\nc)最终损失函数是原始损失函数与正则化项之和。这个曲面的局部最小值更少，全局最小值移\\n至不同位置（箭头指示变化方向） 。\\n9.2概率解释\\n正则化也可以从概率学的视角进行理解。如第 5.1节所示，损失函数是基于最大似\\n然准则构建的：\\nˆϕ=argmax\\nϕ\"IY\\ni=1Pr(yi|xi,ϕ)#\\n. (9.3)\\n这里，正则化项可以视为一个先验知识 Pr(ϕ)，它代表在我们观测到数据之前对参\\n数的了解。于是，我们采用了最大后验（ MAP）准则：\\nˆϕ=argmax\\nϕ\"IY\\ni=1Pr(yi|xi,ϕ)·Pr(ϕ)#\\n. (9.4)\\n通过对上式取对数并乘以负一转换为负对数似然损失函数，我们得到 λ·g(ϕ) =\\n−log(Pr(ϕ))，这表明正则化项 λ·g(ϕ)实际上等同于先验概率的负对数。\\n9.3 L2 正则化\\n本讨论未触及正则化项应当惩罚哪些解决方案（或等价地，先验应当支持哪些解决\\n方案）的问题。考虑到神经网络被广泛应用于各种领域，这些偏好只能是非常通用的。\\n最常用的正则化形式是 L2范数，它通过惩罚参数值的平方和来实施：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 144}, page_content='9.3. L2正则化 129\\nˆϕ=argmax\\nϕ\"IX\\ni=1li(xi,yi) +λX\\njϕ2\\nj#\\n, (9.5)\\n其中j代表参数的索引。这种正则化也被称为 Tikhonov 正则化、岭回归，或者在应用\\n于矩阵时，被称为 Frobenius 范数正则化。\\n对于神经网络而言， L2正则化通常只应用于权重，而不是偏置，因此这被称作权重\\n衰减项。其效果是促使权重更小，从而使模型的输出函数变化更加平缓。为了理解这一\\n点，可以考虑输出预测是最后一个隐藏层激活值的加权和。如果权重较小，输出变化会\\n更少。这一逻辑也适用于最后一个隐藏层之前的预激活计算，如此逐层向后直至网络的\\n输入层。在极端情况下，如果所有权重被强制设置为零，则网络将输出一个由最终偏置\\n参数决定的常数值。\\n图9.2展示了在不同的正则化系数 λ下，使用权重衰减拟合简化网络（参见图 8.4）\\n的效果。当 λ很小时，影响微乎其微。然而，随着 λ的增加，对数据的拟合精度下降，\\n函数变得更加平滑。这可能因两个原因而提升测试性能：\\n-如果网络发生过拟合，引入正则化项意味着网络需要在严格匹配数据与追求平滑\\n输出之间做出权衡。这可以理解为，由方差引起的误差减少了（模型不再试图穿过每个\\n数据点） ，但以增加偏差的代价（模型仅能描述平滑的函数） 。\\n-对于参数过多的网络，一些额外的模型容量用于描述没有训练数据的区域。在这\\n种情况下，正则化项会倾向于选择在相邻数据点之间平滑插值的函数。在不了解真实函\\n数的情况下，这是一种合理的做法。\\n图 9.2:在简化网络中的 L2正则化（参见图 8.4） 。 a-f)随着正则化系数 λ增大，所得到的拟\\n合函数变化。黑色曲线代表真实函数，橙色圆点代表含噪声的训练数据，青色曲线是拟合出的模\\n型。当 λ较小（图 a-b）时，拟合函数精确穿过所有数据点。中等 λ值（图 c-d）时，函数变得\\n更平滑，与真实函数更为接近。 λ值较大（图 e-f）时，拟合函数过于平滑，导致拟合效果不佳。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 145}, page_content='130 CHAPTER 9. 正则化\\n9.4隐式正则化\\n最近的一项引人注目的发现是，无论是梯度下降还是随机梯度下降，它们在向损失\\n函数的最小值移动时都不是中立的；它们都倾向于某些解决方案而不是其他。这种现象\\n被称为隐式正则化。\\n9.4.1梯度下降中的隐式正则化\\n考虑梯度下降的一个连续版本，其步长无限接近于零。在这种情况下，参数 ϕ的变\\n化遵循以下微分方程：\\n∂ϕ\\n∂t=−∂L\\n∂ϕ. (9.6)\\n梯度下降使用一系列固定大小 α的离散步骤来逼近这一过程：\\nϕt+1=ϕt−α∂L[ϕt]\\n∂ϕ, (9.7)\\n这种离散步骤导致了与理想连续路径的偏移（参见图 9.3） 。\\n图 9.3:梯度下降中的隐式正则化。 a)在ϕ1= 0.61的水平线上具有全局最小值族的损失函数。\\n虚线蓝色显示从左下方开始的连续梯度下降路径。青色轨迹展示了步长为 0.1的离散梯度下降\\n过程（前几步以箭头明确标出） 。有限步长使得路径发散，最终达到不同的位置。 b)通过在连续\\n梯度下降的损失函数中添加一个正则化项，该项对梯度的平方幅度进行惩罚，可以近似模拟这种\\n路径差异。 c)添加这一项后，连续梯度下降的路径能够收敛到离散梯度下降在原始函数上达到\\n的同一位置。\\n可以通过为连续情况推导出一个修改后的损失项 ˜L来理解这种偏移，该损失项使\\n离散化版本能够与原始损失 L达到相同的结果。据证明（详见章节末尾） ，这种修改后\\n的损失表达式为：\\n˜LGD[ϕ] =L[ϕ] +α\\n4\\r\\r\\r\\r∂L\\n∂ϕ\\r\\r\\r\\r2\\n. (9.8)\\n也就是说，离散化的路径会避开那些梯度范数较大（即表面较陡峭）的区域。这并\\n不会改变梯度为零处的极小值位置，但它会在其他位置改变有效损失函数，并因此改变'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 146}, page_content='9.5.提升性能的启发式方法 131\\n优化的路径，这可能导致收敛到不同的最小值。梯度下降引起的隐式正则化可能解释了\\n为何在使用较大步长时，全批量梯度下降的泛化能力会更好的观察结果（参见图 9.5a） 。\\n9.4.2在随机梯度下降中的隐式正则化\\n对随机梯度下降的分析同样适用。我们现在寻求一个修改后的损失函数，以便其连\\n续版本的结果与随机 SGD更新的平均值相匹配。其表示方式如下：\\n˜LSGD[ϕ] =˜LGD[ϕ] +α\\n4BBX\\nb=1\\r\\r\\r\\r∂Lb\\n∂ϕ−∂L\\n∂ϕ\\r\\r\\r\\r2\\n=L[ϕ] +α\\n4\\r\\r\\r\\r∂L\\n∂ϕ\\r\\r\\r\\r2\\n+α\\n4BBX\\nb=1\\r\\r\\r\\r∂Lb\\n∂ϕ−∂L\\n∂ϕ\\r\\r\\r\\r2\\n. (9.9)\\n此处，Lb表示某个批次中第 b个批次的损失，而 L和Lb分别代表了整个数据集\\n内I个单独损失值的平均和某个批次内 β个单独损失值的平均：\\nL=1\\nIIX\\ni=1ℓi[xi,yi]andLb=1\\n|β|X\\ni∈βbℓi[xi,yi]. (9.10)\\n方程9.9揭示了一个额外的正则化项，对应于批次损失 Lb梯度的方差。换言之，\\nSGD隐式地倾向于梯度稳定的位置（即所有批次对斜率的一致性） 。这一次，虽然调整\\n了优化路径（见图 9.4） ，但并不必然改变全局最小值的位置；若模型参数过多，可能会\\n完美拟合所有训练数据，在全局最小值处所有梯度项均为零。\\n相较于梯度下降， SGD表现出更好的泛化能力，且一般来说，小批次尺寸比大批次\\n尺寸有更好的表现（见图 9.5b） 。一种可能的解释是，固有的随机性让算法能够探索损\\n失函数的不同区域。然而，这种性能提升部分或全部可能源于隐式的正则化效应；它倾\\n向于促成所有数据都很好拟合的解决方案（因此批次方差小） ，而不是一些数据拟合得\\n非常好而其他数据拟合较差的解决方案（可能总体损失相同，但批次方差更大） 。前者\\n的解决方案往往能更好地泛化。\\n9.5提升性能的启发式方法\\n我们已经观察到，通过在损失函数中加入额外的正则化项，可以促使训练算法寻找\\n到更优的解。这种现象也会作为随机梯度下降的一个非预期（但似乎有益的）副作用而\\n隐式发生。本节将介绍一些用于提高泛化能力的其他启发式方法。\\n9.5.1早停\\n早停指的是在训练过程完全收敛之前终止训练。如果模型已经大致捕捉到了底层函'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 146}, page_content='隐式发生。本节将介绍一些用于提高泛化能力的其他启发式方法。\\n9.5.1早停\\n早停指的是在训练过程完全收敛之前终止训练。如果模型已经大致捕捉到了底层函\\n数的形态，但尚未有足够时间以致过度拟合噪声（见图 9.6） ，这种做法可以有效减少过'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 147}, page_content='132 CHAPTER 9. 正则化\\n图 9.4:随机梯度下降的隐式正则化。 a) Gabor 模型的原始损失函数（参见 6.1.2节） 。 b)梯度\\n下降引入的隐式正则化项对梯度的平方幅度进行惩罚。 c)随机梯度下降的附加隐式正则化通过\\n惩罚批量梯度的方差来实施。 d)修改后的损失函数包括原始损失和两个隐式正则化部分的总和。\\n图 9.5:对于两个隐藏层的神经网络，在 MNIST-1D 数据集（参见图 8.1）中的 4000个训练样\\n本和 4000个测试样本上，学习率和批量大小的影响。 a)较大的学习率相较于中等或小的学习率\\n表现更佳。在各种情况下，为了确保不同学习率的解决方案有相同的优化空间，设置的迭代次数\\n与学习率的乘积保持不变。 b)较小的批量大小表现更优。在每种情况下，选择的迭代次数确保\\n了模型在相似的容量下能够充分拟合训练数据。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 148}, page_content='9.5.提升性能的启发式方法 133\\n拟合。可以这样理解：由于权重最初被设定为小值（见 7.5节） ，它们没有机会变得很\\n大，因此早停实际上起到了与显式 L2正则化相似的作用。另一种看法是，早停降低了\\n模型的有效复杂度，使我们能够从偏差 /方差权衡的关键区域向后退一步，从而提升性\\n能（参见图 8.9和8.10） 。\\n图 9.6:早停。 a)随机初始化的简化浅层网络模型（含有 14个线性区域，见图 8.4） ，采用批量\\n为五、学习率为 0.05的 SGD进行训练。 b-d)训练过程中，模型首先抓住真实函数（黑色曲线）\\n的大致结构，随后 e-f)对噪声训练数据（橙色点）过拟合。尽管训练损失在此过程中持续下降，\\n但 (c)和 (d)面板中的模型与真实底层函数最为接近，平均而言，这些模型在测试数据上的泛化\\n能力更强，而不是 (e)或 (f)面板中的模型。\\n早停的设置只涉及一个超参数——学习停止后的步骤数。这个参数通常通过验证集\\n（见8.5节）来经验性选择。但是，对于早停而言，可以在不训练多个模型的情况下选择\\n这个超参数。模型只训练一次，每隔 T次迭代便监控一次在验证集上的表现，并保存相\\n应的模型。最终选取在验证集上表现最佳的模型。\\n9.5.2集成学习\\n缩小训练数据与测试数据之间的泛化差距的另一策略是构建并平均多个模型的预\\n测结果。这样的模型群称为集成。这种技术可靠地提升了测试性能，但需要付出训练和\\n存储多个模型、多次推理的代价。\\n模型的输出可以通过计算输出的平均值（对于回归问题）或预 softmax激活的平均\\n值（对于分类问题）来整合。这种做法基于一个假设：模型的误差是独立的，因此可以\\n相互抵消。另一种方法是，对于回归问题，可以取输出的中值；对于分类问题，则选择\\n最频繁预测的类别，这样可以使预测更稳定。\\n训练不同模型的一个方法是采用不同的随机初始化。这在训练数据远处的输入空间\\n区域尤其有帮助。在这些区域，由于拟合函数相对自由，不同模型可能给出不同的预测，\\n因此多个模型的平均预测可能比任何单个模型都要泛化得好。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 149}, page_content='134 CHAPTER 9. 正则化\\n第二种方法是通过对训练数据进行重采样（替换采样）来生成多个不同的数据集，\\n并对每个数据集训练一个不同的模型。这种做法称为自助聚合，或简称为 bagging（见\\n图9.7） 。其效果是使数据更加平滑；如果某个数据点在某个训练集中不存在，模型将从\\n周围的数据点进行插值。因此，如果某个数据点是异常值，那么在该区域拟合的函数将\\n会更加温和。其他方法还包括使用不同超参数训练模型，或训练完全不同的模型家族。\\n图 9.7:集成方法。 a)对整个数据集（橙色点）拟合单一模型（灰色曲线） 。 b-e)通过有放回地\\n重采样数据四次（ bagging） ，创建了四个模型（橙色点的大小表示该数据点被重采样的次数） 。 f)\\n当我们对这个集成的预测结果取平均时，得到的结果（青色曲线）比针对完整数据集的单一模型\\n（灰色曲线）的结果更平滑，可能会有更好的泛化能力。\\n9.5.3 Dropout\\nDropout 通过在每次 SGD（随机梯度下降）迭代时随机将一定比例（通常是 50%）\\n的隐藏单元的输出置为零（见图 9.8） ，降低了模型对任一特定隐藏单元的依赖。这一策\\n略促进了权重的减小，从而减少了隐藏单元存在与否对函数变化的影响。\\n这种方法有效地去除了函数在训练数据远处可能形成的、对损失函数无影响的不良\\n变动。举个例子，设想三个隐藏单元随着输入沿某一曲线移动而依次激活（如图 9.9a所\\n示） 。首先，一个隐藏单元引起斜率的大幅上升；随后，第二个单元使斜率下降，函数因\\n此下降；最终，第三个单元抵消了这一下降，使曲线恢复原状。这三个单元一起引起了\\n函数的局部不良变化，虽然这不会改变训练损失，但可能导致泛化能力不佳。\\n在这种情况下，通过 dropout移除任一单元会在该单元原本活跃的区域内显著改变\\n输出函数（见图 9.9b） 。接下来的梯度下降步骤会试图对这一变化进行调整，最终消除\\n这种依赖。其结果是，即便这些变化对损失没有贡献，训练数据点间不必要的大变化也\\n会逐步被削弱（见图 9.9） 。\\n在测试阶段，可以照常全量激活隐藏单元运行网络。但由于实际运行时的隐藏单元\\n比训练中的任何迭代时都多，因此我们通过乘以 1减去dropout概率的方式进行权重调'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 150}, page_content='9.5.提升性能的启发式方法 135\\n图 9.8: Dropout 技术。 a)原始网络。 b-d)在每次训练迭代期间，随机选择一部分隐藏单元设置\\n为零（灰色节点） 。这样，这些单元的输入和输出权重不产生任何效果，我们实际上在每次迭代\\n时训练的是略有不同的网络。\\n图 9.9: Dropout 机制。 a)由于斜率的连续增加、减少（在圆圈交点处） ，然后再次增加，导致曲\\n线出现不希望的折点。此时使用的是全批量梯度下降，模型已经尽可能拟合了数据，因此进一步\\n训练不会消除这个折点。 b)如果我们移除了导致圆圈交点的隐藏单元，如使用 Dropout 时可能\\n发生的情况，由于没有了斜率的减少，函数的右侧呈现向上的轨迹，随后的梯度下降步骤将尝试\\n补偿这一变化。 c)经过 2000次迭代（ i）随机移除一个导致折点的三个隐藏单元，并（ ii）执行\\n梯度下降步骤后的曲线。这个折点虽然不影响损失，但通过模拟 Dropout 机制被有效移除。\\n整，这是所谓的权重缩放推理规则。另一种推理方法是采用蒙特卡罗 dropout，即多次\\n以训练时相同方式随机选取一部分隐藏单元输出置零，运行网络并汇总结果。这种做法\\n与集成方法类似，因为每个随机版本的网络都相当于一个独立模型，但此处无需训练或\\n保存多个网络。\\n9.5.4应用噪声\\nDropout 的作用可以被看作是在网络的激活输出上施加乘性的 Bernoulli 噪声。这\\n启发了一个思路：通过在训练过程中对网络的其它部分添加噪声，可以增强模型的鲁棒\\n性。\\n一种做法是在输入数据中加入噪声，这样做能够使得模型学到的函数更加平滑（见'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 151}, page_content='136 CHAPTER 9. 正则化\\n图9.10） 。在回归问题中，这等同于加入了一个正则化项，用以惩罚网络输出相对其输\\n入的导数的变化。对抗训练是一种特殊形式，它通过优化算法主动寻找能够引起输出大\\n变化的输入微小扰动，这些扰动可视为一种极端情况下的加性噪声。\\n图 9.10:向输入添加噪声。在 SGD的每个步骤中，向批数据添加具有方差 σx2的随机噪声。\\na-c)在不同噪声水平下的拟合模型（小点代表十个样本） 。增加更多噪声使得拟合函数（青色线）\\n更加平滑。\\n另一种方法是在权重中引入噪声，这样即使权重发生微小变化，网络也能给出合理\\n的预测。这导致模型在训练过程中趋向于收敛于宽阔且平坦的局部最小值区域，此时个\\n别权重的变化对模型影响不大。\\n最后，我们还可以对标签进行扰动。多类分类的最大似然目标是要尽可能准确地预\\n测出正确的类别（参见方程 5.24） 。为此，模型会被推动使得对正确类别的预测值非常\\n大，而对错误类别的预测值非常小。\\n我们可以通过一种假设来避免模型过度自信：假定有一定比例 ρ的训练标签是错误\\n的，并等概率地分布于其他类别。这可以通过在每次训练迭代中随机更改标签的方式来\\n实现。然而，通过修改损失函数，使其最小化预测分布与一个真实标签概率为 1−ρ、其\\n他类别概率均等的分布之间的交叉熵，也能达到同样的目的。这种方法被称为标签平滑，\\n它在多种情况下都能有效提升模型的泛化能力。\\n9.5.5贝叶斯推理\\n最大似然估计在训练过程中往往过分自信，它倾向于选取似乎最合适的参数来做预\\n测。但实际上，可能还有很多其他的参数值同样与数据相符，只是概率稍低。贝叶斯方\\n法以一种不同的视角处理这个问题：它将参数视为未知的变量，并通过贝叶斯定理来计\\n算考虑到训练数据 xi,yi后参数ϕ的概率分布 Pr(ϕ|xi,yi)：\\nPr(ϕ|{xi,yi}) =QI\\ni=1Pr(yi|xi,ϕ)Pr(ϕ)RQI\\ni=1Pr(yi|xi,ϕ)Pr(ϕ)dϕ, (9.11)\\n这里，Pr(ϕ)代表参数的先验概率，分母是用于归一化的项。这意味着，每种参数\\n的选择都对应一个概率值（参见图 9.11） 。\\n对新输入 x的预测y被表达为所有参数集合预测的加权无限和（实际上是一个积\\n分） ，其中的权重是各自的概率值：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 152}, page_content='9.5.提升性能的启发式方法 137\\nPr(y|x,{xi,yi}) =Z\\nPr(y|x,ϕ)Pr(ϕ|{xi,yi})dϕ. (9.12)\\n本质上，这是一个基于权重的无限集成模型，权重由参数的先验概率和它们与数据\\n的一致性决定。\\n贝叶斯方法以其优雅性著称，相较于最大似然估计，它能提供更为稳健的预测结果。\\n遗憾的是，对于如神经网络这类复杂模型而言，目前还没有办法实用地表示参数的完整\\n概率分布，或者在推理阶段进行积分计算。因此，目前所有此类方法都不得不采用某种\\n形式的近似，这通常会大幅增加学习和推理的复杂度。\\n图 9.11:对于简化的网络模型（参见图 8.4） ，采用贝叶斯方法处理参数的不确定性。一组参数\\n的后验概率 P r(ϕ|xi, yi )取决于它们与数据 xi,yi的匹配程度和先验分布 P r(ϕ)。a-c)基于具有\\n零均值和三个不同方差的正态分布先验，采样得到两组参数（青色和灰色曲线） 。当先验方差较\\n小时，参数倾向于较小，得到的函数更加平滑。 d-f)通过对所有可能参数值进行加权平均，其中\\n权重为后验概率，进行推断。这样不仅产生了均值预测（青色曲线） ，还估计了与之相关的不确\\n定性（灰色区域代表两个标准差范围） 。\\n9.5.6迁移学习与多任务学习\\n面对训练数据的限制，可以借助其他更为丰富的数据集来增强模型性能。在迁移学\\n习中（见图 9.12a） ，先对网络进行预训练，让它在一个与目标任务相关但数据更为充足\\n的辅助任务上学习。预训练完成后，这个模型会被调整应用于原始的目标任务。具体做\\n法包括移除网络的最后一层，然后增加一层或多层，以便产生适合目标任务的输出。可\\n以选择保持预训练模型不变，仅训练新增的层，或者对整个模型进行细微调整。\\n这种方法的思想基础是，网络通过辅助任务学习到的数据内部表示对于原始任务同\\n样有价值。从另一个角度来看，迁移学习相当于在参数空间的一个合理区域内对网络的\\n大部分参数进行初始化，这个区域很可能导向一个优秀的解决方案。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 153}, page_content='138 CHAPTER 9. 正则化\\n多任务学习（见图 9.12b）是一种类似的策略，它让网络同时针对多个问题进行学\\n习。例如，一个网络可以同时处理图像，学习进行场景分割、估计每个像素的深度，并\\n生成描述图像内容的文字。所有这些任务都需要对图像内容有所理解，通过并行学习，\\n模型在各个任务上的表现有望得到整体提升。\\n图 9.12:转移学习、多任务学习和自监督学习。 a)当主要任务（本例为深度估计）的标签数据\\n有限，而辅助任务（本例为分割）的数据充足时，采用转移学习。我们先针对辅助任务训练模型，\\n然后移除最后的层并用适合主要任务的新层替换，接着仅训练新层或微调整个网络以适应主要\\n任务。这样，网络借助辅助任务学到的优秀内部表示，提升了主要任务的性能。 b)多任务学习\\n中，我们训练模型同时处理多个任务，希望通过这种方式提高各任务的表现。 c)在生成式自监\\n督学习中，我们去除数据的一部分，训练网络预测缺失的信息，如填补图像的遮蔽部分。这种方\\n法允许在缺少标签的情况下进行转移学习。图片来源于 Cordts et al. (2016) 。\\n9.5.7自监督学习\\n当我们手头的训练数据不足时，可以通过自监督学习生成大量无需手动标注的数\\n据，进而利用这些数据进行迁移学习。自监督学习分为两大策略：生成式与对比式。\\n在生成式自监督学习策略中，我们会从每个样本中隐去一部分信息，然后让模型预\\n测这部分缺失的内容（参见图 9.12c） 。举个例子，可以从一系列未标注的图像中随机遮\\n盖部分区域，模型的任务就是尝试恢复这些区域的原貌。同样的方法也可以应用于文本，\\n通过遮蔽部分单词，训练模型预测这些单词，随后针对特定的语言处理任务进行模型的\\n微调。\\n对比式自监督学习则是基于比较的方法，它将有共同特征的样本对与彼此无关的样\\n本对进行对比。对于图像，这个次级任务可能涉及判断一对图像是否是同一图像的不同\\n变体，或者两者无关联。在文本领域，可能需要判断两个句子是否在原文中相邻。有时'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 154}, page_content='9.6.总结 139\\n候，还需要识别出有联系的样本对之间的具体关系，比如判断同一图像中两个片段的相\\n对位置。\\n9.5.8数据增强\\n迁移学习通过挖掘不同数据集的潜力来增强模型性能，而多任务学习则是通过引入\\n额外的标签信息来实现性能提升。除此之外，还有一种方法是直接扩充数据集。我们可\\n以对每个输入样本进行变换，同时保证标签的正确性不受影响。比如，在识别图像中是\\n否存在鸟类的任务中（参见图 9.13） ，我们可以对图像进行旋转、翻转、模糊处理或调\\n整色彩平衡，而“鸟”这一标签依然适用。同样，在处理文本输入的任务中，我们可以\\n通过替换同义词或进行语言的互译来增加数据多样性。而在音频输入的任务中，改变不\\n同频率范围内的音量也是一种有效的数据增强手段。\\n图 9.13:数据增强。对某些问题，可以通过变换每个数据示例来扩充数据集。 a)原始图像。 b-h)\\n此图像经过多种几何和光度变换。对图像分类而言，这些图像尽管经过变换，但标签“鸟”保持\\n不变。根据 W u et al. (2015a) 改编。\\n这种方法称为数据增强，目的在于使模型对于这些与任务本质无关的变化保持不敏\\n感，从而提高模型对实际应用场景的适应性和鲁棒性。\\n9.6总结\\n通过向损失函数加入额外的项，显式正则化改变了损失函数最小值的定位，这可以\\n被视作对参数的先验概率的引入。而随机梯度下降（ SGD）在有限步长的情况下，其下\\n降路径并不会直接指向损失函数的最小点，这种偏差实际上相当于在损失函数中隐式加\\n入了额外的正则化项。\\n为了增强模型的泛化能力，存在多种启发式策略，诸如早停、 dropout、模型集成、\\n贝叶斯方法、添加噪声、迁移学习、多任务学习及数据增强等。这些策略归结为四大核'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 155}, page_content='140 CHAPTER 9. 正则化\\n心原则： （ i）促使模型函数表现得更平滑，如通过 L2正则化； （ ii）扩大训练数据集，例\\n如采用数据增强技术； （ iii）模型的组合使用，例如模型集成；以及（ iv）寻找更加宽广\\n的损失函数最小值区域，比如通过在网络权重上添加噪声。\\n针对特定任务选择或设计合适的模型架构也是提升泛化能力的有效手段。以图像分\\n割为例，通过在模型中共享参数，可以避免在图像的每一个位置重复学习相同特征，如\\n树的形态。书中的第 10至13章详细探讨了针对不同任务设计的架构变种，展示了结构\\n选择对于任务性能的影响。\\n图 9.14:正则化方法。本章讨论的正则化方法通过以下四种机制之一来提高模型的泛化能力：一\\n些方法通过平滑模型函数来实现；其他方法通过增加有效的数据量来达到；第三种方法是结合多\\n个模型，以此来减少拟合过程中的不确定性；最后一种方法则鼓励训练过程趋向于一个广阔的最\\n小值区域，使得参数估计的微小误差影响降低（也参见图 20.11） 。\\n9.7笔记\\n在Kukačka 等人（2017）的研究中，提供了深度学习中正则化技术的综述和分类体\\n系。本章讨论中遗漏了 BatchNorm （Szegedy等人，2016）及其变种，这些内容将在第\\n11章详细介绍。\\n正则化方面， L2正则化通过惩罚网络权重的平方和来促使输出函数变化更加平滑，\\n是应用最广泛的正则化方法。它有时也被称作 Frobenius 范数正则化，因为它惩罚了权\\n重矩阵的 Frobenius 范数。此外，它经常被误称为“权重衰减” ，虽然权重衰减实际上是\\nHanson & Pratt （1988）提出的一种不同技术，通过以下方式更新参数 ϕ：\\nϕ←(1−λ)ϕ−α∂L\\n∂ϕ, (9.13)\\n其中，α代表学习率， L为损失函数。这与梯度下降的过程相同，不同之处在于在\\n梯度更新前，权重会先乘以一个因子 (1−λ′)。对于标准的 SGD，权重衰减与 L2正则化\\n（方程9.5）相当，系数 λ等于λ′/2α。然而，在 Adam优化器中，由于每个参数的学习'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 156}, page_content='9.7.笔记 141\\n率α各不相同， L2正则化与权重衰减并不等价。 Loshchilov & Hutter （2019）提出的\\nAdamW 对Adam进行了改进，以正确实施权重衰减，并证明这一改进提升了性能。\\n其他类型的向量范数用于鼓励权重的稀疏性。 L0正则化为每个非零权重施加固定\\n的惩罚，其效果是“修剪”网络。 L0正则化还可用于促进组内稀疏性，即如果给定隐藏\\n单元的任何权重非零，则施加固定惩罚。若所有权重均为零，则可以移除该单元，从而\\n减小模型大小并加速推断过程。\\n遗憾的是，由于 L0正则化项的导数非平滑，其实现较为困难，需要更先进的拟合\\n方法（参见 Louizos等人，2018） 。L1正则化（又名 LASSO，最小绝对收缩和选择算子）\\n处于L2和L0正则化之间，对权重的绝对值施加惩罚。 L2正则化对稀疏性的鼓励作用\\n不如L1正则化明显，因为随着权重减小，平方惩罚的导数也随之减小。 L1正则化的优\\n势在于其惩罚的导数为常数，能够产生比 L2更稀疏的解，同时比 L0正则化更易于优\\n化。有时， L1和L2正则化项会同时使用，称为弹性网正则化（ Zou & Hastie ，2005） 。\\n正则化的另一途径是在不显式定义新损失函数的情况下，修改学习算法的梯度（例\\n如，方程 9.13） 。这种方法已被用于在反向传播中促进稀疏性（ Schwarz 等人，2021） 。\\n关于显式正则化效果的研究结论并不一致。 Zhang等人（2017a）的研究表明， L2\\n正则化对泛化的贡献有限。网络的 Lipschitz 常数（即函数随输入变化的速度）被证明\\n可以限制泛化误差（ Bartlett等人，2017；Neyshabur 等人，2018） 。但是， Lipschitz 常数\\n依赖于权重矩阵谱范数的乘积，这些范数只是间接受到各个权重大小的影响。 Bartlett\\n等人（2017） 、Neyshabur 等人（2018）以及Yoshida & Miyato （2017）均提出了间接促\\n进谱范数减小的方法。 Gouk等人（2021）采取了不同的策略，开发了一种算法，限制\\n网络的Lipschitz 常数在特定值以下。\\n梯度下降中的隐式正则化 :梯度下降的步骤定义为：\\nϕ1=ϕ0+α·g[ϕ0], (9.14)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 156}, page_content='网络的Lipschitz 常数在特定值以下。\\n梯度下降中的隐式正则化 :梯度下降的步骤定义为：\\nϕ1=ϕ0+α·g[ϕ0], (9.14)\\n这里g[ϕ0]表示损失函数梯度的负值， α是步长。当 α→0时，梯度下降过程可以\\n通过下述微分方程描述：\\n∂ϕ\\n∂t=g[ϕ]. (9.15)\\n对于典型步长 α，离散与连续的梯度下降会收敛至不同解。我们可以利用 *后向误\\n差分析*对连续版本进行修正，找到修正项 g1[ϕ]：\\n∂ϕ\\n∂t≈g[ϕ] +αg1[ϕ] +..., (9.16)\\n使其与离散版本产生相同的结果。\\n考虑对初始位置 ϕ0附近的修正连续解 ϕ进行泰勒展开的前两项：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 157}, page_content='142 CHAPTER 9. 正则化\\nϕ[α]≈ϕ+α∂ϕ\\n∂t+α2\\n2∂2ϕ\\n∂t2\\n≈ϕ+α(g[ϕ] +αg1[ϕ]) +α2\\n2\\x12∂g[ϕ]\\n∂ϕg[ϕ] +α∂g1[ϕ]\\n∂ϕg[ϕ]\\x13\\nϕ=ϕ0\\n=ϕ+α(g[ϕ] +αg1[ϕ]) +α2\\n2\\x12∂g[ϕ]\\n∂ϕg[ϕ] +α∂g1[ϕ]\\n∂ϕg[ϕ]\\x13\\nϕ=ϕ0\\n≈ϕ+αg[ϕ] +α2\\x12\\ng1[ϕ] +1\\n2∂g[ϕ]\\n∂ϕg[ϕ]\\x13\\nϕ=ϕ0, (9.17)\\n在这里，第二行引入了修正项（方程 9.16） ，并在最终行去除了高于 α2阶的项。\\n注意，右侧的前两项 ϕ+αg[ϕ0]与离散更新（方程 9.14）相一致。因此，为了让连\\n续与离散版本达成一致，右侧的第三项必须为零，从而解得 g1[ϕ]：\\ng1[ϕ] =−1\\n2∂g[ϕ]\\n∂ϕg[ϕ]. (9.18)\\n训练过程中，演化函数 g[ϕ]是损失梯度的负值：\\n∂ϕ\\n∂t≈g[ϕ] +αg1[ϕ]\\n=−∂L\\n∂ϕ−α\\n2\\x12∂2L\\n∂ϕ2\\x13∂L\\n∂ϕ. (9.19)\\n这等同于对损失函数执行连续梯度下降：\\nLGD[ϕ] =L[ϕ] +α\\n4\\x0c\\x0c\\x0c\\x0c∂L\\n∂ϕ\\x0c\\x0c\\x0c\\x0c2\\n, (9.20)\\n因为方程 9.19的右侧是方程 9.20中该式的导数。\\nBarrett & Dherin (2021) 首次提出了隐式正则化（ Implicit Regularization ）的概念，\\n并由Smith等人(2021)将其扩展应用到随机梯度下降（ Stochastic Gradient Descent,\\nSGD）中。Smith等人(2020)及其他研究者发现，相较于全批量梯度下降，使用较小或\\n中等批量大小的随机梯度下降在测试集上表现更优，这部分归因于隐式正则化的作用。\\n在此基础上， Jastrzebski 等人(2021)和Cohen等人(2021)均发现，采用较大的学\\n习率可以减少优化过程倾向于移动至损失函数的“尖锐”区域（即，至少有一个方向曲\\n率很高的区域）的现象。这种大学习率带来的隐式正则化效果，可以通过惩罚 Fisher信\\n息矩阵的迹来近似实现，这与在方程 9.20中惩罚梯度范数有着密切的关联（ Jastrzebski\\n等人，2021） 。\\n早停：Bishop (1995) 与Sjöberg & Ljung (1995) 指出，早停策略限制了训练过程'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 157}, page_content='等人，2021） 。\\n早停：Bishop (1995) 与Sjöberg & Ljung (1995) 指出，早停策略限制了训练过程\\n能探索的有效解空间范围。考虑到权重的初始值较小，这种策略有助于避免权重过大。\\nGoodfellow 等人(2016)通过对损失函数进行二次近似，并将参数初始化为零的情况下'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 158}, page_content='9.7.笔记 143\\n证明，早停在梯度下降中相当于 L2正则化。其中，有效的正则化权重 λ大约为 1/(τα)，\\nα代表学习率， τ代表早停的时间。\\n集成学习 ：通过使用不同的随机种子（ Lakshminarayanan 等人，2017）、超参数\\n（Wenzel等人，2020b）或甚至完全不同的模型家族，可以训练出多个模型进行集成。这\\n些模型可以通过平均预测、加权预测或堆叠（ Wolpert，1992）的方式组合，后者是通过\\n另一个机器学习模型将结果合并。 Lakshminarayanan 等人（2017）证明，对独立训练的\\n网络输出进行平均可以提升准确度、校准性和鲁棒性。相反， Frankle等人（2020）发现，\\n若将不同模型的权重简单平均形成单一模型，效果并不理想。 Fort等人（2019）对比了\\n从不同初始化出发得到的集成方案与基于同一原始模型生成的集成方案，发现两种方法\\n均能带来互补的益处，但从不同随机起点进行真正的集成能够带来更显著的性能提升。\\n采用中期训练阶段的模型进行集成是一种高效的方法。 基于此， Izmailov 等人 （2018）\\n提出了随机权重平均方法，通过在不同时间点采样模型权重并进行平均。快照集成\\n（Huang等人，2017a）也采用了类似的策略，存储不同时间步骤的模型并平均它们的\\n预测。通过周期性地增加和减少学习率，可以提高这些模型的多样性。 Garipov 等人\\n（2018）观察到，损失函数的不同最小值通常通过低能量路径相连，即沿途损失较低的路\\n径。受此启发， 他们开发了一种方法， 在初始解附近探索低能量区域， 以获得多样化模型\\n而无需重新训练，称为快速几何集成。关于集成方法的综述可参考 Ganaie等人（2022）\\n的工作。\\n丢弃（ Dropout ）： 丢弃技术最初由 Hinton等人（2012b）和Srivastava 等人（2014）\\n引入。它是在隐藏单元层面上应用的，丢弃一个隐藏单元等同于临时将所有进入和离\\n开的权重及偏置置零。 Wan等人（2013）通过随机将单个权重置零来扩展了 Dropout\\n的概念。 Gal & Ghahramani （2016）和Kendall & Gal （2017）提出了蒙特卡罗丢弃\\n（Monte Carlo Dropout ） ，通过多次应用不同的丢弃模式进行推断，并将结果平均。 Gal'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 158}, page_content='（Monte Carlo Dropout ） ，通过多次应用不同的丢弃模式进行推断，并将结果平均。 Gal\\n& Ghahramani （2016）认为，这可以被视为贝叶斯推断的近似。\\n丢弃等同于对隐藏单元应用乘性伯努利噪声。 采用正态分布 （ Srivastava 等人，2014；\\nShen等人，2017） 、均匀分布（ Shen等人，2017）和Beta分布（Liu等人，2019b）等\\n其他分布也能带来类似的益处。\\n添加噪声 ：Bishop (1995) 和An (1996) 通过向网络输入添加高斯噪声来提升性能，\\nBishop (1995) 展示了这等同于权重衰减。 An (1996) 还研究了向权重添加噪声的效果。\\nDeVries & Taylor (2017a) 尝试向隐藏单元添加高斯噪声。随机 ReLU（Xu等人，2015）\\n通过使激活函数随机化，以不同方式应用噪声。\\n标签平滑 ：标签平滑技术最初由 Szegedy等人（2016）在图像分类中引入，后来在\\n语音识别（ Chorowski & Jaitly, 2017 ） 、机器翻译（ Vaswani 等人，2017）和语言建模\\n（Pereyra等人，2017）中被证明有益。尽管 Müller等人（2019a）显示它能提高预测输\\n出概率的校准度，但标签平滑改善测试性能的确切机制尚未被充分理解。 DisturbLabel\\n（Xie等人，2016）是一个密切相关的技术，它在每次训练迭代中随机改变一定比例的批\\n次标签。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 159}, page_content='144 CHAPTER 9. 正则化\\n寻找更宽的极小值 ：更宽的极小值被认为具有更好的泛化能力（参见图 20.11） 。在\\n这里，权重的精确值不那么重要，因此性能应对它们的估计误差具有鲁棒性。训练期间\\n对网络部分应用噪声之所以有效，是因为它鼓励网络对权重的精确值不敏感。\\nChaudhari 等人（2019）开发了一种 SGD的变体，偏向于寻找平坦极小值，称之为\\n熵SGD。其核心思想是在损失函数中加入局部熵作为一个项。在实际应用中，这涉及到\\n在一个SGD式更新内进行另一个更新。 Keskar等人（2017）发现，随着批量大小的减\\n小，SGD倾向于寻找更宽的极小值。这可能是由于 SGD隐式正则化引入的批量方差项\\n导致的。\\nIshida等人（2020）采用了一种称为“淹没”的技术，故意避免训练损失降至零。这\\n促使模型在损失景观中进行随机漫步，漂移到具有更好泛化能力的平坦区域。\\n贝叶斯方法 ：对于某些模型，包括图 9.11中的简化神经网络模型，贝叶斯预测分布\\n可以用封闭形式计算（参见 Bishop, 2006 ；Prince, 2012 ） 。对于神经网络，参数的后验分\\n布不能用封闭形式表示， 需要通过近似方法计算。 主要的两种方法是变分贝叶斯 （ Hinton\\n& van Camp, 1993 ；MacKay, 1995 ；Barber & Bishop, 1997 ；Blundell 等人，2015） ，用\\n一个更简单的可处理分布近似后验，以及马尔可夫链蒙特卡罗（ MCMC）方法，通过抽\\n取一组样本来近似分布（ Neal, 1995 ；Welling & Teh, 2011 ；Chen等人，2014；Ma等\\n人，2015；Li等人，2016a） 。样本生成可以集成到 SGD中，称为随机梯度 MCMC（参\\n见Ma等人，2015） 。最近发现，通过“冷却”参数的后验分布（使其更尖锐）可以改善\\n这些模型的预测（ Wenzel等人，2020a） ，但这一发现目前尚未完全理解（参见 Noci等\\n人，2021） 。\\n迁移学习 ：迁移学习在视觉任务中的应用非常成功（ Sharif Razavian 等人，2014） ，\\n推动了计算机视觉领域的快速发展， 包括最初的 AlexNet 成果（Krizhevsky 等人，2012） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 159}, page_content='推动了计算机视觉领域的快速发展， 包括最初的 AlexNet 成果（Krizhevsky 等人，2012） 。\\n迁移学习也对自然语言处理（ NLP）产生了影响，许多模型基于 BERT模型的预训练特\\n征（Devlin等人，2019） 。更多信息可以参考 Zhuang等人（2020）和Yang等人（2020b）\\n的工作。\\n自监督学习 ： 图像的自监督学习技术包括填补遮蔽的图像区域 （ Pathak等人，2016） 、\\n预测图像块的相对位置（ Doersch等人，2015） 、 重排乱序的图像瓦片（ Noroozi & Favaro,\\n2016） 、 为灰度图像着色（ Zhang等人，2016b）以及将旋转图像恢复到原始方向（ Gidaris\\n等人，2018） 。SimCLR（Chen等人，2020c）中学习了一个网络，将同一图像经过光度\\n和几何变换的版本映射到相同的表示，同时排斥不同图像的版本，以对不相关的图像变\\n换保持不敏感。 Jing & Tian （2020）提供了图像自监督学习的综述。\\nNLP的自监督学习可以基于预测遮蔽词（ Devlin等人，2019） 、预测句子中的下一\\n个词（Radford 等人，2019；Brown等人，2020）或预测两个句子是否相继而来（ Devlin\\n等人，2019） 。在自动语音识别中， Wav2Vec 模型（Schneider 等人，2019）旨在区分原始\\n音频样本与从剪辑中其他地方换出 10ms音频的样本。自监督学习也被应用到图神经网\\n络中，任务包括恢复遮蔽特征（ You等人，2020）和恢复图的邻接结构（ Kipf & Welling,\\n2016） 。Liu等人（2023a）回顾了图模型的自监督学习。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 160}, page_content='9.8.习题 145\\n数据增强 ：图像的数据增强技术至少可追溯到 LeCun等人（1998） ，并对 AlexNet\\n的成功做出了贡献（ Krizhevsky 等人，2012） ，其中数据集通过 2048倍增加。图像增\\n强方法包括几何变换、改变或操纵色彩空间、注入噪声和应用空间滤波器等。更复杂的\\n技术包括随机混合图像（ Inoue, 2018 ；Summers & Dinneen, 2019 ） 、随机擦除图像部分\\n（Zhong等人，2020） 、风格转移（ Jackson等人，2019）以及随机交换图像块（ Kang等人，\\n2017） 。此外，许多研究利用生成对抗网络（ GANs，见第15章）产生新但可信的数据示\\n例（例如， Calimeri 等人，2017） 。在其他情况下，数据被增强了对抗性示例（ Goodfellow\\n等人，2015a） ，这是对训练数据的微小扰动，导致示例被错误分类。图像数据增强的综\\n述可以参考 Shorten & Khoshgoftaar （2019）的工作。\\n声学数据的增强方法包括音高变化、时间拉伸、动态范围压缩和添加随机噪声（例\\n如，AbeBer等人，2017；Salamon & Bello, 2017 ；Xu等人，2015；Lasseck, 2018 ） ，以及\\n混合数据对（ Zhang等人，2017c；Yun等人，2019） 、遮蔽特征（ Park等人，2019）和\\n使用GANs生成新数据（ Mun等人，2017） 。语音数据的增强包括声道长度扰动（ Jaitly\\n& Hinton, 2013 ；Kanda等人，2013） 、风格转移（ Gales, 1998 ；Ye & Young, 2004 ） 、添\\n加噪声（ Hannun等人，2014）以及合成语音（ Gales等人，2009） 。\\n文本的增强方法包括在字符级别通过交换、删除和插入字母添加噪声（ Belinkov &\\nBisk, 2018 ；Feng等人，2020） ，或通过生成对抗性示例（ Ebrahimi 等人，2018） 、使\\n用常见的拼写错误（ Coulombe, 2018 ） 、随机交换或删除词（ Wei & Zou, 2019 ） 、使用\\n同义词（ Kolomiyets 等人，2011） 、改变形容词（ Li等人，2017c） 、被动化（ Min等人，'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 160}, page_content='同义词（ Kolomiyets 等人，2011） 、改变形容词（ Li等人，2017c） 、被动化（ Min等人，\\n2020） 、使用生成模型创建新数据（ Qiu等人，2020）以及往返翻译到另一种语言再翻译\\n回来（Aiken & Park, 2010 ） 。文本增强方法的综述由 Bayer等人（2022）提供。\\n9.8习题\\n问题 9.1考虑一个模型， 其参数的先验分布是均值为零、方差为 σ2\\nϕ的正态分布， 表\\n达式为：\\nPr(ϕ) =JY\\nj=1Norm ϕj[0,σ2\\nϕ], (9.21)\\n其中j表示模型参数的索引。现在，我们需要最大化QI\\ni=1Pr(yi|xi,ϕ)Pr(ϕ)。证明\\n该模型的相关损失函数等价于 L2正则化。\\n问题 9.2当加入L2正则化（方程 9.5）后，损失函数的梯度将如何改变？\\n问题 9.3设想一个线性回归模型 y=ϕ0+ϕ1x，其中x是输入， y是输出，ϕ0和\\nϕ1是模型参数。假设有 I个训练样例 xi,yi，采用最小二乘法作为损失函数。考虑在每\\n次训练迭代时，给输入 xi加入均值为零、方差为 σ2\\nx的高斯噪声。求期望的梯度更新值\\n是什么？\\n问题 9.4当我们采用标签平滑技术，使目标概率分布在正确类别上为 0.9，而剩余'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 161}, page_content='146 CHAPTER 9. 正则化\\n的概率质量 0.1在剩余的Do−1个类别之间均匀分配时，推导出的多类分类损失函数\\n是什么？\\n问题 9.5展示权重衰减参数更新，衰减率为 λ：\\nϕ←(1−λ)ϕ−α∂L\\n∂ϕ, (9.22)\\n对于原始损失函数 L[ϕ]，这等价于采用 L2正则化的标准梯度更新，从而得到修改\\n后的损失函数 ˜L[ϕ]：\\n˜L[ϕ] =L[ϕ] +λ\\n2αX\\nkϕ2\\nk, (9.23)\\n其中ϕ是模型参数， α是学习率。\\n问题 9.6考虑一个参数为 ϕ= [ϕ0,ϕ1]T的模型。请绘制 L0、L1、L1\\n2和L2正则化\\n项，形式与图 9.1b类似。LP正则化项定义为PD\\nd=1|ϕd|P。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 162}, page_content='Chapter 10\\n卷积网络\\n第2至9章详细介绍了深度神经网络在监督学习中的应用流程。然而，这部分内容\\n仅涉及了具有单一路径从输入到输出的全连接网络。第 10至13章则转向介绍更为专\\n业化的网络构件，这些构件特征为更稀疏的连接、权重共享以及并行的处理途径。本章\\n着重讲述了卷积层，它主要被用于图像数据的处理。\\n图像的三个特性指出了专门模型架构的必要性。首先，图像是高维的，一个用于分\\n类任务的典型图像含有 224×224 RGB 值（即， 150,528个输入维度） 。在全连接网络中，\\n隐藏层的规模通常超过输入大小，因此，即便是对浅层网络而言，权重的总数也将超过\\n150,528的平方，达到 220亿之多。这在所需的训练数据量、内存和计算量方面带来了\\n显著的实际挑战。\\n其次，图像中相邻像素在统计学上是相关联的。但全连接网络无法识别“相邻”概\\n念，对所有输入间的关系处理得同等无差。如果训练集和测试集图像的像素被以同样的\\n方式随机置换，网络依旧能够被训练，且几乎不会有任何实际的区别。第三，图像对几\\n何变换的解释是稳定的。比如，若我们将一幅树的图像向左平移几个像素，它仍然是一\\n幅树的图像。然而，这样的平移会改变网络接收的每一个输入。因此，全连接模型必须\\n在每个位置单独学习代表树的像素模式，这无疑是效率低下的。\\n卷积层通过使用全图共享的参数，独立处理每一个局部图像区域。相比全连接层，\\n卷积层使用更少的参数，能够利用相邻像素之间的空间关系，并且无需在每个位置重新\\n学习像素的含义。一个主要由卷积层构成的网络称为卷积神经网络（ CNN） 。\\n10.1不变性与等变性\\n在之前的讨论中，我们提到图像的某些属性（比如树木的纹理）在经历变换后仍保\\n持不变。本节将进一步明确这一概念，采用更加精确的数学表达。对于图像 x的变换\\nt[x]，如果函数 f[x]满足以下条件：\\nf[t[x]] =f[x] (10.1)\\n147'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 163}, page_content='148 CHAPTER 10. 卷积网络\\n即函数f[x]的输出与变换 t[x]无关，则称这个函数对该变换具有不变性。图像分类网\\n络应该对图像的几何变换（如图 10.1a-b所示）具有不变性，也就是说，即便图像经过\\n平移、旋转、翻转或变形，网络 f[x]也能识别出图像中包含的对象相同。\\n若函数f[x]对图像x在变换t[x]下满足：\\nf[t[x]] =t[f[x]]. (10.2)\\n这意味着，如果函数 f[x]的输出在变换 t[x]下以输入相同的方式发生变化，则称\\nf[x]对该变换具有等变性。针对每个像素的图像分割任务的网络对变换应当是等变的\\n（如图10.1c-f所示） ；换句话说，如果图像被平移、旋转或翻转，网络 f[x]应返回一个\\n经过相同变换处理的分割结果。\\n图 10.1:平移不变性和等变性。 a-b)在图像分类任务中，不论图片如何水平移动，都应将其分类\\n为“山脉” 。这意味着，我们期望网络预测对平移操作保持不变。 c,e)语义分割旨在为每个像素\\n分配标签。 d,f)当输入图像发生平移时，我们期望输出（彩色覆盖层）以相同方式进行平移。换\\n言之，输出应对平移保持等变性。图 c-f)源自 Bousselham 等人 (2021)的改编。\\n10.2适用于一维输入的卷积网络\\n卷积网络构建于一系列对平移显示等变性的卷积层之上。这些网络还通常融入池化\\n机制，以引入对平移的部分不变性。为了便于说明，我们先从较易于理解的一维（ 1D）\\n数据的卷积网络讲起。在第 10.3节中，我们将讨论应用于图像数据的二维（ 2D）卷积。\\n10.2.1 一维卷积操作\\n卷积层利用卷积操作为基础，形成网络的一部分。在一维情况下，卷积把输入向量\\nx转换成输出向量 z，其中每个输出 zi都是周围输入的加权和。这些加权和在所有位置\\n上使用相同的权重，这组权重被称作卷积核或滤波器。定义输入被组合的区域大小为核\\n大小。对于核大小为三的情况，我们得到：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 164}, page_content='10.2.适用于一维输入的卷积网络 149\\nzi=ω1xi−1+ω2xi+ω3xi+1, (10.3)\\n这里的ω= [ω1,ω2,ω3]T就是所谓的卷积核（参见图 10.2） 。值得注意的是，卷积操作对\\n平移保持等变性。即如果输入 x发生平移，对应的输出 z也会以同样的方式进行平移。\\n图 10.2:一维卷积，核大小为三。每个输出值 zi是其最近三个输入值 xi-1、xi和 xi+1的加权\\n和，权重为 ω=[ω1, ω2, ω3]。a)输出 z2的计算公式为 z2 =ω1x1+ω2x2+ω3x3。b)输出 z3的\\n计算公式为 z3=ω1x2+ω2x3+ω3x4。c)在 z1位置，卷积核超出了第一个输入 x1，可以通过\\n零填充解决，即假定输入之外的值为零。最终输出也采用相同处理。 d)另一种方法是仅在卷积\\n核完全位于输入范围内时计算输出（称为“有效”卷积） ，此时输出大小将小于输入。\\n>严格而言，这其实是一种互相关操作而非真正的卷积，因为在真正的卷积中，权\\n重相对于输入会进行翻转（即 xi−1与xi+1的位置会互换） 。尽管如此，这种（技术上不\\n正确的）定义已成为机器学习领域的常规约定。\\n10.2.2 填充\\n方程10.3说明，通过对输入的前、当前和后位置进行加权求和，可以计算出每个输\\n出。这引发了一个问题：对于序列的第一个和最后一个输出（分别缺少前一个和后一个\\n输入）该如何处理？\\n解决此问题有两种典型方法。第一种是在输入序列的两端添加新值，之后按常规操\\n作进行。零填充是指在输入的有效范围外假定其值为零（见图 10.2c） 。其他方法包括视\\n输入为周期性的或在边缘处进行反射处理。第二种方法是舍弃在输入范围之外的核覆盖\\n区域的输出，这种方法的优点是不会在输入的边缘引入额外信息，但缺点是输出的尺寸\\n会有所减小。\\n10.2.3 步长、核大小与扩张\\n在前面的示例中，每个输出是由最近的三个输入加权求和得到的。但实际上，这只\\n是卷积操作大家族中的一种，通过步长、核大小和扩张率的不同进行区分。当我们在每\\n个位置都计算输出时，这称为步长为一。但是，我们也可以将核按大于一的步长进行移\\n动。例如，步长为二时，输出的数量大约减半（见图 10.3a–b） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 165}, page_content='150 CHAPTER 10. 卷积网络\\n可以通过增加核大小来覆盖更大的区域（见图 10.3c） 。但核大小通常保持为奇数，\\n以便可以围绕当前位置居中。核大小的增加意味着需要更多的权重，这就引入了扩张或\\n空洞卷积的概念，在这种卷积中，核的值之间插入了零。例如，我们可以将一个五元素\\n的核通过将第二和第四个元素设为零，转换成三元素的扩张核。这样，我们仍然能够覆\\n盖更大的输入区域，但仅需三个权重（见图 10.3d） 。我们在权重之间插入的零的数量决\\n定了扩张率。\\n图 10.3:步长、核大小和扩张。 a)当步长为二时，我们每隔一个位置对卷积核进行评估，因此\\n第一个输出 z1是基于以 x1为中心的加权和计算得出的， b)第二个输出 z2则是基于以 x3为中\\n心的加权和得出的，依此类推。 c)可以改变卷积核的大小。使用五的核大小时，我们会计算最\\n近五个输入的加权和。 d)在扩张（或带孔）卷积中，我们在权重向量中间隔插入零，这样可以\\n使用较少的权重覆盖更大的区域。\\n10.2.4 卷积层\\n卷积层计算输出的过程涉及将输入与卷积核进行卷积，加入偏置项 β，然后将每个\\n结果通过激活函数 a[•]。在核大小、步长和扩张率均为一的条件下，第 i个隐藏单元 hi\\n的计算公式为：\\nhi=a[β+ω1xi−1+ω2xi+ω3xi+1]\\n=a\"\\nβ+3X\\nj=1ωjxi+j−2#\\n, (10.4)\\n这里，偏置 β与核权重ω1,ω2,ω3均为可训练参数。通过零填充，我们对于超出有\\n效范围的输入 x视作零处理。这实际上是全连接层的一种特例，全连接层对第 i个隐藏\\n单元的计算方式为：\\nhi=a\"\\nβi+DX\\nj=1ωijxj#\\n. (10.5)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 166}, page_content='10.2.适用于一维输入的卷积网络 151\\n对于D个输入x和D个隐藏单元 h，全连接层将需要 D2个权重ω··和D个偏置\\nβ·。相比之下，卷积层仅需三个权重和一个偏置。通过将大多数权重设置为零并约束其\\n他权重保持一致，全连接层也能够实现与卷积层相同的计算效果（参见图 10.4） 。\\n图 10.4:全连接层与卷积层的对比。 a)全连接层为每个输入 x到每个隐藏单元 h设置了一个权\\n重（彩色箭头表示）和每个隐藏单元的偏置（未显示） 。 b)因此，相应的权重矩阵 Ω包含了将六\\n个输入与六个隐藏单元联系起来的 36个权重。 c)三核大小的卷积层通过相同的加权和（加上偏\\n置，未显示）来计算每个隐藏单元，加权和基于三个邻近的输入值（箭头表示） 。 d)权重矩阵是\\n全连接矩阵的一个特例，许多权重为零，其他的则重复（相同颜色表示相同的值，白色表示零权\\n重） 。 e)一个核大小为三且步长为二的卷积层在每隔一个位置计算一个加权和。 f)这也是一个全\\n连接网络的特殊情况，但具有不同的稀疏权重结构。\\n10.2.5 Channels\\n单个卷积操作虽然可以提取信息，但同时也会导致信息的部分丢失，因为它通过对\\n相邻输入的平均以及 ReLU激活函数的非负限制进行处理。为了弥补这一缺陷，常常并\\n行计算多个卷积，每个卷积生成一组新的隐藏变量，形成一个独特的特征图或通道。\\n如图10.5a-b所示，使用两个核大小为三，并采用零填充的卷积核进行说明。第一\\n个卷积核通过计算最近三个像素点的加权和，并加上一个偏置后，通过激活函数生成了\\nh1至h6的隐藏单元，形成了第一个特征通道。第二个卷积核则计算一组不同的加权和，\\n并通过另一个偏置和激活函数，生成了 h7至h12的隐藏单元，这形成了第二个特征通\\n道。\\n通常，输入层和隐藏层都包含多个通道，如图 10.5c所展示。如果输入层具有 Ci个\\n通道，并且采用了大小为 K的卷积核，那么每个输出通道的隐藏单元就是通过对所有\\nCi个通道及K个核位置进行加权求和计算的，这一过程使用了权重矩阵 Ω∈RCi×K和\\n一个偏置完成。因此，如果下一层包含 Co个通道，那么我们需要 Ω∈RCi×Co×K的权重\\n和β∈RCo的偏置。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 167}, page_content='152 CHAPTER 10. 卷积网络\\n图 10.5:通道。通常，对输入 x应用多个卷积操作，并将结果存储在不同的通道中。 a)通过卷积\\n操作生成的隐藏单元 h1到h6构成了第一个通道。 b)应用第二次卷积操作生成的隐藏单元 h7\\n到h12构成了第二个通道。这些通道被存储在一个二维数组 H1中，该数组包含第一隐藏层中\\n的所有隐藏单元。 c)如果我们增加另一个卷积层，那么现在每个输入位置都有两个通道。此时，\\n一维卷积通过在三个最近的位置上对两个输入通道进行加权和计算，以生成每个新的输出通道。\\n10.2.6 卷积网络与感受野\\n如第4章所述，深度网络包括多个全连接层的序列。与此相似，卷积网络则是由多\\n个卷积层序列构成的。在这种网络中，每个隐藏单元的接受字段指的是对应该单元有贡\\n献的原始输入区域。在每个卷积层核大小为三的卷积网络中，第一层的隐藏单元通过对\\n三个最接近的输入进行加权求和来计算，因此它们的接受字段大小为三。而第二层的单\\n元则对第一层中最接近的三个位置进行加权求和，而这些位置本身又是基于三个输入的\\n加权求和。因此，第二层的隐藏单元的接受字段大小扩展到了五。这样，随着层次的增\\n加，每个单元的接受字段也相应扩大，使得整个输入范围内的信息得以逐步整合（见图\\n10.6） 。\\n10.2.7 示例： MNIST-1D\\n我们现在对 MNIST-1D 数据应用了一个卷积网络（参见图 8.1） 。输入 x为一个40\\n维向量，而输出 f是一个10维向量，经 softmax层转换为类概率。我们采用了一个包\\n含三个隐藏层的网络（参见图 10.7） 。第一隐藏层 H1的十五个通道采用核大小为 3、步\\n长为2和“valid”填充计算得到，产生了十九个空间位置。第二和第三隐藏层 H2和 H3\\n的计算方式相同。此时，网络的表示具有四个空间位置和十五个通道。这些值被重塑为\\n一个60维向量，通过一个全连接层映射到十个输出激活上。\\n该网络在一个含 4,000个样本的数据集上，采用无动量的 SGD、0.01的学习率和\\n100的批量大小，训练了 100,000步。我们将其与一个具有相同层数和隐藏单元数（即\\n三个隐藏层，分别具有 285、135和60个隐藏单元）的全连接网络进行了比较。卷积网\\n络有2,050个参数，全连接网络有 59,065个参数。根据图 10.4的逻辑，卷积网络是全'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 167}, page_content='三个隐藏层，分别具有 285、135和60个隐藏单元）的全连接网络进行了比较。卷积网\\n络有2,050个参数，全连接网络有 59,065个参数。根据图 10.4的逻辑，卷积网络是全\\n连接网络的一个特殊情况。后者具有足够的灵活性以精确复制前者。图 10.8显示，两种\\n模型都完美地适配了训练数据。然而，卷积网络的测试误差远低于全连接网络。\\n这种差异可能不仅仅是参数数量的问题；我们知道，过参数化通常有助于提升性能\\n（参见第 8.4.1节） 。 卷积架构之所以表现更好， 很可能是因为其具有更优的归纳偏差（即，'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 168}, page_content='10.3.适用于二维输入的卷积网络 153\\n图 10.6:使用三宽核的网络感受野。 a)一个维度为十一的输入进入一个有三个通道且卷积核大\\n小为三的隐藏层。在第一隐藏层 H1中，三个特定隐藏单元的预激活分别是其最近三个输入的不\\n同加权和，因此 H1的感受野大小为三。 b)在 H2层，四个特定隐藏单元的预激活各取自 H1层\\n的三个通道，在三个最近位置的加权和。 H1层的每个隐藏单元都是基于最近三个输入位置的加\\n权。因此， H2层的隐藏单元具有五的感受野大小。 c)第三层的隐藏单元（核大小为三，步长为\\n二）把感受野大小增加到七。 d)加入第四层后，第三位置的隐藏单元的感受野能覆盖全部输入。\\n更好地在训练数据间进行插值） ，这是因为我们在架构中加入了一些先验知识；我们让\\n网络以统一的方式处理输入中的每个位置。考虑到数据是通过对模板进行随机位移（包\\n括其他操作）生成的，这种处理方式十分合理。\\n与全连接网络必须学习每个数字模板在每个位置的外观不同，卷积网络通过位置间\\n的信息共享，从而更精确地识别各个类别。也可以这样理解，训练卷积网络时，我们在\\n探索一个较小的、所有可能合理的输入 /输出映射家族。另一方面，卷积结构相当于一\\n个正则化器，它对全连接网络可能描述的大多数解决方案施加了无限大的惩罚。\\n10.3适用于二维输入的卷积网络\\n前文讨论了针对一维数据的卷积网络应用，这类网络适用于金融时间序列、音频和\\n文本处理。然而，卷积网络更常见的应用是在二维图像数据上。此时，卷积核变为二维\\n结构。一个 3x3的卷积核 Ω∈R3x3对二维输入中的元素 xij进行计算，生成一个隐藏'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 169}, page_content='154 CHAPTER 10. 卷积网络\\n图 10.7:用于分类 MNIST-1D 数据的卷积网络 （参见图 8.1） 。MNIST-1D 输入的维度为 Di= 40。\\n第一卷积层包含十五个通道，核大小为三，步长为二，仅保留“有效”位置，形成了一个具有十\\n九个位置和十五个通道的表示。随后的两个卷积层配置相同，逐步缩小表示的尺寸。最终，全连\\n接层接收第三隐藏层的全部六十个隐藏单元，输出十个激活值，这些激活值通过 softmax 层转\\n化为十个类别的概率。\\n图 10.8: MNIST-1D 结果。 a)图 10.7的卷积网络最终完美拟合训练数据，测试误差约为 17%。\\nb)一个具有相同隐藏层数量和每层隐藏单元数量的全连接网络虽然学习速度更快，但泛化性较\\n差，测试误差约为 40%。后者模型理论上可以复现卷积模型的性能，但实际未能达到。卷积结\\n构通过限制映射方式，使其能够类似地处理每个位置，从而提高了性能。\\n单元层hij：\\nhij=a\"\\nβ+3X\\nm=13X\\nn=1ωmnxi+m−2,j+n−2#\\n, (10.6)\\n这里ωmn代表卷积核的各个元素，实质上是对一个 3x3区域的输入进行加权求和。\\n卷积核在二维输入上进行横向和纵向的平移操作（参见图 10.9） ，以在每个位置产生输\\n出。\\n通常情况下，输入为 RGB图像，该图像被处理为一个带有三个通道的二维信号\\n（参见图 10.10） 。此时，一个 3x3的卷积核拥有 3x3x3权重，分别应用于每个 3x3位\\n置上的三个输入通道，生成一个高度和宽度与输入图像相同的二维输出（假设使用零填\\n充） 。为了产生多个输出通道，我们通过采用不同的卷积核权重重复此过程，并将结果合'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 170}, page_content='10.3.适用于二维输入的卷积网络 155\\n图 10.9:二维卷积层。每个输出 hij是 3×3最近输入的加权和，再加上偏置，并通过激活函数\\n处理。 a)这里，输出 h23（突出显示的输出）是从 x12到 x34（突出显示的输入）九个位置的加\\n权和。 b)不同的输出通过在图像网格的两个维度上平移核来计算。 c-d)使用零填充时，图像边\\n缘以外的位置被视为零。\\n并成一个三维张量。若卷积核尺寸为 K×K，且输入通道数为 Ci，则每个输出通道是\\nCi×K×K个量的加权和加一个偏置。因此，计算 Co个输出通道需要 Ci×Co×K×K\\n个权重和Co个偏置。\\n图 10.10:对图像应用的二维卷积。图像被处理为一个具有红色、绿色和蓝色三个通道的二维输\\n入。使用 3×3核时，第一隐藏层的每个预激活是通过点对点乘以 3×3×3核权重与同一位置的\\n3×3 RGB 图像块，然后求和并加上偏置来计算的。为了计算隐藏层的所有预激活，我们在图像\\n的水平和垂直方向上滑动核。输出是一层二维的隐藏单元。为了创建多个输出通道，我们将使用\\n多个核重复此过程，生成第一隐藏层 H1的三维张量隐藏单元。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 171}, page_content='156 CHAPTER 10. 卷积网络\\n10.4下采样与上采样\\n图10.7中的网络通过采用步长为 2的卷积操作在每层缩减表示尺寸，以此增大感\\n受野。现在我们来探讨用于减小二维输入尺寸的下采样方法，以及用于尺寸放大的上采\\n样技术，后者在输出为图像时尤其有用。此外，我们还将讨论如何在网络层间改变通道\\n数，这在网络的两个分支合并时特别重要（详见第 11章） 。\\n10.4.1 下采样\\n缩减二维数据的表示有三种主流方法，常见的情况是同时将两个维度都缩小一半。\\n首先，我们可以选择每隔一个位置进行采样。当步长设置为 2时，此方法会与卷积操作\\n同时生效（参见图 10.11a） 。\\n第二种方法，最大池化选取 2×2区域内的最大值（参见图 10.11b） ，这样可以某种\\n程度上对平移变化保持不变；即使输入图像移动了一个像素，许多最大值仍然保持不变。\\n最后一种，平均池化则是取区域内值的平均。这些方法都是独立对每个通道进行下采样\\n的，因此输出的宽度和高度减半，但通道数不变。\\n图 10.11:缩减表示尺寸的方法（下采样） 。 a)子采样。原来的 4×4表示（左侧）通过保留每隔\\n一个输入缩减到 2×2尺寸（右侧） 。左侧的颜色标示了对右侧输出有贡献的输入。这实际上与\\n步长为二的核操作相同，只不过中间过程的值没有被计算出来。 b)最大池化。每个输出由对应\\n2×2区块中的最大值组成。 c)平均池化。每个输出是 2×2区块内值的平均值。\\n10.4.2 上采样\\n提升网络层分辨率最简单的方法是将每个空间位置的所有通道内容复制四次（参见\\n图10.12a） 。第二种方法是最大反池化，适用于之前通过最大池化进行下采样的场景，我\\n们将值还原到其原始位置（参见图 10.12b） 。第三种方法通过双线性插值在已有样本点\\n之间插值填充缺失值（参见图 10.12c） 。\\n第四种方法可视为步长为 2的下采样的逆过程。在该方法中，输出是输入的一半，\\n并且对于 3x3的核，每个输出是三个最近输入的加权和（参见图 10.13a） 。而在转置卷\\n积中，这一过程被反转（参见图 10.13c） ，输出数量是输入的两倍，且每个输入对三个输\\n出有贡献。观察这种上采样机制相关的权重矩阵（参见图 10.13d） ，我们发现它实际上\\n是下采样机制权重矩阵的转置（参见图 10.13b） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 172}, page_content='10.5.应用 157\\n图 10.12:增大表示尺寸的方法（上采样） 。 a)扩大 2D层尺寸最简单的方式是将每个输入复制\\n四次。 b)在我们先前使用过最大池化操作的网络（参考图 10.11b）中，我们可以将值重新分配\\n回它们原本的位置（即最大值所在的位置） ，这称为最大反池化。 c)另一个选项是输入值之间的\\n双线性插值。\\n图 10.13:一维转置卷积。 a)采用三的核大小、两的步长和零填充进行下采样。每个输出是三个\\n输入的加权和（箭头标示权重） 。 b)这可以通过一个权重矩阵表示（相同颜色表示共享的权重） 。\\nc)在转置卷积中，每个输入对输出层贡献三个值，输出层的输出是输入的两倍。 d)相关的权重\\n矩阵是面板（ b）中那个的转置。\\n10.4.3 改变通道数\\n有时候，我们需要在两个隐藏层之间改变通道数，而不进一步进行空间池化。这通\\n常是为了能够将该层的数据与另一并行处理的数据结合起来（详见第 11章） 。为此，我\\n们采用核尺寸为 1的卷积操作。输出层的每个元素通过对同一位置的所有通道进行加权\\n求和来计算（参见图 10.14） 。通过不同的权重重复此过程，我们可以生成所需数量的输\\n出通道。相关的卷积权重尺寸为 1×1×Ci×Co，因此称为 1×1卷积。结合偏置和激\\n活函数后，这等同于在每个位置的通道上执行全连接网络。\\n10.5应用\\n本章的结尾介绍了三个计算机视觉应用。首先是图像分类的卷积网络，目标是将图\\n像分类到预定的一组类别中。接着是物体检测，旨在识别图像中的多个物体并为每个物\\n体绘制边界框。最后，我们探讨了一个早期的语义分割系统，其目标是根据物体的存在\\n为每个像素分配标签。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 173}, page_content='158 CHAPTER 10. 卷积网络\\n图 10.14: 1×1 卷积。为了改变通道数而不进行空间池化，我们使用 1×1的核。每个输出通道\\n通过在相同位置对所有通道进行加权求和、加偏置并通过激活函数来计算。通过不同的权重和\\n偏置重复此操作以创建多个输出通道。\\n10.5.1 图像分类\\n深度学习在计算机视觉领域的开创性工作大多专注于使用 ImageNet 数据集的图像\\n分类（参见图 10.15） 。该数据集含有 128万余张训练图像， 5万张验证图像以及 10万\\n张测试图像，每张图像均被标记为 1000个可能类别中的一个。\\n图 10.15: ImageNet 分类示例图像。模型的目标是将输入图像分配到 1000个类别之一。这一任\\n务因图像在不同属性（列）上的广泛变化而具有挑战性。这包括刚性（猴子 <独木舟） 、图像中\\n的实例数量（蜥蜴 <草莓） 、杂乱度（指南针 <钢鼓） 、大小（蜡烛 <蜘蛛网） 、纹理（螺丝刀\\n<豹） 、颜色的独特性（马克杯 <红酒）以及形状的独特性（海岬 <钟） 。改编自 Russakovsky\\n等人 (2015)。\\n大多数方法需要将输入图像调整到统一尺寸；通常，网络的输入是一个 224×224 的\\nRGB图像，输出则是 1000个类别的概率分布。这项任务颇具挑战，类别繁多且变化巨\\n大（参见图 10.15） 。2011年，深度网络应用之前，最先进的方法在将正确类别排在前\\n五位的测试图像分类中的错误率约为 25%。五年后，最佳深度学习模型的表现已超越人\\n类。\\n2012年，AlexNet 成为第一个在此任务上表现出色的卷积网络。它由八个隐藏层组\\n成，使用了 ReLU激活函数，其中前五层为卷积层，其余为全连接层（参见图 10.16） 。\\n网络首先使用 11×11的核和四步的步长对输入进行下采样，形成 96个通道。接着通过\\n最大池化层进一步下采样，并应用 5×5的核形成 256个通道。再经过三层 3×3核大小\\n的卷积层，最终形成一个含 256个通道的 13×13表示。一个最终的最大池化层得到一个'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 174}, page_content='10.5.应用 159\\n含256个通道的 6×6表示，该表示被调整为 9216长度的向量，并通过包含 4096、4096\\n和1000个隐藏单元的三个全连接层。最后一层通过 softmax函数输出 1000个类别的概\\n率分布。整个网络包含约 6000万个参数，大部分位于全连接层。\\n图 10.16: AlexNet （Krizhevsky 等人， 2012） 。该网络把一张 224×224 的彩色图像转换为代表\\n类别概率的 1000维向量。网络首先通过 11×11的卷积核和 4步长进行卷积，产生 96个通道。\\n接着使用最大池化操作降低分辨率，并应用一个 5×5的卷积层。之后是另一个最大池化层，随\\n后应用了三个 3×3的卷积层。最后一个最大池化操作之后，结果被向量化，并通过三层全连接\\n（FC）层，最终通过 softmax层。\\n通过空间变换和输入强度的调整，数据集的大小被扩增了 2048倍。测试时，图像\\n的五个不同裁剪和镜像版本被输入网络，其预测结果被平均处理。该系统通过 SGD学\\n习，动量系数为 0.9，批大小为 128。在全连接层使用了 Dropout，并采用了 L2正则化\\n（权重衰减） 。该系统达到了 16.4%的前五名错误率和 38.1%的最佳选择错误率。当时，\\n这在被认为远超当代方法能力的任务上实现了巨大的性能飞跃，揭示了深度学习的巨大\\n潜力，开启了现代 AI研究的新纪元。\\n针对ImageNet 任务的分类， VGG网络实现了更佳的性能，前五名错误率为 6.8%，\\n最佳选择错误率为 23.7%。这个网络由交替的卷积层和最大池化层组成，表示的空间尺\\n寸逐渐减小，而通道数增加，之后连接三个全连接层（参见图 10.17） 。VGG网络的训\\n练同样采用了数据增强、权重衰减和 Dropout。\\n尽管训练策略有一些微小的差异，但 AlexNet 和VGG之间最重要的变化是网络的\\n深度。后者使用了 19个隐藏层和 1.44亿个参数。图 10.16和10.17中的网络以相同的\\n比例展示以便于比较。几年来，随着网络深度的增加，这项任务上的性能持续改进，这\\n证明了深度在神经网络中的重要性。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 175}, page_content='160 CHAPTER 10. 卷积网络\\n图 10.17: VGG 网络（ Simonyan & Zisserman ，2014） ，与 AlexNet（参见图 10.16）按相同比\\n例展示。这个网络由一系列卷积层和最大池化操作组成，表示的空间尺度逐渐减小，而通道数逐\\n渐增加。最后一次卷积操作之后的隐藏层被调整为一维向量，然后是三个全连接层。网络输出\\n1000个激活值，对应于类别标签，经 softmax函数处理生成类别概率。\\n10.5.2 对象检测\\n对象检测的目标是识别并定位图像内多个物体。早期基于卷积网络的方法之一是\\n“一次性看全” （ YOLO） 。YOLO网络输入一张 448×448 的RGB图像，经过 24层卷积\\n处理，通过最大池化减小尺寸、增加通道数，类似 VGG网络的做法。最终卷积层尺寸\\n为7×7，含1024通道，后被转换为向量，通过全连接层映射为 4096个值。再有一个全\\n连接层将表示映射到输出。\\n输出值在一个 7×7网格的每个位置编码了存在的类别（图 10.18a–b） 。每个位置的\\n输出还确定了一定数量的边界框。每个框由五个参数定义：中心的 x和y坐标、框的高\\n度和宽度，以及预测的置信度（图 10.18c） 。置信度评估了预测与实际边界框的重叠程\\n度。系统通过动量、权重衰减、 dropout和数据增强等方法训练，并采用迁移学习策略：\\n先在ImageNet 分类任务上训练网络，再针对物体检测进行微调。\\n网络操作后，利用启发式过程去除低置信度的矩形，并抑制重复的预测边界框，只\\n保留最可信的一个。\\n10.5.3 语义分割\\n语义分割旨在为每个像素分配标签，标签根据像素所属的对象决定，如果像素在训\\n练数据库中无对应对象，则不分配标签。一个早期的语义分割网络如图 10.19所示。输\\n入为224×224 RGB 图像，输出为 224×224×21 的数组，每个位置包含 21个可能类别\\n的概率。\\n网络的前部是 VGG的简化版（图 10.17） ，有13而非16层卷积层，表示尺寸缩小\\n至14×14。此后是一次最大池化，再通过两个全连接层映射为两个 4096大小的1D表\\n示，这些层汇总了整个图像的信息。\\n此时，架构与 VGG不同。另一个全连接层将表示恢复为 7×7空间位置和 512通\\n道。接着是一系列最大反池化层和反卷积层，执行 2D转置卷积但不进行上采样。最终，'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 176}, page_content='10.5.应用 161\\n图 10.18: YOLO 对象检测。 a)输入图像调整为 448×448 大小，并划分为 7×7的规则网格。\\nb)系统预测每个网格单元最可能的类别。 c)同时预测每个单元两个边界框及其置信度（线的粗\\n细代表置信度） 。 d)在推理时，保留最可能的边界框，同一对象的低置信度框被抑制。改编自\\nRedmon 等人（ 2016） 。\\n图 10.19: Noh 等人（ 2015）的语义分割网络。输入是一张 224×224 的图像，通过 VGG网络\\n的一个版本处理，并最终通过一个全连接层转换为 4096大小的表示，包含整个图像的信息。然\\n后，这个表示通过另一个全连接层转换为 7×7大小，并通过上采样和反卷积（不含上采样的转\\n置卷积）在 VGG网络的镜像结构中处理。输出是一个 224×224×21 的表示，为每个位置的 21\\n个类别提供输出概率。\\n通过1×1卷积产生 21个代表可能类别的通道，并在每个空间位置执行 softmax操作，\\n将激活映射为类概率。网络的下采样部分称为编码器，上采样部分称为解码器，因此此\\n类网络有时被称为编解码网络或沙漏网络，因其形状而得名。\\n最终分割通过一种启发式方法生成，该方法贪婪搜索最具代表性的类别并推断其区\\n域，既考虑概率也促进连通性。接着，将下一个最具代表性的类别添加至剩余未标记像\\n素中。此过程持续，直至无更多明确证据（图 10.20） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 177}, page_content='162 CHAPTER 10. 卷积网络\\n图 10.20:语义分割结果。最终结果通过从 21个概率图中贪婪选择最佳类别，并使用启发式方\\n法基于概率及其空间邻近性创建一个合理的二值图来生成。如果有充分证据，会添加随后的类\\n别，并组合它们的分割图。改编自 Noh等人（ 2015） 。\\n10.6总结\\n在卷积层，每个隐藏单元的计算基于对邻近输入的加权求和、加偏置以及应用激活\\n函数。由于每个空间位置的权重和偏置保持不变，因此相比全连接网络，卷积网络的参\\n数量大大减少，且不随输入图像的大小而增加。为保证信息完整，采用不同的权重和偏\\n置重复此操作，在每个空间位置生成多通道。\\n典型卷积网络结构包括卷积层与二倍因子降采样层的交替，随网络深入，空间维度\\n通常以二的倍数减小，通道数以二的倍数增加。网络末端通常包含一个或多个全连接层，\\n整合整个输入的信息以产出期望输出。若输出为图像，一个对称的“解码器”则将其上\\n采样至原始尺寸。\\n卷积层的平移等变性引入了有效的归纳偏好，这在图像相关任务中相对全连接网络\\n能够提升性能。我们探讨了图像分类、物体检测和语义分割网络，发现随着网络加深，\\n图像分类性能提升。然而，后续实验表明，无限加深网络深度并不总是有益的；超过某\\n个深度后，网络训练变得困难。这促成了残差连接的提出，将在下一章详细讨论。\\n10.7笔记\\nDumoulin 和Visin (2016) 展开了对卷积数学的全面概述，对本章的简要介绍进行\\n了扩充。\\n卷积网络的早期发展由 Fukushima 和Miyake (1982) 、LeCun等(1989a)以及LeCun\\n等(1989b)推动。其初步应用领域包括手写识别（ LeCun等，1989a；Martin，1993） 、\\n面部识别（ Lawrence 等，1997） 、音素识别（ Waibel等，1989） 、口语词识别（ Bottou\\n等，1990）和签名验证（ Bromley 等，1993） 。然而， LeCun等(1998)通过构建用于分\\n类28×28灰度手写数字图像的 LeNet系统，使卷积网络广为人知。 LeNet可视为现代\\n网络的雏形，采用了多个卷积层后接全连接层，使用 sigmoid激活函数而非 ReLU，并\\n采用平均池化而不是最大池化。 AlexNet（Krizhevsky 等，2012）通常被视为现代深度'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 178}, page_content='10.7.笔记 163\\n卷积网络的起点。\\nImageNet 挑战赛： Deng等(2009)编制的ImageNet 数据库及其关联的分类挑战赛，\\n在AlexNet 之后的几年里推动了深度学习的发展。此挑战赛的显著获胜者包括网络中网\\n络架构（ Lin等，2014） ，它在每个位置的所有通道上交替使用卷积和全连接层（即 1×1\\n卷积） 。Zeiler & Fergus (2014) 和Simonyan & Zisserman (2014) 训练了与 AlexNet 基本\\n相似的更大更深的架构。 Szegedy等(2017)开发的GoogLeNet 引入了inception 块，通\\n过并行使用不同尺寸的滤波器并重新组合，有效地让系统自主学习滤波器尺寸。\\n随着网络深度的增加，性能持续提升。但训练更深网络的难度也随之增大，除非引\\n入新的修改措施，如残差连接和归一化层，后者将在下章详细介绍。 ImageNet 挑战赛的\\n进展在Russakovsky 等(2015)中进行了总结。 Rawat和Wang (2017) 对使用卷积网络\\n进行图像分类进行了更广泛的调研。图像分类网络随时间进步的情况在图 10.21中进行\\n了可视化展示。\\n图 10.21: ImageNet 性能。每个圆圈代表一个不同的已发布模型。蓝色圆圈代表当时的最先进\\n模型。本书讨论的模型也被突出显示。 AlexNet 和 VGG网络在其时代是杰出的，但现在已不是\\n最先进的。 ResNet-200 和 DenseNet 将在第 11章讨论。 ImageGPT 、ViT、SWIN和 DaViT将\\n在第 12章讨论。改编自 https://paperswithcode.com/sota/image-classification-on-imagenet 。\\n卷积层的类型： Atrous或扩张卷积由 Chen等(2018c)和Yu & Koltun (2015) 引入。\\n转置卷积由 Long等(2015)引入。Odena等(2016)指出它们可能导致棋盘效应，应谨\\n慎使用。 Lin等(2014)是早期使用 1×1滤波器进行卷积的例子。\\n标准卷积层的许多变种旨在减少参数的数量。包括深度或通道分离卷积（ Howard\\n等，2017；Tran等，2018） ，在此方式中，不同的滤波器分别作用于每个通道，生成一组'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 178}, page_content='标准卷积层的许多变种旨在减少参数的数量。包括深度或通道分离卷积（ Howard\\n等，2017；Tran等，2018） ，在此方式中，不同的滤波器分别作用于每个通道，生成一组\\n新通道。分组卷积（ Xie等，2017）则是每个卷积核仅作用于通道的一个子集，以减少\\n参数。AlexNet 出于计算原因采用了分组卷积，整个网络无法在单个 GPU上运行。分\\n离卷积视每个核作为 1D向量的外积，并对每个通道使用 C + K + K 参数。局部卷积\\n（Liu等，2018a）用于修补缺失像素，并考虑输入的部分遮挡。门控卷积（ Yu等，2019；\\nChang等，2019b）从上一层学习掩码。 Hu等(2018b)提出的squeeze-and-excitation 网\\n络利用跨所有空间位置汇总的信息来调整通道权重。\\n下采样和上采样：平均池化至少可追溯到 LeCun等(1989a)，最大池化则始于 Zhou'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 179}, page_content='164 CHAPTER 10. 卷积网络\\n& Chellappa (1988) 。Scherer等(2010)比较了这些方法，认为最大池化更为优越。最大\\n反池化技术由 Zeiler等(2011)和Zeiler & Fergus (2014) 引入。最大池化可以视为对待\\n池化的隐藏单元应用 L∞范数。Zhang (2019) 引入的*最大模糊池化 *在下采样前应\\n用低通滤波，以防止混叠效应，证明了这种方法能够改善输入平移的泛化能力，同时防\\n御对抗性攻击。 （见第 20.4.6节） 。\\nShi等人(2016)提出了*PixelShuffle* 技术，该技术通过使用步长为 1/s的卷积滤\\n波器来实现 1D信号的s倍放大。在这个过程中，只有那些精确对齐的权重被用来生成\\n输出，而那些位于中间位置的权重则被舍弃。这一方法通过将内核的通道数乘以 s来实\\n施，其中第 sth个输出位置仅由第 sth个通道子集决定。这种方法也可以简易地扩展至\\n2D卷积，此时需要 s2个通道。\\n在1D和3D数据上的卷积：虽然卷积网络主要用于图像处理，但它们也被应用于\\n处理1D数据，涵盖了语音识别（ Abdel-Hamid 等人，2012） 、句子分类（ Zhang等人，\\n2015；Conneau 等人，2017） 、心电图分类（ Kiranyaz 等人，2015）和轴承故障诊断（ Eren\\n等人，2019）等应用领域。 Kiranyaz 等人(2021)对1D卷积网络进行了综述。此外，卷\\n积网络也被扩展应用于 3D数据，包括视频（ Ji等人，2012；Saha等人，2016；Tran等\\n人，2015）和体积测量（ Wu等人，2015b；Maturana & Scherer ，2015） 。\\n不变性与等变性：卷积层之所以受到关注，部分原因是它们对平移操作大致呈现等\\n变性；而最大池化层引入的动机部分是为了对小范围平移具有不变性。 Zhang (2019) 研\\n究了卷积网络在这些属性上的真实表现，并提出了一种显著提升这些属性的最大模糊池\\n化改进方法。目前，研究界对于让网络对其他类型的变换（如反射、旋转和缩放）具有\\n等变性或不变性表现出了浓厚的兴趣。 Sifre & Mallat (2013) 基于小波构建了一个系统，\\n该系统在图像块中同时引入了平移和旋转不变性，并将其应用于纹理分类。 Kanazawa'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 179}, page_content='等变性或不变性表现出了浓厚的兴趣。 Sifre & Mallat (2013) 基于小波构建了一个系统，\\n该系统在图像块中同时引入了平移和旋转不变性，并将其应用于纹理分类。 Kanazawa\\n等人(2014)开发了局部尺度不变的卷积神经网络。 Cohen & Welling (2016) 利用群论构\\n建了群卷积神经网络 (group CNNs) ，这些网络对更广泛的变换族群，包括反射和旋转，\\n呈现等变性。 Esteves等人(2018)提出了极坐标变换网络，这些网络对平移不变，对旋\\n转和缩放等变。 Worrall等人(2017)开发了谐波网络，这是首个对连续旋转等变的群卷\\n积神经网络。\\n初始化与正则化：卷积网络通常采用 Xavier初始化（ Glorot & Bengio, 2010 ）或\\nHe初始化（ He等人，2015） ，如第 7.5节所述。然而， ConvolutionOrthogonal 初始化\\n器（Xiao等人，2018a）专为卷积网络设计。利用这种初始化，可以训练多达 10,000层\\n的网络，而无需依赖残差连接。\\nDropout 技术在全连接网络中效果显著，但在卷积层中的效果较弱（ Park & Kwak,\\n2016） 。这可能是因为图像中相邻像素高度相关，导致即便某个隐藏单元被丢弃，相邻位\\n置仍能传递相同的信息。这促成了空间 dropout和cutout技术的发展。在空间 dropout\\n技术中（ Tompson 等人，2015） ，不是丢弃单个像素，而是整个特征图。这样就避免了\\n相邻像素信息重复的问题。同样， DeVries & Taylor (2017b) 提出了cutout技术，在训\\n练时遮盖输入图像的一块正方形区域。 Wu & Gu (2015) 为dropout 层的最大池化引入'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 180}, page_content='10.7.笔记 165\\n了一种新方法，该方法基于组成元素的概率分布进行采样，而不是总是选择最大值。\\n自适应内核： Inception 模块（Szegedy等人，2017）并行使用不同尺寸的卷积滤波\\n器，从而为网络提供了一种粗略机制，以学习适当的滤波器尺寸。其他研究探讨了在训\\n练过程中学习卷积尺度（例如， Pintea等人，2021；Romero等人，2021）或下采样层步\\n长（Riad等人，2022） 。\\n在某些系统中，根据数据自适应改变内核尺寸。这有时发生在引导卷积的上下文中，\\n其中一个输入用于辅助另一个输入的计算。例如， RGB图像可能用于帮助上采样低分\\n辨率深度图。 Jia等人(2016)直接预测了滤波器权重，利用不同的网络分支。 Xiong等\\n人(2020b)自适应改变内核尺寸。 Su等人(2019a)通过从另一模态学习的函数来调节固\\n定内核的权重。 Dai等人(2017)学习权重偏移，以便它们可以非规则地应用。\\n对象检测和语义分割：对象检测方法可分为基于提案和无提案两种方案。在基于提\\n案的方案中，处理分为两个阶段：卷积网络先处理整个图像，提出可能包含对象的区\\n域；然后，这些提议区域被调整大小，另一个网络对其进行分析，以确定是否存在对象\\n及其种类。这种方法的早期示例是 R-CNN（Girshick 等人，2014） ，后续通过端到端训\\n练（Girshick, 2015 ）和减少区域提案成本（ Ren等人，2015）进行了扩展。后续关于特\\n征金字塔网络的研究通过结合不同尺度的特征来提高了性能和速度（ Lin等人，2017b） 。\\n相反，无提案方案在单次处理中完成所有任务。 YOLO（Redmon 等人，2016）是无提\\n案方案最著名的示例，编写本文时的最新版本是 YOLOv7 （Wang等人，2022a） 。关于\\n对象检测的最新综述可在 Zou等人(2023)中找到。\\nNoh等人(2015)开发的语义分割网络在第 10.5.3节中有描述。许多后续方法是\\nU-Net（Ronneberger 等人，2015）的变体，后者在第 11.5.3节中介绍。关于语义分割的\\n最新综述可在 Minaee等人(2021)和Ulku & Akagündüz (2022) 中找到。\\n可视化卷积网络：卷积网络的巨大成功促使研究人员尝试以多种方式可视化它们从'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 180}, page_content='最新综述可在 Minaee等人(2021)和Ulku & Akagündüz (2022) 中找到。\\n可视化卷积网络：卷积网络的巨大成功促使研究人员尝试以多种方式可视化它们从\\n图像中提取的信息（参见 Qin等人，2018的回顾） 。 Erhan等人(2009)通过从包含噪声\\n的图像出发，优化输入以使隐藏单元最活跃，使用梯度上升法可视化激活隐藏单元的最\\n佳刺激。 Zeiler & Fergus (2014) 训练了一个网络来重构输入，然后除了他们感兴趣的那\\n个以外，将所有隐藏单元置零；重构结果提供了有关驱动隐藏单元的信息。 Mahendran\\n& Vedaldi (2015) 可视化了网络的一个完整层。他们的网络反转技术旨在找到导致该层\\n活动的图像，同时包含了鼓励图像与自然图像具有相似统计特性的先验知识。\\n最后，Bau等人(2017)引入了网络解剖法。在这种方法中，一系列具有已知像素标\\n签的图像，涵盖颜色、纹理和对象类型，通过网络传递，然后测量隐藏单元与每个属性\\n的相关性。这种方法的优点是它仅使用网络的前向传播，不需进行优化。这些方法确实\\n提供了一些关于网络如何处理图像的初步见解。例如， Bau等人(2017)发现，较早的层\\n更多地与纹理和颜色相关，而较后的层与对象类型更为相关。然而，公平地说，目前还\\n不可能完全理解包含数百万参数的网络的处理机制。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 181}, page_content='166 CHAPTER 10. 卷积网络\\n10.8习题\\n问题10.1∗证明公式 10.3中的操作对平移具有等变性。\\n问题10.2公式10.3定义了一种核尺寸为 3、步长为 1且膨胀系数为 1的一维卷积。\\n请基于图 10.3a–b，写出核尺寸为 3但步长为 2的一维卷积的等效公式。\\n问题10.3根据图10.3d，写出核尺寸为 3且膨胀系数为 2的一维膨胀卷积的公式。\\n问题10.4写出一个核尺寸为 7、膨胀系数为 3且步长为 3的一维卷积公式。\\n问题10.5按照图10.4d的样式，为下列卷积绘制权重矩阵： (i)图10.3a–b中的跨\\n步卷积； (ii)图10.3c中的核尺寸为 5的卷积； (iii)图10.3d中的膨胀卷积。\\n问题10.6∗按照图10.4d的样式，绘制一个 6×12的权重矩阵，表示输入 x1, ..., x6\\n与输出h1, ..., h12 在图10.5a–b描述的多通道卷积之间的关系。 问题 10.7∗按照图10.4d\\n的样式，绘制一个 12×6的权重矩阵，表示输入 h1, ..., h12 与输出h′1,...,h′6在图10.5c\\n中的多通道卷积之间的关系。\\n问题10.8考虑一个输入有三个通道的一维卷积网络。第一隐藏层使用三个核尺寸\\n并有四个通道。第二隐藏层使用五个核尺寸并有十个通道。询问：这两个卷积层分别需\\n要多少偏置和权重？\\n问题10.9一个网络包含三个一维卷积层，每层使用核尺寸为 3、步长为 1且膨胀系\\n数为1的零填充卷积。第三层隐藏单元的感受野大小是多少？\\n问题10.10一个网络包含三个一维卷积层，每层使用核尺寸为 7、步长为 1且膨胀\\n系数为1的零填充卷积。第三层隐藏单元的感受野大小是多少？\\n问题10.11考虑一个一维输入 x的卷积网络。第一隐藏层 H1通过核尺寸为 5、步\\n长为2且膨胀系数为 1的卷积计算得到。第二隐藏层 H2通过核尺寸为 3、步长为 1且\\n膨胀系数为 1的卷积计算得到。第三隐藏层 H3通过核尺寸为 5、步长为 1且膨胀系数\\n为2的卷积计算得到。每个隐藏层的感受野大小分别是多少？\\n问题10.12在图10.7描述的一维卷积网络，通过使用 0.01的学习率和 100的批量\\n大小，在包含 4000个样本的训练集上训练了 100000步。这个网络训练了多少个周期？'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 181}, page_content='问题10.12在图10.7描述的一维卷积网络，通过使用 0.01的学习率和 100的批量\\n大小，在包含 4000个样本的训练集上训练了 100000步。这个网络训练了多少个周期？\\n问题10.13按照图10.4d的样式绘制一个权重矩阵，展示图 10.9中的24个输入与\\n24个输出之间的关系。\\n问题10.14考虑一个核尺寸为 5×5，接收3个输入通道并输出 10个输出通道的二\\n维卷积层。有多少卷积权重和偏置？\\n问题10.15按照图10.4d的样式绘制一个权重矩阵，采样一维输入中的每两个变量\\n之一（即图 10.11a的一维对应物） 。展示核尺寸和步长均为 2的一维卷积的权重矩阵等\\n效于组合核尺寸为 1的一维卷积和此采样矩阵的矩阵。\\n问题10.16∗考虑AlexNet 网络（图 10.16） 。每个卷积层和全连接层使用了多少参\\n数？总共使用了多少参数？\\n问题10.17在AlexNet（图10.16）的前三层中，每层的感受野大小是多少？\\n问题10.18在VGG架构（图 10.17）中，每个卷积层和全连接层分别有多少权重和'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 182}, page_content='10.8.习题 167\\n偏置？\\n问题10.19∗考虑通过一个 3×3卷积层相连的两个隐藏层，大小分别为 224×224，\\n通道数分别为 C1和C2。描述如何使用 He初始化方法来初始化权重。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 183}, page_content='168 CHAPTER 10. 卷积网络'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 184}, page_content='Chapter 11\\n残差网络\\n上一章节阐述了随着卷积网络从八层（ AlexNet）增加到十八层（ VGG）而带来的\\n图像分类性能的显著提升。这一发现激发了对更深层网络的探索。然而，随着层数的继\\n续增加，网络性能反而开始下降。\\n本章将介绍残差块的概念。在残差网络中，每一层不是直接对输入进行转换，而是\\n计算一个加性的变更，即残差，以此修改当前的数据表示。这种设计使得我们能够训练\\n更深的网络，但同时也会在初始化阶段造成激活值的指数级增加。为了解决这一问题，\\n残差块采用了批量归一化技术，在每一层对激活值进行重新中心化和缩放处理。\\n引入批量归一化的残差块使得训练深层网络成为可能，并且这样的网络在多种任务\\n上都实现了性能的提升。本章还将介绍如何将残差块组合应用于图像分类、医学图像分\\n割和人体姿态估计等问题的架构设计。\\n11.1顺序处理\\n到目前为止，我们接触到的所有网络都采用顺序处理数据的方式；即每一层处理完\\n数据后，就将其结果传递给下一层（见图 11.1） 。比如说，一个三层网络的定义可以是\\n这样的：\\nh1=f1[x,ϕ 1]\\nh2=f2[h1,ϕ2]\\nh3=f3[h2,ϕ3]\\ny=f4[h3,ϕ4] (11.1)\\n这里的h1,h2,和h3代表中间的隐藏层， x为网络的输入， y为输出， 而函数 fk[·,ϕk]\\n负责执行相应的处理流程。\\n在标准的神经网络中，每一层都由线性变换和随后的激活函数构成，其中参数 ϕk\\n包含了线性变换的权重和偏差。对于卷积网络而言，每一层则由一系列的卷积操作和激\\n169'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 185}, page_content='170 CHAPTER 11. 残差网络\\n图 11.1:图 11.1顺序处理。标准神经网络把每一层的输出直接传递到下一层。\\n活函数构成，其参数则涵盖了卷积核和偏差。\\n考虑到数据处理的顺序性，我们也可以将该网络视为一系列嵌套函数的形式来理\\n解：\\ny=f4[f3[f2[f1[x,ϕ 1],ϕ2],ϕ3],ϕ4]. (11.2)\\n11.1.1 顺序处理方式的限制\\n理论上，我们能够向网络中添加任意数量的层。正如前一章所示，为卷积网络增添\\n更多层确实能提升性能；例如，拥有十八层的 VGG网络（参见图 10.17）就超过了八层\\n的AlexNet（参见图 10.16）的表现。然而，当继续增加层次时，图像分类的性能又一次\\n出现下降（参见图 11.2） 。这一现象颇为意外，因为一般而言，增加模型的容量会提升\\n其性能（参见图 8.10） 。更值得注意的是，这种性能下降不仅在训练集上出现，也在测\\n试集上观察到，这表明问题在于训练更深网络的难度，而非这些深层网络的泛化能力。\\n图 11.2:增加卷积层导致性能下降。 a)在 CIF AR-10 数据集 (Krizhevsky & Hinton, 2009) 的\\n测试集上，一个 20层的卷积网络在图像分类任务中胜过了一个 56层的神经网络。 b)对于训练\\n集同样如此，这暗示了问题主要在于训练原始网络，而非泛化到新数据上的失败。根据 He等人\\n(2016a)的研究改编。\\n对于这一现象，我们还没有完全理解其原因。一种推测是，初始化时，如果我们改\\n变早期网络层中的参数，损失梯度会发生不可预测的变化。通过适当初始化权重（参考\\n第7.5节） ，这些参数相对于损失的梯度应当是合理的，避免了梯度爆炸或消失的问题。\\n然而，导数是基于参数的无限小变化，而优化算法实际上使用有限的步长。任何合理的\\n步长选择都可能跳到一个完全不同、与原点梯度无关的位置上；损失表面更像是布满了\\n无数微小山峰的广阔山脉，而不是一个易于下降的光滑结构。因此，优化算法无法像在\\n梯度变化较慢时那样取得进展。\\n通过观察单输入单输出网络中的梯度，可以支持这种假设。对浅层网络而言，随着\\n输入的变化，输出相对于输入的梯度变化得很慢（参见图 11.3a） 。但对于深层网络，输\\n入的微小改变就能导致一个截然不同的梯度（参见图 11.3b） 。这一现象通过梯度的自相'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 186}, page_content='11.2.残差连接与残差块 171\\n关函数得到了展示（参见图 11.3c） 。在浅层网络中，相邻的梯度是相关的，但在深层网\\n络中，这种相关性很快降至零，这就是所谓的“碎片化梯度”现象。\\n图 11.3:碎裂梯度。 a)假设一个浅层网络，有 200个隐藏单元，采用 Glorot初始化（去除二\\n倍因子的 He初始化）对权重和偏置进行初始化。随着输入 x的变化，标量网络输出 y对输入\\nx的梯度 ∂y/∂x变化较慢。 b)对于一个深度网络，包含 24层和每层 200个隐藏单元，这个梯\\n度变化得非常快且不可预测。 c)梯度的自相关函数表明，在深层网络中，相邻的梯度变得不相\\n关（自相关接近零） 。这种碎裂梯度现象或许可以解释为什么深度网络难以训练。梯度下降算法\\n依赖于相对平滑的损失表面，因此更新前后的梯度应当是相关的。根据 Balduzzi 等人 (2017)的\\n研究改编。\\n碎片化梯度的出现，可能是因为随着网络加深，早期网络层的变动以越来越复杂的\\n方式影响输出。网络的第一层 f1对输出y的导数如下 11.1所示：\\n∂y\\n∂f1=∂f4\\n∂f3∂f3\\n∂f2∂f2\\n∂f1. (11.3)\\n当改变决定 f1的参数时，这一系列的导数都可能发生变化，因为 f2,f3,和f4层是\\n基于f1计算的。因此，每个训练样例更新的梯度可能完全不同，导致损失函数的行为\\n变得异常。 （在公式 11.3和11.6中，我们用符号 fk来指代函数 fk[•]的输出。 ）\\n11.2残差连接与残差块\\n残差连接或跳过连接是一种特殊的网络架构，它允许每一层的输入直接加到其输出\\n上（见图 11.4a） 。按照前文提到的原理，残差网络的结构可以定义如下：\\nh1=x+f1[x,ϕ 1]\\nh2=h1+f2[h1,ϕ2]\\nh3=h2+f3[h2,ϕ3]\\ny=h3+f4[h3,ϕ4], (11.4)\\n这里，每一行的右侧第一项即代表了残差连接。每个函数 fk负责学习到当前数据\\n表示的加性修改。因此，这些函数的输出尺寸必须与其输入一致。这种输入与经过处理\\n的输出的加和被称作一个残差块或残差层。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 187}, page_content='172 CHAPTER 11. 残差网络\\n图 11.4:残差连接。 a)对于每个函数 fk[x, ϕk ]，其输出与输入相加，通过一个称为残差或跳跃\\n连接的并行计算路径传递。因此，该函数计算的是对表示的加性变化。 b)当我们展开网络方程\\n时，发现输出实际上是输入加上四个小型网络（分别用白色、橙色、灰色和青色表示，对应于方\\n程 11.5中的项）的总和；这可以被视为是一个网络集群。此外，青色网络的输出本身是另一集\\n群中变换 f4[•, ϕ4]的结果，依此类推。我们还可以把这个网络看作是通过计算图的 16条不同\\n路径的组合。一个典型的例子是，无论是在面板 (a)还是 (b)，从输入 x到输出 y的虚线路径都\\n是相同的。\\n通过替换中间变量 hk的表达式，我们可以将整个过程表述为一个单一的函数：\\ny=x+f1[x] +f2[x+f1[x]] +f3[x+f1[x] +f2[x+f1[x]]]\\n+f4[x+f1[x] +f2[x+f1[x]] +f3[x+f1[x] +f2[x+f1[x]]]],(11.5)\\n这里我们为了表述的清晰，省略了参数 ϕ。可以把这个方程看作是对网络的“展\\n开” （见图 11.4b） 。可以发现，最终的网络输出实际上是输入加上四个小型网络的和，这\\n些小型网络对应于方程的每一行；换句话说，残差连接将原网络转化成了这些小网络的\\n集合，它们的输出相加得到最终结果。\\n另一种理解残差网络的方式是，它创造了从输入到输出的十六条不同长度的路径。\\n例如，第一个函数 f1[x]出现在这十六条路径中的八条路径上，包括作为直接的加性项\\n（即，路径长度为一） 。相似地，对于公式 11.3的导数是：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 188}, page_content='11.2.残差连接与残差块 173\\n∂y\\n∂f1= 1 +∂f2\\n∂f1+\\x12∂f3\\n∂f1∂f2\\n∂f1\\x13\\n+\\x12∂f4\\n∂f1∂f2\\n∂f1∂f3\\n∂f1∂f2\\n∂f1\\x13\\n, (11.6)\\n其中每条路径都对应一个项。右手边的恒等项说明了第一层 f1[x,ϕ 1]中参数ϕ1的\\n改变如何直接影响到网络输出 y的变化。它们也通过不同长度的其他导数链间接影响输\\n出。通常，通过较短路径的梯度会更为稳定。因为恒等项和各种短链导数都会对每层的\\n导数贡献，含有残差连接的网络在面对碎片化梯度时表现得更好。\\n11.2.1 残差块中的操作顺序\\n到目前为止，我们提到加性函数 f[x]可以是任何类型的网络层，比如全连接层或卷\\n积层。这种说法技术上没有问题，但需要注意的是，这些函数中的操作顺序至关重要。\\n它们必须嵌入一个如 ReLU这样的非线性激活函数，否则整个网络就会退化成一个线性\\n模型。但在典型的网络层中（如图 11.5a所示） ，ReLU函数通常位于最末端，因此输出\\n会被限制为非负值。如果遵循这种设计，那么每个残差块只能使输入值增大。\\n因此，常见的做法是调整操作的顺序，先进行激活函数操作，再进行线性变换（如\\n图11.5b所示） 。有时候，在一个残差块内部可能包含多个处理层（如图 11.5c所示） ，但\\n这些通常以一个线性变换结束。值得一提的是，如果以 ReLU操作开始这些块，而初始\\n网络输入为负值，那么这些块将不执行任何操作，因为 ReLU会将所有信号截断为零。\\n因此，通常网络会以一个线性变换开始，而不是一个残差块，正如图 11.5b中所示。\\n图 11.5:残差块的运算顺序。 a)通常线性变换或卷积之后接 ReLU非线性运算，这样的顺序使\\n得每个残差块只能增加非负数值。 b)若采用反向顺序，则可以增加正数或负数。但如果初始输\\n入全为负值，那么在网络开始时就必须加入一个线性变换。 c)实际应用中，一个残差块包含多\\n个网络层是很普遍的情况。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 189}, page_content='174 CHAPTER 11. 残差网络\\n11.2.2 采用残差连接的更深网络\\n引入残差连接可以大致加倍实际能够训练的网络深度，直到出现性能下降。然而，\\n我们希望能进一步加深网络层次。要理解为什么残差连接不能让我们随意增加网络深\\n度，我们需要考虑到在前向传播过程中激活值的方差如何变化，以及在反向传播过程中\\n梯度大小如何变化。\\n11.3残差网络的梯度爆炸问题\\n在之前7.5的讨论中，我们了解到正确初始化网络参数至关重要。如果初始化不当，\\n那么在反向传播过程的前向传播阶段，网络内部值的幅度可能会指数级地增加或减少。\\n同理，在网络的反向传播过程中，梯度也可能随着网络层的增加而爆炸或消失。\\n因此，我们通过初始化网络参数来确保各层间激活值的预期方差（在前向传播中）\\n和梯度的预期方差（在反向传播中）保持不变。通过使用 He初始化（参见第 7.5节） ，\\n我们可以实现这一目标，对于 ReLU激活函数， He初始化方法是将偏置 β设置为零，\\n并选择均值为零且方差为 2/Dh的正态分布权重 Ω，其中Dh代表前一层的隐藏单元数\\n目。\\n但当我们考虑残差网络时，由于存在直接贡献到网络输出的路径（参见方程 11.5和\\n图11.4b） ，我们不必担心网络深度导致的中间值或梯度消失问题。然而，即使在残差块\\n内部使用了 He初始化，随着网络层次的加深，在前向传播过程中的值依然会指数级增\\n加。\\n这是因为我们将残差块的处理结果加回到输入上。每个分支都带有一定的（不相关\\n的）变异性。因此， 当我们将它们重新结合时， 总体方差就会增加。尽管使用 ReLU激活\\n和He初始化时，每个块的处理不会改变预期的方差，但与输入结合时方差会翻倍（如\\n图11.6a所示） ，并且随着残差块的增加而指数级增长。这限制了网络能增加的深度，以\\n防在前向传播中超出浮点数的精度范围。反向传播过程中梯度的论证也是相似的。\\n因此，即便采用了 He初始化，残差网络仍面临前向传播不稳定和梯度爆炸的问题。\\n一个可能的解决方案是使用 He初始化，然后通过将每个残差块的合并输出乘以 1/√\\n2\\n来补偿翻倍效应（如图 11.6b所示） 。不过，更常见的做法是应用批量归一化来解决这\\n一问题。\\n11.4批量归一化\\n批量归一化（ BatchNorm ）通过调整和缩放每个激活值 h，使其在批次 B中的均值'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 189}, page_content='一问题。\\n11.4批量归一化\\n批量归一化（ BatchNorm ）通过调整和缩放每个激活值 h，使其在批次 B中的均值\\n和方差转变为训练期间学习到的值。首先，计算出激活值的经验均值 mh和标准偏差 sh：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 190}, page_content='11.4.批量归一化 175\\n图 11.6:残差网络的方差变化。 a) He初始化保证了经过一个线性加 ReLU层的 fk之后，预期\\n的方差保持不变。不过，在残差网络中，每个块的输入都会加回到输出中，导致每层的方差翻\\n倍（灰色数字表示方差）并且以指数方式增加。 b)一种解决方法是在每个残差块之间通过因子\\n1/√2对信号进行重新缩放。 c)另一种方法是在残差块的起始使用批量归一化（ BN） ，并将关联\\n的偏移 δ初始化为零，缩放因子 γ初始化为一。这确保了每层输入的方差为一，结合 He初始\\n化，输出的方差也将为一。现在，方差随残差块数量线性增长。一个副作用是，初始化时，后面\\n层的网络主要由残差连接支配，因此几乎等同于执行恒等变换。\\nmh=1\\n|B|X\\ni∈Bhi\\nsh=s\\n1\\n|B|X\\ni∈B(hi−mh)2 (11.7)\\n这里，所有的数值均为标量。接着，利用这些统计数据将批次中的激活值标准化，\\n使其均值为零，方差为一：\\nˆhi←hi−mh\\nsh+ϵ∀i∈B (11.8)\\n其中，ϵ是一个很小的数值，用来避免在所有批次成员的 hi值相同时sh= 0导致\\n的除零错误。\\n最终，通过 γ缩放并加上 δ来调整归一化变量：\\nˆhi←γˆhi+δ∀i∈B (11.9)\\n经过这一过程，激活值在批次所有成员中的平均值变为 δ，标准偏差变为 γ。这两个参\\n数均在训练过程中学习得到。\\n批量归一化分别对每个隐藏单元进行独立应用。在一个具有 K层、每层含 D个隐\\n藏单元的标准神经网络中，会有 KD个学习到的偏移量 δ和KD个学习到的缩放因子\\nγ。在卷积网络中，归一化的统计量是在批次和空间位置两个维度上计算的。若网络由\\nK层组成，每层包含 C个通道，则会有 KC个偏移量和 KC个缩放因子。在测试阶段，\\n由于缺乏可以用来收集统计数据的批次，解决方案是在整个训练数据集上计算 mh和sh\\n的统计量（而非仅在一个批次中） ，并在最终网络中将其固定。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 191}, page_content='176 CHAPTER 11. 残差网络\\n11.4.1 批量归一化的代价与好处\\n批量归一化（ BatchNorm ）让网络对每个激活函数贡献的权重和偏置的缩放不敏感；\\n当这些参数翻倍时，激活值也会翻倍，估计的标准偏差 sh同样翻倍，公式中的归一化\\n操作会对这些变化进行调整。这一过程在每个隐藏单元中独立进行。因此，存在许多不\\n同的权重和偏置组合，它们能产生相同的效果。批量归一化还在每个隐藏单元引入了两\\n个参数，γ和δ，从而稍微增加了模型的大小。这既在权重参数中引入了冗余，也添加\\n了额外的参数来补偿这种冗余，虽然这看起来效率不高，但批量归一化也带来了几个明\\n显的好处。\\n稳定的前向传播 ：通过将偏移量 δ初始化为零，缩放因子 γ初始化为一，我们可以\\n确保每个输出激活值具有单位方差。在传统网络中，这保证了在初始化时前向传播的方\\n差是稳定的。在残差网络中，尽管我们在每层向输入添加新的变异源，导致方差必须增\\n加，但它会随着每个残差块线性增加；第 k层为现有的方差 k增加一个单位的方差（图\\n11.6c） 。\\n初始化时，这意味着后续层对总变异的贡献小于前面的层。实际上，由于后续层接\\n近于执行恒等运算，训练初期网络相对较浅。随着训练的深入，网络可以在后续层增加\\n缩放因子γ，从而控制自身的有效深度。\\n更高的学习率 ：经验研究和理论均表明，批量归一化让损失表面及其梯度变得更加\\n平滑（即，减少了梯度碎片化现象） ，这意味着由于表面变得更可预测，我们能够使用更\\n高的学习率。正如第 9.2节所述，更高的学习率能够提升测试性能。\\n正则化：正如第 9章所示，向训练过程中引入噪声能够提升泛化能力。批量归一化\\n通过依赖批量统计的归一化引入了噪声。对于给定的训练样本，其激活值根据批次中其\\n他成员的不同而进行归一化，因此在每次训练迭代中都会略有不同。\\n11.5常用残差架构\\n深度学习流程现在标配残差连接。本节将介绍一些融合了残差连接的知名架构。\\n11.5.1 ResNet （残差网络）\\n残差块最初用于图像分类的卷积网络，由此诞生的网络被称为残差网络（ ResNets） 。\\n在ResNets 中，每个残差块都包含一次批量归一化操作、一个 ReLU激活函数以及一个\\n卷积层。之后再重复相同的操作序列，最终将结果加回到输入（图 11.7a） 。实践证明，\\n这种操作顺序非常适合图像分类任务。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 191}, page_content='卷积层。之后再重复相同的操作序列，最终将结果加回到输入（图 11.7a） 。实践证明，\\n这种操作顺序非常适合图像分类任务。\\n对于极深的网络，参数数量可能过大。瓶颈残差块通过三个卷积来更高效地使用参\\n数。首先是一个 1×1卷积核减少通道数，接着是一个常规 3×3卷积核，最后再通过另\\n一个1×1卷积核将通道数恢复（图 11.7b） 。这样一来，可以使用更少的参数在 3×3的\\n像素区域内整合信息。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 192}, page_content='11.5.常用残差架构 177\\n图 11.7: ResNet 块。 a) ResNet 架构中的标准块包括一个批量归一化操作，接着是一个激活函\\n数和一个 3×3卷积层，这个过程会重复一次。 b)瓶颈 ResNet块虽然仍然处理 3×3的区域，但\\n使用的参数更少。它由三步卷积构成：首先，一个 1×1卷积减少通道数；其次，一个 3×3卷积\\n作用于这个缩小了的表示；最后，另一个 1×1卷积将通道数增加，以便将结果加回到输入中。\\nResNet-200 模型（图 11.8）含有200层，用于在 ImageNet 数据库上进行图像分\\n类（图10.15） 。这个架构与 AlexNet 和VGG类似，但采用的是瓶颈残差块而非普通卷\\n积层。与 AlexNet 和VGG相似，这些层周期性地交替减少空间分辨率并同时增加通道\\n数。这里，分辨率通过步长为二的卷积进行下采样来降低。通道数的增加要么通过向表\\n示添加零，要么通过额外的 1×1卷积实现。网络的起始是一个 7×7卷积层，随后是下\\n采样操作。最终，一个全连接层将输出映射到一个长度为 1000的向量上。这一向量通\\n过softmax层生成类别概率。\\nResNet-200 模型取得了 4.8%的前五错误率和 20.1%的正确分类错误率， 与 AlexNet\\n（16.4%，38.1%）和VGG（6.8%，23.7%）相比表现突出，成为最早超越人类表现（前\\n五猜中有 5.1%）的网络之一。然而，该模型诞生于 2016年，已不是最先进的。截至撰\\n写时，最佳模型在此任务上的错误率为 9.0%（见图10.21） 。当前所有顶尖的图像分类\\n模型都基于 Transformer 技术（见第 12章） 。\\n图 11.8: ResNet-200 模型。首先应用一个步长为 2的标准 7×7卷积层， 接着是一个 MaxPool 操\\n作。然后是一系列瓶颈残差块（括号内数字表示第一个 1×1卷积后的通道数） ，伴随周期性的下\\n采样和通道数的增加。网络最终通过在所有空间位置进行平均池化，以及一个映射到预 softmax\\n激活的全连接层来结束。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 193}, page_content='178 CHAPTER 11. 残差网络\\n11.5.2 DenseNet （密集网络）\\n残差块从前一层接收输出，通过若干网络层进行修改后，再将其加回到原始输入。\\n另一种方法是将修改后的信号和原始信号进行连接。这样会增加表示的大小（在卷积网\\n络中表现为通道数增加） ，但可以通过随后的线性变换（卷积网络中的 1×1卷积）将其\\n映射回原始大小。这允许模型以加法、加权和或更复杂的方式组合这些表示。\\nDenseNet 架构通过连接操作，让每层的输入包括所有前面层的输出（图 11.9） 。这\\n些输出经过处理生成新的表示，然后这个新的表示又会与之前的表示进行连接，并传递\\n给下一层。这种连接方式保证了早期层对输出的直接贡献，因此使得损失表面的行为更\\n为合理。\\n图 11.9: DenseNet 。这个架构通过残差连接把早期层级的输出与后期层级进行合并。举例来说，\\n一个三通道的输入图像经过处理后变成一个 32通道的表示。然后，这个输入图像会和之前的表\\n示合并，形成总共 35通道的表示。这个合并后的表示再次被处理，生成另一个 32通道的表示，\\n并将前面所有的表示合并至此，最终形成了 67通道的表示，如此循环往复。\\n实际应用中，由于通道数（以及相应的参数数）逐渐增大，这种方法只能在少数层\\n中维持。在应用下一个 3×3卷积之前， 使用 1×1卷积减少通道数可以缓解这一问题。在\\n卷积网络中，输入会定期下采样。由于表示大小不同，跨下采样连接变得不切实际，因\\n此在这一点上连接链会中断，一个较小的表示开始新的连接链。此外，下采样时还可以\\n应用另一个瓶颈 1×1卷积，以进一步控制表示大小。\\n与ResNet模型相比，这个网络在图像分类任务上表现出竞争力（见图 10.21） ，实\\n际上在相似的参数数量下，它的表现可能更佳。这可能是因为它能更灵活地重用早期层\\n的处理。\\n11.5.3 U-Net 和沙漏型网络\\n第10.5.3节介绍了一个具备编码器 -解码器或沙漏结构的语义分割网络。该网络通\\n过重复下采样图像，扩大感受野并整合图像全域信息。随后，解码器将图像上采样至原\\n始尺寸。最终输出为每个像素点可能的对象类别的概率分布。该架构的一个局限是，网\\n络中间的低分辨率表示需要“记住”高分辨率细节以确保最终结果的准确性。若残差连\\n接能将编码器的表示传递给解码器的对应部分，则无需“记忆”这些细节。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 193}, page_content='络中间的低分辨率表示需要“记住”高分辨率细节以确保最终结果的准确性。若残差连\\n接能将编码器的表示传递给解码器的对应部分，则无需“记忆”这些细节。\\nU-Net（图11.10）采用编码器 -解码器架构，早期的表示被连接到后期的表示中。最\\n初的实现采用了“有效”卷积，导致每应用一次 3×3卷积层，空间尺寸便减少两个像\\n素。这导致上采样版本比编码器中的对应部分小，因此在连接前需进行裁剪。后续实现'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 194}, page_content='11.6.残差连接网络性能优异的原因是什么？ 179\\n采用零填充，避免了裁剪的需要。值得注意的是， U-Net完全基于卷积，训练后可应用\\n于任意尺寸的图像。\\n图 11.10:分割 HeLa细胞的 U-Net。U-Net采用了编解码器架构， 其中表示先是通过下采样（橙\\n色块表示）减少细节，再通过上采样（蓝色块表示）恢复细节。编码部分使用标准的卷积操作，\\n而解码部分则采用转置卷积。残差连接将编码器中每个规模的最后一层输出与解码器中相同规\\n模的第一层输入相连（通过橙色箭头表示） 。原版 U-Net采用了边界明确的卷积方式，使得即便\\n不进行下采样，每层的尺寸也会略微减小。因此，在将编码器的输出附加到解码器之前需要对其\\n进行裁剪（以虚线方框表示） 。根据 Ronneberger 等人 (2015)改编。\\nU-Net设计用于医学图像的分割（图 11.11） ，但也广泛应用于计算机图形和视觉领\\n域。沙漏网络与之相似，但在跳过连接中加入了更多卷积层，并将结果加入解码器中而\\n非简单连接。一系列这样的模型构成了堆叠沙漏网络，它在处理图像的局部与全局信息\\n间交替。这类网络被用于姿态估计（图 11.12） ，系统通过预测每个关节的“热图” ，并\\n将热图上的最大值定位为估计的位置。\\n图 11.11:在 3D中使用 U-Net进行分割。 a)三个切片穿过通过扫描电子显微镜获取的小鼠大\\n脑皮层的 3D体积图。 b)一个 U-Net被用来判断体素是处于神经纤维内部还是外部，通过不同\\n的颜色标出连接的区域。 c)为了得到更好的结果，训练了一个由五个 U-Net组成的集成模型，\\n只有当所有五个网络一致判断时，体素才被认定为细胞的一部分。根据 F alk等人 (2019)改编。\\n11.6残差连接网络性能优异的原因是什么？\\n残差网络使得训练极深网络成为可能； ResNet架构可以扩展到 1000层，仍能有效\\n训练。图像分类性能的提升最初被认为是由于网络深度的增加，但两个观点对此提出了'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 195}, page_content='180 CHAPTER 11. 残差网络\\n图 11.12:用于姿态估计的堆叠沙漏网络。 a)网络的输入是包含一个人的图像，输出是为每个关\\n节生成的一系列热图。这个过程被定义为一个回归问题，目标是生成突出真实关节位置的小区域\\n的热图。估算的热图峰值被用来确定每个关节的最终位置。 b)架构包括最初的卷积和残差层，随\\n后是一系列沙漏形状的块。 c)每个沙漏块都包含了一个与 U-Net相似的编解码网络，不同之处\\n在于卷积采用零填充，残差链接中加入了额外的处理，并且这些处理后的表示被加入而非连接。\\n每个蓝色的长方体块实际上是一个瓶颈残差块（参见图 11.7b） 。根据 Newel l等人 (2016)的研\\n究改编。\\n质疑。\\n首先，参数数量相近时，较浅但更宽的残差网络有时能超过更深但更窄的网络。换\\n言之，通过减少层次而增加每层的通道数，有时能够获得更优的性能。其次，证据显示，\\n在解开的网络中，训练过程中的梯度并不能有效地通过极长的路径传播（图 11.4b） 。实\\n质上，非常深的网络可能更像是多个浅层网络的组合。\\n当前的看法是，残差连接不仅为自身增添了价值，也使得训练更深的网络成为可能。\\n这一观点由一个事实支持：残差网络在最小值周围的损失表面，相较于去除跳跃连接的\\n同一网络，倾向于更平滑、更可预测（图 11.13） 。这或许使得学习一个具有良好泛化能\\n力的优秀解决方案变得更易于实现。\\n11.7总结\\n不断增加网络深度会导致图像分类的训练与测试性能降低。这可能是由于在网络早\\n期阶段，参数相对更新步长的损失梯度变化快速且难以预测。残差连接的策略是将处理\\n后的输出加回到输入。现在，每一层都直接及间接地对输出做出贡献，使得不必强制要\\n求梯度通过众多层次传播，从而使损失表面变得更为平滑。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 196}, page_content='11.7.总结 181\\n图 11.13:神经网络损失表面的可视化。每张图展示了 SGD在 CIF AR-10 数据集上的图像分类\\n任务中找到的最小值周围参数空间内两个随机方向上的损失表面。为了便于比较，这些方向进\\n行了规范化处理。 a)一个有 56层的残差网络。 b)同一网络但去除了跳过连接的结果显示，加\\n入跳过连接后的表面更为平滑。这样不仅促进了学习过程，还使得网络性能对参数中的轻微错\\n误更加鲁棒，从而可能更好地泛化。根据 Li等人 (2018b)的研究改编。\\n图 11.14:不同的归一化策略。 BatchNorm 分别对每个通道进行修改，但基于整个批次和空间\\n位置收集的统计信息以相同的方式调整批次中的每个样本。 Ghost BatchNorm 通过只使用批次\\n的一部分来计算这些统计数据，使得结果更具变异性。 LayerNorm 对每个批次成员分别计算统\\n计数据，这些数据是基于通道和空间位置收集的。它为每个通道保留一个单独的学习缩放因子。\\nGroupNorm 在每组通道内进行归一化， 并为每个通道保留独立的缩放和偏移参数。 InstanceNorm\\n单独对每个通道进行归一化，仅根据空间位置来计算统计数据。根据 W u & He (2018) 的研究\\n改编。\\n残差网络虽然避免了梯度消失问题，但却引入了前向传播过程中激活值方差指数增\\n加的问题，以及相应的梯度爆炸问题。通常情况下，这通过添加批量归一化来解决，它\\n对批次的经验均值和方差进行调整，然后利用学到的参数进行移位和缩放。如果这些参\\n数初始化得当，即可训练极深的网络。残差连接和批量归一化都被证明能使损失表面更\\n加平滑，从而允许采用更大的学习率。此外，批次统计的变异为模型增加了一种正则化\\n手段。\\n残差块已经被整合进卷积网络中，使得可以训练更深的网络并相应提升图像分类性\\n能。残差网络的变体包括 DenseNet 架构，它通过连接所有之前层的输出来作为当前层\\n的输入，并且 U-Net，它将残差连接整合到编码器 -解码器模型中。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 197}, page_content='182 CHAPTER 11. 残差网络\\n11.8笔记\\n残差连接由 He等人于2016年引入，他们构建了一个 152层的网络，是 VGG的八\\n倍大小（图 10.17） ，并在 ImageNet 分类任务上取得了当时的最佳性能。每个残差块包\\n括一个卷积层、批量归一化、 ReLU激活函数、第二个卷积层和第二次批量归一化。在\\n这个块加回主表示后，应用了第二个 ReLU函数。这种架构被命名为 ResNet v1 。He等\\n人（2016b）探索了残差架构的不同变体，包括沿跳跃连接应用处理和两个分支重组后\\n应用处理的方式。他们最终得出结论认为这两种方式都不是必需的，从而形成了图 11.7\\n所示的架构，有时被称为预激活残差块，是 ResNet v2 的核心。他们训练了一个 200层\\n的网络，在 ImageNet 分类任务上取得了进一步改进（见图 11.8） 。自那以后，出现了新\\n的正则化、优化和数据增强方法， Wightman 等人（2021）利用这些方法为 ResNet架\\n构展示了一个更现代的训练流程。\\n残差连接为何有益：残差网络确实允许训练更深的网络。这可能与训练初期减少碎\\n裂梯度（ Balduzzi 等人，2017）和图11.13所示（Li等人，2018b）的最小值附近损失\\n表面更平滑有关。仅残差连接（即无批量归一化）大约将网络的可训练深度增加了两倍\\n（Sankararaman 等人，2020） 。有了批量归一化，可以训练非常深的网络，但深度对性能\\n的关键性还不明确。 Zagoruyko 和Komodakis （2016）展示了仅有 16层的宽残差网络\\n在图像分类上超过了当时所有的残差网络。 Orhan和Pitkow（2017）提出残差连接改善\\n学习的不同解释，即消除了奇点（损失表面上 Hessian退化的地方） 。\\n相关架构：残差连接是高速网络（ Srivastava 等人，2015）的特例，后者也将计算分\\n成两个分支并加性重组。高速网络采用依赖数据本身的门控函数加权两个分支的输入，\\n而残差网络则直接将数据沿两个分支传递。 Xie等人（2017）引入了 ResNeXt 架构，在\\n多个并行卷积分支周围放置残差连接。\\n残差网络作为集成： Veit等人（2016）将残差网络描述为较短网络的集成，并展示'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 197}, page_content='多个并行卷积分支周围放置残差连接。\\n残差网络作为集成： Veit等人（2016）将残差网络描述为较短网络的集成，并展示\\n了“解开的网络”解释（图 11.4b） 。他们通过证明在训练过的网络中删除层（即路径的\\n子集）只对性能产生轻微影响来支持这一解释。相比之下，在像 VGG这样的纯序列网\\n络中移除一层会导致灾难性的后果。他们还研究了不同长度路径上的梯度大小，并发现\\n在较长路径中梯度消失。在一个由 54个块组成的残差网络中，训练期间几乎所有的梯\\n度更新都来自于长度为 5到17个块的路径，尽管这些路径只占总路径的 0.45%。看来，\\n增加更多的块实际上是增加了更多的并行较短路径，而不是创造一个真正更深的网络。\\n残差网络的正则化：在没有批量归一化的普通网络和残差网络中， L2正则化权重\\n有着根本不同的效果。在前者中，它促进层的输出成为一个由偏置确定的常数函数。在\\n后者中，它促使残差块计算出一个恒等函数加上由偏置确定的常数。\\n针对残差架构，开发了几种专用的正则化方法。 ResDrop (Yamada et al., 2016) 、随\\n机深度(Huang et al., 2016) 和RandomDrop (Yamada et al., 2019) 通过在训练过程中随\\n机舍弃残差块来对残差网络进行正则化。特别是在 RandomDrop 中，决定舍弃块的概率\\n由一个伯努利随机变量决定，该变量的参数会在训练过程中线性递减。在测试阶段，这'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 198}, page_content='11.8.笔记 183\\n些残差块将根据其预期概率重新加入网络。这些方法本质上是 Dropout 的变体，其特点\\n是在一个块内同时丢弃所有隐藏单元。从残差网络的多路径视角（图 11.4b）看，这些方\\n法在每个训练步骤中实质上去除了某些路径。 Wu等人（2018b）提出了 BlockDrop ，该\\n方法通过分析现有网络，在运行时确定哪些残差块应被使用，以提高推断过程的效率。\\n针对残差块内含多路径的网络，也开发了其他正则化方法。 Shake-shake （Gastaldi,\\n2017a,b）在前向传播和反向传播过程中随机调整各路径的权重。在前向传播过程中，\\n这相当于生成随机数据；而在反向传播中，则像是向训练过程中注入了另一种噪声。\\nShakeDrop （Yamada et al., 2019 ）利用一个伯努利变量来决定在训练的每一步中，每个\\n块是应用 Shake-Shake 效果还是表现得像标准的残差单元。\\n批量归一化 ：批量归一化最初由 Ioffe & Szegedy （2015）在残差网络之外的背景中\\n引入。他们的实验证明，批量归一化能够支持更高的学习速率，加快收敛速度，并使得\\nsigmoid激活函数更加实用（由于控制了输出分布，样本较少落入 sigmoid函数的饱和\\n区域） 。Balduzzi 等人（2017）研究了在深度网络中使用 ReLU函数时，后续层隐藏单\\n元的激活情况。他们发现，在初始化时，很多隐藏单元不管输入如何都处于始终激活或\\n始终不激活的状态，而批量归一化显著减少了这种现象。\\n尽管批量归一化有助于网络中信号的稳定前向传播， Yang等人（2019）指出，在没\\n有跳跃连接的 ReLU网络中，它会引起梯度爆炸现象，其中每一层都会使梯度的幅度约\\n增加1.21倍。这一发现被 Luther（2020）总结。考虑到残差网络可以视为不同长度路\\n径的组合（图 11.4） ，这种效应也存在于残差网络中。不过，假设在网络的前向传递中\\n消除的2K倍增加的益处超过了在反向传递中使梯度增加 1.21K倍的弊端，因此，总体\\n而言，批量归一化使训练过程更加稳定。\\n批量标准化的变体 ：已提出几种批量标准化（ BatchNorm ）的变体（图 11.14）。\\nBatchNorm 基于整个批次的统计数据，分别对每个通道进行标准化。 GhostNorm （鬼批'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 198}, page_content='批量标准化的变体 ：已提出几种批量标准化（ BatchNorm ）的变体（图 11.14）。\\nBatchNorm 基于整个批次的统计数据，分别对每个通道进行标准化。 GhostNorm （鬼批\\n量标准化， Hoffer et al., 2017 ）仅使用批次的一部分来计算标准化统计，由此引入的统\\n计波动增大，从而在大批次情况下提高了正则化效果（图 11.14b） 。\\n在批次大小极小或批内波动极大的情况下（如自然语言处理中常见） ， BatchNorm\\n的统计可能不再可靠。 Ioffe (2017) 提出批重标准化，通过维护批统计的滑动平均，并调\\n整任何批次的标准化使其更具代表性。另一难题是，批量标准化不适用于循环神经网络\\n（处理序列的网络，其中先前的输出作为额外输入反馈进网络，详见图 12.19） 。此时，必\\n须记录序列每步的统计数据，而对于比训练序列长的测试序列如何处理则是一个未解之\\n谜。第三个挑战是，批量标准化需要访问整个批次的数据，这在分布式训练中可能不易\\n实现。\\nLayerNorm （层标准化， Ba et al., 2016 ）通过对每个样本单独标准化来避免使用批\\n次统计，使用跨通道和空间位置收集的统计数据（图 11.14c） 。但是，每个通道依然有独\\n立的学习比例 γ和偏移δ。GroupNorm （组标准化， Wu & He, 2018 ）与LayerNorm 类\\n似，但是它将通道分成若干组，分别计算每组内部的统计数据（图 11.14d） 。同样，每\\n个通道都有独立的比例和偏移参数。 InstanceNorm （实例标准化， Ulyanov et al., 2016 ）'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 199}, page_content='184 CHAPTER 11. 残差网络\\n进一步将每个通道单独标准化，只依据空间位置的统计数据（图 11.14e） 。Salimans &\\nKingma (2016) 探讨了标准化网络权重而非激活值的方法，尽管这种方法的实证成功较\\n少。Teye et al. (2018) 提出的蒙特卡洛批量标准化能够为神经网络预测的不确定性提供\\n有意义的估计。最近， Lubana et al. (2021) 对不同标准化方案的性质进行了比较研究。\\n批量标准化的优势 ：批量标准化能够在残差网络中控制初始梯度（图 11.6c） 。然而，\\n批量标准化改善性能的具体机制仍有待深入理解。 Ioffe和Szegedy（2015）初衷是减轻\\n内部协变量偏移所导致的问题，这种偏移指的是在反向传播期间更新前置层所引起的层\\n输入分布的变化。但 Santurkar 等人（2018）通过实验人为引入协变量偏移，发现无论\\n是否使用批量标准化，网络的表现均相似，从而对这种观点提出了质疑。\\n基于此，他们寻求了批量标准化改善性能的其他解释。实证研究显示，在 VGG网\\n络中加入批量标准化可减少在梯度方向上移动时损失及其梯度的波动。换言之，损失曲\\n面变得更平滑，变化速度更慢，这使得可以采用更高的学习率。他们还为这些现象提供\\n了理论证明，并表明对于任何参数初始化，使用批量标准化的网络到最近最优解的距离\\n都更短。 Bjorck等人（2018）也认为，批量标准化优化了损失曲面的特性，允许使用更\\n高的学习率。\\n批量标准化改善性能的其他原因包括降低了学习率调整的重要性（ Ioffe & Szegedy,\\n2015；Arora等人，2018） 。事实上， Li和Arora（2019）展示了在批量标准化的情况下，\\n可以使用指数级增长的学习率策略。这主要是因为批量标准化使网络对权重矩阵的尺度\\n变得不敏感（参见 Huszár, 2019 的直观可视化解释） 。\\nHoffer等人（2017）发现，批量标准化因批次随机组合产生的统计波动而具有正则\\n化作用。他们提出了使用“幽灵批次大小” （ ghost batch size ） ，即从批次的一个子集中\\n计算均值和标准差统计数据。如此，即使使用大批次也能保持小批次大小中额外噪声的\\n正则化效果。 Luo等人（2018）研究了批量标准化的正则化效应。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 199}, page_content='计算均值和标准差统计数据。如此，即使使用大批次也能保持小批次大小中额外噪声的\\n正则化效果。 Luo等人（2018）研究了批量标准化的正则化效应。\\n批量标准化的替代方法 ：虽然BatchNorm 得到了广泛应用，但它并非深度残差网\\n络训练的唯一选择；还有其他方法可以让损失曲面更易于处理。 Balduzzi 等人（2017）\\n建议通过p\\n1/2对输出进行重缩放（见图 11.6b） ，这样做虽可以避免梯度爆炸，但无法\\n解决梯度破碎问题。\\n有研究探讨了在残差块的输出加回输入前进行重缩放。例如， De和Smith（2020）\\n提出了SkipInit，采用一个可学习的标量乘数放置在每个残差分支的末端。若该乘数初\\n始值设为小于p\\n1/K（K为残差块数量） ，则效果更佳，他们推荐将其初始值设置为零。\\nHayou等人（2021）提出的 Stable ResNet 通过常数λk重缩放第k个残差块的输出（加\\n入主分支前） 。他们证明了在网络宽度趋于无限大时，第一层权重的梯度范数的期望值\\n至少为λk平方和。通过将 λk设置为p\\n1/K（K为残差块数） ，证明了可以训练高达\\n1000个块的网络。\\nZhang等人（2019a）提出的 FixUp通过He正则化初始化每层，但每个残差块的\\n最后一层线性 /卷积层设置为零。如此一来，初始的前向传播是稳定的（因每个残差块\\n不产生输出） ，且反向传播中梯度不会爆炸。他们还对分支进行了重缩放，确保了不论'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 200}, page_content='11.9.习题 185\\n残差块数量如何，参数的总预期变动幅度保持不变。这些方法虽然支持深度残差网络的\\n训练，但通常未能达到使用 BatchNorm 时的测试性能，主因是它们未能从噪声批次统\\n计引入的正则化中受益。 De和Smith（2020）通过引入 dropout来引起正则化，以缩小\\n这一性能差距。\\nDenseNet 与 U-Net：DenseNet 由Huang等人（2017b）首次提出， U-Net由\\nRonneberger 等人（2015）开发，而叠层沙漏网络则是由 Newell等人（2016）引入。在这\\n些架构中， U-Net获得了最广泛的应用。 CiCek等人（2016）提出了 3D U-Net ，Milletari\\n等人（2016）引入了 V-Net，两者均将 U-Net扩展到了 3D数据处理。 Zhou等人（2018）\\n结合了DenseNet 和U-Net的理念，在架构中加入了图像的降采样与重采样，同时反复\\n利用中间表示。 U-Net通常应用于医学图像分割（参见 Siddique 等人，2021的综述） ，\\n但也已被应用于深度估计、语义分割、图像修复、全色锐化和图像到图像转换等领域。\\nU-Net在扩散模型（第 18章）中也扮演了关键角色。\\n11.9习题\\n问题11.1根据方程 11.4所定义的网络结构，推导出方程 11.5。\\n问题11.2对图11.4a描述的含有四个残差块的网络进行解构，可以发现存在一条长\\n度为零的路径、四条长度为一的路径、六条长度为二的路径、四条长度为三的路径和一\\n条长度为四的路径。若网络包含（ i）三个残差块及（ ii）五个残差块，各长度路径的数\\n量分别是多少？请推导出对于 K个残差块时，各长度路径数量的通用规则。\\n问题11.3证明方程 11.5描述的网络对其第一层 f1[x]的导数可以通过方程 11.6表\\n达。\\n问题11.4*阐明为何图 11.6a中残差块的两个分支的值是不相关的，并证明不相关\\n变量之和的方差等于它们各自方差的和。\\n问题 11.5在给定一组标量值 {zi}I\\ni=1的情况下，批量归一化操作的前向传递步骤如\\n下（参见图 11.15） ：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 201}, page_content='186 CHAPTER 11. 残差网络\\nf1=E[zi]\\nf2i=zi−f1\\nf3i=f2\\n2i\\nI\\nf4=E[f3i]\\nf5=p\\nf4+ϵ\\nf6=1\\nf5\\nf7i=f2i×f6\\nz′\\ni=f7i×γ+δ, (11.10)\\n其中，zi的平均值 E[zi]计算为1\\nIP\\nizi。请编写 Python代码完成这一前向传递过\\n程。接着，推导并实现批量归一化的反向传递算法。反向传递过程涉及从计算图的输出\\n开始，逐步向输入反推，计算出每个步骤的导数，从而得到批中每个元素的∂z′\\ni\\n∂zi。根据这\\n一过程，编写 Python代码实现反向传递。\\n问题11.6设想一个由一个输入层、一个输出层和十个隐藏层组成的全连接神经网\\n络，每个隐藏层都包含二十个神经元。计算这个网络的参数总数。如果在每个线性层与\\nReLU激活函数之间增加一个批量归一化步骤，参数总数将如何变化？\\n问题11.7*假设对图 11.7a描述的卷积网络层的权重应用 L2正则化，但不对后续\\n的批量归一化层的缩放参数施加正则化。预计在训练过程中会出现什么情况？\\n问题11.8考虑一个卷积残差块，其结构为先进行批量归一化，然后是 ReLU激活，\\n最后是一个 3×3卷积层。若输入和输出层的通道数均为 512，求构建此块需要的参数数\\n量。进一步考虑一个瓶颈设计的残差块，它由三个批量归一化 /ReLU/卷积序列组成：第\\n一个序列通过 1×1卷积将通道数从 512减少至128，第二个序列使用 3×3卷积保持通\\n道数不变，第三个序列通过 1×1卷积将通道数从 128增加至512（参见图 11.7b） 。构建\\n此块需要多少参数？\\n问题11.9 U-Net 网络完全基于卷积操作，理论上能处理任何尺寸的图像。为什么在\\n训练时，我们不使用大小不一的图像集合呢？'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 202}, page_content='Chapter 12\\nT ransformers\\n第10章引入了专门用于处理规则网格数据的卷积网络。这类网络非常适合处理图\\n像，因为图像含有极其庞大的输入变量数目，这使得全连接网络不再适用。卷积网络通\\n过参数共享机制，保证了图像中每一处的局部区域都以类似的方式被处理。\\n本章将要介绍的是 Transformer 。它们最初是为了解决自然语言处理（ NLP）的问\\n题而设计的，这类问题的网络输入是一连串表示词汇或词汇碎片的高维嵌入向量。语言\\n数据集在某种程度上与图像数据相似，它们的输入变量数量可能极大，并且不同位置的\\n统计特性也类似；因此，在文本中的不同位置重复学习同一个词汇（如“ dog” ）的含义\\n并不合理。然而，与图像不同的是，语言数据集面临的一个挑战是文本序列长度的不一\\n致性，且没有一个简便的方法来统一调整其大小。\\n12.1文本数据处理\\n为了引出 Transformer 的设计动机，让我们考虑以下场景：\\n“‘因为一家餐馆仅提供素食，所以拒绝了我要求的火腿三明治，最终只给了我两片\\n面包。不过，他们的环境氛围与食物和服务一样出色。 “‘\\n我们的目标是构建一个能够把这段文本转换为适合后续任务处理的表示形式的网\\n络。例如，这样的网络可以用来判断这篇评论是正面的还是负面的，或者回答如“这家\\n餐馆是否提供牛排？ ”这样的问题。\\n首先，我们注意到编码后的输入大小可能远超预期。以这段简短的文本为例， 37个\\n词每个都可能被表示为一个 1024维的嵌入向量，因此即便是这么短的文本，编码后的\\n输入长度也达到了 37×1024=37888 。对于更长的文本，其词数可能达到数百甚至数千，\\n这使得使用全连接网络变得不现实。\\n其次，NLP问题的一个核心特点是每个输入（一个或多个句子）的长度各不相同，\\n这让直接应用全连接网络变得困难。这一观察表明，网络应当采用参数共享策略，类似\\n于卷积网络在图像的不同位置共享参数，以此处理不同位置的词汇。\\n第三，语言存在歧义性，单从句法无法明确区分“它”是指“餐馆”还是“火腿\\n187'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 203}, page_content='188 CHAPTER 12. TRANSFORMERS\\n三明治” 。为了理解文本，词汇间需要建立联系， “它”需要与“餐馆”相关联。按照\\nTransformer 的设计，前者需要对后者“给予注意力” 。这意味着单词之间必须存在联系，\\n而这些联系的强度取决于单词本身。此外，这些联系需要能够覆盖文本中较大的跨度，\\n例如，最后一句的“他们”也是指代餐馆。\\n12.2点积自注意力\\n上一节阐述了处理文本模型需要： (i)采用参数共享策略以处理不同长度的长文本\\n输入，以及 (ii)建立基于单词本身的词表示间的联系。通过采用 *点积自注意力机制 *，\\nTransformer 成功实现了这两种特性。\\n标准的神经网络层 f[x]接收一个维度为 D×1的输入x，并对其执行一次线性变\\n换后应用一个激活函数，如 ReLU，即：\\nf[x] =ReLU [β+ Ωx], (12.1)\\n这里的β代表偏置项， Ω代表权重矩阵。\\n自注意力模块 sa[·]处理N个维度为D×1的输入x1,...,x N，并输出N个同样大\\n小的向量。在自然语言处理中，每个输入都对应一个词或词的一部分。首先，每个输入\\n都会计算出一组对应的 *值*：\\nvm=βv+ Ω vxm, (12.2)\\n这里βv∈RD和Ωv∈RD×D分别代表了偏置项和权重矩阵。\\n接下来，第 nth个输出san[x1,...,x N]通过对所有值 v1,...,v N进行加权求和得到：\\nsan[x1,...,x N] =NX\\nm=1α[xm,xn]vm. (12.3)\\n这里的标量权重 α[xm,xn]表示第nth个输出对输入 xm的*注意力程度 *。这N\\n个权重αp,xn都是非负的，且总和为一。因此，自注意力机制可以视为是将不同比例的\\n值*分配*到每个输出中（如图 12.1所示） 。\\n下文将进一步探讨点积自注意力机制的细节，首先是值的计算及其加权方式（方程\\n12.3） ，随后是注意力权重 α[xm,xn]的计算方法。\\n12.2.1 值的计算与加权\\n方程12.2揭示了对每个输入 xn∈RD应用相同的权重 Ωv∈RD×D和偏置βv∈RD。\\n由于这种运算与序列的长度 N呈线性关系，相比于一个将所有 DN输入与所有 DN输\\n出相关联的全连接网络，它需要更少的参数。可以将这一计算过程视作一个执行了参数\\n共享的稀疏矩阵运算（见图 12.2b） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 204}, page_content='12.2.点积自注意力 189\\n图 12.1:自注意力机制如何实现路由。自注意力机制处理 N个输入 x1, ..., x N∈RD（此处\\nN= 3，D= 4） ，并分别计算出 N个值向量。第 n个输出 san[x1, ...x N]（简称 san,[x]）是通\\n过对这 N个值向量进行加权求和得到的，其中每个权重都是正值并且总和为 1。a)对于输出\\nsa1[x·]，是通过将第一个值向量乘以 0.1，第二个值向量乘以 0.3，第三个值向量乘以 0.6来计算\\n得出。 b)输出 sa2[x·]的计算方式相同，但此时的权重分别为 0.5,0.2和0.3。c)输出 sa3[x·]的\\n权重又是不同的。因此，每个输出可以视为是对 N个值进行了不同的路由处理。\\n注意力权重 α[xm,xn]融合了来自不同输入的信息。这个权重系统是稀疏的，因为\\n不管输入的大小如何，每一对输入 (xm,xn)只对应一个权重（见图 12.2c） 。这意味着，\\n虽然注意力权重的总数与序列长度 N的平方成正比，但它不受每个输入的长度 D的影\\n响。\\n图 12.2:针对三个维度为 D= 4的输入 xn的自注意力。 a)每个输入 xn都独立地通过相同的\\n权重 Ω（相同的颜色代表相同的权重）和偏置 β（未展示）进行操作，以形成值 β+ Ωxn。每个\\n输出都是这些值的线性组合，共享的注意力权重 a[xm, xn]确定了第 m个值对第 n个输出的影\\n响。 b)矩阵展示了输入与值之间的线性转换 Ω的块稀疏性。 c)另一个矩阵展示了连接值与输出\\n的注意力权重的稀疏性。\\n12.2.2 注意力权重的计算\\n在前一节中，我们看到了输出是通过两个连续的线性变换产生的；对于每个输入\\nxm，独立计算得到的值向量 βv+ Ω vxm随后被注意力权重 α[xm,xn]线性整合。然而，自\\n注意力的整个计算过程实际上是 *非线性*的。很快我们就会发现，注意力权重本身实\\n际上是输入的非线性函数。这是一个 *超网络*的范例，即一个网络分支计算另一分支\\n的权重。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 205}, page_content='190 CHAPTER 12. TRANSFORMERS\\n为了计算注意力，我们对输入进行了另外两次线性变换：\\nqn=βq+ Ω qxn\\nkm=βk+ Ω kxm, (12.4)\\n这里{qn}和{km}分别代表 *查询*和*键*。随后，我们计算查询与键之间的\\n点积，并通过 softmax函数处理这些结果：\\na[xm,xn] =softmax m[kT\\n.qn]\\n=exp[kT\\nmqn]PN\\nm′=1exp[kT\\nm′qn], (12.5)\\n因此，对于每个 xn，这些值都是正数且和为一（见图 12.3） 。这种方法因其明显的\\n原因而被称为 *点积自注意力 *。\\n图 12.3:计算注意力权重。 a)对每个输入 xn计算查询向量 qn=βq+ Ω qxn和键向量 kn=\\nβk+ Ω kxn。b)每个查询向量与三个键向量的点积经过 softmax函数处理，得到非负的、和为一\\n的注意力权重。 c)这些注意力权重通过图 12.2c所示的稀疏矩阵来指导值向量（见图 12.1）的\\n路由。\\n“查询”和“键”的术语源于信息检索领域，这里的含义是：点积操作测量输入之间\\n的相似度，因此权重 a[x0,xn]取决于第nth查询与所有键的相对相似度。 softmax函数\\n确保了键向量之间的“竞争” ，以决定它们对最终结果的贡献度。查询和键的维度必须\\n一致。不过，这与值的维度可以不同，值的维度通常与输入的尺寸相同，保证了表示的\\n尺寸不发生变化。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 206}, page_content='12.3.点乘自注意力的扩展 191\\n12.2.3 自注意力机制概述\\n第nth个输出是对所有输入应用了相同线性变换 v的加权总和，其中 v=βv+ Ω vx，\\n而这些注意力权重均为正值且总和为一。权重的计算基于输入 xn与其他输入间相似度\\n的度量。尽管没有使用激活函数，但是这个过程因点积和 softmax操作而呈现非线性特\\n性。\\n这种机制满足了初始设定的需求。首先，存在一组共享的参数集\\nΦ ={βv,Ωv,βq,Ωq,βk,Ωk}\\n它不依赖于输入的数量 N，使得网络能够处理不同长度的序列。其次，输入（单词）间\\n存在相互连接，且这些连接的强度是基于注意力权重直接反映了输入本身的特性。\\n12.2.4 矩阵表示法\\n如果将N个输入xn视为构成了一个 D×N矩阵X的列，则可以将上述过程更简\\n洁地表述。值、查询和键的计算可以表示为：\\nV[X] =βv1T+ Ω vX\\nQ[X] =βq1T+ Ω qX\\nK[X] =βk1T+ Ω kX (12.6)\\n这里，1代表一个所有元素为 1的N×1向量。自注意力的计算过程则为：\\nSa[X] =V[X]·Softmax\\x00\\nK[X]TQ[X]\\x01\\n, (12.7)\\n其中Softmax[•] 函数对矩阵的每一列独立执行 softmax操作（见图 12.4） 。通过这种方\\n式，我们特意强调了值、查询和键是如何基于输入 X计算出一种基于输入的三重乘积。\\n但是，从这一点开始，我们将不再显式表示这种依赖性，简化为：\\nSa[X] =V·Softmax [KTQ]. (12.8)\\n12.3点乘自注意力的扩展\\n在上一节里，我们讨论了自注意力。本节将介绍三种实际应用中常用的扩展技术。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 207}, page_content='192 CHAPTER 12. TRANSFORMERS\\n图 12.4:自注意力的矩阵表示法。如果将 N个输入向量 xn存放在 D×N矩阵 X的列中，则可\\n以高效地实施自注意力。输入 X分别被查询矩阵 Q、键矩阵 K和值矩阵 V所处理。随后，通\\n过矩阵乘法计算点积，并对结果矩阵的每列应用 softmax操作以计算注意力权重。最后，这些值\\n根据注意力权重进行后乘，生成与输入尺寸相同的输出。\\n12.3.1 位置编码\\n细心的读者可能已经发现，自注意力机制忽略了一个重要信息：计算过程与输入 xn\\n的顺序无关。更精确地说，它是对输入排列的不变性。然而，对于句子中的单词而言，顺\\n序是极其重要的。例如，句子“ The woman ate the raccoon ”与“The raccoon ate the\\nwoman”意义截然不同。纳入位置信息有两种主要方法。\\n绝对位置编码： 为了编码位置信息，一个矩阵 Π被加入到输入 X中（见图 12.5） 。\\nΠ的每一列都唯一标示了输入序列中的绝对位置。这个矩阵可以是预设的，也可以通过\\n学习得到。它可以加在网络的输入层，或者是每一层网络中。有时候，它被用于计算查\\n询和键时加到 X中，但不用于值的计算。\\n相对位置编码： 自注意力机制的输入可能是整个句子、多个句子或仅是句子的一部\\n分，这时候单词的绝对位置不如两个输入之间的相对位置重要。尽管如果系统知道两个\\n位置的绝对值可以推导出相对位置，相对位置编码却能直接编码这种信息。注意力矩阵\\n的每个元素都对应于查询位置 a与键位置 b之间的特定偏移量。对于每个偏移量，相对\\n位置编码学习一个参数 πa,b，通过添加、乘以这些值，或以其他方式调整注意力矩阵来\\n使用这些参数。\\n12.3.2 缩放点积自注意力\\n注意力计算中的点积可能会产生较大的数值，导致 softmax函数的参数进入一个区\\n域，其中最大的数值几乎占据主导地位。这使得对 softmax函数输入的微小变化几乎不\\n影响输出（即，梯度非常小） ，从而增加了模型训练的难度。为避免此问题，通过查询和\\n键的维度Dq（即 Ωq和Ωk的行数，这两者必须相同）的平方根来对点积进行缩放：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 208}, page_content='12.3.点乘自注意力的扩展 193\\n图 12.5:位置编码。自注意力架构对输入的排列顺序不敏感。为了使处于不同位置的输入能够\\n被区分处理，可以在数据矩阵中加入位置编码矩阵 Π。因为每一列都是独一无二的，从而可以识\\n别不同的位置。这里的位置编码采用了预定义的程序化的正弦模式（必要时可扩展到更多的 N\\n值） 。但在其他场景中，位置编码是通过学习得到的。\\nSa[X] =V·Softmax \\nKTQp\\nDq!\\n. (12.9)\\n这种方法被称为缩放点积自注意力。\\n12.3.3 多头自注意力\\n通常会并行使用多个自注意力机制，这种方式称为 *多头自注意力 *。此时会计算\\n出H组不同的值、键和查询：\\nVh=βvh1T+ Ω vhX\\nQh=βqh1T+ Ω qhX\\nKh=βkh1T+ Ω khX. (12.10)\\n对于第h个自注意力机制或称之为 *头*，其表示为：\\nSah[X] =Vh·Softmax \\nKT\\nhQhp\\nDq!\\n, (12.11)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 209}, page_content='194 CHAPTER 12. TRANSFORMERS\\n这里每个头都有一套不同的参数 {βvh,Ωvh},{βqh,Ωqh},和{βkh,Ωkh}。通常情况下，\\n如果输入xm的维度是D，且有H个头，那么值、查询和键的尺寸都会是 D/H，这样\\n做可以实现高效的执行。这些自注意力机制的输出会先进行纵向拼接，随后通过另一个\\n线性变换 Ωc进行合并（见图 12.6） ：\\nMhSa [X] = Ω c\\x02\\nSa1[X]T,Sa 2[X]T,...,Sa H[X]T\\x03T. (12.12)\\n多头机制被认为是自注意力机制良好工作的关键。人们推测，这种机制能够让自注\\n意力网络对不良的初始值设定更加鲁棒。\\n图 12.6:多头自注意力。自注意力通过多个独立的“头”并行进行，每个头拥有自己的查询、键\\n和值。示例中展示了两个头，分别用青色和橙色框标出。它们的输出先是垂直堆叠，随后通过另\\n一线性变换 Ωc进行重组。\\n12.4 T ransformer 层\\n自注意力仅是更大的 Transformer 层结构中的一环。它由一个多头自注意力单元组\\n成（使得各个词语的表示能够互相影响） ，接着是一个对每个词分别进行处理的全连接\\n网络mlp[x•]。这两个部分都采用了残差网络的设计（即， 它们的输出会被加到输入上） 。\\n此外，通常在自注意力和全连接网络后都会加入层归一化（ LayerNorm ）操作。这与批\\n归一化（ BatchNorm ）相似，但它是基于单个输入序列中所有 token的统计数据来进行\\n归一化的（见第 11.4节和图11.14） 。完整层的操作流程如下（见图 12.7） ：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 210}, page_content='12.5.面向自然语言处理的 TRANSFORMERS 195\\nX←X+MhSa [X]\\nX←LayerNorm [X]\\nxn←xn+mlp[xn]\\nX←LayerNorm [X],\\n∀n∈{1,...,N} (12.13)\\n这里，列向量 xn是从整个数据矩阵 X中分别提取出来的。在实际的网络中，数据\\n会依次穿过多个这样的 Transformer 层。\\n图 12.7: T ransformer 层。输入是一个包含每个输入 T oken的 D维词嵌入的 D × N矩阵，输出\\n也是同等大小的矩阵。 T ransformer 层包含了一系列操作步骤：首先是多头注意力模块，让词嵌\\n入间互相影响，形成了残差块处理，即输入加回到输出中。其次，执行了层归一化（ LayerNorm ）\\n操作。再接下来是第二个残差层，此处相同的全连接神经网络分别作用于每个词表示（列） 。最\\n终，再次应用层归一化。\\n12.5面向自然语言处理的 T ransformers\\n前一节介绍了 Transformer 层。 本节将探讨它在自然语言处理 （ NLP） 任务中的应用。\\n典型的NLP流程起始于一个分词器， 它负责将文本切分为词或词片段。 随后， 每个 token\\n被映射到一个学习得到的嵌入向量中。这些嵌入向量接着通过一系列的 Transformer 层\\n进行处理。接下来，我们将依次讨论这些阶段。\\n12.5.1 分词\\n文本处理流程始于分词，它将文本拆分成较小的构成单元（ token） ，这些单元来自\\n于一个可能的 token词汇表。虽然我们之前暗示这些 token代表词，但这里存在几个挑\\n战：-难免会有一些词（比如，专有名词）不在词汇表中。 -如何处理标点符号是个问题，\\n但这很关键。例如，如果句子以问号结束，我们必须能够编码这一信息。 -词汇表需要\\n为具有不同后缀的同一词的不同形式（例如， walk, walks, walked, walking ）提供不同的\\ntoken，并且需要有方法表明这些变体之间的关联。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 211}, page_content='196 CHAPTER 12. TRANSFORMERS\\n一个解决方案是采用字母和标点符号作为词汇表的元素，但这会导致将文本拆分成\\n非常小的片段，后续的网络则需要重新学习这些片段之间的关系。\\n实践中，人们采取了一个折中方案，介于字母和完整词之间，最终的词汇表既包括\\n常见的词也包括可以组合成较大、较少见词的词片段。通过使用子词分词器，如字节对\\n编码（图 12.8） ，基于它们出现的频率贪婪地合并常见的子字符串，来计算词汇表。\\n图 12.8:子词 T oken化。 a)选自一首童谣的文本段落。最初的 T oken是字符和空格（用下划\\n线表示） ，它们的出现频率展示在表格中。 b)每轮迭代，子词 T oken化器寻找并合并出现频率\\n最高的相邻 T oken对（此例中为 se） ，新建一个 T oken同时减少原有 T oken s 和 e的计数。 c)\\n第二轮迭代中，算法合并了 e和空格字符 _。注意，被合并的第一个 T oken的末字符不能是空\\n格，以避免跨单词合并。 d)经过 22轮迭代， T oken化为字母、单词片段和常见单词的混合体。\\ne)持续这一过程， T oken最终能够代表完整单词。 f)随时间推移，随着字母和单词片段的不断\\n增加再合并， T oken数量先是增加后减少。在实际应用中，会处理极大量的单词，并在达到预设\\n的词汇量大小时停止算法。标点和大写字母也被视为独立字符。\\n12.5.2 嵌入\\n词汇表V中的每个 token都映射到一个唯一的 词嵌入中，整个词汇表的嵌入向量\\n存储在矩阵 Ωe∈RD×|V|中。为此，首先将 N个输入token编码进矩阵 T∈R|V|×N中，\\n其中第n列对应第n个token，是一个|V|×1的独热编码 （即，除了对应于该 token\\n的条目为一之外，其他所有条目都为零的向量） 。输入嵌入通过计算 X= Ω eT获得， Ωe\\n像任何其他网络参数一样进行学习（图 12.9） 。典型的嵌入大小 D为1024，总词汇量\\n|V|为30,000，因此即使在主网络处理之前， Ωe中就已经有了大量的参数需要学习。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 212}, page_content='12.6. ENCODER 模型案例 : BER T 197\\n图 12.9:输入嵌入矩阵 X∈RD ×N包含 N个长度为 D的嵌入，通过乘以一个包含整个词汇\\n的嵌入 Ωe和一个列中含有对应单词或子词索引的 one-hot向量矩阵来创建。词汇矩阵 Ωe作为\\n模型的参数之一，并随其他参数一同学习。需要注意的是，矩阵 X中单词 an的两个嵌入是相\\n同的。\\n12.5.3 T ransformer 模型\\n最终，代表文本的嵌入矩阵 X被传递通过一系列 K个Transformer 层，形成了所\\n谓的Transformer 模型。Transformer 模型分为三种类型：编码器将文本嵌入转化为能\\n够支持多种任务的表示；解码器预测接下来的 token以继续输入文本；编码器 -解码器用\\n于序列到序列的任务，如将一串文本转换成另一串（例如，机器翻译） 。这些不同的模\\n型变体将分别在第 12.6至12.8节中进行描述。\\n12.6 Encoder 模型案例 : BER T\\nBERT是一种编码器模型，采用 30,000个token的词汇表。输入 token转换为1024\\n维的词向量后，经过 24层Transformer 处理。每层含有 16个自注意力机制的头部，每\\n个头部的查询、键和值的维度均为 64（即， Ωvh,Ωqh,Ωkh矩阵的尺寸是 1024 x 64 ） 。全\\n连接层的隐藏层维度为 4096。总参数量约为 3.4亿。在BERT推出时，这一规模被认\\n为很大，但如今相比最先进模型显得小多了。\\n像BERT这样的编码器模型运用了 迁移学习 。在预训练阶段，通过大规模文本语\\n料的自我监督 学习，训练 Transformer 架构的参数，目的是使模型掌握语言的统计特性。\\n在微调阶段 ，模型通过较少量的监督学习数据进行调整，以解决特定的任务。\\n12.6.1 预训练\\n预训练阶段，网络通过自我监督训练，利用大量数据进行学习而无需人工标记。\\nBERT的自监督任务是从大量网络文本中预测缺失的词语（图 12.10） 。训练时，最大输\\n入长度限制为 512个token，批量大小设置为 256，整个系统训练一百万步，相当于 33\\n亿词语料库的大约 50轮迭代。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 213}, page_content='198 CHAPTER 12. TRANSFORMERS\\n预测缺失词的任务促使网络学习语法知识，例如，形容词“红色”通常出现在“房\\n子”或“车”等名词前，而不是动词如“喊叫”前。这也使模型能够学习到一些关于世界\\n的基本常识，如经训练后，模型会更倾向于将句子中的缺失词填充为“火车”而非“花\\n生” 。然而，这类模型的“理解”能力是有限的。\\n图 12.10:类似 BER T的编码器预训练。输入 T oken（及一个表示序列开始的特殊 <cls> T oken）\\n被转换成单词嵌入。这里，嵌入以行的形式表示，因此标记为“单词嵌入”的盒子是 XT。这\\n些嵌入通过一系列的 T ransformer 层进行处理（橙色连线表示在这些层中，每个 T oken都会关\\n注其他所有 T oken） ，以生成一组输出嵌入。一小部分输入 T oken被随机替换为通用的 <mask>\\nT oken。预训练的目标是根据输出嵌入预测缺失的单词。因此，输出嵌入经过 softmax函数处理，\\n并使用多类分类损失。这种方法的优势在于它利用了左右上下文来预测缺失单词，但缺点是数\\n据利用率不高；例如，处理七个 T oken只为损失函数增加两项内容。\\n12.6.2 微调\\n微调阶段，模型参数被调整以适应特定任务。在 Transformer 网络上添加了额外的\\n层，以将输出向量转换为期望的输出格式。例如：\\n文本分类 ：在BERT中，预训练期间在每个字符串的开头添加了一个称为分类或\\n<cls>token的特殊标记。对于情感分析等文本分类任务（判断文本情绪为正面或负面） ，\\n与 <cls>token关联的向量被映射成一个数值，并通过一个逻辑 sigmoid函数处理（图\\n12.11a） ，这对应于标准的二分类交叉熵损失。\\n词分类：命名实体识别旨在将每个词分类为一个实体类型（如人名、地点、机构或\\n非实体） 。为此，每个输入向量 xn映射到一个 E × 1的向量， E项分别对应 E种实体类\\n型。通过 softmax函数处理后，为每个类别生成概率，进而计算多类别交叉熵损失（图\\n12.11b） 。\\n文本跨度预测 ：在SQuAD 1.1 问答任务中，问题与包含答案的维基百科段落合并\\n后进行分词处理。 BERT用于预测包含答案的段落文本跨度。每个 token映射到两个数'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 213}, page_content='12.11b） 。\\n文本跨度预测 ：在SQuAD 1.1 问答任务中，问题与包含答案的维基百科段落合并\\n后进行分词处理。 BERT用于预测包含答案的段落文本跨度。每个 token映射到两个数\\n字，分别表示其为文本跨度起始和结束位置的可能性。通过两个 softmax 函数处理后，\\n可以通过组合开始和结束的概率来评估任何文本跨度作为答案的可能性。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 214}, page_content='12.7. DECODER 模型案例 : GPT3 199\\n图 12.11:预训练后的细化调整。在预训练完成后，编码器会利用手动标注的数据进行细化调整，\\n以应对特定的任务。通常，会向编码器添加线性变换层或多层感知机（ MLP）来生成需要的输\\n出。 a)文本分类任务示例。在这个情绪分类任务中，使用 <cls> token的嵌入来预测评论是否\\n为正面。 b)单词分类任务示例。在这个命名实体识别任务中，用每个单词的嵌入来判断该词是\\n属于人名、地名、组织名还是非实体。\\n12.7 Decoder 模型案例 : GPT3\\n本节将对 GPT3这一解码器模型进行高层次的描述。其基本架构与编码器模型极\\n其相似，包括了一系列操作于学习得到的词嵌入上的 Transformer 层。然而，其目标不\\n同。编码器的目的是构建能够被细微调整用于解决更多具体 NLP任务的文本表示。相\\n对地，解码器的唯一目的是生成序列中的下一 Token。通过将扩展序列重新输入模型，\\n解码器能够生成连贯的文本段落。\\n12.7.1 语言模型\\nGPT3构建了一种自回归语言模型。以句子“ It takes great courage to let yourself\\nappear weak ”为例，假设以完整单词作为 Token，该句子的概率可以表示如下：\\nPr(It takes great courage to let yourself appear weak ) =\\nPr(It)×Pr(takes|It )×Pr(great|It takes )×Pr(courage|It takes great )×\\nPr(to|It takes great courage )×Pr(let|It takes great courage to )×\\nPr(yourself|It takes great courage to let )×\\nPr(appear|It takes great courage to let yourself )×\\nPr(weak|It takes great courage to let yourself appear ). (12.14)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 215}, page_content='200 CHAPTER 12. TRANSFORMERS\\n更正式地说，自回归模型将 N个观测Token的联合概率 Pr(t1,t2,...,t N)分解为\\n自回归序列：\\nPr(t1,t2,...,t N) =Pr(t1)NY\\nn=2Pr(tn|t1,...,t n−1). (12.15)\\n这种自回归公式展示了最大化 Token的对数概率与下一 Token预测任务之间的直接联\\n系。\\n12.7.2 遮掩自注意力\\n训练解码器时，我们致力于最大化输入文本在自回归模型下的对数概率。理想情况\\n下，我们希望一次性传入整个句子并计算所有对数概率及其梯度。但这样做存在一个问\\n题：若传入整个句子，计算对数 Pr(great|Ittakes )时，既能访问到答案“ great” ，也能\\n访问到右侧上下文“ courage to let yourself appear weak ” ，这可能导致系统通过作弊而\\n非学习来预测下一个词，从而无法正确训练。\\n幸运的是，在 Transformer 网络的自注意力层中， Token之间的相互作用可以解决\\n这个问题。通过确保对答案和右侧上下文的注意力得分为零，可以避免这个问题。这通\\n过在自注意力计算中将相应的点积设为负无穷大后通过 softmax函数前实现，称为遮掩\\n自注意力。其效果是让图 12.1中所有向上倾斜的箭头的权重变为零。\\n解码器网络的整体操作如下：输入文本被分割为 Token，并转换为嵌入表示。这些\\n嵌入随后被输入 Transformer 网络。不同于以前， Transformer 层现在采用遮掩自注意\\n力，使得它们只能关注当前及之前的 Token。每个输出嵌入代表一个部分句子，其目标\\n是预测序列中的下一 Token。因此， 经过 Transformer 层处理后， 一个线性层将每个词嵌\\n入映射至词汇表的大小，随后通过 softmax函数将这些值转换为概率。在训练期间，我\\n们旨在通过标准多类交叉熵损失（图 12.12）最大化真实序列中每个位置的下一 Token\\n的对数概率之和。\\n12.7.3 利用解码器生成文本\\n自回归语言模型是本书讨论的第一个生成模型示例。它定义了文本序列上的概率模\\n型， 可以用来生成新的、看起来合理的文本样本。生成文本时， 我们从一段输入文本（可'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 215}, page_content='12.7.3 利用解码器生成文本\\n自回归语言模型是本书讨论的第一个生成模型示例。它定义了文本序列上的概率模\\n型， 可以用来生成新的、看起来合理的文本样本。生成文本时， 我们从一段输入文本（可\\n能仅为一个特殊的 <start> 标记，表示序列的开始）开始，并将其输入网络，然后网络\\n输出可能的后续 Token的概率分布。接下来，我们可以选择概率最高的 Token或从此\\n概率分布中采样。新扩展的序列被再次输入解码器网络，该网络输出下一个 Token的概\\n率分布。通过重复此过程，我们可以生成大量文本。得益于遮掩自注意力的机制，早期\\n的计算可以在生成后续 Token时被重用，使得计算过程十分高效。\\n在实际应用中，有多种策略可以让生成的文本更加连贯。例如，束搜索算法会跟踪\\n多个可能的句子完成选项，以寻找整体上最可能的完成方式（这并不一定通过每步贪心\\n地选择最可能的下一个词来实现） 。 Top-k抽样从最可能的 top-K选项中随机抽取下一'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 216}, page_content='12.7. DECODER 模型案例 : GPT3 201\\n图 12.12:训练 GPT3类解码器网络。 T oken通过映射转换为词嵌入，序列开始处加上特殊的\\n<start> token。这些嵌入通过一系列使用掩蔽自注意力的 T ransformer 层进行传递。在这种设\\n置下，句子中的每个位置只能关注到它自己的嵌入和序列中之前的 T oken（橙色连线表示） 。每\\n个位置的目标是预测序列中下一真实 T oken的概率。即在第一个位置，预测 T oken It 的概率；\\n第二个位置，预测 T oken takes 的概率；依此类推。掩蔽自注意力确保了系统不能通过查看后续\\n输入进行作弊。自回归任务有效地利用了数据，因为每个词都对损失函数有贡献，但它仅考虑了\\n每个词的左侧上下文。\\n个词，避免了系统偶然从低概率 Token的长尾选择，从而防止进入不必要的语言死胡\\n同。\\n12.7.4 GPT-3 与少样本学习\\n像GPT3这类大型语言模型采用了这些理念，并在巨大的规模上进行了应用。在\\nGPT3中，序列长度达到了 2048个Token，总批次大小为 3200万Token。模型包含 96\\n层Transformer （其中一些层实现了稀疏版本的注意力机制） ，每层处理的词嵌入大小为\\n12288。自注意力层拥有 96个头，值、查询和键的维度均为 128。它利用了 3000亿个\\nToken进行训练，总计含有 1750亿个参数。\\n下面是一个 GPT3模型文本完成的例子，模型接收的文本以普通形态显示，而生成\\n的文本以加粗显示：\\nUnderstanding Deep Learning is a new textbook from MIT Press by Simon Prince\\nthat’s designed to offer an accessible, broad introduction to the field. Deep\\nlearning is a branch of machine learning that is concerned with algorithms\\nthat learn from data that is unstructured or unlabeled. The book is divided\\ninto four sections:'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 216}, page_content='that learn from data that is unstructured or unlabeled. The book is divided\\ninto four sections:\\n1. Introduction to deep learning 2. Deep learning architecture 3. Deep\\nlearning algorithms 4. Applications of deep learning\\nThe first section offers an introduction to deep learning, including its\\nhistory and origins. The second section covers deep learning architecture,\\ndiscussing various types of neural net- works and their applications. The\\nthird section dives into deep learning algorithms, including supervised and'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 217}, page_content='202 CHAPTER 12. TRANSFORMERS\\nunsupervised learning, reinforcement learning, and more. The fourth section\\napplies deep learning to various domains, such as computer vision, natural\\nlanguage processing, and robotics.\\n这一延续是可行的，尽管只是部分准确。\\n这种规模的学习模型一个令人惊奇的特性是，它们能够在不进行特定任务的微调的\\n情况下执行许多任务。如果我们提供几个正确的问题 /答案对之后再提出一个问题，它\\n们通常能够通过完成序列来正确回答最后一个问题。纠正英语语法就是一个例子。\\n• Poor English input: I eated the purple berries.\\n• Good English output: I ate the purple berries.\\n• Poor English input: The mentioned changes have done. or I did the alteration that\\nyou requested. or I changed things you wanted and did the modifications.\\n• Good English output: The requested changes have been made. or I made the\\nalteration that you requested. or I changed things you wanted and made the mod-\\nifications.\\n• Poor English input: I ’d be more than happy to work with you in another project.\\n• Good English output: I ’d be more than happy to work with you on another project.\\n(result from Brown et al., 2020)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 217}, page_content='(result from Brown et al., 2020)\\n在这个例子中，提供给 GPT3的橙色文本包含了一系列成对的示例作为上下文，随\\n后系统便生成了青色的正确答案。这一现象适用于多种场合，如根据自然语言描述生成\\n代码片段、进行算术运算、实现语言间的翻译以及回答文本段落相关的问题。因此，人\\n们认为庞大的语言模型具备少样本学习的能力；它们能够依据寥寥几个示例学习完成新\\n的任务。然而，在实践中，这些模型的表现却是不稳定的，而且它们是如何基于已学习\\n的示例进行推理拓展，而非仅仅进行插值或者直接复制，这一点还不够明确。\\n12.8编码器 -解码器模型案例：机器翻译\\n语言转换是典型的序列到序列的任务，涉及到一个编码器（ encoder） （用于计算源\\n句子的有效表示）和一个解码器（ decoder） （用于生成目标语言的句子） 。这一过程可通\\n过编码器 -解码器模型来完成。\\n以英语翻译到法语为例，编码器首先接收英文句子，并通过一系列的 Transformer\\n层进行处理，为每个 Token生成一个输出表示。训练过程中，解码器接收法语的正确翻\\n译，并通过使用掩蔽自注意力（ masked self-attention ）的Transformer 层序列处理，以\\n预测每个位置的下一个词。同时，解码器层还会关注编码器的输出。这样，每个法语输'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 218}, page_content='12.8.编码器 -解码器模型案例：机器翻译 203\\n出词的生成都依赖于先前的输出词和源英文句子（见图 12.13） 。这一机制通过在解码器\\n中调整Transformer 层实现，原先的设计包括一个掩蔽自注意力层，随后是一个针对每\\n个嵌入分别应用的神经网络（见图 12.12） 。在这两个部分之间新增了一个自注意力层，\\n使得解码器的嵌入能够关注编码器的嵌入，采用的是一种特殊的自注意力形式，称为编\\n码器-解码器注意力或交叉注意力，其查询（ queries）基于解码器的嵌入，而键（ keys）\\n和值（values）则来源于编码器的嵌入（见图 12.14） 。\\n图 12.13:编码器 -解码器架构。两个句子输入系统，目标是将第一个句子翻译成第二个。 a)第\\n一个句子通过标准编码器进行处理。 b)第二个句子通过解码器处理，该解码器不仅使用掩蔽自\\n注意力，还通过交叉注意力关注编码器的输出嵌入（橙色矩形表示） 。损失函数与解码器模型相\\n同，目标是最大化输出序列中下一个词的概率。\\n图 12.14:交叉注意力。计算流程与标准自注意力一致，但查询是基于解码器嵌入 Xdec计算的，\\n键和值则来自编码器嵌入 Xenc。在翻译场景中，编码器包含源语言信息，解码器则含有目标语\\n言的统计信息。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 219}, page_content='204 CHAPTER 12. TRANSFORMERS\\n12.9面向长序列的 T ransformers\\n在Transformer 编码器模型中，每个 Token都会与序列中的其他 Token进行相互\\n作用，导致其计算复杂度随着序列长度的增长而平方级增加。而在解码器模型中，每个\\nToken仅与前面出现的 Token进行交互，虽然交互数量大致减少了一半，但复杂度的增\\n长依旧是平方级的。这种交互关系可以通过交互矩阵来形象展示（见图 12.15a–b） 。\\n由于计算量的平方级增长，这限制了能够处理的序列长度。为了应对更长序列，开\\n发了许多扩展 Transformer 的方法。其中一种方法是通过剪枝自注意力机制或等效地稀\\n疏化交互矩阵来减少计算量（见图 12.15c-h） 。比如，通过将注意力机制限制在一个卷积\\n结构内，使得每个 Token只与其邻近的几个 Token有交互。通过多层的作用，即便是\\n距离较远的 Token也能相互影响，因为感受野随着层数的增加而扩大。类似于图像处理\\n中的卷积，卷积核的大小和扩张率可以有所变化。\\n采用纯卷积的方法需要多层网络才能处理大范围的信息整合。一种加快信息整合的\\n方法是让某些特定的 Token（可能是每句话的开头）能够关注序列中的所有其他 Token\\n（对于编码器模型）或所有前面的 Token（对于解码器模型） 。另一个思路是设计一些全\\n局Token，它们不代表任何具体的单词，而是用来与序列中所有其他 Token以及它们自\\n身建立长距离的连接，如同 <cls>Token的角色。\\n图 12.15:自注意力的交互矩阵。 a)在编码器中，每个 T oken与其他所有 T oken相互作用，计\\n算量随 T oken数量二次方增长。 b)在解码器中，每个 T oken仅与前面的 T oken交互，复杂度\\n依然是二次方。 c)使用卷积结构可以降低编码器中的复杂度。 d)解码器的卷积结构。 e–f)解码\\n器使用二次和三次膨胀率的卷积结构。 g)另一种策略是让选定的 T oken与所有其他 T oken（在\\n编码器中）或之前的所有 T oken（在解码器中，如图所示）进行交互。 h)或者，可以引入全局\\nT oken（左两列和上两行） ，它们与所有 T oken以及彼此相互作用。\\n12.10面向图像的 T ransformers'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 219}, page_content='T oken（左两列和上两行） ，它们与所有 T oken以及彼此相互作用。\\n12.10面向图像的 T ransformers\\nTransformer 最初是针对文本数据而开发的，它们在这一领域取得的巨大成功促使\\n人们开始尝试将其应用于图像数据。虽然这一尝试初看不太乐观——一方面，图像的像\\n素数量远超过句子中的单词数量，使得自注意力机制的二次方计算复杂度成为实践中的'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 220}, page_content='12.10.面向图像的 TRANSFORMERS 205\\n瓶颈；另一方面，卷积神经网络因能自然处理图像的二维结构且对空间平移表现出等变\\n性，从而显示出良好的先验偏好。然而， Transformer 网络需要通过学习来掌握这种处\\n理能力。\\n尽管存在上述挑战，基于 Transformer 的图像网络如今已在图像分类等任务中超越\\n了卷积神经网络的性能。这一成就部分得益于这些网络可以构建的庞大规模以及用于预\\n训练的大量数据。本节将介绍针对图像设计的 Transformer 模型。\\n12.10.1 ImageGPT\\nImageGPT 作为一个 Transformer 解码器，构建了一种图像像素的自回归模型，能\\n够根据部分图像预测下一个像素的值。由于 Transformer 网络的计算复杂度较高，最大\\n的模型（含 68亿参数）处理的图像尺寸仅限于 64×64。此外，为了降低计算负担，需\\n要将原始的 24位RGB颜色空间简化为 9位颜色空间，从而使系统每个位置只需处理\\n512种可能的 Token。\\n虽然图像本质上是二维的， ImageGPT 却能够在每个像素处学习独特的位置编码，\\n从而识别像素之间以及与上一行相邻像素之间的紧密联系。图 12.16展示了一些图像生\\n成的示例。\\n这种解码器内部的表示形式被用来作为图像分类的基础。通过对最终像素嵌入进行\\n平均处理，再通过线性层转换，并利用 softmax层生成分类概率。系统首先在大规模的\\n网络图像库上预训练，随后在调整至 48×48像素的ImageNet 数据库上进行微调，采用\\n的损失函数同时包含了图像分类的交叉熵项和像素预测的生成损失项。尽管利用了大量\\n外部训练数据，该系统在 ImageNet 上的最佳单一错误率仅为 27.4%，虽低于当时的卷\\n积网络架构，但考虑到输入图像的尺寸，其性能仍然显著；然而，它在分类目标对象较\\n小或细长的图像时表现不佳。\\n12.10.2 视觉 T ransformer (ViT)\\n视觉Transformer (ViT) 通过将图像分割成 16×16的小块来解决图像分辨率的挑战\\n（见图12.17） 。每个小块通过一个学习到的线性变换降维，并输入到 Transformer 网络\\n中。这种模型也采用了标准的一维位置编码。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 220}, page_content='（见图12.17） 。每个小块通过一个学习到的线性变换降维，并输入到 Transformer 网络\\n中。这种模型也采用了标准的一维位置编码。\\nViT是一个包含 <cls>标记的编码模型 （参见图 12.10-12.11 ） ， 它通过对来自 18,000\\n个类别的 303百万标记图像的大数据库进行监督式预训练，与 BERT不同。通过最终\\n网络层映射 <cls>标记，生成的激活值通过 softmax函数转换为类别概率。预训练完\\n成后，通过替换最终层以适应特定类别数量的映射并进行微调，以完成最终的分类任务。\\n在ImageNet 基准测试中， ViT实现了11.45%的顶级错误率。然而，它在没有监督预\\n训练的情况下，性能并不如当时最好的卷积网络。只有通过利用大量训练数据，才能超\\n过卷积网络的强大先验偏好。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 221}, page_content='206 CHAPTER 12. TRANSFORMERS\\n图 12.16: ImageGPT 。a)使用自回归模型 ImageGPT 生成的图像。图像的生成从左上角的像\\n素开始，该像素基于其位置的估计经验分布选择。随后的像素基于前一个像素依次生成，沿着行\\n直到达到图像的右下角。对每个像素， T ransformer 解码器按照方程 12.15生成一个条件分布，\\n并从中抽样。这个过程反复进行，直到生成下一个像素，以此类推。 b)图像补全。在每个示例\\n中，图像的下半部被移除（最顶行） ， ImageGPT 逐像素补全剩余部分（展示了三种不同的补全\\n效果） 。\\n图 12.17:视觉 T ransformer （ViT） 。视觉 T ransformer 将图像切分成一个个小块（原始实现中\\n为 16×16大小） 。每个小块通过学习到的线性变换映射成一个小块嵌入。这些小块嵌入输入到\\nT ransformer 编码器网络中，并利用 <cls> token来预测图像的类别概率。\\n12.10.3 多尺度视觉 T ransformers\\n与卷积架构处理图像的单一尺度不同，已有多种 Transformer 模型被提出，它们在\\n多个尺度上处理图像。这些模型通常从高分辨率小块和少数通道开始，逐渐降低分辨率\\n的同时增加通道数。\\n多尺度Transformer 的一个典型例子是移动窗口或 SWin Transformer 。这是一个编\\n码器型Transformer ，通过将图像分割成小块并将这些小块组织成网格窗口，在这些窗\\n口内独立应用自注意力（见图 12.18） 。相邻 Transformer 中的窗口会发生位移，使得特\\n定小块的有效感知范围能够扩展到窗口边界之外。\\n该架构通过定期将来自不重叠 2×2小块的特征合并，并通过线性变换将合并后的'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 222}, page_content='12.11.总结 207\\n特征映射至原始通道数的两倍，从而逐步降低尺度。该架构不采用 <cls>标记，而是在\\n最后一层对输出特征进行平均，然后通过线性层映射至所需的类别数，并通过 softmax\\n函数产生类别概率。据文献记载，这种架构的最高级版本在 ImageNet 数据库上的顶级\\n错误率为 9.89%。\\n另一个想法是定期整合整个图像的信息。双注意力视觉 Transformers (DaViT) 交\\n替使用两种类型的 Transformers ：一种让图像小块互相关注，采用所有通道进行自注意\\n力计算；另一种则是通道互相关注，采用所有图像小块进行自注意力计算。这种架构在\\nImageNet 上的顶级错误率达到了 9.60%，接近于撰稿时的最先进水平。\\n图 12.18:移动窗口 （ SWin）T ransformer （Liu et al., 2021c ） 。 a)原始图像。 b) SWin T ransformer\\n将图像分割成窗口网格，每个窗口进一步细分为小块。在每个窗口内， T ransformer 网络对小块\\n单独应用自注意力。 c)在交替的层中，窗口位置会发生移动，改变小块间相互作用的组合，让\\n信息能够在整幅图像中传递。 d)经过若干层处理后， 2×2的小块表示合并，从而增加有效的小\\n块（和窗口）尺寸。 e)在此新的较低分辨率下，交替层使用移动窗口。 f)最终，分辨率降至只\\n剩一个窗口，此时小块覆盖整个图像。\\n12.11总结\\n本章对自注意力机制及 Transformer 架构进行了介绍，随后阐述了编码器、解码器\\n及编解码器模型的概念和作用。 Transformer 主要处理一系列高维嵌入数据，其在每一\\n层的计算复杂度较低，并且大量计算可通过矩阵的形式实现并行处理。每个输入嵌入与\\n其他嵌入相互作用，使得模型能够捕捉文本中的远距离依赖关系。但是，随着序列长度\\n的增加，计算量会以二次方形式上升；一个减少计算复杂度的策略是对交互矩阵进行稀\\n疏处理。\\n本书首次介绍了使用庞大无标签数据集训练 Transformer 的无监督学习案例。编码\\n器通过预测缺失 Token来学习表示，这种表示可用于其他任务。解码器构建了一个自回\\n归模型，处理输入数据，并成为本书介绍的第一个生成模型示例。这些生成式解码器可\\n以用于生成新的数据实例。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 222}, page_content='器通过预测缺失 Token来学习表示，这种表示可用于其他任务。解码器构建了一个自回\\n归模型，处理输入数据，并成为本书介绍的第一个生成模型示例。这些生成式解码器可\\n以用于生成新的数据实例。\\n第13章将讨论处理图数据的网络。这些网络与 Transformer 有所关联，图中的节点\\n在每一层网络中互相关注。而第 14章至第18章则重新聚焦于无监督学习和生成模型。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 223}, page_content='208 CHAPTER 12. TRANSFORMERS\\n12.12笔记\\n自然语言处理 （Natural Language Processing, NLP ） ：Transformer 设计初衷是为了\\n处理自然语言处理任务，这是一个覆盖文本分析、分类、生成和处理的广泛领域。具体\\n的任务示例包括词性标注、翻译、文本分类、实体识别（如人名、地点、公司等） 、文本摘\\n要、问答、词义消歧及文档聚类。 NLP的初步解决方案是基于规则的方法，这些方法利\\n用了语法的结构和统计特性。关于早期方法的更多信息，可以参考 Manning & Schutze\\n(1999)和Jurafsky & Martin (2000) 的研究。\\n图 12.19:循环神经网络（ RNNs） 。单词嵌入依序通过一系列相同的神经网络。每个网络产生两\\n个输出：一个是输出嵌入，另一个（通过橙色箭头）反馈到下一个网络，连同下一个单词嵌入一\\n起。每个输出嵌入既包含单词本身的信息，也包含其在前一句子片段中上下文的信息。理论上，\\n最终输出包含整个句子的信息，可以像 T ransformer 编码器模型中的 <cls> token那样用于支\\n持分类任务。然而， RNNs有时候会随时间“遗忘”更早出现的 T oken。\\n递归神经网络 （Recurrent Neural Networks, RNNs ）：在Transformer 出现之前，\\n很多领先的 NLP应用采用了递归神经网络（简称 RNNs）。”递归”这一术语最早\\n由Rumelhart 等人在1985年提出，但其核心思想最少可追溯至 1969年的Minsky &\\nPapert。RNNs逐一处理输入序列中的元素（在 NLP中通常指词汇） 。每一步，网络同\\n时接收新的输入和基于前一时间点的隐藏状态计算出的信息（即递归连接） 。最终输出\\n包含了对整个输入序列的理解，这种表示支持了如分类或翻译等 NLP任务。RNNs也\\n被应用于解码场景，其中生成的 token被作为下一次序列输入的一部分反馈给模型。例\\n如，PixelRNN 通过RNNs构建了一个图像的自回归模型。\\n从 RNNs到 T ransformers ：RNNs存在一个问题，即可能会忘记序列前面部分的\\n信息。长短期记忆网络（ LSTMs）和门控循环单元（ GRUs）是对这一架构更为复杂的版'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 223}, page_content='从 RNNs到 T ransformers ：RNNs存在一个问题，即可能会忘记序列前面部分的\\n信息。长短期记忆网络（ LSTMs）和门控循环单元（ GRUs）是对这一架构更为复杂的版\\n本， 它们在一定程度上解决了这个问题。 然而， 在机器翻译领域， 人们发现可以利用 RNN\\n中的所有中间表示来生成输出句子，并且特定的输出词需要根据与输入词的关系更加关\\n注特定的输入词。这种思考最终导致了将递归结构替换为 Encoder-Decoder Transformer\\n模型，其中输入 token之间（自注意力） 、输出 token对先前序列中的 token（遮蔽自\\n注意力）以及输出 token对输入token（交叉注意力）的关注构成了核心。 Transformer\\n的算法细节在 Phuong & Hutter （2022）中有所描述，相关研究的综述可见于 Lin等人\\n（2022） 。然而，文献应该谨慎对待，因为许多对 Transformer 的改进并没有在严格的实\\n验控制下展现出有意义的性能提升。\\n应用领域：基于自注意力机制和 /或Transformer 架构的模型已经被广泛应用于处'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 224}, page_content='12.12.笔记 209\\n理文本序列、图像块、蛋白质序列、图形、数据库架构、语音、将数学积分问题转化为\\n翻译问题，以及时间序列分析等领域。尽管如此，它们在构建语言模型方面的显著成就，\\n以及最近在计算机视觉中作为卷积网络的替代方案，才是最值得称道的成功。\\n大型语言模型 （Large Language Models ） ：Vaswani 等人（2017）最初聚焦于翻译\\n任务，但如今， Transformer 更多地用于构建纯编码器或纯解码器模型。其中， BERT\\n（Devlin等人，2019）和GPT2/GPT3 （Radford 等人，2019；Brown等人，2020）分别是\\n最为人所知的代表。这些模型通常通过诸如 GLUE（Wang等人，2019b） 、SuperGLUE\\n（Wang等人，2019a）和BIG-bench （Srivastava 等人，2022）等基准来测试，这些基准\\n整合了多项 NLP任务，形成一个衡量语言能力的综合得分。解码器模型尽管未经针对\\n性微调，但在提供少数示例问题和答案后，通过填写下一问题的文本表现良好，这种方\\n法称为少样本学习。\\n自GPT3发布以来，出现了许多性能稳步提升的解码器语言模型，包括 GLaM、\\nGopher、Chinchilla 、Megatron-Turing NLG 和LaMDa。性能提升主要归因于模型规模\\n的增加、采用稀疏激活模块和更大数据集的利用。截至目前，最新的模型是 PaLM，拥\\n有5400亿参数，通过 7800亿token在6144个处理器上训练。由于文本的高压缩性，\\n这些模型实际上能够记住整个训练集。尽管存在对大型语言模型超越人类性能的大胆声\\n明，但我们应谨慎对待这些观点。\\n这些模型储备了丰富的世界知识。例如，它们了解深度学习的关键事实，包括它作\\n为一种机器学习的类型及其相关算法和应用。一些模型甚至被误认为具有自我意识。然\\n而，关于这类模型能够理解的深度存在限制的观点值得深思。\\n分词器（Tokenizers ） ：Schuster & Nakajima 和Sennrich 等人分别提出了 WordPiece\\n和字节对编码（ Byte Pair Encoding, BPE ） 。这两种方法通过基于频率贪心合并相邻的\\ntoken对。例如， BPE从字符或标点开始作为初始 token，并特别标记空格以防合并跨'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 224}, page_content='和字节对编码（ Byte Pair Encoding, BPE ） 。这两种方法通过基于频率贪心合并相邻的\\ntoken对。例如， BPE从字符或标点开始作为初始 token，并特别标记空格以防合并跨\\n越空格。随着算法进展，通过递归组合字符，形成子词和完整词 token。单一语法模型\\n选择基于语言模型可能性的最佳合并候选。 BPE dropout 通过引入随机性使候选生成更\\n高效。SentencePiece 库包含了这两种方法的版本，直接处理 Unicode 字符，适用于任何\\n语言。将子词分割视为学习和推断中应边缘化的潜在变量。\\n解码算法（Decoding Algorithms ） ：Transformer 解码器模型计算文本的下一个 token\\n的概率，然后将其加入到前述文本中，再次运行模型。选择概率分布中 token的过程称\\n为解码。简单地贪心选择最可能的 token或随机选择可能导致结果过于平凡或质量下\\n降。一种解决方法是维护固定数量的假设并选择最可能的序列，这称为束搜索。为了探\\n索更多样化的序列，对束搜索进行了改进。 Top-K抽样和核抽样分别从最可能的假设或\\n固定比例的总概率质量中抽样，以解决不合理 token选择问题。\\n注意力机制的类型 （Types of Attention ） ：缩放点积注意力只是包括加法、乘法、键\\n值以及记忆压缩注意力在内的一系列注意力机制中的一种。有研究尝试构建了不具有二\\n次复杂度的“无注意力” Transformer 。多头注意力增加了模型的复杂性和灵活性，但研\\n究表明，训练后可以修剪大部分头部而不影响性能，这表明它们主要防止不良初始化。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 225}, page_content='210 CHAPTER 12. TRANSFORMERS\\n挤压-激励网络是一种类似注意力的机制，根据全局特征重新加权卷积层的通道。\\n自注意力（ Self-attention ）与其他模型间的关系 ：自注意力计算与其他模型紧密\\n相关。首先，它是一个超网络（ Hypernetwork ）的实例，其特点是利用网络的一部分确\\n定另一部分的权重：注意力矩阵构成了一个稀疏网络层的权重，这个层负责将输入值映\\n射到输出（图 12.3） 。合成器（ Synthesizer ）模型（ Tay等，2021）通过直接用一个神\\n经网络为每一行的注意力矩阵从相对应的输入生成，简化了这个概念。虽然输入 Token\\n之间不再直接相互作用来生成注意力权重，这种方法效果仍然出乎意料地好。 Wu等人\\n（2019）提出了一个产生具有卷积结构注意力矩阵的系统， 让 Token关注它们的邻居。门\\n控多层感知机（ Gated Multi-layer Perceptron ） （Wu等，2019）计算出一个矩阵，这个\\n矩阵将值进行点乘操作，从而改变它们而不将它们混合。 Transformer 也与快速权重记\\n忆系统（ Fast Weight Memory Systems ）紧密相关，后者是超网络概念的先驱（ Schlag\\n等，2021） 。\\n从路由机制（图 12.1）的角度来看，自注意力还与胶囊网络 (Capsule Networks)\\n(Sabour等，2017)有关。胶囊网络捕捉图像中的层级关系，例如，较低层次的网络可能\\n检测到面部的各个部分（如鼻子、嘴巴） ，这些部分在更高层的胶囊中被组合（路由） ，\\n以代表一个面孔。但胶囊网络通过协议来进行路由。与此不同，自注意力中，输入间通\\n过softmax运算竞争，以决定它们对输出的贡献。而在胶囊网络中，是层的输出互相竞\\n争，以获得早期层的输入。将自注意力视为路由网络后，我们可以探讨是否有必要使路\\n由动态化（即根据数据变化） 。随机合成器（ Random Synthesizer ） （Tay等，2021）彻\\n底移除了注意力矩阵对输入的依赖，改为使用预设的随机值或学习到的值。这种方法在\\n多种任务中都表现得出乎意料地好。\\n多头自注意力还与图神经网络（第 13章会详细讨论） 、 卷积（ Cordonnier 等，2020） 、'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 225}, page_content='多种任务中都表现得出乎意料地好。\\n多头自注意力还与图神经网络（第 13章会详细讨论） 、 卷积（ Cordonnier 等，2020） 、\\n循环神经网络（ Choromanski 等，2020）以及在霍普菲尔德网络（ Hopfield Networks ）中\\n的记忆检索（ Ramsauer 等，2021）有着密切联系。想了解更多有关 Transformers 与其\\n他模型间关系的信息，请参阅 Prince（2021a） 。\\n位置编码 ：原始的 Transformer 论文（Vaswani 等，2017）探索了预设位置编码矩阵\\nΠ和学习位置编码 Π的方法。将位置编码直接加到数据矩阵 X中，而不是将它们串联\\n起来，可能看起来有些不同寻常。但由于数据维度 D通常大于 Token数量N，位置编码\\n实际上存在于一个子空间中。 X中的词向量是通过学习得到的，因此，理论上系统可以\\n将这两个组成部分维持在互相正交的子空间中，并在需要时提取位置编码。 Vaswani 等\\n人（2017）选择的是一套具有两大优点的正弦波形编码： （ i）通过线性操作可以容易地\\n恢复两个编码间的相对位置， （ ii）随着位置间距离的增加，它们的点积通常会减小（更\\n多细节请参见 Prince，2021a） 。许多系统，例如 GPT-3和BERT，采用了学习位置编\\n码的方式。 Wang等人（2020a）分析了这些模型中位置编码的余弦相似性，发现它们通\\n常随着相对距离的增加而减少，尽管也存在周期性变化。\\n许多后续研究仅仅对注意力矩阵进行了修改，以便在缩放点积自注意力（ scaled dot'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 226}, page_content='12.12.笔记 211\\nproduct self-attention ）方程中：\\nSa[X] =V·Softmax \\nKTQp\\nDq!\\n, (12.16)\\n仅让查询（ Q）和键（ K）包含位置信息：\\nV=βv1T+ Ω vX\\nQ=βq1T+ Ω q(X+ Π)\\nK=βk1T+ Ω k(X+ Π). (12.17)\\n这种做法促成了在方程 12.16的分子中展开二次项并只保留部分项的思路。例如，\\nKe等人（2021年）通过只保留内容 -内容和位置 -位置项，并对每种信息使用不同的投\\n影矩阵 Ω•，来分离或解耦内容和位置信息。\\n另一个创新是直接注入相对位置信息。这比绝对位置更重要，因为文本批次可以在\\n文档的任意位置开始。 Shaw等人（2018年） ，Raffel等人（2020年） ，和 Huang等人\\n（2020年）均开发了系统，在这些系统中，每个相对位置偏移都学习了一个单独的项，并\\n通过使用这些相对位置编码以各种方式修改了注意力矩阵。 Wei等人（2019年）研究了\\n基于预定义的正弦嵌入而非学习值的相对位置编码。 DeBERTa （He等人，2021年）结\\n合了这些思路；他们仅保留了从二次扩展中选出的部分项，对它们应用不同的投影矩阵，\\n并使用相对位置编码。其他研究探讨了以更复杂方式编码绝对和相对位置信息的正弦嵌\\n入（Su等人，2021年） 。\\nWang等人（2020年）比较了在 BERT中使用不同位置编码的 Transformer 的性\\n能。他们发现相对位置编码的性能优于绝对位置编码，但使用正弦和学习嵌入之间差异\\n不大。关于位置编码的综述可以参考 Dufter等人（2021年）的工作。\\n扩展 T ransformer 以处理更长序列 ：自注意力机制的复杂度随序列长度的增长而\\n呈二次方增长。如摘要或问题回答等任务可能需要长输入，因此这种二次方依赖成为性\\n能的限制。三种方法尝试解决这个问题。第一种是减少注意力矩阵的大小，第二种是使\\n注意力稀疏，第三种是修改注意力机制以提高效率。\\n为了减小注意力矩阵的大小， Liu等人（2018年）引入了压缩记忆注意力，通过对\\n键和值应用跨步卷积来减少位置数量，这与卷积网络中的降采样类似。现在，注意力是\\n在相邻位置的加权组合之间应用的，其中权重是通过学习得到的。类似地， Wang等人'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 226}, page_content='键和值应用跨步卷积来减少位置数量，这与卷积网络中的降采样类似。现在，注意力是\\n在相邻位置的加权组合之间应用的，其中权重是通过学习得到的。类似地， Wang等人\\n（2020年）发现，注意力机制中的量在实践中通常是低秩的，并因此开发了 LinFormer ，\\n它在计算注意力矩阵之前，将键和值投影到较小的子空间上。\\n为了使注意力稀疏， Liu等人（2018年）提出了局部注意力方案， 即相邻的 token块\\n仅对彼此进行关注，从而创建了一个块对角交互矩阵（见图 12.15） 。信息无法从一个块\\n传递到另一个块，因此这样的层通常与全注意力层交替使用。同样， GPT-3（Brown等\\n人，2020年）采用了卷积交互矩阵， 并与全注意力交替。 Child等人（2019年）和Beltagy'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 227}, page_content='212 CHAPTER 12. TRANSFORMERS\\n等人（2020年）尝试了包括不同膨胀率的卷积结构在内的多种交互矩阵，但允许一些查\\n询与每个其他键进行交互。 Ainslie等人（2020年）引入了扩展的 Transformer 构造（图\\n12.15h） ，它采用了一组与每个其他 token交互的全局嵌入。这种方法仅在编码器版本\\n中实现，或者这些方法隐式地允许系统“向前看” 。与相对位置编码结合时，这种方案\\n需要特殊的编码，以实现到这些全局嵌入的映射，以及这些映射之间的映射。 BigBird\\n（Ainslie等人，2020年）结合了全局嵌入和卷积结构，并随机采样可能的连接。其他研\\n究探索了学习注意力矩阵稀疏模式的方法（ Roy等人，2021年；Kitaev等人，2020年；\\nTay等人，2020年） 。\\n最后， 已经注意到计算注意力的 softmax操作的分子和分母中的项具有形式 exp[kT\\nq]。这可以被视为一个核函数，因此可以表达为点积 g[k]T g[q] ，其中g[•]是一个非线性\\n变换。 这种公式解耦了查询和键， 使得注意力计算更高效。 不幸的是， 为了复制指数项的\\n形式，变换 g[•]必须将输入映射到无限空间。线性 Transformer （Katharopoulos 等人，\\n2020年） 认识到这一点， 并用不同的相似度度量替换了指数项。 Performer （Choromanski\\n等人，2020年）用有限维方式近似这个无限映射。更多关于将 Transformer 扩展到更长\\n序列的细节可以在 Tay等人（2023年）和Prince（2021年）的研究中找到。\\n训练 T ransformer :训练Transformer 是具有挑战性的任务，这需要学习率预热\\n（Goyal等人，2018年）和Adam优化器（ Kingma & Ba ，2015年） 。Xiong等人（2020\\n年）和Huang等人（2020年）的研究显示，如果不采用学习率预热，梯度将消失，而且\\nAdam更新的幅度会减小。造成这个问题的有几个相互作用的因素。残差连接可能导致\\n梯度爆炸（见图 11.6） ，但归一化层可以防止这种情况。由于自然语言处理（ NLP）的统\\n计数据在不同批次间变化很大， Vaswani 等人（2017年）采用了层归一化（ LayerNorm ）'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 227}, page_content='梯度爆炸（见图 11.6） ，但归一化层可以防止这种情况。由于自然语言处理（ NLP）的统\\n计数据在不同批次间变化很大， Vaswani 等人（2017年）采用了层归一化（ LayerNorm ）\\n而非批归一化（ BatchNorm ） ，尽管后续研究已针对 Transformer 调整了批归一化（ Shen\\n等人，2020年） 。层归一化放置于残差块外部会导致梯度在通过网络回传时减小（ Xiong\\n等人，2020年） 。此外，初始化时随着我们在网络中的移动，残差连接和主自注意力机\\n制的相对权重发生变化（见图 11.6c） 。还有一个额外的复杂性在于查询和键的参数梯度\\n小于值参数的梯度（ Liu等人，2020年） ，这需要使用 Adam优化器。这些因素复杂地\\n相互作用，使得训练过程不稳定，因此需要学习率预热。\\n已经有多种方法尝试稳定训练过程，包括： （ i）一种名为 TFixup的FixUp变体\\n（Huang等人，2020年） ，该方法允许移除层归一化组件； （ ii）改变网络中层归一化组件\\n的位置（ Liu等人，2020年） ； （iii）重新加权残差分支中的两条路径（ Liu等人，2020\\n年；Bachlechner 等人，2021年） 。Xu等人（2021年）引入了一种名为 DTFixup 的初\\n始化方案，使 Transformer 能够在较小的数据集上进行训练。详细的讨论可以在 Prince\\n（2021年）的工作中找到。\\n在视觉领域的应用 ：ImageGPT （Chen等人，2020年）和视觉 Transformer （Doso-\\nvitskiy等人，2021年）都是早期将 Transformer 架构应用于图像的实例。 Transformer\\n已被用于图像分类（ Dosovitskiy 等人，2021年；Touvron 等人，2021年） 、对象检测\\n（Carion等人，2020年；Zhu等人，2020年；Fang等人，2021年） 、语义分割（ Ye等人，'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 228}, page_content='12.12.笔记 213\\n2019年；Xie等人，2021年；Gu等人，2022年） 、超分辨率（ Yang等人，2020年） 、动\\n作识别（ Sun等人，2019年；Girdhar等人，2019年） 、图像生成（ Chen等人，2021年；\\nNash等人，2021年） 、视觉问答（ Su等人，2019年；Tan & Bansal ，2019年） 、图像修\\n复（Wan等人，2021年；Zheng等人，2021年；Zhao等人，2020年；Li等人，2022\\n年） 、上色（ Kumar等人，2021年）以及许多其他视觉任务（ Khan等人，2022年；Liu\\n等人，2023年） 。\\nT ransformer 与卷积网络的结合 ：Transformer 已与卷积神经网络结合用于多种任\\n务，包括图像分类（ Wu等人，2020年） 、对象检测（ Hu等人，2018年；Carion等人，\\n2020年） 、视频处理（ Wang等人，2018年；Sun等人，2019年） 、无监督对象发现\\n（Locatello 等人，2020年）以及多种文本 /视觉任务（ Chen等人，2020年；Lu等人，2019\\n年；Li等人，2019年） 。尽管 Transformer 在视觉任务中可以超越卷积网络，但通常需\\n要大量的数据才能实现更优性能。它们通常在像 JRT（Sun等人，2017年）和LAION\\n（Schuhmann 等人，2021年）这样的庞大数据集上进行预训练。尽管 Transformer 没有\\n卷积网络的归纳偏见，但通过使用海量数据，它可以克服这一劣势。\\n从像素到视频 ：非局部网络（ Wang等人，2018年）是将自注意力应用于图像数据\\n的早期尝试之一。 Transformer 最初应用于局部邻域内的像素（ Parmar等人，2018年；\\nHu等人，2019年；Parmar等人，2019年；Zhao等人，2020年） 。ImageGPT （Chen\\n等人，2020年）扩展了这一概念，用于模拟小图像中的所有像素。视觉 Transformer\\n（ViT） （Dosovitskiy 等人，2021年）使用非重叠的补丁来分析更大的图像。\\n自那以后，开发了许多多尺度系统，包括 SWin Transformer （Liu等人，2021年） 、'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 228}, page_content='（ViT） （Dosovitskiy 等人，2021年）使用非重叠的补丁来分析更大的图像。\\n自那以后，开发了许多多尺度系统，包括 SWin Transformer （Liu等人，2021年） 、\\nSWinV2（Liu等人，2022年） 、多尺度 Transformer （MViT） （Fan等人，2021年）和金\\n字塔视觉 Transformer （Wang等人，2021年） 。Crossformer （Wang等人，2022年）建模\\n了不同空间尺度之间的交互。 Ali等人（2021年）引入了交叉协方差图像 Transformer ，\\n其中通道而非空间位置相互关注，使得注意力矩阵的大小不受图像大小的影响。双注意\\n力视觉Transformer （DaViT）由Ding等人（2022年）开发，它在子窗口内的局部空间\\n注意力和通道间的空间全局注意力之间进行交替。 Chu等人（2021年）采用了类似的方\\n法，在子窗口内的局部注意力和通过对空间域进行子采样的全局注意力之间交替。 Dong\\n等人（2022年）将图 12.15中的元素交互稀疏化的概念适配到 2D图像域。\\n随后，Transformer 被应用于视频处理（ Arnab等人，2021年；Bertasius 等人，2021\\n年；Liu等人，2021年；Neimark 等人，2021年；Patrick等人，2021年） 。关于应用于\\n视频的Transformer 的综述可以在 Selva等人（2022年）的工作中找到。\\n结合图像与文本 ：CLIP（Radford 等人，2021年）通过对比性预训练任务，学习了\\n图像及其标题的联合编码器。该系统处理 N张图像及其标题，并产生一个反映图像与标\\n题之间相容性的矩阵。损失函数旨在让正确的配对得分高，错误的配对得分低。 Ramesh\\n等人（2021年和2022年）训练了一个扩散解码器，用于反转 CLIP图像编码器，进行\\n基于文本条件的图像生成（参见第 18章） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 229}, page_content='214 CHAPTER 12. TRANSFORMERS\\n12.13习题\\n问题 12.1考虑一个自注意力机制，它处理 N个长度为 D的输入并产生大小相同\\n的N个输出。计算查询（ Queries） 、键（Keys）和值（ Values）时一共使用了多少个权\\n重和偏置？将会有多少个注意力权重 a[•, •]？在一个全连接网络中，如果关联所有 DN\\n个输入和所有 DN个输出，将会有多少个权重和偏置？\\n问题 12.2我们为何希望自注意力机制的输入与输出大小一致？\\n问题 12.3∗证明自注意力机制（方程 12.8）对数据 X的置换XP是等变的，这里\\n的P是一个置换矩阵。换句话说，证明以下等式成立：\\nSa[XP] =Sa[X]P. (12.18)\\n问题 12.4考虑softmax操作：\\nyi=softmax i[z] =exp[zi]P5\\nj=1exp[zj], (12.19)\\n在有五个输入的情况下： z1=−3,z2= 1,z3= 100,z4= 5,z5=−1。计算全部 25个\\n导数∂yi\\n∂zj，对于所有的 i,j∈{1,2,3,4,5}。你有什么发现？\\n问题 12.5如果在每个头部中，值、查询和键的维度都是 D/H（这里的 D是数据的\\n原始维度） ，这种实现方式的效率为什么更高？\\n问题 12.6BERT使用了两种预训练任务。第一种任务是预测缺失（遮蔽）的词；第\\n二种任务是判断一对句子在原文中是否相邻。判断这两种任务分别属于生成任务还是对\\n比任务（参见第 9.3.6节） 。为什么选择使用这两种任务？提出两种新的对比任务，用于\\n预训练语言模型。\\n问题 12.7考虑在已有 N个token的预计算遮蔽自注意力机制中加入一个新的\\ntoken。描述加入这个新 token需要进行的额外计算。\\n问题 12.8视觉变换器的计算量随着图像块数量的增加而呈二次方增长。设计两种\\n方法，根据图 12.15所示原则减少计算量。\\n问题 12.9假设用16 × 16 的图像块网格表示一幅图像，每个图像块通过一个 512\\n长度的嵌入向量来表示。比较在 DaViT变换器中执行注意力操作所需的计算量， （ i）在\\n使用所有通道的情况下，图像块之间的注意力；以及（ ii）在使用所有图像块的情况下，\\n通道之间的注意力。\\n问题 12.10*通常，注意力权重计算为：\\nα(xm,xn) =softmax m[kT'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 229}, page_content='使用所有通道的情况下，图像块之间的注意力；以及（ ii）在使用所有图像块的情况下，\\n通道之间的注意力。\\n问题 12.10*通常，注意力权重计算为：\\nα(xm,xn) =softmax m[kT\\n.qn] =exp[kT\\nmqn]PN\\nm′=1exp[kT\\nm′qn](12.20)\\n考虑将exp\\x02\\nkT\\nmqn\\x03\\n替换为点乘 g[km]Tg[qn]，其中g[·]是非线性变换。展示这种替换\\n如何使得注意力权重的计算更加高效。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 230}, page_content='Chapter 13\\n图神经网络\\n第10章介绍了卷积网络，它擅长处理规则的数据阵列（如图像） 。第 12章则讲述\\n了Transformer ，它擅长处理长度可变的序列（如文本） 。本章将讨论图神经网络。正如\\n其名，这些神经网络架构专门用于处理图结构（即，由边连接的节点集） 。\\n在处理图数据时，面临三大挑战。首先，图的拓扑结构多变，要设计出既有强大表\\n达能力又能适应这种变化的网络十分困难。其次，图的规模可能非常庞大，例如一个社\\n交网络用户连接图可能包含高达十亿个节点。第三，可能只能获取到一个庞大的单体图，\\n这就意味着常规的通过大量数据样本进行训练和使用新数据进行测试的做法并不总适\\n用。\\n本章将从介绍图数据在现实世界中的应用例子开始。接下来，讲述如何对这些图进\\n行编码，以及如何为图数据定义监督学习问题。本章还将探讨处理图数据所需的算法要\\n求，并自然引出图卷积网络的概念，这是图神经网络的一种特殊类型。\\n13.1什么是图 ?\\n图是一个极其通用的结构，它包含了一系列节点（或称为顶点） ，这些节点通过边\\n（或链接）相互连接。典型的图结构往往是稀疏的，意味着只有少量可能存在的边实际\\n被使用。\\n在现实世界中，有许多对象天然就具有图的形态。比如，道路网络可以看作是一个\\n图，节点代表地理位置，而边则表示这些位置之间的道路（见图 13.1a） 。化学分子可被\\n视为小型图，其中节点代表原子，边则代表它们之间的化学键（见图 13.1b） 。电路则可\\n以被描述为一个图，其节点表示电路的组件和连接点，边则是它们之间的电连接（见图\\n13.1c） 。\\n进一步地，许多数据集也可以通过图的形式来表达，即便它们表面上看不出这种结\\n构。例如： -社交网络可视为一个图，其中的节点是人，边表示人与人之间的友谊关系。\\n-科学文献网络则是一个节点为论文，边代表论文间引用关系的图。 -维基百科可以被\\n构想为一个图，其节点是文章，边则是文章间的超链接。 -计算机程序也可以用图来表\\n215'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 231}, page_content='216 CHAPTER 13. 图神经网络\\n图 13.1:现实世界的图结构示例。例如： a)道路网络、 b)分子结构、 c)电路布局，它们自然形\\n成了图的结构。\\n示，其中节点是程序中的语法元素（如不同位置的变量） ，边则代表这些变量参与的计\\n算过程。 -几何点云可以被建模为图，每个点作为一个节点，通过边与其他近邻点连接。\\n-细胞内的蛋白质相互作用同样可以用图来描述，这里的节点是蛋白质，而边则表示蛋\\n白质之间的相互作用。此外，一个集合（无序列表）也可以被理解为一个图，其中每个\\n元素都是一个节点，与其他所有节点相连接。图像则可以看作是一个具有规则拓扑结构\\n的图，每个像素点作为一个节点，与周围的像素点通过边连接。\\n13.1.1 图的类型\\n图的分类方法多样。例如，图 13.2a所示的社交网络就包含了无向边，意味着每对\\n朋友之间的连接是互相的，没有明显的方向性。而图 13.2b中的引用网络则由有向边构\\n成，每篇论文对其他论文的引用表明了一种单向的关系。\\n图13.2c展示的知识图通过定义实体之间的关系来表达关于这些实体的知识。这是\\n一个有向的异质多图，其中“异质”指的是能够表示多种类型实体（如人、国家、公司）\\n的能力， “多图”则表示任两节点间可以存在多种类型的边。\\n图13.2d中飞机的点集通过连接每个点及其 K个最近邻来转换为一个几何图，其\\n中每个点在 3D空间中都有一个确定的位置。图 13.2e则描述了一个层次结构图，桌子、\\n灯、房间的每一个都通过展示其组成部分相邻性的图来表示。这三个图自身作为节点构\\n成了另一个图，这个图表达了更大模型中的对象拓扑。\\n尽管深度学习能够处理各种类型的图，本章将重点放在无向图上，如图 13.2a中所\\n示的社交网络那样。\\n13.2图的表示方法\\n在图的结构之外，每个节点通常还会携带特定的信息。比如，在社交网络里，个人\\n的兴趣可能会被表示为一个固定长度的向量。边上也可能包含信息，如在道路网络中，\\n每条道路的特征（长度、车道数量、事故频率和限速）都可能被标记在边上。节点的信\\n息以节点嵌入的形式存储，而边的信息则存储在边嵌入中。\\n具体来说，一个图是由 N个节点和 E条边构成的集合。我们通过三个矩阵 A、X\\n和E来表示这个图，分别对应图的结构、节点的嵌入和边的嵌入（见图 13.3） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 232}, page_content='13.2.图的表示方法 217\\n图 13.2:图的种类。 a)社交网络是一种无向图，其中人与人之间的连接是对称的。 b)引用网络\\n是一种有向图，一篇出版物引用另一篇，关系是单向的。 c)知识图谱是一种有向的异构多重图，\\n节点代表不同类型的对象（如人、地点、公司） ，且不同的边可能表示节点间的不同关系。 d)通\\n过在附近的点之间建立连接，点集可以转换成图。每个节点在 3D空间中都有一个确定的位置，\\n这种图称为几何图（根据 Hu等人， 2022年改编） 。 e)左侧的场景可以用一个层次图来表示，房\\n间、桌子和灯的布局都用图来表达。这些图构成了一个更大图中的节点，表示对象间的邻接关系\\n（根据 F ernández-Madrigal & González ，2002年改编） 。\\n图的结构通过邻接矩阵 A来表示，它是一个 N × N的矩阵，其中若节点 m和n\\n之间有边相连，则矩阵中的 (m, n)项为1，否则为 0。对于无向图，这个矩阵是对称的。\\n对大型稀疏图而言，为了节约内存，可将其以连接列表 (m, n)的形式存储。\\n第nth个节点关联有一个长度为 D的节点嵌入 x(n)。这些节点嵌入串联后，被存储\\n在一个D×N的节点数据矩阵 X中。同理，第 eth条边关联有一个长度为 DE的边嵌\\n入e(e)，这些边嵌入则被汇总进一个 DE×E的矩阵E中。为简化讨论，我们在起初只\\n考虑具有节点嵌入的图，并在第 13.9节再次讨论边嵌入。\\n13.2.1 邻接矩阵的特性\\n通过线性代数，我们可以利用邻接矩阵来确定一个节点的所有邻居节点。具体做法\\n是，首先将第 nth个节点表示为一个独热列向量（这意味着向量中仅第 n位置为1，其\\n余为0） 。通过将这个向量与邻接矩阵相乘，我们可以得到第 nth列，该列标记了所有与\\n第nth个节点直接相连的节点（即，直接可达的节点） 。\\n如果重复这个乘法过程（即，再次用邻接矩阵乘以该向量） ，所得的向量则显示了\\n从节点n出发，通过两步可以到达的所有节点的数量（见图 13.4d–f） 。\\n更一般地，如果我们将邻接矩阵自乘至 L次幂，那么在 AL的矩阵中，位置 (m,n)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 233}, page_content='218 CHAPTER 13. 图神经网络\\n图 13.3:图的表示方式。 a)一个包含六个节点和七条边的图示例。每个节点都关联一个长度为\\n五的嵌入向量（棕色向量） 。每条边都关联一个长度为四的嵌入向量（蓝色向量） 。这个图可以通\\n过三个矩阵来表示： b)邻接矩阵是一个二进制矩阵，如果节点 m与节点 n相连，则元素 (m,n)\\n设为 1。c)节点数据矩阵 X包含了串联的节点嵌入。 d)边数据矩阵 E包含边的嵌入。\\n的值表示从节点 m到节点n有多少种长度为 L的路径（见图 13.4a–c） 。需要注意的是，\\n这里统计的是路径的数量，并不限于不重复访问节点的路径。虽然如此， AL仍旧提供\\n了图的连通性质的重要信息： (m,n)位置的非零值表明，从 m到n的路径长度不会超\\n过L。\\n图 13.4:邻接矩阵的属性。 a)图示例。 b)邻接矩阵 A中的位置 (m, n)表示从节点 m到节点 n\\n的单步路径数量。 c)平方后的邻接矩阵 A2中的位置 (m, n)表示从节点 n到节点 m的两步路\\n径数量。 d)代表节点六的独热向量，在面板 (a)中被高亮显示。 e)当此向量左乘 A时，结果包\\n含了从节点六出发到每个节点的单步路径数量；我们可以通过一步到达节点五、七和八。 f)当\\n此向量左乘 A2时，结果向量包含了从节点六出发到每个节点的两步路径数量；我们可以在两步\\n内到达节点二、三、四、五和八，并且能通过三种不同的路径（经过节点五、七和八）回到原点。\\n13.2.2 节点索引的置换\\n在图中，节点的编号是可以任意调整的；重新排列节点编号会改变节点数据矩阵 X\\n的列序以及邻接矩阵 A的行和列序。尽管如此，图的基本结构保持不变（见图 13.5） 。\\n这与图像和文本不同，在图像中重新排列像素会产生全新的图像，在文本中重新排列单\\n词会形成不同的句子。\\n节点编号的这种交换操作可以通过所谓的置换矩阵 P来数学描述。置换矩阵是一'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 234}, page_content='13.3.图神经网络、应用任务及损失函数 219\\n种特殊的矩阵，其每行和每列中有且仅有一个元素为 1，其他元素均为 0。当置换矩阵\\n的(m,n)位置为1时，意味着置换后的编号中 m会变成n。为了实现索引间的映射，\\n我们采用以下操作：\\nX′=XP\\nA′=PTAP, (13.1)\\n这里，P的后乘操作会改变列的顺序， PT的前乘操作则改变行的顺序。这意味着，\\n对图进行的任何处理都应当对这种编号的改变保持不变。如果不是这样，处理的结果就\\n会依赖于节点编号的具体选择。\\n图 13.5:节点索引的排列变换。 a)示例图， b)相应的邻接矩阵和 c)节点嵌入。 d)相同图形的\\n索引顺序被任意改变后的样子。 e)相应的邻接矩阵和 f)节点矩阵现在发生了变化。因此，任何\\n操作图形的网络层都应对节点的顺序排列保持中立。\\n13.3图神经网络、应用任务及损失函数\\n图神经网络是一种模型，它将节点嵌入 X和邻接矩阵 A作为输入，通过一系列 K\\n层进行传递。在每一层，节点嵌入会被更新，形成中间的“隐藏”表示 Hk，直到最终计\\n算出输出嵌入 HK。\\n在网络的起始阶段，输入节点嵌入 X的每一列仅含有关于节点自身的信息。而在\\n网络的末端，模型输出 HK的每一列则包含了节点及其在图中上下文的信息。这与单词\\n嵌入经过 Transformer 网络后的转变类似：起初代表单词本身，最后则代表单词在句子\\n中的含义。\\n13.3.1 任务与损失函数\\n我们先把图神经网络模型的详细讨论留到 13.4节，现在先介绍这些网络处理的问\\n题类型及其相关的损失函数。监督式图问题通常可分为三个类别（参见图 13.6） 。\\n图级任务 ：网络对整个图赋予一个标签或估算一个或多个值，同时利用图的结构和\\n节点嵌入。例如，我们可能想预测某分子在何温度下会液化（回归任务） ，或判断某分\\n子是否对人类有害（分类任务） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 235}, page_content='220 CHAPTER 13. 图神经网络\\n在图级任务中，输出节点嵌入会被合并（如通过求平均值）并通过线性变换或神经\\n网络映射成一个固定大小的向量。在回归任务中，使用最小二乘法损失来计算结果与实\\n际值之间的差异。对于二元分类，输出通过 Sigmoid函数处理，差异则通过二元交叉熵\\n损失计算。图属于第一类的概率可以表示为：\\nPr(y= 1|X,A ) =sig(βk+ωT\\nkHK1\\nN), (13.2)\\n其中，标量 βk和1×D向量ωk是通过学习得到的参数。通过后乘输出嵌入矩阵\\nHK和一个包含所有元素为 1的列向量，实现了将所有嵌入相加的效果，随后除以节点\\n数量N得到平均值，这一过程称为平均池化（参见图 10.11） 。\\n节点级任务 ：网络对图中每个节点分配一个标签（分类）或一个或多个值（回归） ，\\n利用图结构和节点嵌入。例如，在一个类似于图 13.2d的由3D点云构建的图中，目标\\n可能是根据节点是属于机翼还是机身来进行分类。损失函数的定义与图级任务相同，不\\n过此时是在每个节点 n上独立完成的：\\nPr(y(n)= 1|X,A ) =sigh\\nβK+ωT\\nkh(n)\\nKi\\n. (13.3)\\n边预测任务 ：网络预测节点 n与m之间是否应存在边。例如，在社交网络的场景\\n中，网络可能预测两人是否相识且相互喜欢，并在是的情况下建议他们建立连接。这是\\n一个二元分类任务，需将两个节点的嵌入映射为一个表示边存在概率的单个数值。一种\\n做法是计算节点嵌入的点积，并通过 Sigmoid 函数处理以得出概率：\\nPr(ymn= 1|X,A ) =sig\\x02\\nh(m)Th(n)\\x03\\n. (13.4)\\n13.4图卷积网络 (GCN)\\n图神经网络具有多种类型，这里我们重点介绍基于空间的卷积图神经网络（ Spatial-\\nbased Convolutional Graph Neural Networks, 简称GCNs） 。GCNs之所以被视为卷积\\n网络，是因为它们更新节点时会综合周围节点的信息。这种做法引入了关系归纳偏置\\n（relational inductive bias ） ，即偏向于优先考虑邻近节点的信息。它们被称为基于空间\\n的，是因为使用了图的原始结构，与此相反，基于频谱的方法（ Spectral-based methods ）\\n则在傅里叶域进行卷积处理。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 235}, page_content='的，是因为使用了图的原始结构，与此相反，基于频谱的方法（ Spectral-based methods ）\\n则在傅里叶域进行卷积处理。\\nGCN的每一层都是一个带参数 Φ的函数F[·]，它接收节点嵌入和邻接矩阵作为输\\n入，并产出新的节点嵌入。因此，网络的表示可以是：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 236}, page_content='13.4.图卷积网络 (GCN) 221\\n图 13.6:图处理的常见任务。在每个案例中，输入都是通过邻接矩阵和节点嵌入表示的图。图\\n神经网络通过将节点嵌入通过系列层进行处理。最终层的节点嵌入包含了关于节点及其图中上\\n下文的信息。 a)图分类，节点嵌入被合并（如通过平均）后映射到一个固定大小向量，再通过\\nsoftmax 函数产生类别概率。 b)节点分类，每个节点嵌入分别用作分类基准（青色和橙色表示\\n分配的节点类别） 。 c)边预测，相邻边的节点嵌入被合并（如通过点积）来计算一个数字，通过\\nsigmoid函数映射产生一个概率表示缺失边是否应存在。\\nH1=F[X,A,ϕ 0]\\nH2=F[H1,A,ϕ 1]\\nH3=F[H2,A,ϕ 2]\\n...\\nHK=F[HK−1,A,ϕ K−1], (13.5)\\n其中X表示输入， A代表邻接矩阵， Hk包含了第k层的更新节点嵌入，而 ϕk指\\n的是从第k层到第k+ 1层的映射参数。\\n13.4.1 等变性与不变性\\n正如我们先前所指出的，图中的节点索引是随意的，节点索引的任何排列变换都不\\n会改变图本身的结构。因此，任何模型都必须遵守这一性质。这就要求每一层对节点索'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 237}, page_content='222 CHAPTER 13. 图神经网络\\n引的排列变换保持等变性（ equivariance ） （参见第 10.1节） 。换言之，如果我们对节点\\n索引进行排列，各阶段的节点嵌入将以同样的方式进行排列。用数学语言表示，如果 P\\n是一个排列矩阵，那么我们必须满足：\\nHk+1P=F[HkP,PTAP,ϕ k]. (13.6)\\n对于节点分类和边预测任务，输出同样需要对节点索引的排列保持等变性。然而，\\n对于图级任务，由于最终层聚合了整个图的信息，输出对节点顺序应保持不变性（ in-\\nvariance） 。实际上，等式 13.2中的输出层就实现了这一点：\\ny=sig[βK+ωT\\nkHK1\\nN] =sig[βK+ωT\\nkHKP1/N], (13.7)\\n适用于任何排列矩阵 P（参见问题 13.6） 。\\n这一概念与图像处理领域的情况相呼应，其中图像的分割应对几何变换保持等变\\n性，而图像分类则应保持不变性（参见图 10.1） 。虽然卷积和池化层能在一定程度上针\\n对平移实现这些性质，但目前尚无方法可以确切保证对于更广泛的变换实现完全的等变\\n性或不变性。然而，在图处理领域，我们可以定义网络以确保对节点排列的等变性或不\\n变性。\\n13.4.2 参数共享\\n第10章指出，对图像使用全连接网络（ Fully Connected Networks ）并不合理，因\\n为这样做要求网络必须在图像的每一个位置独立学习识别对象。作为替代，我们采用卷\\n积层（Convolutional Layers ） ，它能够以统一的方式处理图像中的每个位置。这种做法\\n不仅减少了模型的参数量，还引入了归纳偏置（ Inductive Bias ） ，迫使模型均等对待图\\n像的每个部分。\\n对图中的节点也适用相同的逻辑。理论上，我们可以为每个节点设计一个拥有独立\\n参数的模型。但这会导致网络需要在每个位置独立解释图中的连接含义，并且训练需要\\n大量具有相同拓扑结构的图。相反，我们构建了一种在每个节点处使用相同参数的模\\n型，这样做不仅减少了参数的数量，还能使得在整个图中每个节点处学习到的知识得以\\n共享。\\n回顾一下，卷积操作（根据方程 10.3）是通过从其邻域中获取加权信息的总和来更\\n新变量。这个过程可以理解为每个邻居向目标变量发送信息，然后通过汇总这些信息来\\n进行更新。在处理图像时，邻居是来自当前位置周围固定大小区域内的像素，这使得每'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 237}, page_content='新变量。这个过程可以理解为每个邻居向目标变量发送信息，然后通过汇总这些信息来\\n进行更新。在处理图像时，邻居是来自当前位置周围固定大小区域内的像素，这使得每\\n个位置的空间关系保持不变。然而，在图这种数据结构中，每个节点可能有不同数目的\\n邻居，且它们之间缺乏一致的空间关系；即不存在一个统一的规则来区分来自节点“上\\n方”与“下方”的信息，因为图中根本就没有明确的“上”和“下”的概念。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 238}, page_content='13.4.图卷积网络 (GCN) 223\\n13.4.3 GCN 层的实例\\n这番思考促成了简单的 GCN层设计（参见图 13.7） 。在第k层的每个节点 n，我\\n们通过累加其邻居节点的节点嵌入 h来聚合信息：\\nagg[n,k] =X\\nm∈ne[n]h(m)\\nk, (13.8)\\n这里ne[n]返回节点n的邻居索引集合。接着，我们对当前节点的嵌入 h(n)\\nk以及\\n聚合后的值应用线性变换 Ωk，加上偏置项 βk，并将结果通过非线性激活函数 a[·]处理，\\n该函数对其向量参数的每一元素独立作用：\\nh(n)\\nk+1=ah\\nβk+ Ω k·h(n)\\nk+ Ω k·agg[n,k]i\\n. (13.9)\\n通过观察矩阵与向量后乘所得列的加权和，我们可以更为简洁地描述这一过程。邻\\n接矩阵A中第n列在邻居对应的位置上为 1，因此，如果我们把节点嵌入组合成 D×N\\n矩阵Hk并与邻接矩阵 A后乘，得到的结果的第 n列就是agg[n,k]。如此，节点更新公\\n式变为：\\nHk+1=a[βk1T+ Ω kHk+ Ω kHkA]\\n=a[βk1T+ Ω kHk(A+I)], (13.10)\\n这里的1是一个包含全 1的N×1向量。非线性激活函数 a[·]对其矩阵参数中的\\n每一元素独立应用。\\n这种层设计满足了我们的设计准则：它对节点索引的排列具有等变性，能够处理任\\n意数量的邻居，通过利用图的结构来提供关系归纳偏置，并在整个图中共享参数。\\n图 13.7:简易图 CNN层。 a)输入图包括结构（体现在邻接矩阵 A中，未显示）和节点嵌入（存\\n于 X的列中） 。 b)第一隐藏层的每个节点通过 (i)聚合邻近节点形成单向量， (ii)应用线性变换\\nω0到聚合节点上， (iii)对原节点应用相同线性变换 ω0，(iv)这些相加后加上偏置 β0，并最终\\n(v)应用非线性激活函数 a[•]如 ReLU。c)此过程在后续层重复（但每层用不同参数） ，直至在\\n网络末端产出最终嵌入。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 239}, page_content='224 CHAPTER 13. 图神经网络\\n13.5案例分析：图形分类\\n我们现在将这些思想综合起来，描述一个网络，该网络用于判断分子是有毒还是无\\n害。网络的输入包括邻接矩阵 A和节点嵌入矩阵 X。邻接矩阵 A∈RN×N基于分子的\\n结构。节点嵌入矩阵 X∈R118×N的每列是一个表示周期表中的 118个元素是否出现的\\n一热向量（ One-hot Vector ） 。简单来说，这些向量的长度为 118，除了对应元素的位置\\n置为1外，其余各位置均为 0。节点嵌入可以通过首个权重矩阵 Ω0∈RD×118转换成任\\n意维度D。\\n网络方程如下：\\nH1=a[β01T+ Ω 0X(A+I)]\\nH2=a[β11T+ Ω 1H1(A+I)]\\n...\\nHK=a[βK−11T+ Ω K−1Hk−1(A+I)]\\nf[X,A, Φ] =sig[βK+ωKHK1/N], (13.11)\\n其中网络输出 (f[X,A, Φ]是一个单值，用于决定分子是否有毒（参见方程 13.2） 。\\n13.5.1 批量训练方法\\n给定I个训练图{Xi,Ai}及其相应的标签 yi，我们可以通过使用随机梯度下降\\n（SGD）和二元交叉熵损失（ Binary Cross-Entropy Loss ） （参见方程 5.19）来学习参数\\n集Φ ={βk,Ωk}K\\nk=0。无论是全连接网络、卷积网络还是 Transformers ，它们都利用了现\\n代硬件的并行计算能力，可以同时处理一批训练示例。为此，批次中的元素会被合并成\\n一个更高维度的张量（见第 7.4.2节） 。\\n然而，每个图的节点数可能不同。因此， Xi和Ai矩阵的尺寸亦各不相同，无法直\\n接合并成 3D张量。\\n幸运的是，有一个简单的策略能让我们并行处理整批数据。该批次中的图被视作一\\n个单一大图中的离散组成部分。网络随后可以作为单一实例的网络方程来运行。仅在各\\n自的图上执行平均池化操作，从而为每个图生成一个独立的表示，这个表示之后可以被\\n用于损失函数的计算。\\n13.6归纳式 vs.转导式模型\\n到目前为止，本书介绍的所有模型均采用了归纳学习方法：通过一个含有标签数据\\n的训练集来探索输入与输出之间的关联，进而将这种关联应用到新的测试数据上。这可\\n以理解为，我们在学习一个将输入映射到输出的规则，并在其他场合使用这一规则。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 240}, page_content='13.7.案例分析：节点分类 225\\n而转导学习模型则不同，它同时考虑已标记和未标记的数据。该模型并不生成一个\\n具体的规则，而是直接为未知输出分配标签。这种方法有时被称为半监督学习，其优势\\n在于能够利用未标记数据中的模式来辅助决策。不过，它也存在缺点，即当新增未标记\\n数据时，模型需要重新训练。\\n这两种问题在处理图数据时尤为常见（见图 13.8） 。有时，我们拥有大量已标记的\\n图数据，通过学习这些数据与其标签之间的映射关系。例如，我们可能会有多个分子图，\\n每个图根据分子是否对人类有害进行标记。我们学习这种从图到有害 /无害标签的映射\\n规则，并将其应用于新分子。但在某些情况下，我们面对的是一个庞大的单体图，如科\\n学论文引用网络图，其中一些节点按领域（如物理、生物等）进行标记，而我们希望为\\n其他节点也进行标记。在这种情况下，训练数据和测试数据是密切相关的。\\n图级任务仅出现在有训练和测试数据的归纳学习场景中。不过，无论是在归纳还是\\n转导学习环境下，节点级任务和边预测任务均可能发生。在转导学习中，损失函数旨在\\n最小化模型输出与已知真值之间的差异。通过执行前向传播并对未知真值的情况下获得\\n的结果进行预测，从而计算出新的预测结果。\\n图 13.8:归纳与演绎问题。 a)归纳设置中的节点分类任务。给定一组 I训练图，节点标签（橙\\n色和青色）已知。训练后，给定测试图，需为每个节点分配标签。 b)演绎设置中的节点分类。存\\n在一个大图，部分节点标签（橙色和青色）已知，其他未知。训练模型以正确预测已知标签，然\\n后预测未知节点的标签。\\n13.7案例分析：节点分类\\n作为另一个示例，让我们来看一个在转导学习环境下的二分类节点任务。我们从一\\n个包含数百万节点的商用规模图开始。部分节点已有明确的二元标签，我们的目标是为\\n剩余的未标记节点进行标签分配。网络的架构在很大程度上与前述示例相似（参见方程\\n13.11） ，但采用了一个不同的最终层来产生一个 1×N大小的输出向量：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 241}, page_content='226 CHAPTER 13. 图神经网络\\nf[X,A, Φ] =sig[βK1T+ωKHK], (13.12)\\n这里的函数 sig[·]对输入行向量的每一个元素独立应用 sigmoid函数。我们继续使\\n用二元交叉熵损失函数，但仅限于那些我们已知地面真值标签 y的节点。值得注意的\\n是，方程 13.12实际上是将方程 13.3中的节点分类损失函数向量化了。\\n训练这样规模的图神经网络面临着两个主要问题。首先，从逻辑上讲，训练如此庞\\n大的图神经网络颇具挑战。考虑到我们需要在前向传播过程中为每层网络存储节点嵌\\n入，这意味着需要存储和处理的数据量将是整个图数据量的数倍，这在实践中可能并不\\n现实。其次，由于我们只处理一个单一图，如何执行随机梯度下降并不直观。如果只有\\n一个单一实体，我们应该如何组织批处理呢？\\n13.7.1 选择批次\\n在训练过程中形成批次的一个方法是，每一步随机选取一部分已标记的节点。每个\\n节点依赖于其上一层的邻节点，这些邻节点又依赖于它们前一层的邻节点，因此每个节\\n点都有一个相当于接收区的范围（见图 13.9） 。这个接收区的大小被定义为 k-跳邻域。\\n因此，我们可以通过使用包含批次节点的 k-跳邻域联合而成的图来进行一次梯度下降；\\n其他输入节点则不参与此过程。\\n图 13.9:图神经网络的感受野。考虑第二隐藏层中的橙色节点（右侧） ，它从第一隐藏层的 1-跳\\n邻域节点（中央阴影区域）接收输入。这些第一隐藏层节点又从其邻居处接收输入，从而第二层\\n中的橙色节点接收来自 2-跳邻域（左侧阴影区域）所有输入节点的输入。图中给定节点的输入\\n区域相当于卷积神经网络中感受野的概念。\\n遗憾的是，如果图层多且连接密集，每个输入节点可能都处于每个输出节点的接收\\n范围内，这可能根本不会缩减图的规模。这就是所谓的图扩展问题。解决此问题的两种\\n方法包括邻域采样和图分割。\\n邻域采样 ：通过对进入节点批次的完整图进行采样，进而在每一网络层减少连接数\\n（见图13.10） 。举个例子，我们可以从批次节点开始，随机采样一定数量的它们在前一\\n层的邻节点。然后，对它们在更前一层的邻节点进行随机采样，以此类推。尽管图的规\\n模每增加一层而扩大，但这种增长是在可控范围内的。每个批次的处理都是独立进行\\n的，因此即便是相同的批次被选中两次，参与的邻节点也会有所不同。这种做法也类似'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 241}, page_content='模每增加一层而扩大，但这种增长是在可控范围内的。每个批次的处理都是独立进行\\n的，因此即便是相同的批次被选中两次，参与的邻节点也会有所不同。这种做法也类似\\n于dropout（第9.3.3节）的操作，增加了一定的规则化效果。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 242}, page_content='13.8.图卷积网络的构建层 227\\n图 13.10:邻域采样技术。 a)在大型图中形成批次的一种方法是，从输出层选择一小部分已标记\\n的节点（此例中，仅选择第二层的一个节点） ，接着向后追溯直到找到 K-跳邻域内的所有节点。\\n只需此子图即可训练该批次。然而，如果图高度密集连接，可能会涉及图的大部分。 b)一个解决\\n策略是采用邻域采样。从最终层向前追溯时，我们在前一层选择一小部分邻居（此例中为三个） ，\\n并对这些邻居的邻居执行相同操作，以此减少训练批次所需图的规模。所有图示中，亮度等级表\\n示距离原始节点的远近。\\n图分割：另一种方法是在处理之前将原图聚类成彼此不连通的节点子集（即，各自\\n独立的小图） （见图 13.11） 。有标准算法用于选择这些子集，以最大化它们内部的连接\\n数。这些小图可以分别当作批次处理，或者将它们的随机子集合并为一个批次（同时恢\\n复它们在原图中的边） 。\\n采用上述任一方法形成批次后，我们可以像处理归纳问题一样训练网络参数，按需\\n将标记节点划分为训练集、测试集和验证集；我们有效地将一个转导问题转化为归纳问\\n题。在进行推断时，我们基于它们的 k-跳邻域计算未知节点的预测。不同于训练阶段，\\n这不需要存储中间表示，因此更加节省内存。\\n13.8图卷积网络的构建层\\n在之前的示例中，我们把相邻节点的信息与当前节点经过变换后的数据相加来实现\\n合并。具体做法是，将节点的嵌入矩阵 H乘以邻接矩阵加上单位矩阵 (A + I)。现在，\\n我们将探讨不同的策略，这些策略旨在改进当前嵌入与累积邻居信息的结合方式以及聚'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 243}, page_content='228 CHAPTER 13. 图神经网络\\n图 13.11:图的分割方法。 a)输入图。 b)通过一种原理性方法将输入图分割成多个小子图，尽\\n量减少切断的边。 c-d)现在，我们可以将这些子图作为批次在演绎学习环境下进行训练，这里展\\n示了四个可能的批次。 e)另一种方法是利用子图的组合作为批次，并重新连接它们之间的边缘。\\n若使用子图对组合，此处将有六个可能的批次。\\n合过程本身。\\n13.8.1 结合当前节点与累积邻居\\n在前述的 GCN层示例中，我们简单地通过加和的方式将累积的邻居信息 HA和当\\n前节点H结合起来：\\nHk+1=a\\x02\\nβk1T+ Ω kHk(A+I)\\x03\\n. (13.13)\\n在另一个变体中，当前节点在加入总和之前，会先乘以一个因子 (1 +ϵk)，其中ϵk\\n是一个对于每层都不同的学习参数：\\nHk+1=a\\x02\\nβk1T+ Ω kHk(A+ (1 +ϵk)I)\\x03\\n. (13.14)\\n这种方法称为“对角线增强” 。还有一种变体，它对当前节点应用了一个不同的线\\n性变换 Ψk：\\nHk+1=a\\x02\\nβk1T+ Ω kHkA+ Ψ kHk\\x03\\n=a\"\\nβk1T+ [Ω kΨk]\"\\nHkA\\nHk##\\n=a\"\\nβk1T+ Ω′\\nk\"\\nHkA\\nHk##\\n, (13.15)\\n其中 Ω′\\nk= [Ω kΨk]在上述等式的第三行被定义。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 244}, page_content='13.8.图卷积网络的构建层 229\\n13.8.2 残差连接\\n在残差连接的应用中，邻居的聚合表示会先进行变换并通过激活函数处理，然后再\\n与当前节点进行加和或连接。对于后一种情况，对应的网络方程如下：\\nHk+1=a\\x02\\nβk1T+ Ω kHkA\\x03\\n(13.16)\\n13.8.3 Mean aggregation\\n尽管上述方法通过对节点嵌入进行加和来汇总邻居信息，我们还有其他方式来组合\\n这些嵌入数据。有时候，与其简单求和，不如计算邻居的平均值，尤其是在嵌入信息的\\n重要性超过结构信息时更是如此，因为这样做不会使得邻域贡献的大小依赖于邻居的数\\n量：\\nagg[n] =1\\n|ne[n]|X\\nm∈ne[n]hm, (13.17)\\n这里ne[n]表示的是包含第 n个节点所有邻居索引的集合。通过引入一个对角线为\\nN×N的度数矩阵 D，方程13.17可以优雅地用矩阵形式表达出来。这个矩阵的每个非\\n零元素代表了相应节点的邻居数目。从而，在逆矩阵 D−1中，每个对角线元素就是我们\\n计算平均值所需的分母。据此，新的 GCN层可以表示为：\\nHk+1=a\\x02\\nβk1T+ Ω kHk(AD−1+I)\\x03\\n. (13.18)\\n13.8.4 Kipf 归一化\\n在基于平均聚合的图神经网络设计中， Kipf归一化是一个特殊的变体，它不仅考虑\\n节点自身，还包括其邻居节点在内进行平均计算。通过 Kipf归一化，节点的表示总和\\n按如下方式规范化：\\nagg[n] =X\\nm∈ne[n]hmp\\n|ne[n]||ne[m]|, (13.19)\\n这样做的目的是对那些连接较多、因而提供的信息较少独特性的节点，给予较低的\\n权重。这个思想也可以利用度矩阵 D，以矩阵形式精确表达：\\nHk+1=a\\x02\\nβk1T+ Ω kHk(D−1/2AD−1/2+I)\\x03\\n. (13.20)\\n13.8.5 最大池化聚合\\n作为对节点排列不变性的另一种处理方式，最大池化聚合通过计算邻居节点嵌入向\\n量中的最大值来实现。最大池化的操作定义如下：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 245}, page_content='230 CHAPTER 13. 图神经网络\\nagg[n] =max\\nm∈ne[n][hm], (13.21)\\n这里的max[·]操作符选取当前节点 n的所有邻居向量 hm中每个元素的最大值。\\n13.8.6 通过注意力机制聚合\\n我们之前讨论的聚合方法或是平等考虑每个邻居节点的贡献，或是根据图的结构特\\n性来加权。与之不同，图注意力网络层的权重是基于节点数据动态计算的。首先，对当\\n前节点的嵌入进行线性变换：\\nH′\\nk=βk1T+ Ω kH. (13.22)\\n接下来，计算变换后节点嵌入之间的相似度 smn，方法是将它们成对连接，与一组\\n学习得到的参数 ϕk做点积，然后应用激活函数：\\nsmn=a\"\\nϕT\\nk\"\\nh′\\nm\\nh′\\nn##\\n. (13.23)\\n这个过程得到的相似度值被存放在一个 N×N的矩阵S中，每个元素代表一个节\\n点与其他所有节点的相似度。类似于自注意力机制中的点积计算，每个输出嵌入的注意\\n力权重经过 softmax操作归一化，使得权重为正且和为一。但是，只有当前节点及其邻\\n居的相似度才会被考虑。这些注意力权重随后被用于调整变换后的嵌入数据：\\nHk+1=a[H′\\nk·Softmask [S,A +I]], (13.24)\\n其中a[·]表示另一个激活函数。 Softmask [·,·]函数通过对 S的每列应用 softmax操\\n作并将A+I为零的位置设为负无穷，从而计算出注意力权重，确保只有邻居节点的注\\n意力被考虑。\\n这与Transformer 中的自注意力机制非常相似，但有三个关键区别： (i)键、查询和\\n值在此处是相同的， (ii)相似度的计算方法有所不同， (iii)注意力被限制在节点及其邻\\n居之间。与 Transformer 一样，可以通过并行运行多个“头”并将结果结合起来，来扩\\n展这一机制。\\n13.9边图\\n到目前为止，我们的讨论主要集中在节点嵌入上，随着它们在网络中的传播，节点\\n嵌入逐渐演化，最终反映了节点及其在图中的上下文信息。现在，我们将注意力转向图\\n中边上的信息。\\n边图（又称为伴随图或线图）提供了一种适应处理边嵌入的方法。在这种图表示法\\n中，原图的每条边都被视为一个新的节点，原图中任意两条有共同节点的边在边图中构'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 246}, page_content='13.9.边图 231\\n成一条边（如图 13.13所示） 。通常情况下，原始图可以从其边图中恢复，这意味着我们\\n可以在这两种图表示之间自由转换。\\n处理边嵌入时，图被转换成它的边图。接下来，我们采用与处理节点嵌入相同的技\\n术：聚合来自新节点邻居的信息，并将其与当前的表示相结合。当同时存在节点和边嵌\\n入时，我们能够在这两种图表示之间进行转换。如此，存在四种更新方式（节点更新节\\n点，节点更新边，边更新节点，以及边更新边） ，可以根据需要轮换使用。或者，通过一\\n些小的调整，可以让节点同时根据节点和边的信息进行更新。\\n图 13.12:图卷积网络、点积注意力机制与图注意力网络的比较。在各自情况中，机制将存储在\\nD×N矩阵 X中的大小为 D的 N个嵌入映射到同等大小的输出。 a)图卷积网络通过应用线性\\n变换 X′= ΩX至数据矩阵。接着基于邻接矩阵计算变换数据的加权和，加入偏置 β，并通过\\n激活函数处理结果。 b)自注意力机制的输出也是变换输入的加权和，但此时权重基于数据本身，\\n通过注意力矩阵计算。 c)图注意力网络融合了这两种机制，其权重既基于数据计算，也参照邻\\n接矩阵。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 247}, page_content='232 CHAPTER 13. 图神经网络\\n图 13.13:边图创建过程。 a)具有六个节点的图。 b)为创建边图，我们为原图中的每条边分配一\\n个新节点（青色圆圈） ， c)如果这些新节点代表的边在原图中连接至相同节点，则它们之间建立\\n连接。\\n13.10总结\\n图是由一系列节点组成的，这些节点通过边连接。节点和边都可以携带数据，分别\\n对应于节点嵌入和边嵌入。许多现实世界问题可以被建模为图问题，目标是确定整个图、\\n各个节点或边的属性，或图中是否存在额外的边。\\n图神经网络是一类应用于图的深度学习模型。由于图中节点的顺序是不固定的，图\\n神经网络层必须能够适应节点索引的任意排列。空间基卷积网络是图神经网络的一族，\\n它们通过聚合一个节点的邻居信息并使用这些信息更新节点嵌入。\\n图处理的一大挑战在于，图数据通常呈现在传递性设置中，这意味着我们处理的是\\n一个部分标记的单一大图，而不是分开的训练和测试图集合。这样的图可能非常庞大，\\n给训练带来挑战，催生了采样和分区算法。边图让每条原图的边都对应一个节点。通过\\n这种表示转换，图神经网络可以更新边嵌入。\\n13.11笔记\\nSanchez-Lengeling 等人（2021年）和Daigavane 等人（2021年）撰写的文章为使用\\n神经网络进行图处理提供了良好的入门指导。近期关于图神经网络研究的综述可以参考\\nZhou等人（2020年） 、Wu等人（2020年） 、Veličković （2023年）的论文， 以及 Hamilton\\n（2020年）和Ma与Tang（2021年）的著作。 GraphEDM （Chami等人，2020年）将\\n多种现有图算法整合到了一个框架之下。在本章中，我们遵循 Bruna等人（2013年）的\\n方法，将图与卷积网络关联起来，同时指出了图神经网络与信念传播（ Dai等人，2016\\n年）和图同构测试（ Hamilton 等人，2017年）之间的强关联。 Zhang等人（2019年）专\\n门回顾了图卷积网络。 Bronstein 等人（2021年）对包括图上学习在内的几何深度学习\\n进行了全面概述。 Loukas（2020年）探讨了图神经网络能学习哪些类型的函数。\\n应用领域 ：图神经网络的应用领域包括图分类（例如， Zhang等人，2018年） 、节'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 247}, page_content='进行了全面概述。 Loukas（2020年）探讨了图神经网络能学习哪些类型的函数。\\n应用领域 ：图神经网络的应用领域包括图分类（例如， Zhang等人，2018年） 、节\\n点分类（例如， Kipf与Welling，2017年） 、边预测（例如， Zhang与Chen，2018年） 、\\n图聚类（例如， Tsitsulin 等人，2020年）以及推荐系统（例如， Wu等人，2023年） 。节'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 248}, page_content='13.11.笔记 233\\n点分类方法由 Xiao等人（2022年）综述，图分类方法由 Errica等人（2019年）综述，\\n边预测方法由 Mutlu等人（2020年）和Kumar等人（2020年）综述。\\n图神经网络 ：图神经网络最初由 Gori等人（2005年）和Scarselli 等人（2008年）\\n提出，将其定义为递归神经网络的一种泛化形式。该模型通过下面的迭代更新公式实现：\\nhn←f\\x02\\nxn,xm∈N(n),eee∈N(n),hm∈N(n),ϕ\\x03\\n, (13.25)\\n在这个公式中，每个节点的嵌入 hn通过初始嵌入 xn、相邻节点的初始嵌入 xm∈N(n)、相\\n邻边的初始嵌入 eee∈N(n)以及相邻节点的嵌入 hm∈N(n)进行更新。为了确保模型能够收\\n敛，函数f[·,·,·,·,ϕ]必须是一个收缩映射（见图 16.9） 。如果我们对这个方程沿时间维\\n度进行K步展开，并在每一步允许参数 ϕk发生变化，那么方程 13.25就会与图卷积网\\n络非常相似。后续的研究将图神经网络扩展到了使用门控循环单元（ Li等人，2016年）\\n和长短期记忆网络（ Selsam等人，2019年） 。\\n谱方法：Bruna等人（2013年）首次在傅立叶域内应用了卷积操作。傅立叶基向量\\n可以通过对图的拉普拉斯矩阵 L = D − A 进行特征分解得到，其中 D是度矩阵， A是\\n邻接矩阵。这种方法的缺点在于滤波器不是局部化的，并且对于大型图而言，分解过程\\n的计算成本过高。 Henaff等人（2015年）解决了第一个问题，他们通过使傅立叶表示保\\n持平滑（从而实现空间域的局部化） 。 Defferrard 等人（2016年）提出了 ChebNet ，它通\\n过利用切比雪夫多项式的递归性质来有效近似滤波器，既实现了空间局部化的滤波器，\\n又降低了计算量。 Kipf和Welling（2017年）进一步简化了这一过程，构造了仅使用一\\n跳邻域的滤波器，形成了一种与本章描述的空间方法相似的公式，并搭建了谱方法和空\\n间方法之间的桥梁。\\n空间方法 ：由于谱方法基于图拉普拉斯矩阵，图结构一旦改变就需重新训练模型，\\n这促使了空间方法的发展。 Duvenaud 等人（2015年）提出了一种在空间域中定义卷积\\n的方法，使用不同的权重矩阵来结合每个节点度的邻接嵌入。但这种方法存在一个缺点：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 248}, page_content='这促使了空间方法的发展。 Duvenaud 等人（2015年）提出了一种在空间域中定义卷积\\n的方法，使用不同的权重矩阵来结合每个节点度的邻接嵌入。但这种方法存在一个缺点：\\n对于连接数极多的节点，它变得不实际。扩散卷积神经网络（ Atwood与Towsley，2016\\n年）利用归一化邻接矩阵的幂来在不同尺度间混合特征，通过求和、点对点乘以权重并\\n通过激活函数来生成节点嵌入。 Gilmer等人（2017年）引入了消息传递神经网络，通\\n过从空间邻居传递消息来定义图上的卷积。 GraphSAGE （Hamilton 等人，2017年）的\\n“聚合与组合”模式适应于此框架。\\n聚合与组合 ：图卷积网络（ Kipf与Welling，2017年）对邻居和当前节点取加权平\\n均， 然后施加线性映射和 ReLU激活函数。 GraphSAGE （Hamilton 等人，2017年）对每\\n个邻居应用一个神经网络层，采用元素级最大值聚合。 Chiang等人（2019年）提出了对\\n角线增强法， 使得之前的嵌入相比邻居具有更高的权重。 Kipf与Welling（2017年）提出\\n的Kipf归一化，根据当前节点及其邻居的度来归一化邻接嵌入的和（参见方程 13.19） 。\\n混合模型网络或 MoNet（Monti等人，2017年）通过学习基于当前节点及其邻居的\\n度的权重来进一步深入。它们为每个节点关联了一个伪坐标系统，邻居的位置依赖于这\\n两个度量。然后它们基于高斯混合模型学习一个连续函数，并在邻居的伪坐标上采样以'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 249}, page_content='234 CHAPTER 13. 图神经网络\\n获取权重。这样，它们能够为任意度的节点和邻居学习权重。 Pham等人（2017年）对\\n节点嵌入及其邻居采用线性插值，每个维度都采用不同的加权组合。该门控机制的权重\\n作为数据功能而产生。\\n高阶卷积层 ：Zhou与Li（2017年）采用高阶卷积，将邻接矩阵 A替换为 ˆA=\\nMin[AL+I,1]， 其中L表示最大步长， 1为仅含1的矩阵， Min[·]对其两个矩阵参数取逐\\n点最小值；更新将所有至少存在一条长度为 L的路径的节点的贡献求和。 Abu-El-Haija\\n等人（2019年）提出了 MixHop，从邻居（使用 A矩阵） 、邻居的邻居（使用 A2）等计\\n算节点更新，并在每层将这些更新连接起来。 Lee等人（2018年）通过使用图中的小型\\n局部几何模式（如，五个节点的完全连接团）整合了来自超出直接邻居的节点的信息。\\n残差连接 ：Kipf与Welling（2017年）提出在其中原始嵌入被加到更新的嵌入上的\\n残差连接。 Hamilton 等人（2017年）将先前的嵌入与下一层的输出连接起来（参见方\\n程13.16） 。Rossi等人（2020年）展示了一种接收式网络，其中节点嵌入不仅与其邻居\\n的聚合连接，还与两步行走范围内所有邻居的聚合连接（通过计算邻接矩阵的幂） 。 Xu\\n等人（2018年）引入了跳跃知识连接，其中每个节点的最终输出由整个网络中的节点嵌\\n入连接而成。 Zhang与Meng（2019年）提出了一种称为 GResNet 的残差嵌入通用公\\n式，并研究了几种变种，在这些变种中，前一层的嵌入被添加，或输入嵌入被添加，或\\n这些的聚合版本从邻居那里添加了信息（无需进一步变换） 。\\n图神经网络中的注意力机制 ：Veličković 等人（2019年）发展了图注意力网络（图\\n13.12c） 。他们的公式使用多个注意力头， 输出以对称方式组合。门控注意力网络（ Zhang\\n等人，2018年）根据数据本身对不同注意力头的输出进行加权。 Graph-BERT （Zhang\\n等人，2020年）仅使用自注意力进行节点分类；通过向数据添加位置嵌入来捕获图的结\\n构， 这类似于 Transformer 中如何捕获单词的绝对或相对位置（第 12章） 。例如， 他们添'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 249}, page_content='等人，2020年）仅使用自注意力进行节点分类；通过向数据添加位置嵌入来捕获图的结\\n构， 这类似于 Transformer 中如何捕获单词的绝对或相对位置（第 12章） 。例如， 他们添\\n加了基于节点间跳数的位置信息。 排列不变性 ：在DeepSets 研究中， Zaheer等人（2017\\n年）提出了一种处理集合的通用排列不变操作。 Janossy池化（Murphy等人，2018年）\\n认为许多函数并不具备排列等变性，因此采用了一种对排列敏感的函数，并对多个排列\\n的结果进行平均。\\n边图：边图、线图或邻接图的概念最早由 Whitney（1932年）提出。 Kearnes 等人\\n（2016年）提出了一种更新节点嵌入的“编织”层概念，包括从节点嵌入更新到节点嵌\\n入、从边嵌入更新到节点嵌入、从边嵌入更新到边嵌入，以及从节点嵌入更新到边嵌\\n入，但此过程不涉及相邻节点。 Monti等人（2018年）引入了双原图 -边图卷积神经网络\\n（CNN） ，这是一种现代化的 CNN架构，它在原图和边图之间交替进行更新。\\n图神经网络的能力 ：Xu等人（2019年）认为神经网络应该能区分不同的图结构；\\n如果两个图尽管具有相同的初始节点嵌入但不同的邻接矩阵，却被映射到相同的输出，\\n这是不应发生的。他们识别出了以前的方法（如 GCNs（Kipf & Welling ，2017年）和\\nGraphSAGE （Hamilton 等人，2017a年） ）无法区分的图结构。他们开发了一种具有与\\nWeisfeiler-Lehman 图同构测试（ Weisfeiler & Leman ，1968年）同等区分能力的强大架'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 250}, page_content='13.11.笔记 235\\n构，这种测试能够区分大范围的图结构。这一成果的图同构网络基于下列聚合操作：\\nh(n)\\nk+1=mlp2\\n4(1 +ϵk)h(n)\\nk+X\\nm∈N(n)h(m)\\nk3\\n5. (13.26)\\n批处理：关于图卷积网络的原始论文（ Kipf & Welling ，2017年）采用了全批量梯度下降\\n法，这在训练过程中的内存需求与节点数量、嵌入大小以及层数成正比。从那时起，提\\n出了三种方法以减少内存需求并为转导设置中的随机梯度下降（ SGD）创建批次：节点\\n采样、层采样和子图采样。\\n节点采样方法从随机选择一组目标节点开始，然后逆向穿过网络，在每个阶段添加\\n一部分接收场中的节点。 GraphSAGE （Hamilton 等人，2017a年）提出了图 13.10b所\\n示的固定数量邻域样本方法。 Chen等人（2018b年）引入了一种方差减少技术，但它依\\n然依赖于节点的历史活动记录，因此内存需求仍然较高。 PinSAGE （Ying等人，2018a\\n年）通过从目标节点开始的随机游走，选择访问次数最多的 K个节点，优先连接更紧\\n密的祖先节点。\\n节点采样需要随着通过图的逆向传播增加节点数量。 层采样方法 通过直接在每层独\\n立采样接收场来解决此问题。层采样的例子包括 FastGCN （Chen等人，2018a年） 、自\\n适应采样（ Huang等人，2018b年）和层依赖的重要性采样（ Zou等人，2019年） 。\\n子图采样方法随机抽取子图或将原始图分成多个子图。这些子图随后作为独立的数\\n据实例进行训练。这些方法的示例包括 GraphSAINT （Zeng等人，2020年） ，它在训练\\n过程中通过随机游走采样子图，然后在子图上运行完整的 GCN，同时校正小批次的偏\\n差和方差。 ClusterGCN （Chiang等人，2019年）在预处理阶段将图划分为多个簇（通\\n过最大化嵌入使用率或批内边数）并随机选择簇形成小批次。为了增加随机性，他们训\\n练了这些簇的随机子集及其相互间的边（参见图 13.11） 。\\nWolfe等人（2021年）提出了一种分布式训练方法，该方法通过不同方式划分特\\n征空间，来并行训练更窄的 GCNs。有关采样图的更多信息可以在 Rozemberczki 等人\\n（2020年）的研究中找到。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 250}, page_content='征空间，来并行训练更窄的 GCNs。有关采样图的更多信息可以在 Rozemberczki 等人\\n（2020年）的研究中找到。\\n正则化与标准化 ：Rong等人（2020年）提出了一种称为 DropEdge 的技术，通过\\n掩盖邻接矩阵在每次训练迭代中随机丢弃图中的边缘。这可以应用于整个神经网络，也\\n可以在每一层中分别实施（分层 DropEdge ） 。从某种程度上说，这与 dropout类似，因\\n为它断开了数据流动中的连接，但也可以看作是一种数据增强方法，因为改变图结构类\\n似于扰乱数据。 Schlichtkrull 等人（2018年） 、Teru等人（2020年）和Veličković 等人\\n（2019年）也提出了作为一种类似于 dropout的正则化手段，从图中随机丢弃边缘的方\\n法。节点采样方法（ Hamilton 等，2017a；Huang等，2018b；Chen等，2018a）也被视\\n为一种正则化手段。 Hasanzadeh 等人（2020年）提出了一个名为 DropConnect 的通用\\n框架，整合了上述多种方法。\\n图神经网络还提出了许多标准化方案，包括 PairNorm （Zhao & Akoglu ，2020年） 、\\n权重标准化（ Oono & Suzuki ，2019年）、可微分群标准化（ Zhou等，2020b年）和\\nGraphNorm （Cai等，2021年） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 251}, page_content='236 CHAPTER 13. 图神经网络\\n多关系图 ：Schlichtkrull 等人（2018年）针对多关系图（即，具有多种边类型的图）\\n提出了图卷积网络的变体。他们的方案通过使用不同参数，分别从每种边类型聚合信息。\\n若边类型众多，参数数量可能会很大，为了解决这一问题，他们建议每种边类型采用一\\n组基础参数集的不同权重。\\n层级表示与池化 ：图像分类的 CNN在网络深入时，逐渐减少表示的大小，但增加\\n通道数。然而，本章节的图分类 GCN保持完整图结构直至最后一层，再组合所有节点\\n计算最终预测。 Ying等人（2018b年）提出了 DiffPool，通过将图节点聚类，使得图随\\n网络深度增加而逐渐缩小，这一过程是可微分的，因此可以学习。这既可以基于图结构\\n单独进行，也可以基于图结构及其嵌入进行自适应完成。其他池化方法包括 SortPool\\n（Zhang等，2018b年）和自注意力图池化（ Lee等，2019年） 。Grattarola 等人（2022\\n年）对图神经网络的池化层进行了比较。 Gao & Ji （2019年）基于 U-Net提出了一种图\\n的编解码器结构（参见图 11.10） 。\\n几何图：MoNet模型（Monti等，2017年）能够利用几何信息，因为邻近节点有\\n明确的空间位置。他们学习一个高斯混合函数，并基于邻居的相对坐标进行采样。这样，\\n他们能够基于相对位置为邻近节点加权，就像传统的卷积神经网络一样，尽管这些位置\\n并非固定不变。测地线 CNN（Masci等，2015年）和各向异性 CNN（Boscaini 等，2016\\n年）都适配了流形（即，表面）的卷积，如通过三角网格表示。它们在当前节点周围的\\n平面上定义了坐标系统，并将表面近似为平面。\\n过平滑与暂停动画 ：与其他深度学习模型不同，直到最近，图神经网络并未因深度\\n增加而显著受益。实际上，原始 GCN论文（Kipf & Welling ，2017年）和GraphSAGE\\n（Hamilton 等，2017a年）均仅使用两层， 而 Chiang等人（2019年）训练了五层 Cluster-\\nGCN，在PPI数据集上取得了最佳性能。一个可能的解释是过平滑现象（ Li等，2018c\\n年） ；每一层网络融合了更广阔邻域的信息，可能最终导致（重要的）局部信息消散。事'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 251}, page_content='GCN，在PPI数据集上取得了最佳性能。一个可能的解释是过平滑现象（ Li等，2018c\\n年） ；每一层网络融合了更广阔邻域的信息，可能最终导致（重要的）局部信息消散。事\\n实上（Xu等，2018年）证明了一个节点对另一个节点的影响与通过 K步随机游走到达\\n该节点的概率成正比。随着 K增加，这接近于图上游走的平稳分布，导致局部邻域信息\\n被淡化。\\nAlon & Yahav （2021年）为网络深度增加不改善性能提供了另一种解释。他们认\\n为，深度增加允许从更长路径聚合信息。然而，实际上，邻居数量的指数增长造成了一\\n个瓶颈，即太多信息被“压缩”进固定大小的节点嵌入中。\\nYing等人（2018a年）还指出，当网络深度超过某一限度时，梯度不再回传，导致\\n训练和测试数据的学习失败。他们将这种现象称为“暂停动画” 。这类似于在卷积神经\\n网络中盲目添加多层（参见图 11.2） 。他们提出了一系列残差连接，允许训练更深的网\\n络。梯度消失问题（第 7.5节）也被 Li等人（2021b年）认为是一个限制。\\n最近，通过使用各种形式的残差连接（ Xu等，2018年；Li等，2020a年；Gong等，\\n2020年；Chen等，2020b年；Xu等，2021a年） ，成为可能训练更深的图神经网络。 Li\\n等人（2021a年）使用一个可逆网络训练了一个超过 1000层的先进模型，以减少训练的\\n内存需求（见第 16章） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 252}, page_content='13.12.习题 237\\n13.12习题\\n问题13.1为图13.14中的两幅图绘制邻接矩阵。\\n问题13.2*根据下列邻接矩阵绘制对应的图形：\\nA1=2\\n666666666640 1 0 0 0 0\\n1 0 1 1 1 0\\n0 1 0 0 1 1\\n0 1 0 0 0 1\\n0 1 1 0 0 0\\n0 0 1 1 0 03\\n77777777775\\n及\\nA2=2\\n666666666640 1 1 0 0 1\\n0 0 1 1 0 0\\n1 1 0 0 0 0\\n1 0 0 0 1 1\\n0 1 0 1 0 0\\n1 0 0 1 0 13\\n77777777775\\n问题13.3*考虑图13.14中的两幅图，探讨以下两种情况下从节点一到节点二的走\\n法数量： (i)三步之内； (ii)七步之内。\\n问题13.4在图13.4c中，A2对角线上的数字表示每个对应节点连接的边数。请解\\n释这一现象。\\n问题13.5是哪个排列矩阵实现了图 13.5a–c与图13.5d–f之间的转换？\\n问题13.6证明以下等式成立：\\nsig[βk+ωkHk1] =sig[βk+ωkHKP1], (13.27)\\n其中P是一个N×N的排列矩阵（一个矩阵，除了每行和每列恰好一个条目为一以外，\\n其余全为零） ， 1是一个N×1的全一向量。\\n问题13.7*考虑以下简单的 GNN层：\\nHk+1=GraphLayer [Hk,A]\\n=a2\\n664βk1T\\nΩk\"\\nHk\\nHkA#3\\n775, (13.28)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 253}, page_content='238 CHAPTER 13. 图神经网络\\n其中H是一个D×N矩阵，其列包含 N个节点嵌入， A是N×N的邻接矩阵，\\nβ是偏差向量， Ω是权重矩阵。证明该层对节点顺序的排列是等变的，即满足以下条件：\\nGraphLayer [Hk,A]P=GraphLayer [HkP,PTAP], (13.29)\\n其中P是一个N×N的排列矩阵。\\n问题13.8对图13.14中的每幅图，其度矩阵 D分别是什么？\\n问题13.9 GraphSAGE 的作者(Hamilton et al., 2017a) 提出一种池化方法，在该方\\n法中，节点嵌入与其邻居的嵌入一起被平均计算，具体如下：\\nagg[n] =1\\n1 +|N(n)|0\\n@hn+X\\nm∈N(n)hm1\\nA. (13.30)\\n说明如何利用线性代数方法，同时对 D×N嵌入矩阵H中所有节点嵌入执行此操\\n作。需要使用邻接矩阵 A和度矩阵D。\\n问题13.10*设计一个基于点积自注意力的图注意力机制，并按照图 13.12的风格画\\n出其机制示意图。\\n问题13.11*绘制图13.15a所示图的边图。\\n问题13.12*根据图13.15b的边图，绘制相应的节点图。\\n问题13.13对于一般的无向图，阐述节点图的邻接矩阵与对应边图的邻接矩阵之间\\n的关系。\\n问题13.14*设计一个层，该层根据节点的邻接节点嵌入 {hm}m∈N(n)和邻接边嵌入\\n{em}m∈E(n)来更新节点嵌入 hn。设计时需考虑边嵌入的维度可能与节点嵌入的维度不\\n一致的情况。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 254}, page_content='Chapter 14\\n无监督学习\\n第2章至第9章详细讲解了监督学习的流程。在这些章节中，我们定义了模型，这\\n些模型能将观测数据 x映射到输出值 y，并引入了损失函数来衡量这种映射对于训练数\\n据集xi,yi的准确性。随后，我们讨论了如何对这些模型进行拟合及评估其性能。第 10\\n章到第13章则引入了采用参数共享和支持并行计算路径的更为复杂的模型架构。\\n无监督学习模型的核心特点在于，它们是在没有标签的情况下，从观察数据集 xi学\\n习得到的。所有的无监督模型都有这一共同点，但它们的目标却各不相同。这些模型可\\n以用来生成数据集中的新样本，或者对样本进行操作、去噪、插值和压缩。它们还能够\\n揭示数据集的内在结构（例如，通过把数据集分成几个有内在联系的群体）或者判断新\\n样本是属于原有数据集还是异常值。\\n本章将介绍无监督学习模型的系统分类，并探讨模型理想的属性及其性能评估方\\n法。紧接着的四章将分别深入讨论四种特殊模型：生成对抗网络（ GANs） 、变分自编码\\n器（VAEs） 、归一化流（ Normalizing Flows ）和扩散模型（ Diffusion Models ） 。在此之\\n前，大部分相关的数学知识都已在文中提及。但是，后续四章需要对概率学有深入的理\\n解，附录 C提供了所需的相关背景知识。\\n14.1无监督学习模型的分类\\n在无监督学习的一个常见策略中，我们定义了数据示例 x与一组未见的潜变量 z之\\n间的映射关系。这些潜变量揭示了数据集的底层结构，它们的维度通常低于原始数据；\\n因此，潜变量 z可以看作是捕获了数据示例 x核心特征的压缩版（图 1.9-1.10） 。\\n从原理上讲，观测变量与潜变量之间的映射可以是任一方向。有的模型将数据 x映\\n射到潜变量 z。例如，著名的 k-means（k-均值）算法就是将数据 x映射到一个聚类分\\n配z∈1,2,...,K。而其他模型则是从潜变量 z映射回数据 x。在这些模型中，定义了潜\\n变量z上的分布 Pr(z)。通过(i)抽取该分布的样本及 (ii)将样本映射到数据空间 x，现\\n在可以生成新的数据示例。因此，这些模型被称为生成模型（见图 14.1） 。\\n第15至18章介绍的四种模型都是利用潜变量的生成模型。生成对抗网络（ Gener-\\n239'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 255}, page_content='240 CHAPTER 14. 无监督学习\\native Adversarial Networks ，GANs，第15章）通过使用一种使生成样本与真实样本难\\n以区分的损失函数，学会如何从潜变量 z生成数据示例 x*（图14.2a） 。\\n标准化流（ Normalizing Flows ） ，变分自编码器（ Variational Autoencoders ，VAEs）\\n和扩散模型（ Diffusion Models ） （第16至18章）属于概率生成模型。除了生成新的示\\n例外，它们还为每个数据点 x分配一个概率 Pr(x|ϕ)。这个概率取决于模型参数 ϕ，在\\n训练过程中，我们的目标是最大化观测数据 xi的概率，因此损失函数表达为负对数似\\n然的总和（图 14.2b） ：\\nL(ϕ) =−IX\\ni=1logPr (xi|ϕ). (14.1)\\n由于概率分布的总和必须为一，这种方法隐式地降低了与观测数据差距较大的示例\\n的概率。分配概率不仅提供了训练标准，其本身也极具价值；可以使用测试集上的概率\\n来量化比较两个模型，并且可以通过阈值来判断一个示例是否属于同一数据集或是异常\\n值。值得注意的是，并不是所有的概率生成模型都依赖潜变量。例如，基于自回归公式\\n（方程12.15）的变换器解码器（第 12.7节）在无标签的情况下学习，能够生成新的示\\n例，并为这些示例分配概率。\\n图 14.1:无监督学习模型分类。无监督学习指在无标签数据集上训练的模型。生成模型能够合成\\n具有与训练数据相似统计特性的新示例。其中的一个子集是基于概率的，定义了一个覆盖数据\\n的分布。我们通过从这个分布中抽样来生成新示例。潜在变量模型（ latent variable models ）建\\n立了底层解释性（ latent）变量与数据之间的映射关系，这些模型可以属于以上任何一类。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 256}, page_content='14.2.如何定义一个优秀的生成模型？ 241\\n图 14.2:拟合生成模型 a）生成对抗网络（ GANs）提供了一种生成样本（橙色点）的机制。随\\n着训练进程（从左至右） ，损失函数促使这些样本逐渐与真实示例（青色点）难以区分。 b）概\\n率模型（包括变分自编码器（ V AEs） 、规范化流（ Normalizing Flows ）和扩散模型（ Diffusion\\nModels） ）学习了训练数据上的概率分布。随着训练进程（从左至右） ，这个分布下真实示例的似\\n然性增加，可以用来抽取新样本和评估新数据点的概率。\\n14.2如何定义一个优秀的生成模型？\\n基于潜变量的生成模型应具备以下特性： -高效抽样 ：生成模型样本的过程在计算\\n上应低成本，能够充分发挥现代硬件并行处理的优势。 -高品质抽样 ：生成的样本应当\\n与模型训练所用的真实数据难以区分。 -全面覆盖 ：生成的样本应覆盖整个训练数据的\\n分布范围，仅仅生成一小部分训练样本的相似项是不足够的。 -良好的潜空间表现 ：每\\n一个潜变量 z都应对应一个可信的数据示例 x。z的平滑变动应引发 x的平滑变化。 -\\n可解释的潜空间 ：调整z的任意一个维度都应该对应于数据某个可解释特征的变化。比\\n如，在语言模型中，可能是改变话题、时态或是文本的详略程度。 -高效的概率计算 ：如\\n果模型基于概率，我们希望能够高效准确地计算新样本的概率。\\n由此，我们不禁会问：我们当前考虑的生成模型能否满足这些特性呢？虽然答案比\\n较主观，图 14.3对此提供了一些指导。尽管具体的归类可能存在争议，但大多数实践者\\n认为，没有任何一个模型能够完全满足上述所有条件。\\n图 14.3:四种生成模型的属性。生成对抗网络（ GANs）、变分自编码器（ V AEs）、规范化流\\n（Flows）以及扩散模型（ Diffusion Models ）都不完全具备理想属性的全集。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 257}, page_content='242 CHAPTER 14. 无监督学习\\n14.3性能量化\\n前一节我们讨论了生成模型所期望具备的属性。接下来，我们将探讨对生成模型成\\n功度量的量化标准。许多生成模型的实验选择了图像作为研究对象，这一选择主要得益\\n于图像数据的广泛可得性及其便于定性评价的特点。据此，一些评价指标专门针对图像\\n数据设计。\\n测试似然度：评估概率模型的一种方法是通过测试数据集的似然度进行比较。因为\\n模型可能对每个训练数据点分配极高的概率，而在这些点之间分配极低的概率，所以仅\\n通过训练数据的似然度来评估是不准确的。这样的模型虽然在训练集上似然度很高，但\\n却只能重现训练数据。测试似然度能够反映模型从训练数据中泛化的能力，以及其覆盖\\n范围；如果模型只给训练数据的一个子集分配了高概率，那么它在其他部分必然分配了\\n较低的概率，这意味着部分测试样本的概率会很低。\\n虽然测试似然度是评价概率模型的一个合理方式，但遗憾的是，它不适用于生成对\\n抗模型（ Generative Adversarial Models ，GAM） （这类模型不分配概率） ，并且对于变\\n分自编码器和扩散模型来说，估计成本高昂（尽管可以计算对数似然的下界） 。规范化\\n流（Normalizing Flows ）是唯一可以准确且高效计算似然度的模型类型。\\nInception 分数：Inception 分数（IS）专为图像设计，最理想的应用场景是在 Im-\\nageNet数据库上训练的生成模型。该分数通过一个预训练的分类模型来计算，通常是\\n“Inception ”模型，因此而得名。它基于两个准则：首先，每个生成的图像 x∗应当仅对\\n应ImageNet 数据库中的一个类别 y。因此，概率分布 Pr(yi|x∗\\ni)在正确类别上应高度集\\n中。其次，所有生成的图像集应该等概率地被分配到各个类别中，因此平均下来， Pr(y)\\n应当是平坦的。\\nInception 分数衡量了生成集上这两个分布间平均距离。如果一个分布高度集中而\\n另一个分布平坦，这个距离会很大（图 14.4） 。更具体地，它返回 Pr(yi|x∗\\ni)与Pr(y)之\\n间期望KL散度的指数：\\nIS=exp \\n1\\nIIX\\ni=1DKL[Pr(y|x∗\\ni)||Pr(y)]!\\n, (14.2)\\n其中*I*表示生成样例的数量，且有：\\nPr(y) =1\\nIIX\\ni=1Pr(y|x∗\\ni) (14.3)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 257}, page_content='1\\nIIX\\ni=1DKL[Pr(y|x∗\\ni)||Pr(y)]!\\n, (14.2)\\n其中*I*表示生成样例的数量，且有：\\nPr(y) =1\\nIIX\\ni=1Pr(y|x∗\\ni) (14.3)\\n此度量标准仅适用于 ImageNet 数据库的生成模型，对特定的分类模型较为敏感；\\n重训练这个模型可能会导致不同的数值结果。此外，它不奖励类别内部的多样性；如果\\n模型仅生成每个类别的一个逼真示例，它就会返回一个高值。\\nF réchet Inception 距离：此度量标准也是为图像而设计，用于计算生成样本与真\\n实样本分布之间的对称距离。鉴于很难具体描述任一分布（实际上，描述真实样本分布'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 258}, page_content='14.4.总结 243\\n正是生成模型的初衷） ，这个距离必须是近似的。因此， Fréchet Inception 距离通过多变\\n量高斯分布来近似这两个分布，并利用 Fréchet距离来估计它们之间的距离。\\n然而，这一度量不是基于原始数据，而是基于 Inception 分类网络中最深层激活的\\n距离。这些隐藏单元与对象类别高度相关，因此比较发生在语义层面，而忽略了图像的\\n更细节特征。这个度量标准虽然考虑了类别内的多样性，但极度依赖于 Inception 网络\\n中保留的特征信息；网络丢弃的任何信息都不会影响结果。网络丢弃的部分信息可能对\\n生成逼真样本仍然十分重要。\\n流形精确度 /召回率：Fréchet Inception 距离对样本的逼真度和多样性都敏感，但不\\n能区分这些要素。为了分离这些属性，我们考量了数据流形（即，真实样本所处的数据\\n空间子集）与模型流形（即，生成样本所在的位置）之间的重合程度。精确度是落入数\\n据流形内的模型样本比例，衡量了生成样本的逼真度。召回率是落入模型流形内的数据\\n样本比例，衡量了模型能生成的真实数据的比例（图 14.5） 。\\n为估计流形，我们在每个数据样本周围放置一个以第 k近邻距离为半径的超球体。\\n这些球体的并集近似表示了流形，可以轻易判断新点是否位于其中。这个流形也通常在\\n分类器的特征空间中计算，这既是其优点也是缺点。\\n图 14.4: Inception 分数。 a）一个预训练网络对生成图像进行分类。如果图像逼真，那么相应\\n的类别概率 P r(yi|x∗\\ni)应在正确的类别上高度集中。 b）如果模型等概率地生成所有类别，边际\\n（平均）类别概率应为平坦。 Inception 分数测量了 (a)和 (b)中分布之间的平均距离。图片来源：\\nDeng等（ 2009） 。\\n14.4总结\\n无监督模型能够在缺少标签的情况下掌握数据集的结构。这些模型中的一部分具有\\n生成性，能够创造新的数据示例。再进一步，其中的一些模型是基于概率的，不仅能生\\n成新的示例，还能对观测到的数据赋予概率。接下来四章将讨论的模型以一个已知分布\\n的潜在变量 z作为起点。随后，一个深度神经网络将潜在变量映射到观察到的数据空间。\\n我们探讨了生成模型所期望的属性，并介绍了旨在量化其性能的度量指标。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 259}, page_content='244 CHAPTER 14. 无监督学习\\n图 14.5:流形精确度 /召回率。 a）真实示例与生成模型合成样本的真实分布。 b）重叠可以通过\\n精确度（与真实示例的分布或流形重叠的合成样本的比例）和 c）召回率（与合成样本的流形重\\n叠的真实示例的比例）来概括。 d）通过取一组围绕每个样本中心的超球体的并集，可以近似合\\n成样本的流形。这里，这些球体有固定的半径，但通常基于到第 k近邻的距离确定半径。 e）真\\n实示例的流形也通过类似方法近似。 f）精确度可计算为位于样本近似流形内的真实示例的比例。\\n同样，召回率计算为位于真实示例近似流形内的样本的比例（未展示） 。根据 Kynkäänniemi 等\\n（2019）改编。\\n14.5笔记\\n热门的生成模型包括生成对抗网络 （ Generative Adversarial Networks, GANs, Good-\\nfellow等，2014） 、变分自编码器（ Variational Autoencoders, VAEs, Kingma & Welling ，\\n2014） 、 规范化流（ Normalizing Flows, Rezende & Mohamed ，2015） 、 扩散模型（ Diffusion\\nModels, Sohl-Dickstein 等，2015; Ho 等，2020） 、自回归模型（ Autoregressive Models,\\nBengio等，2000; Van den Oord 等，2016b）以及基于能量的模型（ Energy-Based Models,\\nLeCun等，2006） 。除能量模型外，本书讨论了所有这些模型。 Bond-Taylor 等（2022）\\n提供了关于生成模型的最新综述。\\n评估：Salimans 等（2016）提出了 Inception 分数，而 Heusel等（2017）提出了\\nFréchet Inception 距离，两者均基于 Inception V3 模型的Pool-3层（Szegedy等，2016） 。\\nNash等（2021）采用了该网络更早的层级，这些层级保留了更多空间信息，确保图像的\\n空间统计特征得到复制。 Kynkäänniemi 等（2019）引入了流形精度 /召回方法。 Barratt'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 259}, page_content='Nash等（2021）采用了该网络更早的层级，这些层级保留了更多空间信息，确保图像的\\n空间统计特征得到复制。 Kynkäänniemi 等（2019）引入了流形精度 /召回方法。 Barratt\\n& Sharma （2018）对Inception 分数进行了详细讨论并指出其缺陷。 Borji（2022）讨论\\n了评估生成模型不同方法的优点和缺点。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 260}, page_content='Chapter 15\\n生成对抗网络\\n生成对抗网络（ GAN）是一种无监督学习模型，其目标是创造出与训练样本集难以\\n区分的新样本。 GAN主要是用来生成新样本的一种机制，它并不建立模型数据的概率\\n分布，因此无法判断一个新数据点是否属于同一分布。\\n在GAN框架中，生成器网络通过将随机噪声映射到输出数据空间来生成样本。若\\n鉴别器网络无法区分生成样本与真实样本，则可认为这些样本是合理的。若鉴别器能识\\n别出二者的差异，则这种识别结果可以作为训练信号反馈给生成器，以提高生成样本的\\n质量。这个概念虽然简单，但 GAN的训练充满挑战：学习算法可能会出现不稳定，而且\\n虽然GAN能够生成高度逼真的样本，这并不保证它们能够覆盖所有可能的样本类型。\\nGAN已经被广泛应用于众多数据类型，包括音频、三维模型、文本、视频及图形\\n数据等。尤其在图像处理领域， GAN展现出了极高的成就，能够生成与真实图片几乎\\n无法区分的图像样本。因此，本章主要讨论的是图像合成的应用实例。\\n15.1将鉴别作为信号\\n我们的目标是生成新样本集 {x∗\\nj}，这些样本来源于与真实训练数据集 {xi}同一分\\n布。生成单个新样本 x∗\\nj的过程包括： (i)从一个简单的基础分布（如标准正态分布）中\\n选择一个潜变量 zj，然后(ii)通过参数为 θ的网络x∗=g(zj,θ)传递这些数据。此网络\\n称为*生成器*。学习过程的目标是寻找参数 θ，使得生成的样本集 {x∗\\nj}与真实数据集\\n{xi}在视觉上“相似” （参见图 14.2a） 。\\n“相似”可以有多种定义方式，但 GAN采用的原则是，样本与真实数据在统计上应\\n无法区别。为达此目的，引入了一个名为 *鉴别器*的第二网络 f(·,ϕ)，参数为ϕ。该\\n网络试图将输入分类为真实样本或生成样本。若做到这一点变得不可能，即生成样本与\\n真实样本无法区分，我们便达成了目标。若能区分，鉴别器便提供了一个信号，可用于\\n改善生成过程。\\n图15.1说明了这一方案。我们从一组真实的一维（ 1D）示例{xi}作为训练集出\\n发。每个面板展示了这些示例的不同批次的十个 {xi}10\\ni=1（青色箭头） 。为生成一批样本\\n245'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 261}, page_content='246 CHAPTER 15. 生成对抗网络\\n{x∗\\nj}，我们采用简单的生成器公式：\\nx∗\\nj=g[zj,θ] =zj+θ, (15.1)\\n其中潜变量{zj}源自标准正态分布，参数 θ使生成样本沿 x轴进行平移（见图\\n15.1） 。\\n在初始阶段， θ= 3.0，生成的样本（橙色箭头）位于真实样本（青色箭头）的左侧。\\n通过训练，鉴别器学习区分生成样本与真实样本（ sigmoid曲线显示了数据点为真实的\\n可能性） 。训练过程中，调整生成器参数 θ，以提高其样本被认为是真实的概率。这意味\\n着增加θ值，使样本向右移，达到 sigmoid曲线的较高位置。\\n我们交替更新鉴别器和生成器。图 15.1b–c显示了这个过程的两次迭代。随着时间\\n的推移，数据分类变得越来越困难，改变 θ的动力相应减弱（即， sigmoid曲线变得更\\n加平缓） 。在过程结束时，两组数据变得无法区分；此时的鉴别器表现如同随机选择，因\\n此被舍弃，留下能够生成可信样本的生成器。\\n图 15.1: GAN 机制。 a)给定一个参数化函数（生成器） ，它可以合成样本（橙色箭头）并且接收\\n一批真实样本（青色箭头） 。接着，我们对鉴别器进行训练，使其能区分真实样本与生成样本（ S\\n形曲线表示样本为真实的估计概率） 。 b)通过调整生成器的参数，降低鉴别器对样本合成性的判\\n断准确度（此处通过将橙色样本向右移动实现） 。随后更新鉴别器。 c)通过交替更新生成器和鉴\\n别器，使生成样本与真实样本变得难以区分，同时减少改变生成器的动力（即 S形函数的斜率） 。\\n15.1.1 GAN 损失函数\\n我们接下来将精确定义训练生成式对抗网络（ GAN）所用的损失函数。鉴别器\\nf(x,ϕ)接收输入x，拥有参数 ϕ，并返回一个标量值，当输入被判定为真实样本时，\\n此值较大。鉴于这是一个二分类任务，我们适用了二元交叉熵损失函数（见第 5.4节） ，\\n它的原始形式是：\\nˆϕ=argmin\\nϕ\"X\\ni(1−yi)log(1−sig[f(xi,ϕ)])−yilog(sig[f(xi,ϕ)])#\\n,(15.2)\\n这里yi∈{0,1}表示标签，而 sig[·]代表logistic sigmoid 函数（参见图 5.7） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 262}, page_content='15.1.将鉴别作为信号 247\\n在此基础上，我们假定真实样本 x的标签y= 1，生成样本 x∗的标签y= 0，因此\\n损失函数变为：\\nˆϕ=argmin\\nϕ\"X\\nj−log\\x00\\n1−sig[f(x∗\\nj,ϕ)]\\x01\\n−X\\nilog(sig[f(xi,ϕ)])#\\n, (15.3)\\n其中索引i和j分别代表真实样本和生成样本。\\n现在，我们用生成器的定义 x∗\\nj=g(zj,θ)来替代，并注意到对于 θ我们需要寻求最\\n大化，因为我们希望生成的样本被误判（即，它们被识别为合成样本的可能性低，或负\\n对数似然度高） ：\\nˆθ=argmaxθ\"\\nmin\\nϕ\"X\\nj−log(1−sig[f(g(zj,θ),ϕ)])−X\\nilog(sig[f(xi,ϕ)])##\\n.(15.4)\\n15.1.2 训练 GANs\\n方程15.4描述的损失函数较之前我们所见要复杂；鉴别器参数 ϕ通过最小化损失\\n函数进行调整， 而生成器参数 θ通过最大化损失函数进行调整。 生成式对抗网络（ GAN）\\n的训练可以被视作一种 *极小极大游戏 *；生成器不断寻找新方法以欺骗鉴别器，而鉴\\n别器则不断探索新方法区分出生成样本与真实样本。技术上，这一解决方案被称为 *纳\\n什均衡*——优化算法旨在找到一个同时对一个函数是最小值而对另一个函数是最大值\\n的点。如果训练顺利进行，最终在收敛时， g[z,θ]的产出将与数据同分布，且 sig[f(·,ϕ)]\\n的值会接近机会水平（即， 0.5） 。\\n为了训练 GAN，我们将方程 15.4分解成两个损失函数：\\nL[ϕ] =X\\nj−log[1−sig[f(g(zj,θ),ϕ)]]−X\\nilog[sig[f(xi,ϕ)]]\\nL[θ] =X\\njlog[1−sig[f(g(zj,θ),ϕ)]], (15.5)\\n其中，我们通过将第二个损失函数乘以负一来将其转化为最小化问题，并且忽略了\\n与θ无关的第二项。最小化第一个损失函数的目的是训练鉴别器，而最小化第二个损失\\n函数则是为了训练生成器。\\n在训练的每一步骤中，我们从基础分布中抽取一批潜变量 zj，通过生成器生成样本\\nx∗\\nj=g[zj,θ]。接着我们选取一批真实训练样本 xi。有了这两批数据，我们现在可以对每\\n个损失函数执行一次或多次梯度下降步骤（参见图 15.2） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 263}, page_content='248 CHAPTER 15. 生成对抗网络\\n图 15.2: GAN 损失函数。一个潜变量 zj从基本分布中提取，并通过生成器生成样本 x∗。一批\\n生成样本 x∗\\nj和真实样本{xi}被送至鉴别器，后者为每个样本分配一个真实性的概率。调整鉴\\n别器参数 ϕ，以提高对真实样本的识别概率，降低对生成样本的识别概率。同时调整生成器参数\\nθ，使其能够让鉴别器更倾向于将生成样本判定为真实。\\n15.1.3 深度卷积生成式对抗网络（ DCGAN ）\\n深度卷积生成式对抗网络（ DCGAN）是早期专为图像生成设计的 GAN架构（参\\n见图15.3） 。生成器 g[z,θ]接收的输入是一个从均匀分布中采样的 100维潜变量z。首\\n先，通过线性变换将其映射到一个具有 1024个通道的 4x4空间表示中。紧接着是四层\\n卷积操作，每层采用分步卷积，实现分辨率加倍（即步长为 0.5的卷积）。在最终层，\\n64x64x3 的信号通过一个 tanh函数处理，生成一个取值范围在 [−1,1]内的图像x∗。鉴\\n别器f(·,ϕ)采用标准的卷积网络架构，在最后一层卷积操作后，图像尺寸被缩减到 1x1，\\n通道数为 1。这个单一数值经过 sigmoid函数sig[·]处理后，得到最终的输出概率。\\n训练完成后，鉴别器部分将被舍弃。生成新样本时，从基础分布中抽取潜变量 z，并\\n通过生成器进行处理。图 15.4展示了一些生成图像的示例。\\n15.1.4 训练 GAN的困难\\n理论上，生成式对抗网络（ GAN）的概念相对简单。然而， GAN的训练实践却异常\\n困难。 举例来说， 为了确保深度卷积 GAN（DCGAN） 能够稳定训练， 需要采取以下措施：\\n(i)采用步进卷积实现上下采样； (ii)在生成器和鉴别器中使用批量归一化 （ BatchNorm ） ，\\n但分别在最末层和首层除外； (iii)在鉴别器中应用 leaky ReLU 激活函数（参见图 3.13） ；\\n及(iv)采用Adam优化器，但其动量系数需低于常规设置。这种情况不太常见，因为大\\n部分深度学习模型对这类设置相对不敏感。\\n一个频繁出现的失败模式是生成器虽能产生看起来合理的样本，但这些样本只覆盖\\n了数据的一小部分（例如，在生成人脸时，可能无法生成带胡须的面孔） 。这种现象被'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 264}, page_content='15.2.提高稳定性 249\\n图 15.3: DCGAN 架构。在生成器中，一个 100D潜变量 z从均匀分布中抽取，并通过线性变\\n换被映射到一个 4×4、1024通道的表示。这个表示随后通过多个卷积层进行处理，逐步上采样\\n并减少通道数。最终，通过一个 tanh函数将 64×64×3 的表示映射到一个固定范围，用于表示\\n图像。鉴别器则由一个标准的卷积网络组成，用于判断输入是真实样本还是生成样本。\\n图 15.4:来自 DCGAN 模型的合成图像。 a)随机抽取的样本，基于在人脸数据集上训练的\\nDCGAN。b)使用 ImageNet 数据库的随机样本（参见图 10.15） 。 c)基于 LSUN场景理解数据\\n集的随机抽取样本。据 Radford 等（ 2015）改编。\\n称为“模式丢失” 。更极端的情况是生成器几乎或完全忽视潜在变量 z，导致所有样本收\\n敛至一个或少数几个点，这一现象被称作“模式塌缩” （参见图 15.5） 。\\n图 15.5:模式坍塌。使用与 DCGAN 参数和层数相似的 MLP生成器，在 LSUN场景理解数据\\n集上训练得到的 GAN合成图像。这些样本质量低，且多数相似。根据 Arjovsky 等（ 2017）改\\n编。\\n15.2提高稳定性\\n要弄清楚为什么 GAN训练难度大，首先需要深入理解损失函数的实际含义。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 265}, page_content='250 CHAPTER 15. 生成对抗网络\\n15.2.1 GAN 损失函数的分析\\n如果我们将方程 15.3中两个求和分别除以真实样本数 I和生成样本数 J，则损失\\n函数可以用期望形式表示：\\nL[ϕ] =1\\nJJX\\nj=1log\\x02\\n1−sig[f(x∗\\nj,ϕ)]\\x03\\n+1\\nIIX\\ni=1log[sig[f(xi,ϕ)]]\\n≈Ex∗[log(1−sig[f(x∗,ϕ)])] +Ex[log(sig[f(x,ϕ)])]\\n=Z\\nPr(x∗)log[1−sig[f(x∗,ϕ)]]dx∗+Z\\nPr(x)log[sig[f(x,ϕ)]]dx,(15.6)\\n这里Pr(x∗)和Pr(x)分别表示生成样本和真实样本的概率分布。\\n对于来源未知的示例 ˜x，最优鉴别器表达为：\\nPr(real|˜x) =sig[f(˜x,ϕ)] =Pr(˜x|real)\\nPr(˜x|generated ) +Pr(˜x|real)=Pr(x)\\nPr(x∗) +Pr(x)(15.7)\\n这里，我们把 ˜x分别与生成的分布 Pr(x∗)和真实分布 Pr(x)进行对比。将其代入\\n方程15.6中，我们得到：\\nL[ϕ] =Z\\nPr(x∗)log[1−sig[f(x∗,ϕ)]]dx∗+Z\\nPr(x)log[sig[f(x,ϕ)]]dx\\n=Z\\nPr(x∗)log\\x141−Pr(x)\\nPr(x∗) +Pr(x)\\x15\\ndx∗+Z\\nPr(x)log\\x14Pr(x)\\nPr(x∗) +Pr(x)\\x15\\ndx\\n=Z\\nPr(x∗)log\\x14Pr(x∗)\\nPr(x∗) +Pr(x)\\x15\\ndx∗+Z\\nPr(x)log\\x14Pr(x)\\nPr(x∗) +Pr(x)\\x15\\ndx.(15.8)\\n去掉加法和乘法常数后，这是合成分布 Pr(x∗)与真实分布 Pr(x)之间的詹森 -香农\\n散度：\\nDJS[Pr(x∗)∥Pr(x)] =1\\n2DKL\\x14\\nPr(x∗)∥Pr(x∗) +Pr(x)\\n2\\x15\\n+1\\n2DKL\\x14\\nPr(x)∥Pr(x∗) +Pr(x)\\n2\\x15\\n=1\\n2Z\\nPr(x∗)log\\x142Pr(x∗)\\nPr(x∗) +Pr(x)\\x15\\ndx∗\\n+1\\n2Z\\nPr(x)log\\x142Pr(x)\\nPr(x∗) +Pr(x)\\x15\\ndx. (15.9)\\n其中DKL[·∥·]表示库尔巴克 -莱布勒散度。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 265}, page_content='Pr(x∗) +Pr(x)\\x15\\ndx∗\\n+1\\n2Z\\nPr(x)log\\x142Pr(x)\\nPr(x∗) +Pr(x)\\x15\\ndx. (15.9)\\n其中DKL[·∥·]表示库尔巴克 -莱布勒散度。\\n第一项指出，如果样本密度 Pr(x∗)较高的地区，混合分布 (Pr(x∗) +Pr(x))/2也\\n具有较高概率，则距离较小。换言之，它惩罚了那些有 x∗样本但没有真实样本 x的区'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 266}, page_content='15.2.提高稳定性 251\\n域；这保证了生成样本的质量。第二项表明，如果真实样本密度 Pr(x)较高的地区，混\\n合分布 (Pr(x∗) +Pr(x))/2也具有较高概率，则距离较小。换言之，它惩罚了那些有真\\n实样本但没有生成样本的区域；这确保了覆盖范围。回顾方程 15.6，我们注意到第二项\\n不依赖于生成器，因此生成器不关心覆盖范围；它只专注于准确生成可能的样本子集。\\n这就是所谓的模式丢失的原因。\\n15.2.2 梯度消失\\n在上一节，我们了解到，当鉴别器达到最优时，损失函数旨在最小化生成样本与真\\n实样本间距离的度量。然而，将这种概率分布间的距离作为优化 GANs的准则时，会遇\\n到一个问题。如果这些概率分布彼此之间完全没有交集，那么这个距离将变得无限大，\\n任何微小的调整对于生成器来说都无法减少损失。考虑到原始的公式设定，如果鉴别器\\n能够完美区分生成样本和真实样本，那么对生成数据做出的任何细微调整都不会影响分\\n类得分(图15.6)。\\n遗憾的是，生成样本和真实样例的分布可能确实是分离的。生成样本存在于一个由\\n潜在变量 z定义的子空间中，而真实样例也因数据生成的物理过程而处于一个低维子空\\n间中(图1.9)。这些子空间之间可能几乎没有或根本没有交集，导致梯度非常小或者根\\n本不存在。\\n图15.7提供了支持这种假设的实证证据。如果将 DCGAN 的生成器固定不变，而\\n不断更新鉴别器以提高其分类性能，我们会发现生成器的梯度逐渐减少。简言之，鉴别\\n器与生成器的质量之间需要保持一个极其精细的平衡；一旦鉴别器的性能过于出色，就\\n会削弱对生成器的训练更新。\\n图 15.6: GAN 损失函数问题。当生成样本（橙色箭头）与真实样本（青色箭头）容易区分时，鉴\\n别器（ sigmoid）在样本处的斜率可能非常平缓；因此，用于更新生成器参数的梯度可能非常微\\n小。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 267}, page_content='252 CHAPTER 15. 生成对抗网络\\n图 15.7: DCGAN 的生成器梯度消失问题。生成器在第 1、10和 25个训练周期后冻结，而鉴别\\n器继续进行训练。生成器的梯度迅速下降（注意对数刻度） ；若鉴别器过于精准，生成器的梯度\\n将消失。根据 Arjovsky & Bottou (2017) 改编。\\n15.2.3 W asserstein 距离\\n前面的部分讨论了两点： (i) GAN 损失可以被理解为不同概率分布间距离的表达，\\n以及(ii)当生成样本与真实样例过于容易区分时，这种距离的梯度会降为零。一个自然\\n的改进方向是采用一种具备更佳特性的距离衡量标准。\\nWasserstein 距离，或对于离散分布来说的地球推土机距离，指的是将一个分布的概\\n率质量转移至另一个分布所需的劳动量。这里的“劳动量”定义为移动距离与质量的乘\\n积。这一定义明显更具吸引力；即使在分布完全不重叠的情况下， Wasserstein 距离也是\\n有明确定义的，并且随着分布间逐渐接近，其距离会平滑减小。\\n15.2.4 离散分布的 W asserstein 距离\\nWasserstein 距离在处理离散分布时最为直观（见图 15.8） 。设想有两个分布 Pr(x=\\ni)和q(x=j)，它们分别定义在 K个区间上。设从第一个分布中某区间 i向第二个\\n分布中某区间 j移动单位质量的成本为 Cij，这个成本可以是两个区间索引的绝对差值\\n|i−j|。这种移动构成了一个 *运输计划 *，其细节通过矩阵 P来记录。\\nWasserstein 距离的计算公式为：\\nDw[Pr(x)||q(x)] =min\\nP\"X\\ni,jPij·|i−j|#\\n, (15.10)\\n这一计算受到几个约束条件的限制：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 268}, page_content='15.2.提高稳定性 253\\nX\\njPij=Pr(x=i), Pr (x)的起始分布\\nX\\niPij=q(x=j), q(x)的起始分布\\nPij≥0,所有质量都是非负的。 (15.11)\\n简而言之， Wasserstein 距离是一个将一个分布的质量转移到另一个分布上的最优\\n化问题的解，这个过程受到一系列约束的限制。虽然这个最优化问题需要每次计算距离\\n时都解决，这可能有些不便，但幸运的是，这是一个标准的线性规划问题，对于小型系\\n统方程来说是容易解决的。\\nPrimal form Dual form\\nminimizecTp,\\nsuch thatAp=b\\nandp≥0maximizebTf,\\nsuch thatATf≤c\\n表 15.1: Primal and Dual F orms\\n此处，p包含向量化的元素 Pij，这些元素确定了转移的质量量， c记录了各点间的\\n距离，Ap=b规定了初始分布的约束条件，而 p≥0确保了转移的质量非负。\\n与所有线性规划问题相同，存在一个等价的 *对偶问题 *，其解与原问题相同。在\\n对偶问题中，我们尝试最大化与初始分布相关联的变量 f的值，这一过程需要遵循基于\\n距离c的约束条件。对偶问题的解可以表达为：\\nDw[Pr(x)||q(x)] =max\\nf\"X\\niPr(x=i)fi−X\\njq(x=j)fj#\\n,(15.12)\\n这个过程遵循的约束是：\\n|fi+1−fi|<1 (15.13)\\n换言之，我们在一组新变量 {fi}上寻求最优解，要求这组变量中任意相邻两个值之间\\n的差异不得超过一。\\n15.2.5 连续分布的 W asserstein 距离\\n在回到连续多维空间的背景下，原始问题的连续形式（即方程 15.10）可以表示为：\\nDw[Pr(x),q(x)] =min\\nπ≥0Z Z\\nπ(x1,x2)·|x1−x2|dx1dx2, (15.14)\\n这里，π(x1,x2)代表从x1位置到x2位置转移的质量的运输计划，需要满足与方程\\n15.11相似的约束条件。对偶问题的连续形式（即方程 15.12）为：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 269}, page_content='254 CHAPTER 15. 生成对抗网络\\n图 15.8: W asserstein 距离或 earth mover ’s distance 。a)考虑离散分布 P r(x = i) 。b)我们希\\n望移动概率质量以形成目标分布 q(x = j)。c)运输计划 P确定了从 i到 j的质量转移量。例如，\\n青色高亮的方块 p54表示从 i = 5到 j = 4将转移的质量。运输计划的元素必须非负，对 j的\\n总和应等于 P r(x = i) ，对 i的总和应等于 q(x = j)。因此， P是一个联合概率分布。 d)元素 i\\n与 j之间的距离矩阵。最优运输计划 P旨在最小化 P与距离矩阵点乘的总和（即 W asserstein\\n距离） ，因此 P的元素倾向于聚集在距离成本最低的对角线附近。根据 Hermann (2017) 改编。\\nDw[Pr(x),q(x)] =max\\n[f]x\\x14Z\\nPr(x)f(x)dx−Z\\nq(x)f(x)dx\\x15\\n,(15.15)\\n这一最大化过程受到一个条件的约束，即函数 f(x)的Lipschitz 常数必须小于一\\n（也就是说，函数的梯度绝对值必须小于一） 。\\n15.2.6 W asserstein GAN 损失函数\\n在神经网络应用中，我们通过调整神经网络 f[x,ϕ]中的参数ϕ来最大化函数 f[x]\\n空间，利用生成的样本 x∗\\ni和真实样本 xi进行积分近似：\\nL[ϕ] =X\\nj[f[x∗\\nj,ϕ]]−X\\ni[f[xi,ϕ]],\\n=X\\nj[f[g[zj,θ],ϕ]]−X\\ni[f[xi,ϕ]], (15.16)\\n我们需要确保神经网络中的判别器 f[xi,ϕ]在每一个点 x处的梯度范数都小于一：\\n\\x0c\\x0c\\x0c\\x0c∂f[x,ϕ]\\n∂x\\x0c\\x0c\\x0c\\x0c<1. (15.17)\\n一种实现方法是将判别器的权重限制在一个较小的区间内（比如 [−0.01,0.01]） 。另\\n一种策略是使用 *梯度惩罚 Wasserstein GAN （WGAN-GP ）*，通过添加一个正则项\\n来确保梯度范数接近于一，当梯度范数偏离一时，这个正则项的值会增加。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 270}, page_content='15.3.渐进式增长、小批量判别和截断 255\\n15.3渐进式增长、小批量判别和截断\\nWasserstein 方法为GAN训练带来了更高的稳定性。不过，要生成高品质图像，我\\n们还需要额外的技术手段。接下来，我们将介绍渐进式增长、小批量判别和截断技术，\\n它们均能显著提升生成图像的品质。\\n在渐进式增长策略中（参见图 15.9） ，起始阶段是训练一个能够生成 4×4图像的\\nGAN，采用与 DCGAN 相似的架构。随后，我们向生成器添加新的层，这些层负责上\\n采样并进一步处理，以生成 8×8尺寸的图像。判别器同样被加入新的层，使其能够处理\\n并分类更高分辨率的图像。在实践中，高分辨率层会逐渐并平滑地引入，起初通过残差\\n连接传递上采样的结果，随后新加入的层逐步发挥作用。\\n小批量判别技术确保生成的样本具备足够的多样性，从而有效避免了模式崩溃现\\n象。通过对合成数据和真实数据的小批次进行特征统计，并将统计结果作为特征图加入\\n到判别器中，判别器能够反馈信号给生成器，鼓励其在生成数据时引入与原始数据集相\\n仿的多样性。\\n提高生成质量的另一技巧是截断策略（见图 15.10） ，在此策略中，仅在采样时选择\\n那些高概率（即，接近均值的）潜在变量 z。这虽然减少了样本的多样性，但能显著提\\n升样本的品质。通过精确的归一化和规范化处理，样本质量得到进一步改善。采用这些\\n技术组合， GAN能够生成既多样化又逼真的图像（如图 15.11所示） 。通过在潜在空间\\n内平滑过渡，有时还能实现从一个合成图像到另一个的逼真插值（如图 15.12所示） 。\\n15.4条件生成\\n尽管GAN能够生成逼真的图像，但它们并不允许指定图像的具体属性，比如无法\\n选择生成的面孔的头发颜色、种族或年龄，除非针对每种属性组合训练单独的 GAN。条\\n件生成模型则为我们提供了这种属性控制的能力。\\n15.4.1 条件 GAN\\n条件GAN通过向生成器和判别器同时传递一个包含属性信息的向量 c来工作，分\\n别用g[z,c,θ ]和f[x,c,ϕ ]表示。这样，生成器的任务就变成了将潜在变量 z转换成带有\\n特定属性 c的数据样本 x，而判别器则致力于辨别生成的样本是否携带目标属性或者是\\n真实样本携带真实属性（见图 15.13a） 。\\n对生成器来说，可以将属性 c直接加入到潜在向量 z中。而对于判别器，如果处理'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 270}, page_content='真实样本携带真实属性（见图 15.13a） 。\\n对生成器来说，可以将属性 c直接加入到潜在向量 z中。而对于判别器，如果处理\\n的是一维数据，这些属性可以加入到输入数据中；对于图像数据，则可以将属性转换成\\n二维形式并作为一个额外通道加入到判别器的输入或其内部某个中间层。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 271}, page_content='256 CHAPTER 15. 生成对抗网络\\n图 15.9:逐步增长的 GAN训练。 a)初始阶段，生成器被训练生成非常小的图像（ 4×4） ，鉴别器\\n则被训练识别这些图像是合成的还是降采样的真实图像。 b)在这个低分辨率的训练完成后，为\\n生成器添加更多层来生成更大的图像（ 8×8） ，鉴别器也增加相应的降采样层。 c)此过程持续进\\n行，依次生成更大的图像（如 16×16等） 。通过这种方式，可以训练出能产生极为逼真的高分\\n辨率图像的 GAN。d)使用相同的潜变量，在不同阶段生成的逐步增大分辨率的图像。据 W olf\\n(2021)，采用 Karras等人 (2018)的方法。\\n15.4.2 辅助分类器 GAN\\n辅助分类器 GAN（ACGAN）通过简化条件生成的要求——判别器需要正确识别出\\n属性——来实现其功能（见图 15.13b） 。对于有 C类别的离散属性，判别器接收真实或\\n合成图像作为输入，并输出 C + 1个结果；其中第一个结果经过 sigmoid函数处理，用\\n于预测样本是真实还是生成的，而其他输出通过 softmax函数处理，预测样本属于各个\\n类别的概率。采用此方法训练的网络能够生成 ImageNet 中的多类图像（见图 15.14） 。\\n15.4.3 InfoGAN\\n与条件GAN和ACGAN 不同，它们生成具有特定属性的样本， InfoGAN （见图\\n15.13c）则旨在自动发现重要属性。生成器接收一个由随机噪声变量 z和随机属性变量\\nc组成的向量，而判别器则负责判断图像的真假并估计属性变量。\\n关键洞察是，那些能够容易预测的、与现实世界特征相关的属性，最有可能被属性\\n变量c所表示。 c中的属性既可以是离散的（此时使用二元或多分类交叉熵损失函数） ，\\n也可以是连续的（此时使用最小二乘损失函数） 。离散变量用于识别数据的类别，而连\\n续变量则揭示数据的渐变模式（见图 15.15） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 272}, page_content='15.4.条件生成 257\\n图 15.10:样本截断。通过拒绝偏离均值超过 τ标准差的潜变量 z的样本，可以权衡 GAN样本\\n的质量与多样性。 a)当这个阈值较大（ τ= 2.0）时，样本在视觉上多样但可能有缺陷。 b-c)随\\n着这个阈值的降低，样本的平均视觉质量提升，但多样性减少。 d)当阈值非常小，样本看起来\\n几乎相同。通过合理选择这个阈值，可以提高 GAN结果的平均质量。根据 Brock等人 (2019)\\n改编。\\n图 15.11:逐步增长法。这种方法在训练 CELEBA-HQ 数据集时能生成逼真的人脸图像，在训\\n练 LSUN分类时则能生成更为复杂和多变的对象。据 Karras等（ 2018）改编。\\n图 15.12:遍历 LSUN汽车数据集上训练的渐进式 GAN的潜空间。在潜空间中的移动使得汽车\\n图像平滑地变化，这种现象通常仅在短距离轨迹中有效；最终，潜变量移至一个区域，导致产生\\n不现实的图像。据 Karras等（ 2018）改编。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 273}, page_content='258 CHAPTER 15. 生成对抗网络\\n图 15.13:条件生成。 a)条件 GAN的生成器还接收一个描述图像特征的属性向量 c。如常规做\\n法，鉴别器接收真实或生成的样本，但现在它还得接收属性向量，以鼓励样本同时符合逼真性和\\n属性兼容性。 b)辅助分类器 GAN（ACGAN）的生成器采用一个离散属性变量。鉴别器需要判\\n断输入是真实还是合成，并正确识别类别。 c) InfoGAN 把潜变量分成噪声 z和未指定的随机属\\n性 c。鉴别器需要辨识输入的真实性，并重构这些属性。实践中，这意味着变量 c对应于具有现\\n实世界解释的数据的显著特征（即，潜空间被解耦） 。\\n图 15.14:辅助分类器 GAN。生成器接收类别标签和潜向量作为输入。鉴别器不仅需判断数据\\n点是否真实，还要预测类别标签。该模型在十个 ImageNet 类别上进行训练，生成的样本包括帝\\n王蝶、金翅雀、雏菊、红腿鹬和灰鲸等。据 Odena等（ 2017）改编。\\n15.5图像翻译\\n虽然对抗性判别器 (adversarial discriminator) 最初是在生成对抗网络 (GAN)中用\\n于生成随机样本的背景下提出的，但它也可作为一种偏好于现实感的先验，用于将一种\\n数据形式转换成另一种形式的任务中。这种应用最常见于图像处理，例如将灰度图像转'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 274}, page_content='15.5.图像翻译 259\\n图 15.15:图 15.15 InfoGAN 在 MNIST数据集上的应用。 a) MNIST 数据库的训练样本包含\\n28×28像素的手写数字图像。 b)第一个属性 c1是一个具有 10个类别的分类变量；每一列展示\\n了使用其中一个类别生成的样本。 InfoGAN 能够复原十个数字。属性向量 c2和 c3是连续的。\\nc)从左到右，每列代表在其他潜变量保持不变时 c2的不同值，这个属性似乎与字符的方向有\\n关。 d)第三个属性与笔画的粗细度相关。据 Chen等（ 2016b）改编。\\n换成彩色、将噪声图像清理成干净的图像、将模糊图像转换成清晰的图像，或是将草图\\n转换成照片级逼真的图像。\\n本节将讨论三种图像翻译模型， 它们在训练时依赖于不同程度的手工标注。 Pix2Pix\\n模型利用成对的前 /后图像进行训练。采用对抗性损失的模型在主模型中使用成对的图\\n像，同时在判别器中使用未配对的“后”图像。 CycleGAN 模型则使用未配对的图像。\\n15.5.1 Pix2Pix\\nPix2Pix 模型（图 15.16）是一个网络 x=g[c,θ]，通过一个带有参数 Θ的U-Net\\n（图11.10）将一幅图像 c映射到另一种风格的图像 x上。一个典型的应用场景是色彩\\n化，即将灰度输入转换为彩色输出。输出图像应与输入相似，这一目标通过一个内容损\\n失(content loss) 来实现，该损失惩罚输入和输出之间的 ℓ1范数∥x−g[c,Θ]∥1差异。\\n然而，输出图像还应看似对输入的一个逼真转换。为达到此目的，使用了一个对\\n抗性判别器 f[c,x,ϕ ]来处理前后图像 c和x。判别器每一步尝试区分真实的前后对和\\n前/合成对。成功区分这些对时，将反馈信号用于调整 U-Net以让其输出更逼真。由于\\n内容损失确保了图像的大尺度结构正确，判别器主要用于确保局部纹理的真实性。为此，\\nPatchGAN 损失基于纯卷积分类器设计。在最后一层，每个隐藏单元判断其接收范围内\\n的区域是真实的还是合成的。这些反应被平均化，以得出最终输出。\\n可以将此模型视为一个条件 GAN，其中U-Net作为生成器，并且是以图像而非标\\n签作为条件。值得注意的是， U-Net的输入不包含噪声，因此并不完全是传统意义上的\\n“生成器” 。有趣的是，原始作者尝试向 U-Net中添加噪声 z以及输入图像 c，但网络最'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 274}, page_content='签作为条件。值得注意的是， U-Net的输入不包含噪声，因此并不完全是传统意义上的\\n“生成器” 。有趣的是，原始作者尝试向 U-Net中添加噪声 z以及输入图像 c，但网络最\\n终学会忽略了噪声。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 275}, page_content='260 CHAPTER 15. 生成对抗网络\\n图 15.16: Pix2Pix 模型。 a)这个模型利用 U-Net（参见图 11.10）将输入图像转换成不同风格\\n的预测结果。例如，它能将灰度图像转换为看似真实的彩色版本。 U-Net的训练基于两种损失：\\n内容损失鼓励输出图像结构与输入相似，而对抗损失则确保灰度和彩色图像对在图像的每个局\\n部区域内难以区分。这个框架能够适用于多种任务，包括 b)将地图转换为卫星图像， c)将包包\\n的素描转换为逼真图像， d)彩色化处理，以及 e)将标签地图转换为逼真的建筑立面图。据 Isola\\n等（ 2017）改编。\\n15.5.2 对抗性损失\\nPix2Pix模型的判别器尝试判断图像翻译任务中的前后图像对是否合理。这样做的\\n不便之处在于，我们需要真实的前后对来利用判别器损失。幸运的是，存在一种更简单\\n的方法可以在监督学习的背景下，不需要额外的标注训练数据，就能利用对抗性判别器\\n的力量。\\n对抗性损失 (adversarial loss) 通过判别器来增加惩罚，如果判别器能区分出监督网\\n络的输出与其输出域中的真实样例。因此，监督模型会调整其预测以减少这种惩罚。这\\n既可以在整个输出层面上进行，也可以在补丁级别进行，如 Pix2Pix算法中所示。这有\\n助于提升复杂结构输出的逼真度。然而，这并不一定能在原始损失函数方面带来更好的\\n解决方案。\\n超分辨率 GAN（SRGAN）采用了这种方法（图 15.17） 。主模型是一个含有残差连\\n接的卷积网络，它接收一个低分辨率图像，并通过上采样层转换成高分辨率图像。网络'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 276}, page_content='15.5.图像翻译 261\\n通过三种损失来训练：内容损失测量输出和真实高分辨率图像之间的平方差异； VGG\\n损失或感知损失通过 VGG网络传递合成和真实输出，测量它们激活值之间的平方差异，\\n鼓励图像在语义上与目标相似；对抗性损失则使用判别器来尝试区分该图像是否为真实\\n的高分辨率图像或是上采样的图像，以促进输出与真实样例无法区分。\\n图 15.17:超分辨率生成对抗网络（ SRGAN） 。 a)利用残差连接的卷积网络被训练来将图像分辨\\n率提高四倍。这个模型旨在使内容尽可能接近真实的高分辨率图像，同时通过对抗损失惩罚那些\\n可与真实高分辨率图像区分开的结果。 b)采用双三次插值法上采样的图像。 c)使用 SRGAN 上\\n采样的图像。 d)再次采用双三次插值法上采样的图像。 e)再次使用 SRGAN 上采样的图像。据\\nLedig等（ 2017）改编。\\n15.5.3 CycleGAN\\n对抗性损失假设我们拥有用于主监督网络的标记前后图像。 CycleGAN 解决了当我\\n们拥有两组具有独特风格但无匹配对的数据时的情况。一个例子是将照片转换为莫奈的\\n艺术风格。虽然存在许多照片和莫奈的画作， 但它们之间没有直接对应关系。 CycleGAN\\n利用了一个理念：若图像先转换成一种风格（例如，照片 →莫奈） ，然后再转换回原始\\n风格，应能恢复原图。\\nCycleGAN 的损失函数是三种损失的加权和（图 15.18） 。内容损失鼓励前后图像相\\n似，基于 l1范数。对抗性损失利用判别器来鼓励输出与目标域的真实样例无法区分。最\\n后，循环一致性损失鼓励映射的可逆性。此处，同时训练两个模型：一个负责从第一个\\n域映射到第二个域，另一个则反向映射。如果通过映射转换的图像能够成功地再次转换\\n回原始域的图像，则循环一致性损失较低。该模型通过结合这三种损失来训练网络，实\\n现图像从一种风格到另一种风格的转换，然后再回到原来的风格。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 277}, page_content='262 CHAPTER 15. 生成对抗网络\\n图 15.18: CycleGAN 。同时训练两个模型，一个模型将第一种风格的图像（马）转换成第二种风\\n格的图像（斑马） ，另一个模型则进行相反的映射。循环一致性损失确保这两个模型能够成功地\\n进行领域转换并恢复到原图。除此之外，两个对抗损失使转换后的图像在目标领域中看起来更\\n真实（此处以斑马为例） 。内容损失确保每次映射前后图像的细节和布局保持一致性（即斑马和\\n马的位置和姿态相同，背景也相同） 。据 Zhu等（ 2017）改编。\\n15.6 StyleGAN\\nStyleGAN 是一款较为先进的生成对抗网络 (GAN)，它能够将数据集中的变异分解\\n为有意义的组件，每个组件都由一小部分潜变量控制。特别地， StyleGAN 能够在不同\\n层级上调控输出图像，并明确区分风格与噪声。在处理人脸图像时，大尺度的变化包括\\n脸型和头部姿势；中尺度变化涉及面部特征的形态和细节；而细尺度变化则涵盖头发和\\n皮肤颜色。风格成分指的是对人类显著的图像特征，而噪声成分则指图像中不那么重要\\n的变化，比如头发的精确位置、胡渣、雀斑或皮肤毛孔等。\\n我们之前见到的 GAN从一个标准基础分布中抽取的潜变量 z开始，经过一系列卷\\n积层的处理生成输出图像。但是，在生成器中，潜变量的输入可以 (i)在架构的不同位\\n置引入，且 (ii)以不同方式调整这些位置的当前表示。 StyleGAN 精心选择了这些方式\\n来控制不同的尺度，并区分风格与噪声（图 15.19） 。\\nStyleGAN 的主要生成分支以一个学习得到的 4×4、512通道的常数表示开始，通\\n过一系列逐渐上采样的卷积层，生成最终分辨率的图像。在每个尺度上，都会引入代表\\n风格和噪声的两组随机潜变量；这些变量越接近输出，它们代表的细节就越精细。\\n代表噪声的潜变量是独立采样的高斯向量 z1,z2等，它们在主生成流程的每次卷积'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 278}, page_content='15.7.总结 263\\n操作后以加法形式注入。这些向量在空间大小上与它们被加入时的主要表示相同，但通\\n过乘以学习到的每通道缩放因子 ψ1,ψ2等，因此对每个通道的贡献量不同。随着网络分\\n辨率的提高，这些噪声在更细的尺度上产生影响。\\n代表风格的潜变量起始于一个 1×1×512 的噪声张量，经过一个七层全连接网络处\\n理，生成一个中间变量 w。这样做使得网络能够解耦风格的各个方面，使得 w的每个维\\n度都能独立代表现实世界的某个因素，如头部姿势或头发颜色。这个 w变量经线性转\\n换后成为 2×1×512 的张量y，用于在主分支的空间位置上调整表示的每通道均值和方\\n差，此过程称为自适应实例规范化 (adaptive instance normalization) （图11.14e） 。通过\\n这种方式，在主分支的几个不同位置注入一系列向量 y1,y2等，使得相同的风格在不同\\n尺度上有所贡献。图 15.20展示了在不同尺度上操纵风格和噪声向量的示例。\\n图 15.19: StyleGAN 。其核心流程（中间行）起始于一个固定的学习表示（灰色框） 。通过多层\\n卷积和逐步上采样过程生成最终图像。不同尺度的噪声（顶行）通过周期性加入具有每通道缩放\\n的高斯变量 z•来实现。高斯风格变量 z通过全连接网络转换成中间变量 w（底行） ，用于在流\\n程的不同阶段调整每个通道的均值和方差。\\n15.7总结\\nGAN（生成对抗网络）通过学习一个生成器网络，可以将随机噪声变换成与训练集\\n中的数据相似的数据。为了达成这一目标，训练生成器时会用到一个鉴别器网络，该网\\n络试图区分出真实的样本与生成的样本。接着，生成器会被调整，以便它产生的数据更\\n加被鉴别器认为是“真实”的。这个思想的原始表述存在一个问题，即当判定样本是真\\n实还是生成的变得容易时，训练信号会变弱。这促成了 Wasserstein GAN 的发展，它能\\n够提供一个更稳定的训练信号。\\n我们回顾了用于生成图像的卷积 GAN技术及一系列提升生成图像质量的技巧，包\\n括渐进增长、小批量判别和截断策略。条件 GAN架构通过引入一个辅助向量来控制输'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 279}, page_content='264 CHAPTER 15. 生成对抗网络\\n图 15.20: StyleGAN 结果。前四列展示了不同尺度下风格的系统性变化。第五列显示了增大噪\\n声幅度的效果。最后两列在两个不同的尺度上展示了不同的噪声向量变化。\\n出内容（如，选择特定的对象类别） 。在图像翻译任务中，这种条件信息以图像的形式\\n被保留，但随机噪声则被省略。如今， GAN的鉴别器充当了一个额外的损失函数，偏\\n好生成看起来“更真实”的图像。最终，我们介绍了 StyleGAN ，它在不同尺度上通过\\n策略性地向生成器注入噪声来控制风格和噪声。\\n15.8笔记\\nGoodfellow 等人在2014年引入了生成对抗网络（ GAN） 。Goodfellow 在2016年的\\n文章中对早期的进展进行了回顾。更近期的综述包括 Creswell 等人于2018年以及Gui\\n等人于2021年的工作。 Park等人在2021年发布的综述专注于 GAN模型在计算机视觉\\n应用中的进展。 Hindupur 在2022年维护了一份命名的 GAN模型列表，目前共有 501\\n个，从ABC-GAN （Susmelj等人，2017年）到ZipNet-GAN （Zhang等人，2017年）都\\n有涵盖。 Odena在2019年列出了 GAN相关的开放性问题。\\n数据：GAN主要用于图像数据处理，例如本章介绍的深度卷积 GAN（Radford 等\\n人，2015年） 、渐进式 GAN（Karras等人，2018年）以及 StyleGAN （Karras等人，2019\\n年） 。因此，多数 GAN基于卷积层构建，近期还开发了融合 Transformer 的GAN，通过\\n生成器和鉴别器捕捉长距离相关性，如 SAGAN（Zhang等人，2019年） 。此外， GAN还\\n应用于生成分子结构图（ De Cao & Kipf, 2018 ） 、声音数据（ Saito等人，2017; Donahue\\n等人，2018; Kaneko & Kameoka, 2017; Fang 等人，2018） 、脑电波数据（ Hartmann 等\\n人，2018） 、文本（ Lin等人，2017; Fedus 等人，2018） 、音乐（ Mogren，2016; Guimaraes'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 279}, page_content='人，2018） 、文本（ Lin等人，2017; Fedus 等人，2018） 、音乐（ Mogren，2016; Guimaraes\\n等人，2017; Yu 等人，2017） 、3D模型（Wu等人，2016） 、DNA（Killoran 等人，2017）'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 280}, page_content='15.8.笔记 265\\n及视频数据（ Vondrick 等人，2016; Wang 等人，2018） 。\\nGAN损失函数 ：虽然最初认为 GAN在训练过程中会收敛到纳什均衡，但更多的\\n证据表明这种情况并不总发生（ Farnia & Ozdaglar, 2020; Jin 等人，2020; Berard 等人，\\n2019） 。Arjovsky 等人（2017） 、Metz等人（2017）和Qi（2020）指出，原始的 GAN损\\n失函数存在不稳定性，促使人们提出了不同的公式。 Mao等人在2017年引入了最小二\\n乘GAN，对某些参数选择，这隐式地最小化了 Pearsonχ2分歧。Nowozin 等人（2016）\\n认为Jensen-Shannon 分歧是f-分歧大家族中的一个特例，展示了任何 f-分歧都可以用\\n于训练GAN。Jolicoeur-Martineau （2019）提出了相对论 GAN，其鉴别器估计真实数据\\n样本比生成样本更真实的概率，而不是绝对的真实性概率。 Zhao等人（2017）将GAN\\n重构为一个基于能量的通用框架，鉴别器将低能量赋予真实数据，其他情况则赋予高能\\n量。例如，他们使用自编码器，根据重构误差来定义能量。\\nArjovsky 和Bottou（2017）分析了 GAN中的梯度消失问题，进而提出了基于地球\\n移动距离 /最优传输的 Wasserstein GAN （Arjovsky 等人，2017） 。Wasserstein 方法要求\\n鉴别器的 Lipschitz 常数小于一；原文提议通过裁剪鉴别器的权重来实现，但后续研究\\n通过引入梯度惩罚（ Gulrajani 等人，2016）或施加谱归一化（ Miyato等人，2018）来限\\n制Lipschitz 常数。Wasserstein GAN 的其他变种由 Wu等人（2018） 、Bellemare 等人\\n（2017）和Adler & Lunz （2018）提出。 Hermann （2017）讨论了对偶性和 Wasserstein\\nGAN的卓越博客文章。关于最优传输的更多信息，可以参考 Peyré等人（2019）的著\\n作。Lucic等人（2018）对当时的 GAN损失函数进行了实证比较。\\n训练 GAN的技巧：许多启发式方法提高了训练 GAN的稳定性和最终结果的质'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 280}, page_content='作。Lucic等人（2018）对当时的 GAN损失函数进行了实证比较。\\n训练 GAN的技巧：许多启发式方法提高了训练 GAN的稳定性和最终结果的质\\n量。Marchesi （2017）首次采用截断技巧来平衡 GAN输出的多样性和质量。 Pieters &\\nWiering（2018）和Brock等人（2019）也提出了此法，并增加了一个使生成器中权重矩\\n阵保持正交的正则器。这意味着截断潜在变量与缩小输出方差的关系更为紧密，从而提\\n升了样本质量。\\n其他技巧包括仅利用最真实的前 K张图像的梯度（ Sinha等人，2020） 、在鉴别器\\n中使用标签平滑技术（ Salimans 等人，2016） 、通过使用生成图像的历史记录而非最新\\n生成器产生的图像来更新鉴别器，以避免模型“振荡” （ Salimans 等人，2016） ，以及在\\n鉴别器输入中加入噪声（ Arjovsky & Bottou, 2017 ） 。Kurach等人（2019）综述了 GAN\\n中的标准化和正则化方法。 Chintala 等人（2020）进一步提出了训练 GAN的建议。\\n样本多样性 ： 原始GAN论文 （Goodfellow 等人，2014） 提出， 只要有足够的容量、 训\\n练样本和计算时间， GAN就能学会最小化生成样本与真实分布之间的 Jensen-Shannon\\n分歧。然而，后来的研究对此提出了疑问。 Arora等人（2017）指出，鉴别器的有限容量\\n导致即便输出分布的变异有限， GAN训练目标也可能接近其最优值。 Wu等人（2017）\\n通过退火重要性采样估算 GAN产生的分布的对数似然值，发现生成的分布与真实分布\\n存在不匹配。 Arora & Zhang （2017）通过让人类观察者识别 GAN生成的（几乎）重复\\n样本，从重复的频率中推测出图像的多样性。他们发现，对于 DCGAN，400个样本中\\n出现重复的概率超过 50%，这表明其支持的大小约为 400,000，低于训练集的规模。他'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 281}, page_content='266 CHAPTER 15. 生成对抗网络\\n们还发现，随着鉴别器的大小增加，多样性有所增加。 Bau等人（2019）采用了不同的\\n方法，探索了 GAN无法生成的数据空间部分。\\n增加多样性与防止模式塌陷 ：缺乏多样性的极端案例是模式塌陷，这种情况下网络\\n反复生成相同的图像（ Salimans 等人，2016） 。这在条件 GAN中尤为突出，因为潜变\\n量有时会被完全忽略，输出完全依赖于条件信息。 Mao等人（2019）提出了一种正则项，\\n以防止条件 GAN发生模式塌陷，通过最大化生成图像与其对应潜变量之间距离的比率，\\n从而鼓励输出多样性。其他旨在减少模式塌陷的工作包括 VEEGAN （Srivastava 等人，\\n2017） ，它引入了一个重构网络，把生成的图像映射回原始噪声，从而避免噪声到图像\\n的多对一映射。\\nSalimans 等人（2016）提出了一种计算小批次内部统计量的方法，并利用鉴别器确\\n保这些统计量与真实图像批次的统计量无法区分。这被称为小批次鉴别，通过在鉴别器\\n的末端添加一个层来实现， 该层学习每个图像的批次统计量的张量。 Karras等人（2018）\\n简化了这一过程，为小批次中每个空间位置的每个特征计算标准差。然后，他们对空间\\n位置和特征进行平均， 得到一个单一估计值， 该估计值被复制形成一个单一特征图， 附加\\n在鉴别器网络接近末端的一个层上。 Lin等人（2018）将连接后的（真实或生成的）样本\\n输入鉴别器， 并理论分析了向鉴别器提供多个样本如何增加多样性。 MAD-GAN （Ghosh\\n等人，2018）通过使用多个生成器并要求单一鉴别器识别出哪个生成器创建了样本，增\\n加了GAN样本的多样性，从而为生成器提供了创造不同样本的动力。\\n多尺度处理 ：Wang等人 （2018b） 通过在不同尺度上使用多个鉴别器， 确保了所有频\\n率带中图像质量的高度一致。其他研究在不同分辨率上定义了生成器和鉴别器（ Denton\\n等人，2015; Zhang 等人，2017d; Huang 等人，2017c） 。Karras等人（2018）引入了一\\n种渐进式增长的方法（图 15.9） ，这种方法更简单，训练速度也更快。\\nStyleGAN ：Karras等人（2019）介绍了 StyleGAN 框架（第 15.6节） 。在随后的研'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 281}, page_content='种渐进式增长的方法（图 15.9） ，这种方法更简单，训练速度也更快。\\nStyleGAN ：Karras等人（2019）介绍了 StyleGAN 框架（第 15.6节） 。在随后的研\\n究中 （Karras等人，2020b） ， 他们通过重新设计生成器中的归一化层来消除“水滴”伪影，\\n以及通过改变渐进式增长框架来减少细节不跟随粗略细节的伪影，从而提升了生成图像\\n的质量。进一步的改进包括开发了在数据有限的情况下训练 GAN的方法（ Karras等人，\\n2020a）和修正走样伪影（ Karras等人，2021） 。大量研究通过找到并操纵 StyleGAN 中\\n的潜变量来编辑图像，例如 Abdal等人（2021） 、Collins等人（2020） 、Härkönen 等人\\n（2020） 、Patashnik 等人（2021） 、Shen等人（2020b） 、Tewari等人（2020） 、Wu等\\n人（2021） 、Roich等人（2022）等的工作。 条件生成对抗网络（ Conditional GANs ）\\n:条件生成对抗网络（ Conditional GAN ）是由Mirza & Osindero 在2014年提出的，辅\\n助分类器生成对抗网络（ auxiliary classifier GAN ）则是由 Odena等人在2017年开发，\\nInfoGAN 则是由Chen等人于2016年提出。这些模型的鉴别器通常会将条件信息加在\\n输入层（ Mirza & Osindero, 2014; Denton 等人, 2015; Saito 等人, 2017）或某个中间隐\\n藏层（Reed等人, 2016a; Zhang 等人, 2017d; Perarnau 等人, 2016） 。不过， Miyato &\\nKoyama 在2018年的实验中尝试了一种新方法，将嵌入的条件信息与鉴别器的某层做\\n内积，这个做法受到了底层概率模型中类别信息作用的启发。 GAN生成的图像可基于'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 282}, page_content='15.8.笔记 267\\n多种条件，例如类别（如 Odena等人, 2017） 、文本输入（ Reed等人, 2016a; Zhang 等\\n人, 2017d） 、属性（ Yan等人, 2016; Donahue 等人, 2018a; Xiao 等人, 2018b） 、边界框\\n和关键点（ Reed等人, 2016b）以及其他图像（如 Isola等人, 2017） 。\\n图像翻译 : Isola等人在2017年开发了 Pix2Pix算法（图 15.16） ， 随后Wang等人于\\n2018年提出了一个能生成更高分辨率结果的相似系统。 StarGAN （Choi等人, 2018）能\\n够使用单一模型跨多个域进行图像到图像的翻译。周期一致性损失的概念首次由 Zhou\\n等人（2016b）在DiscoGAN 中引入，并由 Zhu等人（2017）在CycleGAN （图15.18）\\n中进一步发展。\\n对抗性损失 :在众多图像翻译任务中，并不总是需要“生成器” ；这类模型可视为一\\n种带有促进生成结果真实性的对抗性损失的监督学习任务。 Ledig等人在2017年提出\\n的超分辨率算法就是一个典型例子（图 15.17） 。Esser等人于2021年利用带对抗性损失\\n的自编码器。这种网络通过减小数据表示的尺寸来创建一个“瓶颈” ，然后从这一缩减\\n的数据空间重建图像。这个架构在实际应用中类似于编解码网络（例如，图 10.19） 。训\\n练后，自编码器能够复原与原图像非常接近且极具真实感的图像。他们将自编码器的瓶\\n颈进行矢量量化（离散化） ，随后使用 Transformer 解码器来学习离散变量上的概率分\\n布。通过从该 Transformer 解码器采样，他们能生成极其高质量的大尺寸图像。\\n反转 GANs:编辑真实图像的一种方法是将它们映射到潜在空间，调整潜在变量\\n后，再将其投射回图像空间，这一过程称为重合成。遗憾的是， GANs只能从潜在变量\\n映射到观察数据，反之则不行。这促成了反转 GANs的方法发展，即寻找与观察图像\\n尽可能接近的潜在变量。这些方法大致分为两类：第一类是学习一个能够反向映射的网\\n络（Donahue 等人, 2018b; Luo 等人, 2017a; Perarnau 等人, 2016; Dumoulin 等人, 2017;'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 282}, page_content='络（Donahue 等人, 2018b; Luo 等人, 2017a; Perarnau 等人, 2016; Dumoulin 等人, 2017;\\nGuan等人, 2020） ，即编码器。第二种方法是从某个潜在变量 z出发，通过优化使其尽\\n可能精确地重构图像（ Creswell & Bharath, 2018; Karras 等人, 2020b; Abdal 等人, 2019;\\nLipton & Tripathi, 2017 ） 。Zhu等人（2020a）将这两种方法结合起来。\\nStyleGAN 的反转特别受到关注，因为它能产生出色的结果，并能在不同尺度上控\\n制图像。然而， Abdal等人（2020）表明，在没有人为痕迹的情况下反转 StyleGAN 是\\n不可能的，并提出了向扩展的样式空间反转的方案， Richardson 等人（2021）训练了一\\n个可靠映射到该空间的编码器。即使在反转到扩展空间之后，编辑超出域的图像可能仍\\n旧面临挑战。 Roich等人（2022）通过对 StyleGAN 的生成器进行微调以精确重建图像\\n来解决这一问题，并展示了良好的编辑效果。他们还增加了精确重建邻近点的额外条件，\\n以确保修改的局部性。这种技术称为关键调整。关于 GAN反转技术的综述可以在 Xia\\n等人（2022）的研究中找到。\\n利用 GANs编辑图像 : iGAN（Zhu等人，2016）允许用户通过在现有图像上涂鸦\\n或变形来进行交互式编辑。工具随后调整输出图像，使之既真实又符合这些新的约束条\\n件。它通过寻找一个能生成与编辑图像相似并遵循任何新增线条边缘映射的潜在向量来\\n实现这一点。通常，还会添加一个遮罩，以便只有靠近编辑部位的图像区域会被更改。\\nEditGAN （Ling等人，2021）同时处理图像及其语义分割掩码，并允许对掩码进行编辑。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 283}, page_content='268 CHAPTER 15. 生成对抗网络\\n/section 习题 问题 15.1当q(x) =Pr(x)时，方程 15.8中的损失是多少？\\n问题15.2*描述方程 15.8中的损失L与方程15.9中的Jensen-Shannon 距离\\nDJS[q(x)||Pr(x)]之间的关系。\\n问题15.3考虑使用线性规划的原始形式来计算推土机距离（ Wasserstein 距离） 。离\\n散分布Pr(x=i)和q(x=j)定义在x = 1,2,3,4 上，其中：\\nb= [Pr(x= 1),Pr(x= 2),Pr(x= 3),Pr(x= 4),q(x= 1),q(x= 2),q(x= 3),q(x= 4)]T\\n(15.18)\\n请给出8x16矩阵A的内容。假设 P的内容已按列优先顺序向量化为 p。\\n问题15.4*计算两个分布之间的 (i) KL散度(KL divergence) ，(ii)反向KL散度\\n(reverse KL divergence) ，(iii) Jensen-Shannon 散度(Jensen-Shannon divergence) ，以及\\n(iv) Wasserstein 距离(Wasserstein distance) ：\\nPr(z) =8\\n>>><\\n>>>:0z <0\\n1 0≤z≤1\\n0z >1\\n和\\nPr(z) =8\\n>>><\\n>>>:0z <a\\n1a≤z≤a+ 1\\n0z >a(15.19)\\n对于a∈[−3,3]的范围。为了这个特殊情况下计算 Wasserstein 距离，考虑必须移\\n动的总“土壤” （即，概率质量）并乘以其必须移动的平方距离。\\n问题15.5当σ1=σ2= 1时，以µ1−µ2为自变量，绘制单变量高斯分布间的 KL\\n距离和Wasserstein 距离：\\nDKL=log\\x12σ2\\nσ1\\x13\\n+σ2\\n1+ (µ1−µ2)2\\n2σ2\\n2−1\\n2, (15.20)\\n和\\nDW= (µ1−µ2)2+σ2\\n1+σ2\\n2−2√σ1σ2, (15.21)\\n问题15.6设想一个维度为 100的潜变量 z。当我们对这个变量的值进行截断处理，\\n分别考虑τ= 2.0、τ= 1.0、τ= 0.5以及τ= 0.04标准差(standard deviations) 的情况。\\n在每种情况下，有多大比例的原始概率分布被排除了？'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 284}, page_content='Chapter 16\\n标准化流\\n第15章介绍了生成对抗网络（ GANs） 。这些生成模型通过深度网络处理潜在变量\\n来生成新的样本。 GANs的训练原则是让样本与真实数据难以区分。然而，它们并没有\\n定义在数据样本上的分布，因此不容易评估新样本属于同一数据集的概率。\\n本章将讨论标准化流（ Normalizing Flows ） 。这种方法通过深度网络将简单的分布\\n转化为复杂的分布，从而学习概率模型。标准化流不仅能从该分布采样，还能计算新样\\n本的概率。但它们需要特定的架构设计，即每个网络层都必须是可逆的，这意味着数据\\n转换能够双向进行。\\n16.1一维示例\\n标准化流（ Normalizing Flows ）是概率生成模型，它们通过拟合训练数据来建立概\\n率分布（见图 14.2b） 。考虑建模一维分布 Pr(x)。标准化流以一个简单、易于处理的基\\n础分布Pr(z)作为起点，这个分布基于潜变量 z，并应用函数 x=f[z,ϕ]。这里的参数\\nϕ被选定，目的是使得 Pr(x)达到期望的分布（见图 16.1） 。生成新的样本 x∗相当简单：\\n我们从基础分布中抽取一个 z∗，然后通过函数得到 x∗=f[z∗,ϕ]。\\n图 16.1:概率分布的转换。 a)基本分布是定义在潜变量 z上的标准正态分布。 b)该变量经过函\\n数x=f[z, ϕ]转换为新变量 x，进而 c)形成新的分布。要从该模型抽样，我们需要从基本分\\n布中抽取 z值（图 (a)示意了两个抽样过程，分别用绿色和棕色箭头表示） 。这些值经过函数\\nf[z, ϕ]的转换，如图 (b)中的虚线箭头所示，生成 x的值，在图 (c)中以箭头形式显示。\\n269'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 285}, page_content='270 CHAPTER 16. 标准化流\\n16.1.1 测量概率\\n衡量数据点 x的概率更为复杂。设想应用函数 f[z,ϕ]到具有已知密度 Pr(z)的随\\n机变量z。当函数拉伸其输入的区域时，概率密度会减少；当函数压缩其输入的区域时，\\n概率密度则会增加，以保证新分布下的面积总和为一。函数 f[z,ϕ]拉伸或压缩输入的程\\n度，依赖于其梯度的大小。若输入的微小变化导致输出变化较大，则函数发生拉伸；若\\n导致输出变化较小，则发生压缩（见图 16.2） 。\\n更具体地说，数据 x在变换后的分布下的概率为：\\nPr(x|ϕ) =\\x0c\\x0c\\x0c\\x0c∂f(z,ϕ)\\n∂z\\x0c\\x0c\\x0c\\x0c−1\\n·Pr(z), (16.1)\\n其中z=f−1[x,ϕ]是产生x的潜在变量。项 Pr(z)是这个潜在变量在基础密度下\\n的原始概率，根据函数的导数大小进行调整。如果这个导数值大于一，则概率减小；如\\n果小于一，则概率增加。\\n图 16.2:分布的转换。基本分布（青色，底部）通过一个函数（蓝色曲线，右上）转换，形成模\\n型分布（橙色，左侧） 。将基本分布划分为等间隔（灰色垂直线） ，变换后相邻间隔之间的概率质\\n量保持不变。当青色阴影区域通过梯度大于一的函数部分时，该区域被拉伸；因此，橙色阴影区\\n域的高度降低，以保持面积不变。在其他位置（例如， z = −2） ，梯度小于一，模型分布相对于\\n基本分布有所增加。\\n16.1.2 正向与逆向映射\\n为了从分布中抽样，我们需要使用正向映射 x=f[z,ϕ]，但为了计算似然度，我们\\n必须计算逆映射 z=f−1[x,ϕ]。因此，我们必须谨慎选择 f[z,ϕ]，以确保它是可逆的。\\n正向映射有时也被称作生成方向。基础密度通常设为标准正态分布。相应地，由于\\n反向映射将关于 x的生成分布转化为关于 z的正态分布（图 16.3） ，它被称为规范化方\\n向。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 286}, page_content='16.2.通用案例 271\\n图 16.3:逆映射（归一化方向） 。如果函数可逆，则可以将模型分布逆转回原始基本分布。模型\\n分布下 x点的概率部分依赖于基本分布下等效 z点的概率（参见方程 16.1） 。\\n16.1.3 学习\\n为了学习这个分布，我们需要找到参数 ϕ，这些参数能使训练数据集 {xi}I\\ni=1的似\\n然度最大化，或等效地，使负对数似然度最小化：\\nˆϕ=argmax\\nϕ\"IY\\ni=1Pr(xi|ϕ)#\\n=argmin\\nϕ\"\\n−IX\\ni=1log[Pr(xi|ϕ)]#\\n=argmin\\nϕ\"IX\\ni=1log\\x0c\\x0c\\x0c\\x0c∂f(zi,ϕ)\\n∂zi\\x0c\\x0c\\x0c\\x0c−1\\n−log[Pr(zi)]#\\n, (16.2)\\n其中，我们假定数据在第一行是独立同分布的，并且第三行使用了方程 16.1的似\\n然定义。\\n16.2通用案例\\n前一节通过转换一个简单的基础密度 Pr(z)来模拟一个一维的概率分布 Pr(x)的\\n例子。现在我们将这种方法扩展到多元分布 Pr(x)和Pr(z)，并引入深度神经网络定义\\n的变换作为新的复杂性因素。\\n设想对一个随机变量 z∈RD应用函数x=f[z,ϕ]，这里z有一个基础密度 Pr(z)，\\n而f[z,ϕ]是一个深度神经网络。得到的变量 x∈RD将具有新的分布。可以通过以\\n下步骤生成新的样本 x∗：(i)从基础密度中抽取样本 z∗，(ii)通过神经网络计算得到\\nx∗=f[z∗,ϕ]。\\n根据方程 16.1的类比，这个分布下的样本似然度为：\\nPr(x|ϕ) =\\x0c\\x0c\\x0c\\x0c∂f(z,ϕ)\\n∂z\\x0c\\x0c\\x0c\\x0c−1\\n·Pr(z), (16.3)\\n这里z=f−1[x,ϕ]是生成x的潜变量z。第一项是关于 z的f[z,ϕ]的D×D雅可\\n比矩阵的行列式的逆，该矩阵在 (i,j)位置的元素是∂f(z,ϕ)\\n∂zi。就像绝对导数衡量一维函'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 287}, page_content='272 CHAPTER 16. 标准化流\\n数应用时点的面积变化，绝对行列式衡量多变量函数中点的体积变化。第二项是基础密\\n度下潜变量的概率。\\n16.2.1 深度神经网络的正向映射\\n在实际应用中，正向映射 f[z,ϕ]通常由一个包含多个层次 [f◦\\nk,ϕk]的神经网络定义，\\n其中每层都有其参数 ϕk，这些层次按照以下方式组合：\\nx=f[z,ϕ] =fk[fk−1[...[f1[z,ϕ 1],ϕ2],...ϕ k−1],ϕk]. (16.4)\\n反向映射（即规范化方向）则是通过按相反顺序应用每个层的逆 [f◦\\nk,ϕk]来定义的：\\nz=f−1[x,ϕ] =f−1\\n1\\x02\\n...\\x02\\nf−1\\nk−1\\x02\\nf−1\\nk[x,ϕ k],ϕk−1\\x03\\n,...ϕ 2\\x03\\n,ϕ1\\x03\\n. (16.5)\\n基础密度Pr(z)通常定义为多元标准正态分布（即均值为零，协方差为单位矩阵） 。\\n因此，每个后续逆层的作用是逐步将数据密度向这个正态分布“流动” （图 16.4） ，从而\\n引出了“标准化流”这一术语。\\n正向映射的雅可比可以表达为：\\n∂f[z,ϕ]\\n∂z=∂fk[fk−1,ϕk]\\n∂fk−1·∂fk−1[fk−2,ϕk−1]\\n∂fk−2·...·∂f1[z,ϕ 1]\\n∂z, (16.6)\\n其中fk表示函数fℓ[·,ϕℓ]的输出。这个雅可比的绝对行列式可以通过计算各个绝对\\n行列式的乘积来得到：\\n\\x0c\\x0c\\x0c\\x0c∂f[z,ϕ]\\n∂z\\x0c\\x0c\\x0c\\x0c=\\x0c\\x0c\\x0c\\x0c∂fk[fk−1,ϕk]\\n∂fk−1\\x0c\\x0c\\x0c\\x0c·\\x0c\\x0c\\x0c\\x0c∂fk−1[fk−2,ϕk−1]\\n∂fk−2\\x0c\\x0c\\x0c\\x0c·...·\\x0c\\x0c\\x0c\\x0c∂f1[z,ϕ 1]\\n∂z\\x0c\\x0c\\x0c\\x0c.(16.7)\\n通过对方程 16.5应用同样的规则，可以找到反向映射的雅可比的绝对行列式，它\\n是正向映射中绝对行列式的倒数。\\n使用负对数似然标准，我们用数据集 {xi}中的I个训练样本来训练标准化流：\\nˆϕ=argmax\\nϕ\"IY\\ni=1Pr(zi)·\\x0c\\x0c\\x0c\\x0c∂f[zi,ϕ]\\n∂zi\\x0c\\x0c\\x0c\\x0c−1#\\n=argmin\\nϕ\"IX\\ni=1log\\x0c\\x0c\\x0c\\x0c∂f[zi,ϕ]\\n∂zi\\x0c\\x0c\\x0c\\x0c−log[Pr(zi)]#\\n, (16.8)\\n其中zi=f−1[xi,ϕ]，Pr(zi)是在基础分布下测量的，绝对行列式\\x0c\\x0c\\x0c∂f[zi,ϕ]\\n∂zi\\x0c\\x0c\\x0c根据方程\\n16.7计算得出。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 288}, page_content='16.3.可逆网络层 273\\n图 16.4:深度神经网络的正向和逆向映射。基本分布（左侧）通过网络层 f1[•, ϕ1]、f2[•, ϕ2]\\n等逐渐转换，形成模型分布。每层都是可逆的，可以认为是通过这些层的逆过程逐渐将模型分布\\n“流动”回基本分布。\\n16.2.2 网络层设计要求\\n标准化流理论本身是直观的。但要实际应用，我们的神经网络层 fk必须具备四个\\n特性。\\n1.网络层整体上必须具有足够的表达能力，能将多元标准正态分布映射到任意密\\n度函数。 2.网络层需可逆，即每层都应定义从任一输入点到输出点的唯一双射关系。如\\n果多个输入映射到同一个输出，则逆映射将不明确。 3.每层的逆映射必须能够高效计\\n算。鉴于我们在训练过程中需要反复评估似然性，故此过程必须有闭式解或快速算法。\\n4.无论正向还是逆向映射，都必须能高效计算雅可比行列式。\\n这些要求确保了标准化流在实践中的可行性和效率。\\n16.3可逆网络层\\n接下来，我们将介绍用于这些模型的各种可逆网络层或流类型。首先考虑的是线性\\n流和逐元素流。这些流易于逆向计算，并且可以计算它们的雅可比行列式，但它们对于\\n描述基础密度的任意转换表达能力不足。然而，它们是构建更具表达性的耦合流、自回\\n归流和残差流的基础。\\n16.3.1 线性流\\n线性流的形式为 f[ht!] =β+ Ωh，其中如果矩阵 Ω可逆，则这种线性变换也是可逆\\n的。对于维度为 D×D的Ω，其逆运算和行列式的计算复杂度均为 O(D3)，意味着随\\n着维度D增大，线性流的计算成本急剧上升。\\n如果 Ω采用特殊的结构， 如对角矩阵， 逆运算和行列式的计算会更高效， 仅需 O(D)\\n的复杂度，但这会限制其表达能力，因为此时 h的各元素不互相作用。而正交矩阵虽然\\n逆运算更高效且行列式固定，但不能对各维度进行缩放。三角矩阵在实用性方面表现更\\n好，可以通过O(D2)复杂度的回代过程逆运算，其行列式为对角元素的乘积。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 289}, page_content='274 CHAPTER 16. 标准化流\\n一种既通用又易于逆运算、能高效计算雅可比行列式的线性流可以通过直接基于\\nLU分解来参数化，即：\\nΩ =PL(U+D), (16.9)\\n其中P是预定的置换矩阵， L是下三角矩阵， U是对角线元素为零的上三角矩阵，\\nD是补充对角线元素的对角矩阵。该形式的逆运算复杂度为 O(D2)，且其对数行列式为\\nD对角线上绝对值的对数和。\\n然而，线性流的表达能力有限。当应用于正态分布输入 Norm [µ,Σ]的线性函数\\nf[ht!] =β+ Ωh会产生均值为 β+ Ωµ、方差为 ΩΣΩ⊤的正态分布输出，因此仅用线性\\n流无法实现正态分布到任意密度的映射。\\n16.3.2 逐元素流\\n鉴于线性流表达能力的限制，我们转向非线性流，其中最基本的是逐元素流。逐元\\n素流通过对输入的每个元素应用带参数 ϕ的逐点非线性函数 f[·,ϕ]来工作，表达式为：\\nf[ht!] = [f[h1,ϕ],f[h2,ϕ],...,f [hD,ϕ]]T. (16.10)\\n逐元素流的雅可比∂f[ht!]\\n∂h是对角矩阵，这意味着 f[ht!]的每个输入元素只影响相应\\n的输出元素。因此，雅可比的行列式是对角线元素乘积：\\n\\x0c\\x0c\\x0c\\x0c∂f[ht!]\\n∂h\\x0c\\x0c\\x0c\\x0c=DY\\nd=1\\x0c\\x0c\\x0c\\x0c∂f[hd]\\n∂hd\\x0c\\x0c\\x0c\\x0c. (16.11)\\n这里的f[·,ϕ]函数可以是固定的可逆非线性函数，比如泄露的 ReLU，或者任何参\\n数化的一对一可逆映射。例如，一个分段线性函数划分为 K个区域，它将区间 [0,1]映\\n射到自身：\\nf[hd,ϕ] = b−1X\\nk=1ϕk!\\n+ (hK−b)ϕb, (16.12)\\n这里的参数 ϕ1,ϕ2,...,ϕ K是正值且总和为 K，b=⌊Kh⌋是包含h的区间的索引。\\n第一项是所有先前区间的参数和，第二项反映了 h在当前区间的位置比例。这样的函数\\n不仅易于逆运算，而且其梯度几乎在所有位置都可计算。类似地，使用样条函数等方案\\n可以创建光滑且因为单调性保证可逆的函数。\\n尽管逐元素流是非线性的，但它们不混合输入维度，无法产生变量间的相关性。若\\n与混合维度的线性流交替使用，能够实现更为复杂的变换。实际上，逐元素流常作为更\\n复杂结构，如耦合流的组成部分。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 290}, page_content='16.3.可逆网络层 275\\n图 16.5:分段线性映射。可以通过将输入域 h∈[0,1]分为 K个等大小的区域（此处 K= 5）\\n来创建一个可逆的分段线性映射 h′=f[h, ϕ]。每个区域都有一个参数为 ϕk的斜率。 a)当这些\\n参数均为正且和为一时， b)该函数将是可逆的，并能将输出映射到 h′∈[0,1]的输出域。\\n16.3.3 耦合流\\n耦合流通过将输入 h分割成两个部分 h= [hT\\n1,hT\\n2]T来工作，其流的定义为：\\nh′\\n1=h1\\nh′\\n2=g[h2,ϕ[h1]]. (16.13)\\n其中g[·,ϕ]是以输入h1的非线性函数 ϕ[h1]为参数的逐元素流（或其他可逆层） ，\\n通常通过神经网络实现 ϕ[·]。原始变量的恢复可以表示为：\\nh1=h′\\n1\\nh2=g−1[h′\\n2,ϕ[h1]]. (16.14)\\n若g[·,ϕ]为逐元素流，则其雅可比为对角矩阵，左上角是单位矩阵，右下角是逐元\\n素变换的导数。雅可比的行列式即为这些对角线值的乘积。\\n耦合流的逆映射和雅可比都能高效计算，但它仅调整第二部分参数，这一调整依赖\\n于第一部分。为了达到更广泛的变换效果，层间通过置换矩阵随机打乱 h的元素，确保\\n每个变量最终都被其他变量转换。实际上，这些置换矩阵一旦随机初始化就固定下来，\\n不再学习。对于结构化数据，如图像，通过在层间用 1x1卷积进行置换，将通道分为两\\n部分h1和h2。\\n16.3.4 自回归流\\n自回归流是对耦合流的泛化，它把每个输入维度处理为独立的“块” （图 16.7） 。这\\n种方法根据输入 h的前d−1维度来计算输出 h′的第d维度：\\nh′\\nd=g[hd,ϕ[h1:d−1]]. (16.15)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 291}, page_content='276 CHAPTER 16. 标准化流\\n图 16.6:耦合流。 a)输入（橙色向量）被划分为 h1和h2。输出的第一部分 h′\\n1（青色向量）是\\nh1的副本。输出 h′\\n2由对 h2应用可逆变换 g[·, ϕ]产生，其中参数 ϕ是h1的一个（不必可逆）\\n函数。 b)在逆映射中， h1=h′\\n1。这允许我们计算 ϕ[h1]参数，然后应用逆变换 g−1[h′\\n2, ϕ]来恢\\n复h2。\\n这里的函数 g[·,ϕ]称为转换器（ transformer ） ，参数ϕ、ϕ[h1]、ϕ[h2]等称为条件器\\n（conditioners ） 。与耦合流相同，转换器 g[·,ϕ]需要是可逆的，但条件器 ϕ[·]可以是任意\\n形式，通常是神经网络。如果转换器和条件器足够灵活，自回归流可以作为通用逼近器\\n（universal approximators ） ，表示任意的概率分布。\\n通过使用带有适当掩码的网络， 可以并行计算输出 h′的所有元素， 使得在 d位置的\\n参数ϕ仅依赖于之前的位置。 这种方法称为掩码自回归流（ masked autoregressive flow ） 。\\n其原理与掩码自注意力（第 12.7.2节）非常相似，它剪除了将输入与之前输出相关联的\\n连接。\\n反向变换的效率较低。考虑如下的前向映射：\\nh′1=g(h1,ϕ)\\nh′2=g(h2,ϕ|h1)\\nh′3=g(h3,ϕ|h1:2)\\nh′4=g(h4,ϕ|h1:3). (16.16)\\n这需要按照耦合流的类似原理，顺序反向进行：\\nh1=g−1(h′1,ϕ)\\nh2=g−1(h′2,ϕ|h1)\\nh3=g−1(h′3,ϕ|h1:2)\\nh4=g−1(h′4,ϕ|h1:3). (16.17)\\n因为hd的计算依赖于 h1:d−1（即迄今为止的部分结果） ，所以这个过程不能并行执\\n行。因此，当输入规模较大时，逆变换过程会非常耗时。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 292}, page_content='16.3.可逆网络层 277\\n图 16.7:自回归流。输入 h（橙色列）和输出 h′（青色列）被拆分为各自的维度（这里是四个维\\n度） 。 a)输出 h′1是输入 h1的一个可逆变换。输出 h′2是输入 h2的一个可逆函数，其参数取决\\n于h1h′3是输入 h3的一个可逆函数，其参数依赖于先前的输入 h1和h2，以此类推。由于输\\n出间无相互依赖，它们可以并行计算。 b)使用类似耦合流的方法计算自回归流的逆，但需注意\\n计算 h2时必须知道 h1，计算 h3时必须知道 h1和h2，依此类推，因此逆过程不能并行执行。\\n16.3.5 逆自回归流\\n掩码自回归流是在规范化（逆向）过程中定义的，目的是为了高效评估似然值，从\\n而学习模型。然而，在正向过程中进行采样时，每一层的每个变量都必须逐个计算，导\\n致速度较慢。使用自回归流进行正向（生成性）变换可以高效采样，但计算似然值（和\\n训练）则较慢。这种流称为逆自回归流（ inverse autoregressive flow ） 。\\n一个技巧是构建一个掩码自回归流来学习分布（即教师） ，然后利用它来训练一个\\n可以高效采样的逆自回归流（即学生） 。这种方法需要一种新的标准化流形式，它基于\\n另一个函数学习，而不是依赖于一组样本（参见第 16.5.3节） 。\\n16.3.6 残差流： iRevNet\\n残差流受到残差网络设计的启发，将输入分为两部分 h= [hT\\n1,hT\\n2]T（与耦合流类\\n似） ，并按如下方式定义输出：\\nh′1=h1+f1[h2,ϕ1]\\nh′2=h2+f2[h′1,ϕ2], (16.18)\\n其中，f1[·,ϕ1]和f2[·,ϕ2]是两个函数，它们不一定要可逆（见图 16.8） 。逆过程可\\n以通过逆转计算顺序得到：\\nh2=h′2−f2[h′1,ϕ2]\\nh1=h′1−f1[h2,ϕ1]. (16.19)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 293}, page_content='278 CHAPTER 16. 标准化流\\n如同耦合流，通过将输入分块，限制了可以表示的变换类型。因此，为了使变量能\\n够以任意方式混合，需要在各层之间进行输入置换。\\n虽然这种公式可以较容易地进行反转，但对于一般的函数 f1[·,ϕ1]和f2[·,ϕ2]，没有\\n一种高效的方法来计算其雅可比矩阵。在训练残差网络时，有时采用这种公式以节省内\\n存，因为网络是可逆的，在前向传播中无需存储每一层的激活状态。\\n图 16.8:残差流。通过将输入拆分为 h1和h2并建立两个残差层来计算一个可逆函数。在第一\\n层，处理 h2并加上 h1。在第二层，再次处理结果并加上 h2。b)在反向操作中，函数计算顺序\\n相反，加法变为减法。\\n16.3.7 残差流与收缩映射： iResNet\\n利用残差网络的另一种方法是采用 *Banach 不动点定理 *（Banach fixed point\\ntheorem）或*收缩映射定理 *（contraction mapping theorem ） ，这些定理指出每个收\\n缩映射都有一个不动点。收缩映射 f[·]具有以下特性：\\ndist[f(z′),f(z)]<β·dist[z′,z]∀z,z′, (16.20)\\n其中dist[·,·]是距离函数， 0<β < 1。当这种具有特定性质的函数反复迭代（即输\\n出被反复作为输入传回）时，结果会收敛至固定点，满足 f[z] =z（见图16.9） 。理解这\\n个过程可以通过将函数同时作用于固定点和当前位置来实现；固定点保持不变，但两者\\n之间的距离会减小，导致当前位置逐渐接近固定点。\\n我们可以利用这一定理来求逆形如\\ny=z+f[z] (16.21)\\n的方程，前提是 f[z]为收缩映射。换言之，可以用它来寻找映射到给定值 y∗的\\nz∗。这个过程可以从任意点 z0开始，通过迭代 zk+1=y∗−f[zk]来实现，并最终在\\nz+f[z] =y∗处收敛到固定点（见图 16.9b） 。\\n如果我们确保 f[h,ϕ]是一个收缩映射，同样的原理可以用于逆转形式为 h′=h+\\nf[h,ϕ]的残差网络层。在实践中，这意味着 Lipschitz 常数（Lipschitz constant ）必须小\\n于一。假设激活函数的斜率不超过一，这相当于要求每个权重矩阵 Ω的最大特征值必\\n须小于一。一种粗略的方法是通过限制它们的绝对大小来确保权重 Ω较小。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 294}, page_content='16.3.可逆网络层 279\\n雅可比行列式不容易直接计算，但可以通过一系列技巧近似计算其对数值。\\nlog\\x14\\nI+∂f(h,ϕ)\\n∂h\\x15\\n=trace\\x14\\nlog\\x12\\nI+∂f(h,ϕ)\\n∂h\\x13\\x15\\n=∞X\\nk=1(−1)k−1trace\"\\x12∂f(h,ϕ)\\n∂h\\x13k#\\n, (16.22)\\n其中利用了 log|A|=trace [log|A|]的恒等式，并将其展开为幂级数。\\n即便是截断该级数，计算各项的迹值仍然计算量大。因此，我们采用 Hutchinson\\n迹估计器 （Hutchinson’s trace estimator ）来进行近似。考虑均值为 0且方差为 I的正\\n态随机变量 ϵ，矩阵A的迹可以估计为：\\ntrace [A] =trace [E[ϵϵT]]\\n=trace [E[AϵϵT]]\\n=E[trace [AϵϵT]]\\n=E[trace [ϵTAϵ]]\\n=E[ϵTAϵ],(16.23)\\n其中第一行成立因为 E[ϵϵT] =I。后续各行基于期望算子的性质、迹算子的线性及\\n迹的循环置换不变性。最后，我们通过从 Pr(ϵ)中抽取样本 ϵi来估计迹值：\\ntrace [A] =E[ϵTAϵ]≈1\\nIIX\\ni=1ϵT\\niAϵi. (16.24)\\n通过这种方法，我们可以近似地计算泰勒级数幂次的迹，并估算对数概率（方程\\n16.22） 。\\n图 16.9:收缩映射。若函数处处的绝对斜率小于一，则该函数的迭代会收敛到固定点 f[z] =z。\\na)从z0开始，我们计算 z1=f[z0]，然后将 z1重新传入函数并迭代。最终，此过程会收敛到\\nf[z] =z的点（即函数与虚线对角恒等线交汇处） 。 b)通过观察固定点 y∗−f[z]（橙线与虚线恒\\n等线的交点） ，可以用来反转形如 y=z+f[z]的方程，找到 y∗=z+f[z]的解。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 295}, page_content='280 CHAPTER 16. 标准化流\\n16.4多尺度流\\n在正规化流模型中，潜变量空间 z必须与数据空间 x的尺寸相同，但我们知道，自\\n然数据集往往可以由更少的底层变量描述。因此，在某个阶段，我们需要引入这些变量，\\n但让它们穿越整个网络是效率低下的。这催生了多尺度流（图 16.10）的理念。\\n在生成过程中，多尺度流将潜向量分割为 z= [z1,z2,...,z N]。第一部分 z1经过一系\\n列与z1维数相同的可逆层处理，直至某一阶段， z2被追加并与第一部分合并。这个过\\n程一直进行，直到网络尺寸与数据 x相匹配。在规范化过程中，网络从 x的完整维度开\\n始，但当达到添加 zn的阶段时，这一部分会根据基础分布进行评估。\\n图 16.10:多尺度流。在正规化流中，潜在空间 z的大小必须与模型密度相等。但是，它可以被\\n分成几个部分，这些部分可以在不同的层次逐渐引入，从而加快密度估计和抽样速度。对于逆过\\n程，黑色箭头方向反转，且每块的最后部分跳过剩余处理步骤。例如， f−1\\n3[·, ϕ3]仅作用于前三\\n块，而第四块直接成为 z4并根据基本密度进行评估。\\n16.5应用\\n现在，我们讨论正规化流的三个应用场景。首先是建模概率密度，其次是用于图像\\n合成的GLOW模型，最后是使用正规化流来近似其他分布。\\n16.5.1 建模密度\\n本书讨论的四种生成模型中，只有正规化流能够精确计算新样本的对数似然值。生\\n成对抗网络（ GAN）不具有概率特性，变分自编码器（ VAE）和扩散模型则只能提供似\\n然的下界。图 16.11展示了在两个简单问题中使用 i-ResNet 估计的概率分布。密度估计\\n的一项应用是异常检测，即用正规化流模型描述干净数据集的分布。低概率的新样本会\\n被标记为离群点。然而，需要谨慎，因为高概率的离群点也可能存在，这些点不属于典\\n型集（参见图 8.13） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 296}, page_content='16.5.应用 281\\n图 16.11:建模密度。 a)二维玩具数据样本。 b)利用 iResNet 建模得到的密度。 c–d)第二个示\\n例。摘自 Behrmann et al. (2019) 。\\n16.5.2 图像合成\\n生成流模型 GLOW是一种正规化流模型，能够生成高保真度的图像（见图 16.12） ，\\n采用了本章提到的许多概念。这一模型在规范化方向上更易于理解。 GLOW以一个包\\n含RGB图像的256×256×3 张量开始，使用耦合层进行处理，其中通道被分为两部分。\\n第二部分在每个空间位置经过不同的仿射变换，这些变换的参数由运行在另一半通道上\\n的2D卷积神经网络计算。耦合层与 1×1卷积层交替进行，后者通过 LU分解进行参数\\n化，从而混合各通道。\\n为了降低分辨率，系统会周期性地将每个 2×2区域合并为一个位置，并将通道数\\n量增加四倍。 GLOW作为一种多尺度流，其部分通道会周期性地被移除，并加入到潜向\\n量z中。由于图像是离散的（ RGB值被量化） ，在输入中加入噪声以防止训练似然值无\\n限增加，这个过程称为去量化。\\n为了生成更逼真的图像， GLOW模型从提高到正次幂的基础密度中采样。这种方\\n法倾向于选择更接近密度中心而不是边缘的样本，类似于 GAN中的截断技巧（见图\\n15.10） 。但是，这些样本的质量并不如 GAN或扩散模型生成的样本。目前尚不清楚这\\n是否由于可逆层相关的基本限制，还是因为对这一目标的研究投入较少。\\n图16.13展示了使用 GLOW进行插值的例子。通过对两个真实图像在规范化方向\\n进行转换，计算得到两个潜向量。这些潜向量之间的中间点通过线性插值计算得出，并\\n通过生成方向的网络映射回图像空间，生成了一系列在两个真实图像之间逼真过渡的图\\n像。\\n16.5.3 近似其他密度模型\\n正规化流还能学习生成样本，这些样本近似于一个易于评估却难以从中抽样的现有\\n密度。在这种情境下，我们把正规化流 Pr(x|ϕ)称为“学生” ，将目标密度 q(x)称为“教\\n师” 。\\n为了进展，我们从“学生”模型生成样本 xi=f(zi,ϕ)。因为这些样本是由我们自\\n己生成的，我们知道它们的对应潜变量 zi，可以直接计算学生模型中的似然度，而不需\\n要进行逆运算。因此，我们可以采用掩码自回归流（ masked-autoregressive flow ）这样的'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 296}, page_content='己生成的，我们知道它们的对应潜变量 zi，可以直接计算学生模型中的似然度，而不需\\n要进行逆运算。因此，我们可以采用掩码自回归流（ masked-autoregressive flow ）这样的\\n模型，在这种模型中逆运算较慢。我们定义了一个基于反向 KL散度的损失函数，该函'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 297}, page_content='282 CHAPTER 16. 标准化流\\n图 16.12:基于 CelebA HQ 数据集（ Karras et al., 2018 ）训练的 GLOW模型样本。这些样本\\n质量较好，虽然与 GANs和扩散模型相比， GLOW的结果稍逊一筹。摘自 Kingma & Dhariwal\\n(2018)。\\n图 16.13:使用 GLOW模型的插值。左右两边的图像是真实的人物照片。中间的图像是通过将\\n真实图像映射到潜空间进行插值，然后将插值结果映射回图像空间而生成的。摘自 Kingma &\\nDhariwal (2018) 。\\n数促使学生模型和教师模型的似然度一致，并用它来训练学生模型（见图 16.14） ：\\nˆϕ=argmin\\nϕKL\"IX\\ni=1δ[x−f(zi,ϕ)]||q(x)#\\n. (16.25)\\n这种方法与通常使用正规化流构建概率模型 Pr(xi,ϕ)形成对比，后者是基于未知\\n分布的样本 xi采用最大似然估计，依赖于前向 KL散度中的交叉熵项（参见第 5.7节） ：\\nˆϕ=argmin\\nϕKL\"\\r\\r\\r\\r\\r1\\nIIX\\ni=1δ(x−xi)||Pr(xi;ϕ)\\r\\r\\r\\r\\r#\\n. (16.26)\\n正规化流可以利用这种技巧在变分自编码器（ VAE）中建模后验（参见第 17章） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 298}, page_content='16.6.总结 283\\n图 16.14:近似密度模型。 a)训练数据。 b)通常，我们调整流模型的参数，以最小化训练数据与\\n流模型之间的 KL散度，这相当于执行最大似然拟合（参见第 5.7节） 。 c)或者，我们可以调整\\n流参数 ϕ，以将流样本 xi=f[zi, ϕ]与目标密度之间的 KL散度最小化。\\n16.6总结\\n正规化流把基础分布（通常是正态分布）转变为新的密度。其优势在于能够精确计\\n算样本的似然值并生成新样本。但它们的一个架构限制是每一层必须可逆；我们需要用\\n正向变换生成样本，用反向变换计算似然值。\\n确保可以高效估计雅可比行列式对于评估似然值也很关键；为了学习密度，这个过\\n程需要反复执行。即便雅可比行列式不能高效估计，可逆层本身依然有用，因为它们能\\n将训练一个 K层网络的内存需求从 O[K]降低到O[1]。本章回顾了可逆网络层或流动。\\n我们讨论了线性流和元素级流，这些流简单但表达能力有限。接着，我们探讨了更复杂\\n的流类型，如耦合流、自回归流和残差流。最后，我们展示了正规化流如何用于估计似\\n然值、生成及插值图像和近似其他分布。\\n16.7笔记\\n归一化流最早由 Rezende & Mohamed (2015) 提出，其思想基础还包括 Tabak &\\nVanden-Eijnden (2010) 、Tabak & Turner (2013) 和Rippel & Adams (2013) 的研究。 关于\\n归一化流的综述可参见 Kobyzev 等(2020)和Papamakarios 等(2021)的工作。 Kobyzev\\n等(2020)对多种归一化流方法进行了定量比较，并认为当时 Flow++ 模型（一种引入\\n了新型元素级变换和其他创新的耦合流模型）表现最佳。\\n可逆网络层 ：可逆层可以减少反向传播算法的内存需求，因为在反向传播时可以\\n重新计算前向传播过程中的激活值，无需存储。除了本章讨论的常规网络层和残差层'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 299}, page_content='284 CHAPTER 16. 标准化流\\n（Gomez等, 2017; Jacobsen 等, 2018），图神经网络（ Li等, 2021a）、循环神经网络\\n（MacKay 等, 2018） 、掩蔽卷积（ Song等, 2019） 、U-Net（Brügger等, 2019; Etmann 等,\\n2020）以及Transformer （Mangalam 等, 2022）等领域也开发了可逆层。\\n径向和平面流 ：归一化流的初始论文（ Rezende & Mohamed, 2015 ）介绍了平面流\\n（沿特定维度压缩或扩展分布）和径向流（围绕特定点压缩或扩展） 。这些流的逆过程不\\n易计算，但对于近似难以快速采样的分布或只能评估到未知缩放因子的似然，它们非常\\n有用（图 16.14） 。\\n应用：归一化流的应用范围广泛，包括图像生成（ Ho等, 2019; Kingma & Dhariwal,\\n2018） 、噪声建模（ Abdelhamed 等, 2019） 、视频生成（ Kumar等, 2019b） 、音频生成\\n（Esling等, 2019; Kim 等, 2018; Prenger 等, 2019） 、图生成（ Madhawa 等, 2019） 、图像\\n分类（Kim等, 2021; Mackowiak 等, 2021） 、图像隐写（ Lu等, 2021） 、超分辨率（ Yu等,\\n2020; Wolf 等, 2021; Liang 等, 2021） 、风格转换（ An等, 2021） 、运动风格转换（ Wen\\n等, 2021） 、3D形状建模（ Paschalidou 等, 2021） 、压缩（ Zhang等, 2021b） 、sRGB到\\nRAW图像转换（ Xing等, 2021） 、去噪（ Liu等, 2021b） 、异常检测（ Yu等, 2021） 、图\\n像到图像转换（ Ardizzone 等, 2020） 、细胞显微图像合成（ Yang等, 2021）以及光传输\\n模拟（Müller等, 2019b） 。对于处理图像数据的应用，在学习前需加入噪声，因为输入\\n数据是量化且离散的（参见 Theis等, 2016） 。\\nRezende & Mohamed (2015) 利用归一化流对 VAEs中的后验进行建模。 Abdal等'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 299}, page_content='数据是量化且离散的（参见 Theis等, 2016） 。\\nRezende & Mohamed (2015) 利用归一化流对 VAEs中的后验进行建模。 Abdal等\\n(2021)通过归一化流来建模 StyleGAN 潜在空间中的属性分布，并据此改变真实图像\\n中的指定属性。 Wolf等(2021)则用归一化流学习噪声输入图像与干净图像之间的关系，\\n进而生成可用于训练去噪或超分辨率模型的噪声数据。\\n归一化流还在物理（ Kanwar等, 2020; Köhler 等, 2020; Noé 等, 2019; Wirnsberger\\n等, 2020; Wong 等, 2020） 、 自然语言处理（ Tran等, 2019; Ziegler & Rush, 2019; Zhou 等,\\n2019; He 等, 2018; Jin 等, 2019）和强化学习（ Schroecker 等, 2019; Haarnoja 等, 2018a;\\nMazoure 等, 2020; Ward 等, 2019; Touati 等, 2020）领域找到了广泛应用。\\n线性流：对角线性流能够实现类似 Batch-Norm （Dinh等, 2016）和ActNorm\\n（Kingma & Dhariwal, 2018 ）的规范化转换。 Tomczak & Welling (2016) 研究了结合\\n三角矩阵和使用 Householder 变换参数化的正交变换。 Kingma & Dhariwal (2018) 提出\\n了第16.5.2节所述的 LU参数化方法。 Hoogeboom 等(2019b)建议使用 QR分解，避免\\n了预设置换矩阵的需求。卷积作为线性变换（图 10.4） ，在深度学习中被广泛应用，但计\\n算其逆和行列式并不直观。 Kingma & Dhariwal (2018) 使用1×1卷积，实质上是在每个\\n位置独立应用的完整线性变换。 Zheng等(2017)提出了仅限于一维卷积的 ConvFlow 。\\nHoogeboom 等(2019b)为二维卷积建模提供了更通用的解决方案，方法包括堆叠掩蔽\\n自回归卷积或在傅立叶域操作。\\n逐元素流和耦合函数 ：逐元素流通过使用相同的函数独立变换每个变量来工作，每\\n个变量有其参数。这些流也可以形成耦合流和自回归流中的耦合函数，其中参数由前面'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 299}, page_content='自回归卷积或在傅立叶域操作。\\n逐元素流和耦合函数 ：逐元素流通过使用相同的函数独立变换每个变量来工作，每\\n个变量有其参数。这些流也可以形成耦合流和自回归流中的耦合函数，其中参数由前面\\n的变量决定。为保证函数的可逆性，必须保证这些函数是单调的。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 300}, page_content='16.7.笔记 285\\n加性耦合函数 （ Dinh等, 2015） 只向变量添加一个偏移量。 仿射耦合函数则对变量进\\n行缩放并添加偏移量， 这一方法被 Dinh等(2015)、Dinh等(2016)、Kingma & Dhariwal\\n(2018)、Kingma等(2016)和Papamakarios 等(2017)所采用。 Ziegler & Rush (2019) 提\\n出了非线性平方流，即用五个参数的多项式之比构成的可逆函数。连续混合 CDF（Ho\\n等, 2019）通过基于 K logistics 混合物的累积密度函数 (CDF)应用单调变换，然后经过\\n逆逻辑sigmoid函数处理，并进行缩放和偏移。\\n分段线性耦合函数（图 16.5）由Müller等(2019b)开发。此后，基于三次样条\\n（Durkan等, 2019a）和有理二次样条（ Durkan等, 2019b）的系统被提出。 Huang等\\n(2018a)引入了神经自回归流，其函数由能产生单调函数的神经网络表示。一个必要条\\n件是所有权重均为正，且激活函数是单调的。由于训练所有权重为正的网络较难，因此\\n提出了无约束单调神经网络（ Wehenkel & Louppe, 2019 ） ，它们建模严格正的函数，并\\n通过数值积分获得单调函数。 Jaini等(2019)根据所有正单变量多项式均为多项式平方\\n和的原理，构建了可以闭式积分的正函数。 Dinh等(2019)进一步探讨了分段单调耦合\\n函数。\\n耦合流：Dinh等(2015)首次引入了耦合流，其中将维度分为两半（图 16.6） 。Dinh\\n等(2016)推出的RealNVP 通过交替选取像素或通道块来分割图像输入。 Das等(2019)\\n根据导数的大小选择特征进行传播。 Dinh等(2016)将逐步引入维度的多尺度流视为\\n耦合流，其中参数 ϕ不依赖于数据的另一半。 Kruse等(2021)提出了耦合流的层次化\\n表述，递归地将每个分区一分为二。 GLOW（图16.12–16.13）由Kingma & Dhariwal\\n(2018)设计，并采用耦合流，同样适用于 NICE（Dinh等, 2015） 、RealNVP （Dinh等,\\n2016） 、FloWaveNet （Kim等, 2018） 、WaveGlOW （Prenger等, 2019）和Flow++（Ho'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 300}, page_content='2016） 、FloWaveNet （Kim等, 2018） 、WaveGlOW （Prenger等, 2019）和Flow++（Ho\\n等, 2019） 。\\n自回归流 ：Kingma 等(2016)在归一化流研究中采用了自回归模型。 Germain 等\\n(2015)开发了一种遮蔽前面变量的通用方法， Papamakarios 等(2017)利用该方法在\\n遮蔽自回归流中同时计算所有输出。 Kingma 等(2016)推出了逆自回归流。 Parallel\\nWaveNet （Van den Oord 等, 2018）将WaveNet （Van den Oord 等, 2016）转化为逆自\\n回归流，以加速音频生成的采样过程（参见图 16.14c–d） 。\\n残差流：残差流基于残差网络（ He等, 2016a）。RevNets（Gomez等, 2017）和\\niRevNets （Jacobsen 等, 2018）将输入分为两部分（图 16.8） ，每部分通过一个残差网络。\\n这些网络虽可逆，但雅可比行列式不易计算。残差连接被视为普通微分方程的离散化，\\n这一观点催生了不同的可逆架构（ Chang等, 2018, 2019a ） 。Behrmann 等(2019)提出，\\n若网络的 Lipschitz 常数小于一，可通过固定点迭代反转网络，进而开发了 iResNet，可\\n以用Hutchinson 的迹估计器（ Hutchinson, 1989 ）估计雅可比的对数行列式。 Chen等\\n(2019)使用俄罗斯轮盘赌估计器消除方程中功率级数截断引起的偏差。\\n无穷小流 ：如果将残差网络视作普通微分方程（ ODE）的离散化，那么直接用 ODE\\n表示变量变化成为下一步合逻辑的发展。 Chen等(2018e)探索了神经 ODE，利用标准\\n方法进行 ODE的前向和后向传播。此时， 计算似然不再需要雅可比， 因为可以通过另一'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 301}, page_content='286 CHAPTER 16. 标准化流\\n个ODE表示，其中对数概率的变化与前向传播的导数的迹相关。 Grathwohl 等(2019)\\n使用Hutchinson 估计器估计迹，并进一步简化了这一过程。 Finlay等(2020)在损失函\\n数中添加了正则化项以简化训练，而 Dupont等(2019)扩展了表达形式，使神经 ODE\\n能表示更广泛的微分同胚类。 Tzen & Raginsky (2019) 和Peluchetti & Favaro (2020) 将\\nODE替换为随机微分方程。\\n通用性：通用性指归一化流能够任意精确地模拟任何概率分布的能力。某些流（如\\n平面流、逐元素流）不具备这种属性。当耦合函数为神经单调网络（ Huang等, 2018a） 、\\n基于单调多项式（ Jaini等, 2020）或基于样条（ Kobyzev 等, 2020）时，自回归流被证\\n明具有通用性。对于 D维，D个耦合流可以构成自回归流。分成两部分 h1和h2的过\\n程说明，在任一层， h2仅依赖于先前变量（图 16.6） 。因此，每层将 h1增加一个单位，\\n可以实现自回归流，从而达到通用性。目前尚不清楚耦合流是否能在少于 D层的情况\\n下实现通用性，但实践中它们（如 GLOW）表现良好，无需诱导的自回归结构。\\n其他研究 ： 归一化流的研究热点包括离散流 （ Hoogeboom 等, 2019a; Tran 等, 2019） 、\\n非欧几里得流形上的归一化流 （ Gemici等, 2016; Wang & Wang, 2019 ） 及等变流 （ Köhler\\n等, 2020; Rezende 等, 2019） ，后者旨在创建对变换族不变的密度。\\n16.8习题\\n问题 16.1考虑用函数 x=f(z) =z2变换在z∈[0,1]上定义的均匀基本密度。求\\n变换后分布 Pr(x)的表达式。\\n问题 16.2考虑将标准正态分布：\\nPr(z) =1√\\n2πexp\\x12\\n−z2\\n2\\x13\\n, (16.27)\\n通过函数变换：\\nx=f(z) =1\\n1 +exp(−z). (16.28)\\n求变换后的分布 Pr(x)的表达式。\\n问题 16.3写出逆映射 z=f−1(x,ϕ)的雅可比矩阵及其绝对行列式的表达式，形式\\n类似于方程 16.6和16.7。\\n问题 16.4手动求解以下矩阵的逆和行列式：\\nΩ1=2\\n666642 0 0'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 301}, page_content='问题 16.3写出逆映射 z=f−1(x,ϕ)的雅可比矩阵及其绝对行列式的表达式，形式\\n类似于方程 16.6和16.7。\\n问题 16.4手动求解以下矩阵的逆和行列式：\\nΩ1=2\\n666642 0 0\\n0−5 0\\n0 0 1\\n0 0 23\\n77775,Ω2=2\\n666641 0 0 0\\n2 4 0 0\\n1−1 2 0\\n4−2−2 13\\n77775. (16.29)\\n问题 16.5假设随机变量 z的均值为µ，协方差为 Σ，经变换x=Az+b。证明x\\n的期望值为 Aµ+b，x的协方差为 AΣAT。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 302}, page_content='16.8.习题 287\\n问题 16.6若x=f(z) =Az+b且Pr(z) =Norm z[µ,Σ]， 证明Pr(x) =Norm x[Aµ+\\nb,AΣAT]，利用关系式：\\nPr(x) =Pr(z)·\\x0c\\x0c\\x0c\\x0c∂f\\n∂z\\x0c\\x0c\\x0c\\x0c−1\\n. (16.30)\\n问题 16.7Leaky ReLU 定义为：\\nLReLU [z] =8\\n<\\n:0.1zifz <0,\\nzifz≥0.(16.31)\\n求leaky ReLU 的逆函数表达式。对于多元变量 z的逐元素变换 x=f[z]，其中：\\nf[z] = [LReLU [z1],LReLU [z2],...,LReLU [zp]]T, (16.32)\\n求雅可比的逆绝对行列式\\x0c\\x0c∂f\\n∂z\\x0c\\x0c−1的表达式。\\n问题 16.8考虑对输入 h= [h1,h2,...,h p]T逐元素应用方程 16.12中定义的分段线\\n性函数f[h,ϕ]，其中h′∈[0,1]，使得f[ht!] = [f[h1,ϕ],f[h2,ϕ],...,f [hp,ϕ]]。求出雅可比\\n∂f\\n∂h及其行列式。\\n问题 16.9考虑基于等间隔区间中平方根函数的锥形组合构建逐元素流：\\nh′=f[h,ϕ] =√\\nKh−bϕb+X\\nkp\\nϕk, (16.33)\\n其中b= [Kh]是h所属的区间，且参数 ϕk均为正且和为一。当 K= 5且ϕ1=\\n0.1,ϕ2= 0.2,ϕ3= 0.5,ϕ4= 0.1,ϕ5= 0.1时，画出函数 f[h,ϕ]和其逆函数 f−1[h′,ϕ]。\\n问题 16.10对残差流的前向映射的雅可比结构进行绘图（指出哪些元素为零） ，当\\nf1[ϕ1]和f2[ϕ2]分别为(i)全连接神经网络， (ii)逐元素流时。\\n问题 16.11写出方程 16.25中KL散度的表达式。为何只能估计概率 q(x)至一个\\n缩放因子K也没有关系？最小化这个损失函数时，网络必须是可逆的吗？解释你的推\\n理。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 303}, page_content='288 CHAPTER 16. 标准化流'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 304}, page_content='Chapter 17\\n变分自编码器\\n生成对抗网络 (Generative Adversarial Networks) 学习了一种机制， 可以生成与训练\\n数据{xi}在统计上无法区分的样本。 与此相对， 像归一化流 （ normalizing flows ） 、 变分自\\n编码器(Variational Autoencoders, VAEs) 这类的概率生成模型 (probabilistic generative\\nmodels)则旨在学习覆盖数据的分布 Pr(x)（见图14.2） 。训练结束后，可以从该分布中\\n抽取（生成）样本。然而，由于 VAE的特性，遗憾的是无法精确计算新样本 x∗的概率。\\n虽然人们通常会将 VAE视为P r(x)的模型，但这种说法有误导性； VAE实际上\\n是一种神经架构，设计用于帮助学习 Pr(x)的模型。 P r(x)的最终模型既不包括“变\\n分”也不包括“自编码器”部分，更准确地说，它应被描述为一个非线性潜在变量模型\\n(nonlinear latent variable model) 。\\n本章首先对潜在变量模型 (latentvariablemodels) 进行概述， 然后特别讨论非线性潜\\n在变量模型的情况。我们将了解到，对这种模型进行最大似然估计 (maximum likelihood\\nlearning) 并非易事。尽管如此，还是可以定义似然的下界，并且 VAE架构采用蒙特卡\\n罗(Monte Carlo, 抽样)方法来近似这个下界。本章最后将介绍 VAE的几个应用案例。\\n17.1潜在变量模型\\n潜在变量模型 (Latent variable models) 采取了一种间接的方法来描述多维变量 x\\n上的概率分布 Pr(x)。它们不直接给出 Pr(x)的表达式，而是构建数据 x与未观测的 *\\n隐变量*（*latent variable* ）z的联合分布 Pr(x,z)。接着，通过将这个联合概率边缘\\n化来描述Pr(x)的概率，形式为：\\nPr(x) =Z\\nPr(x,z)dz. (17.1)\\n一般情况下，联合概率 Pr(x,z)通过条件概率规则被分解为关于潜变量的 *似然*\\n（likelihood ）Pr(x|z)和*先验*（prior）Pr(z)：\\nPr(x) =Z\\nPr(x|z)Pr(z)dz. (17.2)\\n289'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 305}, page_content='290 CHAPTER 17. 变分自编码器\\n虽然这是描述 Pr(x)的一种较间接的方法，但由于 Pr(x|z)和Pr(z)的表达式相\\n对简单，它可以用来定义 Pr(x)的复杂分布。\\n17.1.1 示例：高斯混合\\n在一维高斯混合模型（图 17.1a）中，潜在变量 z是离散的，其先验 Pr(z)为分类\\n分布（图 5.9） ，每个可能的 z值对应一个概率 λn。当潜变量 z取值为n时，数据x的\\n似然Pr(x|z=n)符合均值为 µn、方差为σ2\\nn的正态分布：\\nPr(z=n) =λn\\nPr(x|z=n) =Nx(µn,σ2\\nn). (17.3)\\n正如方程 17.2中所示，Pr(x)的似然通过对潜变量 z进行边缘化得到（图 17.1b） 。\\n在这里，潜变量是离散的，因此我们对其所有可能的值进行求和以实现边缘化：\\nPr(x) =NX\\nn=1Pr(x,z=n)\\n=NX\\nn=1Pr(x|z=n)·Pr(z=n)\\n=NX\\nn=1λn·N≀∇⇕x(µn,σ2\\nn). (17.4)\\n从简单的似然和先验表达式出发，我们描述了一个复杂的多峰概率分布。\\n图 17.1:高斯混合模型 (MoG)。a)高斯混合模型将一个复杂的概率分布（青色曲线）表达为多\\n个高斯分量（虚线曲线）的加权和。 b)该加权和即是通过边际化过程，将连续观测数据 x与离\\n散潜变量 z之间的联合密度 Pr(x, z) 进行整合得到的。\\n17.2非线性潜在变量模型\\n在非线性潜在变量模型中，数据 x和潜变量z均为连续且多维的。其先验 Pr(z)为\\n标准多元正态分布：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 306}, page_content='17.2.非线性潜在变量模型 291\\nPr(z) =Nz(0,I). (17.5)\\n似然Pr(x|z,ϕ)亦服从正态分布，其均值由潜变量的非线性函数 f(z,ϕ)确定，协\\n方差σ2I为球形：\\nPr(x|z,ϕ) =Norm x\\x02\\nf(z,ϕ),σ2I\\x03\\n. (17.6)\\n函数f(z,ϕ)由带参数ϕ的深度网络所定义。潜变量 z的维度小于数据 x的维度。\\n模型f(z,ϕ)描述了数据的关键特征，而未建模的部分则归咎于噪声 σ2I。\\n数据概率Pr(x|ϕ)通过对潜变量 z进行边缘化得到：\\nPr(x|ϕ) =Z\\nPr(x|z,ϕ)dz\\n=Z\\nPr(x|z,ϕ)·Pr(z)dz\\n=Z\\nNorm x\\x02\\nf(z,ϕ),σ2I\\x03\\n·Norm z[0,I]dz. (17.7)\\n这可以被理解为具有不同均值的球形高斯分布的无限加权和（即无限混合） ，其中\\n权重为Pr(z)，均值为网络输出 f(z,ϕ)（见图17.2） 。\\n图 17.2:非线性潜变量模型。通过对潜变量 z的联合分布 Pr(x, z)（左图）进行边际化，生成了\\n一个复杂的 2D密度 Pr(x)（右图） 。要构造 Pr(x)，我们需要在 z维度上积分整个 3D体积。对\\n于每个 z，x的分布呈现为球形高斯分布（展示了两个切面） ，其均值 f[z, ϕ]是关于 z的非线性\\n函数，且依赖于参数 ϕ。Pr(x)分布是这些高斯分布的加权和。\\n17.2.1 生成\\n通过祖先抽样（见图 17.3）可以生成新的样本 x∗。我们从先验 Pr(z)中抽取z∗，并\\n通过网络f(z∗,ϕ)传递来计算似然 Pr(x∗|z∗,ϕ)的均值（见方程 17.6） ，从而生成 x∗。由'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 307}, page_content='292 CHAPTER 17. 变分自编码器\\n于先验和似然都是正态分布，这一过程相对直接。\\n图 17.3:从非线性潜变量模型中生成数据。 a)我们从潜变量的先验概率 Pr(z)中抽取一个样本\\nz∗。b)接着从条件概率 Pr(x|z∗, ϕ)中抽取一个样本 x∗。 这是一个均值为 z∗的非线性函数 f[·, ϕ]，\\n方差为 σ2I的球形高斯分布。 c)通过多次重复这一过程，我们能够得到条件密度 Pr(x|ϕ)。\\n17.3训练\\n为了训练模型，我们需要最大化训练数据集 {xi}I\\ni=1上模型参数的对数似然值。为\\n了简化问题，我们假定似然表达式中的方差项 σ2是已知的，并专注于学习 ϕ：\\nˆϕ=argmax\\nϕ\"IX\\ni=1logPr(xi|ϕ)#\\n, (17.8)\\n其中：\\nPr(xi|ϕ) =Z\\nNorm xi\\x02\\nf(z,ϕ),σ2I\\x03\\n·Norm z[0,I]dz. (17.9)\\n不幸的是，这是不切实际的。这个积分没有封闭形式的解，并且没有简单的方法可以用\\n来评估特定 x的积分值。\\n17.3.1 证据下界 (ELBO)\\n为了进一步推进，我们定义了对数似然的一个 *下界*（Evidence Lower Bound ，\\nELBO） 。这是一个对于给定的 ϕ值，总是小于或等于对数似然的函数，并且还依赖于\\n一些其他参数 Θ。我们将构建一个网络来计算这个下界并对其进行优化。为了定义这个\\n下界，我们需要使用 *詹森不等式 *（Jensen’s inequality ） 。\\n17.3.2 詹森不等式\\n詹森不等式表明，对于数据 y的期望的凹函数 g(·)，有g(E[y])大于或等于该函数\\n的期望值：\\ng(E[y])≥E[g(y)]. (17.10)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 308}, page_content='17.3.训练 293\\n在本例中，凹函数是对数函数，因此我们有：\\nlog(E[y])≥E[log(y)], (17.11)\\n或者更完整地写出期望的表达式：\\nlog\\x12Z\\nPr(y)ydy\\x13\\n≥Z\\nPr(y)log(y)dy. (17.12)\\n这在图17.4–17.5中被详细探讨。实际上，更通用的陈述也是成立的：\\nlog\\x14Z\\nPr(y|h)[y]dy\\x15\\n≥Z\\nPr(y)log[h(y)]dy. (17.13)\\n图 17.4: Jensen 不等式（离散案例） 。对数函数（黑色曲线）是一个凹函数；在曲线上任意两点\\n之间画直线，该直线总位于曲线之下。因此，对数函数上任意六点形成的凸组合（正权重的加权\\n和，权重总和为一）必定落在曲线下方的灰色区域内。此处，我们等权重地加权这些点（即取均\\n值） ，得到了青色点。因为这个点位于曲线下，所以有 log[E[y]] > E[log[y]] 。\\n17.3.3 导出下界\\n现在我们利用詹森不等式来导出对数似然的下界。首先，我们通过乘除以潜变量上\\n的任意概率分布 q(z)来处理对数似然：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 309}, page_content='294 CHAPTER 17. 变分自编码器\\n图 17.5: Jensen 不等式（连续案例） 。对于凹函数，计算分布 Pr(y)的期望值并应用该函数，所\\n得结果大于或等于先对变量 y应用函数变换后计算新变量的期望值。以对数函数为例，我们得\\n到log[E[y]]≥E[log[y]]。图的左侧对应不等式的左侧，图的右侧对应不等式的右侧。可以这样\\n理解：我们在 y∈[0,1]范围内的橙色分布上取了一系列点的凸组合。根据图 17.4的逻辑，这些\\n点的组合必然位于曲线下方。另外，可以将凹函数视为相对于低值，压缩了 y的高值，所以当我\\n们先对 y应用函数时，其期望值更低。\\nlog[Pr(x|ϕ)] =log\\x14Z\\nPr(x,z|ϕ)dz\\x15\\n=log\\x14Zq(z)\\nq(z)Pr(x,z|ϕ)dz\\x15\\n, (17.14)\\n接着我们应用对数函数的詹森不等式（方程 17.12）来寻找一个下界：\\nlog\\x14Zq(z)\\nq(z)Pr(x,z|ϕ)dz\\x15\\n≥Z\\nq(z)log\\x14Pr(x,z|ϕ)\\nq(z)\\x15\\ndz, (17.15)\\n右侧称为 *证据下界 *（Evidence Lower Bound, ELBO ） 。之所以这样命名，是因为在\\n贝叶斯法则的背景下 Pr(x|ϕ)被称为证据（方程 17.19） 。在实践中，分布 q(z)具有参\\n数θ，因此ELBO可以表示为：\\nELBO [ϕ,θ] =Z\\nq(z|θ)log\\x14Pr(x,z|ϕ)\\nq(z|θ)\\x15\\ndz. (17.16)\\n为了学习非线性潜在变量模型，我们要将此量作为 ϕ和Θ的函数最大化。执行这\\n一计算的神经架构是变分自编码器（ VAE） 。\\n17.4 ELBO 特性\\n首次接触 ELBO时，它可能给人一种难以捉摸的感觉，因此我们将对其特性提供一\\n些直观的理解。考虑到数据的原始对数似然是参数 ϕ的函数，并且我们希望找到它的最\\n大值。对于任何固定的 Θ，ELBO也是参数的函数，但必须低于原始似然函数。当我们'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 310}, page_content='17.4. ELBO 特性 295\\n改变 Θ时，会相应地调整这个函数，并且根据选择的不同，下界可能会更接近或更远离\\n对数似然。当我们改变 ϕ时，我们就在下界函数上移动（见图 17.6） 。\\n图 17.6:证据下界 (ELBO)。目标是相对于参数 φ最大化对数似然度 log[P r(x|φ)]（黑色曲线） 。\\nELBO是一种始终位于对数似然度下方的函数，它同时依赖于参数 φ和第二组参数 θ。当 θ固\\n定时，我们可以得到 ϕ的函数表达（不同 θ值对应的两条彩色曲线） 。因此，可以通过针对 a)新\\n参数 θ（从一条彩色曲线转至另一条）或 b)原始参数 φ（沿着当前彩色曲线移动）改善 ELBO\\n来提升对数似然度。\\n17.4.1 界限紧密性\\n在ϕ固定的条件下，如果 ELBO与似然函数相等，我们认为 ELBO达到了紧密度\\n（tight） 。为寻找使边界达到紧密度的分布 q(z|θ)，我们根据条件概率的定义展开 ELBO\\n的对数项分子：\\nELBO [θ,ϕ] =Z\\nq(z|θ)log\\x14Pr(x,z|ϕ)\\nq(z|θ)\\x15\\ndz\\n=Z\\nq(z|θ)log\\x14Pr(z|x,ϕ)Pr(x|ϕ)\\nq(z|θ)\\x15\\ndz\\n=Z\\nq(z|θ)log[Pr(x|ϕ)]dz+Z\\nq(z|θ)log\\x14Pr(z|x,ϕ)\\nq(z|θ)\\x15\\ndz\\n=log[Pr(x|ϕ)] +Z\\nq(z|θ)log\\x14Pr(z|x,ϕ)\\nq(z|θ)\\x15\\ndz\\n=log[Pr(x|ϕ)]−DKL[q(z|θ)||Pr(z|x,ϕ)]. (17.17)\\n在第三至第四行间，由于 log[Pr(x|ϕ)]与z无关，故其积分消失，同时概率分布\\nq(z|θ)的积分为一。最终一行中我们应用了 Kullback-Leibler (KL) 散度的定义。\\n上述等式表明， ELBO等于原始对数似然减去 KL散度DKL[q(z|θ)||Pr(z|x,ϕ)]。KL\\n散度衡量了分布间的“距离”，其值非负。因此， ELBO是log[Pr(x|ϕ)]的下界。当\\nq(z|θ) =Pr(z|x,ϕ)时，KL散度为零，此时边界达到紧密度。这对应于给定观测数据 x\\n下潜在变量 z的后验分布，揭示了数据点是由哪些潜在变量 z的值生成的（图 17.7） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 311}, page_content='296 CHAPTER 17. 变分自编码器\\n图 17.7:潜变量上的后验分布。 a)后验分布 P r(z|x∗, ϕ)表示潜变量 z的值分布，这些值可能\\n导致了数据点 x∗。我们通过贝叶斯规则来计算这个分布，即 P r(z|x∗, ϕ)∝P r(x∗|z, ϕ)P r(z)b)\\n通过评估数据点 x∗针对每个 z值的对称高斯分布的概率来计算似然项。在这个场景中，数据点\\nx∗由 z1生成的可能性比由 z2生成的大。第二个因素是潜变量的先验概率 Pr(z)。将这两个因\\n素结合并归一化，使得总和为一，得到后验分布 P r(z|x∗, ϕ)。\\n17.4.2 ELBO 为重构损失与先验的 KL距离之差\\n方程式17.16和17.17描述了ELBO的两种不同表达方式。另一种方式是理解为重\\n建误差与先验之间的距离之差：\\nELBO [θ,ϕ] =Z\\nq(z|θ)log\\x14Pr(x,z|ϕ)\\nq(z|θ)\\x15\\ndz\\n=Z\\nq(z|θ)log\\x14Pr(x|z,ϕ)Pr(z)\\nq(z|θ)\\x15\\ndz\\n=Z\\nq(z|θ)log[Pr(x|z,ϕ)]dz+Z\\nq(z|θ)log\\x14Pr(z)\\nq(z|θ)\\x15\\ndz\\n=Z\\nq(z|θ)log[Pr(x|z,ϕ)]dz−DKL[q(z|θ)||Pr(z)],(17.18)\\n在这里，联合分布 Pr(x,z|ϕ)被分解为条件概率 Pr(x|z,ϕ)Pr(z)，并在最后一步中\\n再次应用了 KL散度的定义。\\n在此表达中，第一项用于衡量潜变量与数据之间的平均符合度 Pr(x|z,ϕ)，即所谓\\n的*重建损失 *。第二项则衡量辅助分布 q(z|θ)与先验分布的吻合程度。这种表述方式\\n在变分自编码器（ Variational Autoencoder, VAE ）中得到应用。\\n17.5变分近似\\n如方程17.17所示，当q(z|θ)等同于后验 Pr(z|x,ϕ)时，我们称 ELBO达到紧密\\n度。理论上我们可以通过贝叶斯规则计算后验：\\nPr(z|x,ϕ) =Pr(x|z,ϕ)Pr(z)\\nPr(x|ϕ), (17.19)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 312}, page_content='17.6.变分自编码器（ V AE） 297\\n但实践中这是不可行的，因为我们无法计算分母中的数据似然（参见第 17.3节） 。\\n一种方案是采用变分近似：选择一个简单的参数形式作为 q(z|θ)，用以近似真实的\\n后验。这里，我们选择均值为 µ、对角协方差为 Σ的多元正态分布。这种方式可能不总\\n能精确匹配后验，但对于某些 µ和Σ的值效果会更佳。在训练过程中，我们将寻找一\\n个与真实后验 Pr(z|x)最为接近的正态分布（图 17.8） ，这相当于在方程 17.17中最小\\n化KL散度，并将图 17.6中的彩色曲线上移。\\n鉴于q(z|θ)的最优选择是依赖于数据样本 x的后验Pr(z|x,ϕ)，变分近似也应该遵\\n循这一点，因此我们选取：\\nq(z|x,θ) =Norm z[gµ[x,θ],gΣ[x,θ]], (17.20)\\n其中gµ[x,θ]是一个以θ为参数的第二神经网络，用于预测正态变分近似的均值 µ\\n和方差 Σ。\\n图 17.8:变分近似。后验分布 P r(z|x∗, ϕ)无法闭式解算。变分近似选择一族分布 q(z|x, θ)（这\\n里是高斯分布）并试图找到最接近真实后验的分布。 a)有时候，近似值（青色曲线）与真实后验\\n（橙色曲线）非常接近。 b)然而，如果后验是多峰的（如图 17.7所示） ，高斯近似的效果会较差。\\n17.6变分自编码器（ V AE）\\n最终，我们可以阐述变分自编码器（ VAE） 。我们建立了一个网络来计算 ELBO：\\nELBO [θ,ϕ] =Z\\nq(z|x,θ)log[Pr(x|z,ϕ)]dz−DKL[q(z|x,θ)||Pr(z)],(17.21)\\n这里的分布 q(z|x,θ)是基于方程 17.20的近似。\\n第一项包含一个难以直接计算的积分，但因为它是相对于 q(z|x,θ)的期望值，我们\\n可以通过采样来进行近似。对于任意函数 a[z]，我们得到：\\nEz[a[z]] =Z\\na[z]q(z|x,θ)dz≈1\\nNNX\\nn=1a[zn], (17.22)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 313}, page_content='298 CHAPTER 17. 变分自编码器\\n其中zn是从q(z|x,θ)中抽取的第 n个样本。这种方法被称为蒙特卡罗（ Monte\\nCarlo）估计。对于一个非常近似的估计，我们可以仅使用来自 q(z|x,θ)的单一样本 z∗：\\nELBO [θ,ϕ]≈log[Pr(x|z∗,ϕ)]−DKL[q(z|x,θ)||Pr(z)]. (17.23)\\n第二项是变分分布 q(z|x,θ) =Norm z[µ,Σ]与先验Pr(z) =Norm z[0,I]之间的KL\\n散度。两个正态分布之间的 KL散度可以通过封闭形式计算。特别是，当一个分布的参\\n数为µ,Σ，而另一个为标准正态分布时，其 KL散度可由以下公式给出：\\nDKL[q(z|x,θ)||Pr(z)] =1\\n2\\x00\\nTr[Σ] +µTµ−Dz−log|det[Σ]|\\x01\\n. (17.24)\\n这里Dz代表潜在空间的维度。\\n17.6.1 V AE 算法\\n总结来说，我们旨在构建一个模型，用于计算数据点 x的证据下界（ ELBO） 。随后，\\n我们利用优化算法在整个数据集上最大化这一下界，以此提高对数似然值。计算 ELBO\\n的步骤包括：\\n-利用网络g(x,θ)为数据点x计算变分后验分布 q(z|θ,x)的均值µ和方差 Σ，-从\\n该分布中抽取样本 z∗，-根据方程 17.23计算ELBO。\\n相应的架构展示于图 17.9。这就是其被称为变分自编码器（ VAE）的原因。它之所\\n以称为变分，是因为它对后验分布进行了高斯近似。之所以称为自编码器，是因为它从\\n数据点x出发，计算得到低维潜在向量 z，然后利用这个向量来尽可能精确地重建数据\\n点x。在这种情况下，网络 g(x,θ)实现的从数据到潜在变量的映射称为 *编码器*，而\\n网络f(z,ϕ)实现的从潜在变量到数据的映射称为 *解码器*。\\nVAE将ELBO作为θ和ϕ的函数进行计算。为了最大化这一边界，我们通过网络\\n处理小批量样本，并使用 SGD或Adam等优化算法更新这些参数。通过自动微分计算\\n与参数相关的 ELBO梯度。在这个过程中，我们会在图 17.10所示的彩色曲线上进行移\\n动，即改变 θ和ϕ。这一过程中，参数的调整旨在为每条曲线分配适当的权重，确保曲\\n线整体的均匀性和延展性。这些参数变化反映了非线性潜变量模型的调整。\\n17.7重参数化技巧'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 313}, page_content='动，即改变 θ和ϕ。这一过程中，参数的调整旨在为每条曲线分配适当的权重，确保曲\\n线整体的均匀性和延展性。这些参数变化反映了非线性潜变量模型的调整。\\n17.7重参数化技巧\\n另外，还有一个难题：网络涉及一个抽样步骤，而对这种随机过程进行微分操作具\\n有一定难度。但是，为了更新网络之前的参数 θ，必须对这一步骤进行微分。\\n幸运的是，这里有一个简便的方法；我们可以把随机过程部分移到网络的一个分支\\n中，这个分支从标准正态分布 Norm [0,I]抽取一个样本 e∗，然后利用以下关系式：\\nz∗=µ+ Σ1/2·e∗, (17.25)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 314}, page_content='17.8.应用 299\\n图 17.9:变分自编码器 (V AE)。编码器 g[x, θ]输入一个训练样本 x，并预测变分分布 q(z|x, θ)\\n的参数 µ和Σ。我们从该分布中采样，再通过解码器 f[z, φ]来预测数据 x。损失函数为负的\\nELBO，其取决于预测的准确性和变分分布 q(z|x, θ)与先验 Pr(z)之间的相似度（公式 17.21） 。\\n图 17.10: V AE 在每次迭代时更新影响下界的两个因子。解码器的参数 ϕ和编码器的参数 θ会\\n被调整以提高这个下界。\\n从而从目标的高斯分布中抽取样本。如此一来，我们就可以像通常一样计算导数了，\\n因为反向传播算法无需经过随机过程的分支。这种方法被称为 *重参数化技巧 *（图\\n17.11） 。\\n17.8应用\\n变分自编码器 (Variational Autoencoders) 在多个领域有广泛的应用，包括去噪 (de-\\nnoising)、异常检测 (anomaly detection) 和数据压缩 (compression) 。本节将回顾这些技\\n术在图像处理领域的若干应用场景。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 315}, page_content='300 CHAPTER 17. 变分自编码器\\n图 17.11:重参数化技巧。在原始架构（图 17.9）下，通过采样步骤进行反向传播不太直接。重\\n参数化技巧消除了主流程中的采样步骤；我们从标准正态分布中取样，然后将这些样本与预测的\\n均值和协方差结合，从而获取变分分布的样本。\\n17.8.1 样本概率的近似\\n在第17.3节中，我们讨论了为什么无法使用 VAE (Variational Autoencoder) 准确\\n评估样本的概率，这个概率的表达式为：\\nPr(x) =Z\\nPr(x|z)Pr(z)dz\\n=Ez[Pr(x|z)]\\n=Ez[Norm x[f(z,ϕ),σ2I]]. (17.26)\\n理论上，我们可以根据公式 17.22通过从正态分布 Pr(z) =Norm z[0,I]中抽样来 *\\n近似*这个概率，并计算：\\nPr(x)≈1\\nNNX\\nn=1Pr(x|zn). (17.27)\\n但是，由于维度灾难的影响，我们抽取的几乎所有 zn的值都将具有非常低的概率；\\n因此，我们需要抽取大量样本以获得可靠的估计。一个更优的策略是采用 *重要性采\\n样(importance sampling)* 。在这种方法中，我们从一个辅助分布 q(z)中抽取z，计算\\nPr(x|zn)，并利用新分布下 q(z)的概率对结果值进行调整：\\nPr(x) =ZPr(x|z)Pr(z)\\nq(z)q(z)dz\\n=Eq(z)\\x14Pr(x|z)Pr(z)\\nq(z)\\x15\\n≈1\\nNNX\\nn=1Pr(x|zn)Pr(zn)\\nq(zn), (17.28)\\n此时，样本抽取自 q(z)。如果q(z)接近Pr(x|z)高似然的z区域，那么我们可以\\n将采样集中在这一关键区域，从而更加高效地估计 Pr(x)。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 316}, page_content='17.8.应用 301\\n我们试图积分的乘积 Pr(x|z)Pr(z)与后验分布 Pr(z|x)成比例（根据贝叶斯规则） 。\\n因此，选取辅助分布 q(z)时，变分后验 q(z|x)是一个明智的选择，这是由编码器计算\\n得到的。\\n通过这种方法，我们可以近似估算新样本的概率。当有充足的样本时，这种方法将\\n提供比下限更好的估计值，并可用于通过评估测试数据的对数似然度来衡量模型的质\\n量。此外，它还可以作为一种判别依据，用来确定新的样例是属于现有的分布还是属于\\n异常值。\\n17.8.2 生成\\nVAEs构建了一个概率模型，可以轻松从该模型中抽样。具体方法是，从潜在变量\\n的先验Pr(z)抽样，将结果传递给解码器 f(z,ϕ)，并根据Pr(x|f(z,ϕ))添加噪声。遗\\n憾的是，原始 VAEs生成的样本通常质量较低（见图 17.12a-c） 。这种情况部分是由于简\\n单的球形高斯噪声模型，部分是因为先验和变分后验采用的高斯模型。\\n一种提升生成质量的方法是，从 *聚合后验 *q(z|θ) = (1/L)P\\niq(z|xi,θ)抽样，而\\n不是直接从先验抽样。聚合后验是基于所有样本的平均后验，它是一个在潜在空间中更\\n能代表真实分布的高斯混合模型。\\n现代VAEs通过使用层次化先验、专门的网络架构和正则化技术，能够产生高质量\\n的样本（见图 17.12d） 。扩散模型（第 18章讨论）可视为具有层次化先验的 VAEs，也\\n能生成非常高质量的样本。\\n图 17.12:从训练于 CELEBA 数据集的标准 V AE中抽样。在每列中，一个潜变量 z∗被抽取\\n并传递通过模型来预测均值 f[z∗, ϕ]，之后加上独立的高斯噪声（参见图 17.3） 。 a)样本集合是\\nb)预测均值和 c)球形高斯噪声向量的总和。在加入噪声前图像过于平滑，加入后则过于嘈杂。\\n这是典型情况，通常展示无噪声版本，因为噪声被视为表示图像中未被模型捕捉的部分。改编自\\nDorta等（ 2018） 。 d)通过使用分层先验、特殊架构和精细的正则化，现在可以利用 V AE生成\\n高质量的图像。改编自 V ahdat & Kautz (2020) 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 317}, page_content='302 CHAPTER 17. 变分自编码器\\n17.8.3 重新合成\\nVAEs不仅可以生成数据，还能修改真实数据。将数据点 x投影到潜在空间可以通\\n过两种方法： （ i）取编码器预测分布的均值； （ ii）通过优化过程寻找最大化后验概率的\\n潜在变量z，后者依据贝叶斯规则与 Pr(x|z)Pr(z)成比例。\\n在图17.13中，标为“中性”和“微笑”的多个图像被映射到潜在空间。这种变化的\\n向量是通过计算两组均值在潜在空间中的差来估算的。同样，用于表示“闭嘴”和“张\\n嘴”状态的向量也是如此估算得出。\\n接着，感兴趣的图像被映射到潜在空间，并通过增加或减少这些向量来修改其表示。\\n生成中间图像时，采用球面线性插值（ Slerp）而非普通线性插值，类似于在三维空间中\\n沿球面而不是直线插值。\\n这种对输入数据进行编码、修改后再解码的过程称为再合成。这一过程不仅可在\\nVAEs中实现，也可通过 GANs和规范化流技术来完成。但在 GANs中，缺乏编码器，\\n需要另外一套程序来确定观察数据的潜在变量。\\n图 17.13:重合成。原始图像通过编码器被投影到潜空间，并且图像被预测的高斯均值所代表。\\n网格中心左侧的图像是输入的重建。其他图像是在调整潜空间中代表微笑 /中性（水平方向）和\\n嘴巴张开 /闭合（垂直方向）的方向后重建的图像。改编自 White (2016) 。\\n17.8.4 解耦\\n在上述再合成的示例中，需要用带标签的训练数据来估计代表可解释特性的空间方\\n向。其他研究旨在优化潜在空间的特性，以便其坐标轴能对应到现实世界的属性。当每\\n个维度代表一个独立的现实世界因素时，我们称潜在空间为 *解耦*的。例如，在面部\\n图像建模中，我们期望识别出头部姿态或头发颜色等独立因素。\\n促进解耦的方法通常会在损失函数中加入基于以下两种情形的正则化项： (i)基于\\n潜变量z的后验q(z|x,θ)，或(ii)基于聚合后验 q(z|θ) = (1/I)P\\niq(z|xi,θ)：\\nLnew=−ELBO [θ,ϕ] +λ1EPr(x)[r1(q(z|x,θ))] +λ2r2[q(z|θ)].(17.29)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 318}, page_content='17.9.总结 303\\n其中，正则化项 r1[·]是后验的函数，并且由 λ1加权。项r2[·]是聚合后验的函数，\\n并且由λ2加权。\\n例如，在 *beta VAE* 中，增加了 ELBO（方程17.18）的第二项权重：\\nELBO [θ,ϕ]≈log[Pr(x|z∗,ϕ)]−β·DKL[q(z|x,θ)||Pr(z)], (17.30)\\n这里的β >1表示与重构误差相比，先验 Pr(z)偏差的相对权重。因为先验通常是\\n具有球形协方差矩阵的多元正态分布，其各维度是独立的。因此，增加这一项的权重有\\n助于使后验分布之间的相关性降低。另一个变体是总相关性 VAE，它通过增加一个项\\n来降低潜空间中变量之间的总相关性（参见图 17.14） ，并致力于最大化潜变量的一个小\\n子集与观测数据之间的互信息。\\n图 17.14:在总相关性 V AE中的解耦。 V AE模型被修改，使得损失函数鼓励潜变量的总相关性\\n最小化，从而鼓励解耦。在对椅子图像的数据集进行训练时，几个潜在维度具有明确的现实世界\\n解释，包括 a)旋转， b)总体大小，和 c)腿部（旋转椅与普通椅） 。在每种情况下，中心列展示\\n了模型的样本，当我们左右移动时，我们在潜空间中减去或添加一个坐标向量。改编自 Chen等\\n人（ 2018d） 。\\n17.9总结\\nVAE是一种帮助学习 x上的非线性潜在变量模型的架构。通过从潜在变量抽样、 通\\n过深度网络处理抽样结果、再加上独立高斯噪声，这个模型能够生成新的数据样本。\\n我们无法精确计算数据点的似然度，这在最大似然训练方法中造成了难题。不过，\\n我们可以确定似然度的一个下限，并尽量使这个下限最大化。但遗憾的是，为了使这个\\n下限足够接近真实似然度，我们需要计算观测数据的潜在变量的后验概率，这一计算过\\n程同样复杂。因此，采用变分近似成为了解决这一问题的方法。这种简化的分布（通常\\n是高斯分布）可以近似地代表后验概率，并且其参数通过另一个编码器网络得到计算。\\n为了生成高质量的 VAE样本，必须使用比高斯先验和后验更复杂的概率分布来构\\n建潜在空间。一种方法是采用层次化先验，即一个潜在变量由另一个生成。接下来的章\\n节将讨论扩散模型， 它们能产生极高质量的样本， 并可以被看作是具有层次结构的 VAE。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 319}, page_content='304 CHAPTER 17. 变分自编码器\\n17.10笔记\\nVAE最初由Kingma和Welling在2014年引入。关于变分自编码器的全面介绍可\\n以在Kingma等人（2019）的研究中找到。\\n应用：VAE及其变体已经被应用于图像（ Kingma & Welling, 2014; Gregor 等人,\\n2016; Gulrajani 等人, 2016; Akuzawa 等人, 2018）、语音（ Hsu等人, 2017b）、文本\\n（Bowman 等人, 2015; Hu 等人, 2017; Xu 等人, 2020）、分子（ Gómez-Bombarelli 等\\n人, 2018; Sultan 等人, 2018） 、图形（ Kipf & Welling, 2016; Simonovsky & Komodakis,\\n2018） 、机器人技术（ Hernández 等人, 2018; Inoue 等人, 2018; Park 等人, 2018） 、强\\n化学习（ Heess等人, 2015; Van Hoof 等人, 2016） 、3D场景（Eslami等人, 2016, 2018;\\nRezende Jimenez 等人, 2016）以及书写（ Chung等人, 2015） 。\\n应用包括重合成和插值（ White, 2016; Bowman 等人, 2015） 、协同过滤（ Liang等\\n人, 2018）和压缩（ Gregor等人, 2016） 。Gómez-Bombarelli 等人（2018）使用VAE构\\n建化学结构的连续表示，然后可以针对期望的属性进行优化。 Ravanbakhsh 等人（2017）\\n模拟天文观测以校准测量。\\n与其他模型的关系 ：自编码器（ Rumelhart 等人, 1985; Hinton & Salakhutdinov,\\n2006）通过编码器传递数据到瓶颈层，然后使用解码器重构它。瓶颈层类似于 VAE中\\n的潜在变量，但动机不同。这里的目标不是学习概率分布，而是创建一个低维表示，捕\\n捉数据的本质。自编码器还有各种应用，包括去噪（ Vincent等人, 2008）和异常检测\\n（Zong等人, 2018） 。\\n如果编码器和解码器是线性变换，那么自编码器就是主成分分析（ PCA） 。因此，'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 319}, page_content='（Zong等人, 2018） 。\\n如果编码器和解码器是线性变换，那么自编码器就是主成分分析（ PCA） 。因此，\\n非线性自编码器是 PCA的泛化。 PCA也有概率形式。概率 PCA（Tipping & Bishop,\\n1999）通过对重构添加球形高斯噪声来创建概率模型，因子分析添加对角高斯噪声（见\\nRubin & Thayer, 1982 ） 。如果我们使这些概率变体的编码器和解码器非线性，我们就回\\n到了变分自编码器。\\n架构变化 ：条件VAE（Sohn等人, 2015）将类信息 c传递到编码器和解码器。结果\\n是潜在空间不需要编码类信息。例如，当 MNIST数据基于数字标签进行条件化时，潜\\n在变量可能编码数字的方向和宽度，而不是数字类别本身。 Sønderby 等人（2016a）引\\n入了梯变分自编码器，通过数据相关的近似似然项递归修正生成分布。\\n修改似然 ：其他工作探讨了更复杂的似然模型 P r(x|z)。PixelVAE （Gulrajani 等人,\\n2016）使用了一个自回归模型来处理输出变量。 Dorta等人（2018）建模解码器输出的\\n协方差以及均值。 Lamb等人（2016）通过添加额外的正则化项来提高重构的质量，这\\n些正则化项鼓励重构与图像分类模型的一层的激活空间中的原始图像相似。这个模型鼓\\n励保留语义信息，并用于生成图 17.13中的结果。 Larsen等人（2016）使用对抗性损失\\n来改善重构，这也提高了结果。\\n潜在空间、先验和后验 ：已经有许多不同形式的变分后验近似方法被研究，其中包\\n括正规化流（ Rezende & Mohamed, 2015; Kingma et al., 2016 ） 、有向图模型（ Maaløe'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 320}, page_content='17.10.笔记 305\\net al., 2016 ） 、无向模型（ Vahdat et al., 2020 ）和针对时间数据的递归模型（ Gregor et\\nal., 2016, 2019 ） 。\\n其他研究者探索了离散潜在空间的使用（ Van Den Oord et al., 2017; Razavi et al.,\\n2019b; Rolfe, 2017; Vahdat et al., 2018a,b ） 。例如， Razavi et al. （2019b）采用了向量量\\n化潜在空间，并利用自回归模型来建模先验（方程 12.15） 。这一方法虽取样速度慢，但\\n能描述极其复杂的分布。 Jiang et al. （2016）采用高斯混合作为后验来实现聚类。这是一\\n种层次化潜在变量模型，它通过增加离散潜在变量来提升后验的灵活性。还有一些研究\\n者（Salimans et al., 2015; Ranganath et al., 2016; Maaløe et al., 2016; Vahdat & Kautz,\\n2020）尝试了使用连续变量的层次模型。这些模型与扩散模型（第 18章）有着紧密的\\n联系。\\n与其他模型的组合 ：Gulrajani 等人（2016年）将变分自编码器 (VAEs)与自回归\\n模型结合，生成更逼真的图像。 Chung等人（2015年）将VAE与循环神经网络结合使\\n用，以模拟时间变化的测量值。\\n如上所讨论，对抗性损失已被用来直接影响似然项。然而，其他研究通过不同方式\\n结合了生成对抗网络 (GANs)和VAEs的理念。 Makhzani 等人（2015年）在潜空间中\\n采用了对抗性损失，目的是让判别器保证聚合的后验分布 q(z)与先验分布 Pr(z)无法区\\n分开来。 Tolstikhin 等人（2018年）将这个概念推广到先验分布与聚合后验分布之间更\\n广的距离族。 Dumoulin 等人（2017年）引入了对抗性学习推断，它利用对抗性损失来\\n区分两组潜在 /观察数据点，其中一组的潜在变量来自后验分布，另一组来自先验。其\\n他关于VAEs和GANs结合的研究则由 Larsen等人（2016年） 、Brock等人（2016年）\\n和Hsu等人（2017a年）提出。\\n后验坍塌问题 ：在训练过程中，一个潜在问题是后验坍塌，即编码器始终预测先验'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 320}, page_content='和Hsu等人（2017a年）提出。\\n后验坍塌问题 ：在训练过程中，一个潜在问题是后验坍塌，即编码器始终预测先验\\n分布。Bowman 等人（2015年）发现了这一问题，并指出通过在训练过程中逐步增加鼓\\n励后验与先验之间的 KL散度较小的项，可以缓解这一问题。已经有多种方法被提出来\\n防止后验坍塌（ Razavi等人，2019a；Lucas等人，2019b, a） ，使用离散潜在空间也是其\\n中一个动机（ Van Den Oord 等人，2017年） 。\\n模糊的重建 ：Zhao等人（2017年c）提供的证据显示，模糊重建部分原因是高斯噪\\n声，以及变分近似导致的次优后验分布。有趣的是，一些最好的合成结果是通过使用由\\n复杂自回归模型建模的离散潜在空间（ Razavi等人，2019b）或分层潜在空间（ Vahdat\\n& Kautz，2020年；参见图 17.12d）得到的。图 17.12a-c 使用的是在 CELEBA 数据库\\n上训练的 VAE（Liu等人，2015年） 。图 17.12d使用的是在 CELEBA HQ 数据集上训\\n练的分层 VAE（Karras等人，2018年） 。\\n其他问题 ：Chen等人（2017年）指出，当使用更复杂的似然项，例如 PixelCNN\\n（Van den Oord 等人，2016c） ，输出可能完全不再依赖潜变量。他们将这种现象称为信\\n息偏好问题。 Zhao等人（2017b）在InfoVAE 中通过增加一个额外项来最大化潜变量和\\n观察分布之间的互信息，从而解决了这个问题。\\nVAE存在的另一个问题是潜空间中可能出现不对应任何现实样本的“空洞” 。 Xu'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 321}, page_content='306 CHAPTER 17. 变分自编码器\\n等人（2020年）提出了受限后验 VAE，通过添加一个正则项来防止潜空间中的这些空\\n区域，从而实现了更好的真实样本插值。\\n解耦潜在表示 ：解耦潜在表示的方法包括 beta VAE （Higgins等人，2017年）和其\\n他方法（例如， Kim & Mnih ，2018年；Kumar等人，2018年） 。Chen等人（2018年\\nd）进一步分解了 ELBO， 展示了存在一个衡量潜变量之间总相关性（即聚合后验与其边\\n际分布乘积之间的距离）的项。他们提出总相关性 VAE，旨在最小化这一指标。 Factor\\nVAE（Kim & Mnih ，2018年）采用了一种不同的方法来最小化总相关性。 Mathieu 等\\n人（2019年）探讨了解耦表示中的重要因素。\\n重参数化技巧 ： 考虑计算某函数的期望值， 其中涉及的概率分布依赖于特定参数。 重\\n参数化技巧涉及计算这个期望值相对于这些参数的导数。本章将其作为一种方法介绍，\\n通过采样过程近似期望值进行微分；尽管存在其他方法（参见问题 17.5） ，重参数化技\\n巧提供了一个通常具有低方差的估计器。这个问题在 Rezende 等人（2014年） 、Kingma\\n等人（2015年）和Roeder等人（2017年）的讨论中得到了阐述。\\n证据下界与 EM算法：VAE训练基于优化证据下界（有时也被称为 ELBO，变分\\n下界，或负变分自由能） 。 Hoffman 和Johnson（2016年）以及 Lücke等人（2020年）用\\n几种方式重新表述了这一下界， 明确了其特性。其他研究旨在使这个界更加严格（ Burda\\n等人，2016年；Li和Turner，2016年；Bornschein 等人，2016年；Masrani 等人，2019\\n年） 。例如， Burda等人（2016年）基于使用多个重要性加权样本从近似后验中提取来\\n形成目标函数的修改界。\\n当分布q(z|θ)与后验Pr(z|x,ϕ)相匹配时， ELBO达到紧致状态。这是 *期望最大\\n化（EM）*算法（Dempster 等人，1977年）的基础。这里，我们轮流（ i）选择θ使\\nq(z|θ)等于后验Pr(z|x,ϕ)，以及（ ii）调整ϕ以最大化下界（见图 17.15） 。这种方法适'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 321}, page_content='q(z|θ)等于后验Pr(z|x,ϕ)，以及（ ii）调整ϕ以最大化下界（见图 17.15） 。这种方法适\\n用于可以闭式计算后验分布的高斯混合模型等模型。遗憾的是，对于非线性潜在变量模\\n型，这种方法不可行。\\n17.11习题\\n问题 17.1构建一个一维高斯混合模型，该模型有 n = 5个组成部分（参见方程\\n17.4） ，需要多少个参数？并说明每个参数可能的取值范围。\\n问题 17.2如果一个函数的二阶导数在任何处都小于或等于零，则该函数是凹的。\\n证明函数g[x] =log[x]满足这一性质。\\n问题 17.3对于凸函数， Jensen不等式是相反的：\\ng[E[y]]≤E[g[y]]. (17.31)\\n如果一个函数的二阶导数在任何地方都大于或等于零，则该函数是凸的。证明函数\\ng[x] =x2n对于任意的 n∈{1,2,3,...}是凸的。利用这个结果和 Jensen不等式证明分\\n布Pr(x)的平均值的平方 E[x]2必须小于或等于其二阶矩 E[x2]。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 322}, page_content='17.11.习题 307\\n图 17.15:期望最大化 (EM)算法。 EM算法轮流调整辅助参数 θ（跨越不同的彩色曲线）和模\\n型参数 φ（沿彩色曲线移动） ，直至达到最大值。这两种调整分别称为 E步骤和 M步骤。由于\\nE步骤利用后验分布 P r(h|x, φ)来代替 q(h|x, θ)，因此这个界限非常接近实际情况，每次完成\\nE步骤后，彩色曲线都会接触到黑色的似然曲线。\\n问题 17.4展示如何从变分分布 q(z|x)与真实后验分布 Pr(z|x,ϕ)之间的KL散度\\n出发，推导出 ELBO的表达式（如方程 17.18所示） ：\\nDKL[q(z|x)||Pr(z|x,ϕ)] =Z\\n(q(z|x)logq(z|x)\\nPr(z|x,ϕ))dz. (17.32)\\n从贝叶斯定理（方程 17.19）开始。\\n问题17.5重参数化技巧用于计算函数 f[x]关于其期望的导数：\\n∂\\n∂ϕEPr(x|ϕ)[f[x]], (17.33)\\n这里的导数是关于分布 Pr(x|ϕ)参数ϕ的。证明这个导数还可以表示为：\\n∂\\n∂ϕEPr(x|ϕ)[f[x]] =EPr(x|ϕ)\\x14\\nf[x]∂\\n∂ϕlog(Pr(x|ϕ))\\x15\\n≈1\\nIIX\\ni=1f[xi]∂\\n∂ϕlog(Pr(xi|ϕ)). (17.34)\\n这种方法称为 REINFORCE 算法或得分函数估计器 （score function estimator ） 。\\n问题 17.6在潜在空间中移动时，为什么使用球面线性插值而不是常规线性插值更\\n为合适？提示：参考图 8.13。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 323}, page_content='308 CHAPTER 17. 变分自编码器\\n问题 17.7推导N个成分的一维高斯混合模型的 EM算法。这需要你（ i）为数据\\n点x求出其潜变量 z∈{1,2,...,N}上的后验分布 Pr(z|x)的表达式，以及（ ii）基于\\n所有数据点的后验分布来更新证据下界的表达式。需要使用拉格朗日乘数法来确保各高\\n斯成分的权重 λ1,...,λ N之和为一。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 324}, page_content='Chapter 18\\n扩散模型\\n第15章描述了生成对抗模型（ Generative Adversarial Models, GANs ） ，这些模型\\n可以生成逼真样本，但不为数据定义概率分布。第 16章讨论了归一化流（ Normalizing\\nFlows） ， 它们确立了特定的概率分布， 但须对网络架构施加限制： 每层都必须可逆， 且其雅\\n可比矩阵的行列式计算要简便。 第 17章介绍的变分自编码器 （ Variational Autoencoders,\\nVAEs）具有坚实的概率基础，但似然性的计算不可直接求解，需要用一个下界来近似。\\n本章将介绍扩散模型（ Diffusion Models ） 。与归一化流类似，扩散模型是定义了从\\n潜在变量到观测数据之间非线性映射的概率模型，且这两者的维度是相同的。与变分自\\n编码器相似，扩散模型使用基于某种编码器的下界来近似数据的似然，该编码器将数据\\n映射到潜在变量。不过，在扩散模型中，这种编码器是预设的。其目标是学习一个解码\\n器，作为该过程的逆过程，以生成样本。扩散模型训练简便，并能生成高于生成对抗网\\n络所产样本真实度的高质量样本。在阅读本章之前，读者应熟悉变分自编码器（第 17\\n章） 。\\n18.1概览\\n扩散模型包括一个编码器（ encoder）和一个解码器（ decoder） 。编码器取一个数据\\n样本x，通过一连串中间潜变量 z1...z T进行映射。解码器则逆向操作：从 zT开始，逐\\n步映射回zT−1,...,z 1，最终重构出数据点 x。编码器和解码器的映射过程都是随机的，\\n而非确定性的。\\n编码器的设计是固定的，它会逐步将输入数据与白噪声融合（参见图 18.1） 。随着\\n步骤增加，最终潜变量的条件分布 q(zT|x)和边缘分布 q(zT)会趋于标准正态分布。这\\n一过程既定，解码器中包含了所有的学习参数。\\n解码器由一系列网络组成，这些网络负责逆向映射每对相邻潜变量 zt和zt−1。损\\n失函数促使每个网络反转对应的编码步骤，从而逐渐消除表示中的噪声，留下逼真的数\\n据样例。为生成新的数据样例 x，我们从q(zT)抽样，并通过解码器进行处理。\\n第18.2节将详细探讨编码器的特性，这些特性虽不显眼，但对学习算法至关重要。\\n309'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 325}, page_content='310 CHAPTER 18. 扩散模型\\n第18.3节将讨论解码器。第 18.4节将推导出训练算法，而第 18.5节将对其进行改进，\\n使之更加实用。第 18.6节讨论实施细节，包括如何依据文本提示来指导生成过程。\\n图 18.1:扩散模型。编码器（前向或扩散过程）将输入 x映射通过一系列潜变量 z1 ... zT 。此过\\n程是预设的，它逐步将数据与噪声混合，最终仅留下噪声。解码器（逆过程）经过学习，逐级通\\n过潜变量传递数据，同时在每个阶段去除噪声。训练完成后，通过对噪声向量 zT进行采样，并\\n通过解码器处理这些向量来生成新的样本。\\n18.2编码器（前向过程）\\n扩散或前向过程（图 18.2）将数据样例 x映射为一系列与 x同维度的中间变量\\nz1,z2,...,z T，过程如下：\\nz1=p\\n1−β1·x+p\\nβ1·ϵ1\\nzt=p\\n1−βt·zt−1+p\\nβt·ϵt∀t∈{2,...,T}, (18.1)\\n其中ϵt是从标准正态分布中抽取的噪声。第一项逐渐减弱原始数据和已添加噪声\\n的影响，而第二项引入更多噪声。噪声级别 βt∈[0,1]控制噪声融合的快慢，这一系列\\n参数被称为 噪声调度（ noise schedule ） 。前向过程可以等价表达为：\\nq(z1|x) =Norm z1hp\\n1−β1,β1i\\nq(zt|zt−1) =Norm zthp\\n1−βt−1,βti\\n∀t∈{2,...,T}. (18.2)\\n该过程形成了一个马尔可夫链（ Markov chain ） ，其中zt的概率仅依赖于它前一变\\n量zt−1的值。经过足够多的步骤 T，所有原始数据的痕迹将被消除，最终 q(zT|x)和\\nq(zT)都会趋向于标准正态分布。\\n给定输入 x，所有潜变量 z1,z2,...,z T的联合分布表达为：\\nq(z1...T|x) =q(z1|x)TY\\nt=2q(zt|zt−1). (18.3)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 326}, page_content='18.2.编码器（前向过程） 311\\n图 18.2: Figure18.2\\n18.2.1 Diffusion kernel q(zt|x)\\n为了训练解码器逆转此过程， 我们对同一数据样本 x在不同时间点 t生成多个样本。\\n然而，当t较大时，根据方程 (18.1)顺序生成这些样本会非常耗时。幸运的是， q(zt|x)\\n有一个封闭形式的解，使我们能直接从给定的初始数据点 x抽取zt样本，而不需要计\\n算中间的变量 z1...z t−1。这称为扩散核（图 18.3） 。为了得出 q(zt|x)的表达式，让我们\\n考虑前向过程的前两步：\\nz1=p\\n1−β1·x+p\\nβ1·ϵ1\\nz2=p\\n1−β2·z1+p\\nβ2·ϵ2 (18.4)\\n将第一步的结果代入第二步，我们得到：\\nz2=p\\n1−β2\\x10p\\n1−β1·x+p\\nβ1·ϵ1\\x11\\n+p\\nβ2·ϵ2\\n=p\\n1−β2\\x10p\\n1−β1·x+p\\n1−(1−β1)·ϵ1\\x11\\n+p\\nβ2·ϵ2\\n=p\\n(1−β2)(1−β1)·x+p\\nβ2−(1−β2)(1−β1)·ϵ1+p\\nβ2·ϵ2.(18.5)\\n最后两项分别是均值为零的正态分布中独立抽取的样本，其方差为 1−β2−(1−\\nβ2)(1−β1)和β2。这些项的和的均值为零，其方差为各部分方差之和（参见问题 18.2） 。\\n因此：\\nz2=p\\n(1−β2)(1−β1)·x+p\\n1−(1−β2)(1−β1)·ϵ, (18.6)\\n其中，ϵ也是标准正态分布的一个样本。\\n若继续这一过程，将该方程代入 z3的表达式中，以此类推，我们可以得出：\\nzt=√αt·x+√\\n1−αt·ϵ, (18.7)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 327}, page_content='312 CHAPTER 18. 扩散模型\\n其中αt=Qt\\ns=1(1−βs)。这可以等价地表示为概率形式：\\nq(zt|x) =Norm zt[√αt·x,1−αt]. (18.8)\\n对于任何初始数据点 x，变量zt遵循均值和方差已知的正态分布。因此，如果我们\\n不考虑中间变量 z1...z t−1的演化历史，生成 q(zt|x)的样本就变得简单。\\n图 18.3:扩散核。 a)点 x∗ = 2.0 使用方程 18.1在潜变量中传播（显示为灰色的五条路径） 。扩\\n散核 q(zt|x∗)表示从 x∗出发到变量 zt的概率分布，这个分布可以以闭合形式计算，是一个均\\n值向零递减、方差随时间 t增加的正态分布。热图展示了每个 zt的 q(zt|x∗)，青色线条表示均\\n值的 ±2标准差。 b)对 t = 20、40、80，扩散核 q(zt|x∗)被具体显示出来。实际上，扩散核使\\n我们能够直接采样给定 x∗的潜变量 zt，而无需计算 z1,...,zt−1 的中间变量。当 t非常大时，扩\\n散核近似为标准正态分布。\\n18.2.2 边缘分布q(zt)\\n边际分布q(zt)表示在给定初始点 x的分布和每个初始点可能的扩散路径的条件下，\\n观察到zt值的概率（见图 18.4） 。通过考虑联合分布 q(x,z 1...)并对所有其他变量进行\\n边际化，可以计算得到：\\nq(zt) =Z Z\\n...Z\\nq(z1...t,x )dz1...dz t−1dx\\n=Z Z\\n...Z\\nq(z1...t|x)Pr(x)dz1...dz t−1dx, (18.9)\\n其中q(z1...t|x)的定义见方程 18.3。\\n但是，鉴于我们已有表示扩散核 q(zt|x)的表达式，该表达式直接“跳过”了中间变\\n量，因此我们可以等价地表达为：\\nq(zt) =Z\\nq(zt|x)Pr(x)dx. (18.10)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 328}, page_content='18.2.编码器（前向过程） 313\\n所以， 如果我们不断从数据分布 Pr(x)中取样， 并在每个样本上应用扩散核 q(zt|x)，\\n就能得到边际分布 q(zt)（见图18.4） 。然而，由于不知道原始数据分布 Pr(x)，边际分\\n布不能用封闭形式表示。\\n图 18.4:边缘分布。 a)给定一个初始密度 Pr(x)（顶行） ，随着扩散过程通过潜变量 zt的传播，\\n分布逐渐模糊，趋向于标准正态分布。热图的每一层代表一个时间点的边缘分布 q(zt)。b)顶部\\n图展示了初始分布 Pr(x)，其他两图分别展示了 z20和 z60时刻的边缘分布 q(z20)和 q(z60)。\\n18.2.3 条件分布q(zt−1|zt)\\n我们定义条件概率 q(zt−1|zt)来描述混合过程（见方程 18.2） 。为了逆向这一过程，\\n我们采用贝叶斯规则：\\nq(zt−1|zt) =q(zt|zt−1)q(zt−1)\\nq(zt)(18.11)\\n这一计算难以实现，因为我们无法得出边际分布 q(zt−1)。\\n对于这个简单的一维例子，可以通过数值方法评估 q(zt−1|zt)（参见图 18.5） 。通常\\n情况下，这类分布形态较为复杂，但它们经常可以用正态分布进行良好的近似。这一点\\n对我们来说极为重要，因为在构建解码器时，我们会用正态分布来近似这一逆过程。\\n18.2.4 条件扩散分布 q(zt−1|zt,x)\\n最后，我们需要考虑与编码器相关的一个分布。之前我们提到无法确定条件分布\\nq(zt−1|zt)，因为我们不知道边际分布 q(zt−1)。但是，如果我们已知起始变量 x，则可以\\n确定之前时刻的分布 q(zt−1|x)，即扩散核（见图 18.3） ，这是一个正态分布。\\n因此，我们能够闭式计算条件扩散分布 q(zt−1|zt,x)（见图18.6） 。这个分布用于训\\n练解码器，它描述了在已知当前潜在变量 zt和训练样本 x的情况下zt−1的分布（显然，\\n在训练时我们是知道这些的） 。要计算 q(zt−1|zt,x)的表达式，我们首先应用贝叶斯规则：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 329}, page_content='314 CHAPTER 18. 扩散模型\\n图 18.5:条件分布 q(zt−1|zt) 。a)展示了边缘密度 q(zt)和三个特定点 zt∗。b)条件概率\\nq(zt−1|zt∗) （青色曲线）是通过贝叶斯规则计算得到的，与 q(zt∗|zt−1) 和 q(zt−1) 的乘积成\\n比例。通常，这个分布不是正态的（顶部图） ，但在许多情况下正态分布是一个良好的近似（底\\n部两个图） 。第一个似然项 q(zt∗|zt−1) 关于 zt−1是正态的（方程 18.2） ，其均值比 zt∗略远离\\n零点（棕色曲线） ，第二项是边\\nq(zt−1|zt,x) =q(zt|zt−1,x)q(zt−1|x)\\nq(zt|x)\\n∝q(zt|zt−1)q(zt−1|x)\\n=Norm zthp\\n1−βt·zt−1,βti\\nNorm zt−1hp\\nαt−1·x,(1−αt−1)i\\n∝Norm zt−1\\x141√1−βtzt,βt\\n1−βt\\x15\\nNorm zt−1hp\\nαt−1·x,(1−αt−1)i\\n(18.12)\\n在第一行和第二行之间，我们依据扩散过程是马尔可夫的，因此 q(zt|zt−1,x) =\\nq(zt|zt−1)，所有关于 zt的信息均由 zt−1表达。在第三行和第四行之间，我们应用高斯\\n变量变换公式：\\nNorm v[Aw,B ]∝Norm w\\x02\\n(ATB−1A)−1ATB−1v,(ATB−1A)−1\\x03\\n, (18.13)\\n将第一个分布转换为 zt−1的形式。接下来，我们利用另一个高斯公式：\\nNorm w[a,A]·Norm w[b,B]∝Norm w\\x02\\n(A−1+B−1)−1(A−1a+B−1b),(A−1+B−1)−1\\x03\\n,\\n(18.14)\\n结合zt−1中的两个正态分布，得到：\\nq(zt−1|zt,x) =Norm zt−1\"\\n(1−αt−1)\\n1−αtr\\nβt\\n1−αtzt+r\\nαt−1βt\\n1−αtx,βt(1−αt−1)\\n1−αt#\\n.(18.15)\\n需要注意的是，方程 18.12、18.13和18.14中的比例常数最终必须相互抵消，因为\\n最终结果是一个已正确归一化的概率分布。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 330}, page_content='18.3.解码器模型（反向过程） 315\\n图 18.6:条件分布 q(zt−1|zt,x) 。a)对于 x∗ = −2.1 的扩散核，其中三个点 zt∗被突出显示。 b)\\n概率 q(zt−1|zt∗,x∗) 根据贝叶斯规则计算，与 q(zt∗|zt−1) 和 q(zt−1|x∗) 成正比。这是一个正态\\n分布，可以以闭合形式计算。第一个似然项 q(zt∗|zt−1) 在 zt−1中呈正态分布（根据方程 18.2） ，\\n其均值略大于 zt∗（棕色曲线） ，第二项为扩散核 q(zt−1|x∗) （灰色曲线） 。\\n18.3解码器模型（反向过程）\\n在学习扩散模型时，我们主要关注的是逆过程，即通过一系列概率映射从潜在变\\n量zT逐步回溯到 zT−1，再到zT−2，直至回到原始数据 x。扩散过程中真实的逆分布\\nq(zt−1|zt)形态复杂且多模态（见图 18.5） ，取决于数据分布 Pr(x)。我们用正态分布来\\n近似这些复杂分布：\\nPr(zT) =Norm zT[0,I]\\nPr(zt−1|zt,ϕt) =Norm zt−1[ft[zt,ϕt],σ2\\nt]\\nPr(x|z1,ϕ1) =Norm x[f1[z1,ϕ1],σ2\\n1], (18.16)\\n其中ft[zt,ϕt]代表一个神经网络，用于计算从 zt映射到zt−1的正态分布的均值。\\n这里的{σ2\\nt}是预先确定的。如果扩散过程的超参数 βt接近于零（且时间步长 T足够\\n大） ，这种正态近似是可行的。\\n通过祖先抽样方法从 Pr(x)生成新样本。首先从 Pr(zT)抽取zT，然后从\\nPr(zT−1|zT,ϕT)中抽取zT−1，接着从Pr(zT−2|zT−1,ϕT−1)中抽取zT−2，如此继续，直\\n到最终从Pr(x|z1,ϕ1)生成x。\\n18.4训练\\n观测变量x和潜在变量{zt}的联合分布定义如下：\\nPr(x,z 1...T|ϕ1...T) =Pr(x|z1,ϕ1)TY\\nt=2Pr(zt−1|zt,ϕt)·Pr(zT)(18.17)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 331}, page_content='316 CHAPTER 18. 扩散模型\\n通过对潜在变量边际化处理，我们得到观测数据的似然函数 Pr(x|ϕ1...T)：\\nPr(x|ϕ1...T) =Z\\nPr(x,z 1...T|ϕ1...T)dz1...T. (18.18)\\n为了训练模型，我们需要最大化训练数据集 {xi}相对于参数 ϕ的对数似然函数：\\nˆϕ1...T=argmax\\nϕ1...T\"IX\\ni=1logPr(xi|ϕ1...T)#\\n. (18.19)\\n因为方程 18.18中的边际化过程难以直接处理，所以我们不能直接进行最大化。因\\n此，我们采用詹森不等式 (Jensen’s inequality) 来定义似然的下界，并以此对参数 ϕ1...T\\n进行优化，这一做法与我们在变分自编码器 (VAE)的处理方式完全一致（参见章节\\n17.3.1） 。\\n18.4.1 证据下界（ ELBO）\\n为了推导下界，我们在对数似然函数中引入编码器分布 q(z1...T|x)，并应用詹森不\\n等式（参见章节 17.3.2） ：\\nlog[Pr(x|ϕ1...T)] =log\\x14Z\\nPr(x,z 1...T|ϕ1...T)dz1...T\\x15\\n=log\\x14ZPr(x,z 1...T|ϕ1...T)\\nq(z1...T|x)q(z1...T|x)dz1...T\\x15\\n≥Z\\nq(z1...T|x)log\\x14Pr(x,z 1...T|ϕ1...T)\\nq(z1...T|x)\\x15\\ndz1...T. (18.20)\\n从而得到证据下界（ ELBO） ：\\nELBO [ϕ1...T] =Z\\nq(z1...T|x)log\\x14Pr(x,z 1...T|ϕ1...T)\\nq(z1...T|x)\\x15\\ndz1...T. (18.21)\\n在变分自编码器（ VAE）中，编码器 q(z|x)逼近潜在变量的后验分布，以使得边界\\n尽可能紧密，解码器则努力最大化这一边界（见图 17.10） 。在扩散模型中，所有工作\\n均由解码器承担，因为编码器没有参数。解码器通过改变其参数使静态编码器近似后验\\n分布Pr(z1...T|x,ϕ 1...T)，并围绕这一边界优化其参数，以此使边界更加紧密（参见图\\n17.6） 。\\n18.4.2 简化 ELBO\\n我们将ELBO中的对数项转化为将要优化的最终形式。首先将等式 18.17和18.3\\n定义的分子和分母代入：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 332}, page_content='18.4.训练 317\\nlog\\x14Pr(x,z 1...T|ϕ1...T)\\nq(z1...T|x)\\x15\\n=log\"\\nPr(x|z1,ϕ1)QT\\nt=2Pr(zt−1|zt,ϕt)·Pr(zT)\\nq(z1|x)QT\\nt=2q(zt|zt−1)#\\n=log\\x14Pr(x|z1,ϕ1)\\nq(z1|x)\\x15\\n+log\"TY\\nt=2Pr(zt−1|zt,ϕt)\\nq(zt|zt−1)#\\n+log[Pr(zT)].\\n(18.22)\\n然后我们展开第二项的分母：\\nq(zt|zt−1) =q(zt|zt−1,x)q(zt|x)/q(zt−1|x), (18.23)\\n其中第一个等式成立是因为关于变量 zt的所有信息都包含在 zt−1中，所以额外的\\n条件数据x是无关的。第二个等式是贝叶斯规则的直接应用。\\n代入这个结果得到：\\nlog\\x14Pr(x,z 1...T|ϕ1...T)\\nq(z1...T|x)\\x15\\n=log\\x14Pr(x|z1,ϕ1)\\nq(z1|x)\\x15\\n+log\"QT\\nt=2Pr(zt−1|zt,ϕt)·q(zt−1|x)QT\\nt=2q(zt|zt−1,x)·q(zt|x)#\\n+log\\x14Pr(zT)\\nq(zT|x)\\x15\\n=log\\x14Pr(x|z1,ϕ1)\\nq(z1|x)\\x15\\n+log\"TY\\nt=2Pr(zt−1|zt,ϕt)\\nq(zt|zt−1,x)#\\n+log\\x14Pr(zT)\\nq(zT|x)\\x15\\n≈log[Pr(x|z1,ϕ1)] +TX\\nt=2log\\x14Pr(zt−1|zt,ϕt)\\nq(zt|zt−1,x)\\x15\\n,(18.24)\\n其中在第二行和第三行之间的乘积比中的项 q(zt−1|x)/q(zt|x)除了q(z1|x)和\\nq(zT|x)之外都相互抵消了。第三行中的最后一项大约是 log[1] = 0，因为前向过程\\n的结果q(zT|x)是一个标准正态分布，与先验 Pr(zT)相等。\\n因此，简化的 ELBO是：\\nELBO [ϕ1...T] =Z\\nq(z1...T|x)logPr(x,z 1...T|ϕ1...T)\\nq(z1...T|x)dz1...T\\n≈Z\\nq(z1...T|x) \\nlog[Pr(x|z1,ϕ1)] +TX\\nt=2logPr(zt−1|zt,ϕt)\\nq(zt−1|zt,x)!\\ndz1...T\\n=Eq(z1|x)[log[Pr(x|z1,ϕ1)]]\\n−TX'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 332}, page_content='log[Pr(x|z1,ϕ1)] +TX\\nt=2logPr(zt−1|zt,ϕt)\\nq(zt−1|zt,x)!\\ndz1...T\\n=Eq(z1|x)[log[Pr(x|z1,ϕ1)]]\\n−TX\\nt=2Eq(zt|x)[DKL[q(zt−1|zt,x)||Pr(zt−1|zt,ϕt)]], (18.25)\\n其中我们在第二行和第三行之间对 q(z1...T|x)中的不相关变量进行了边际化，并使\\n用了KL散度的定义（见问题 18.7） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 333}, page_content='318 CHAPTER 18. 扩散模型\\n18.4.3 分析 ELBO\\nELBO中的第一个概率项在等式 18.16中被定义为：\\nPr(x|z1,ϕ1) =Norm x\\x02\\nf1[z1,ϕ1],σ2\\n1\\x03\\n, (18.26)\\n这相当于 VAE中的重构项。如果模型预测与观测数据匹配， ELBO将会增大。与\\nVAE相同，我们将使用蒙特卡洛估计来近似这个数量对数的期望值（见等式 17.22-\\n17.23） ，其中我们用从 q(z1|x)抽取的样本来估计期望值。\\nELBO中的KL散度项衡量了 Pr(zt−1|zt,ϕt)与q(zt−1|zt,x)之间的距离，它们分别\\n在等式18.16和18.15中定义：\\nPr(zt−1|zt,ϕt) =Norm zt−1\\x02\\nft[zt,ϕt],σ2\\nt\\x03\\nq(zt−1|zt,x) =Norm zt−1\"\\n(1−αt−1)\\n1−αt−p\\nαt−1βt\\n1−αtzt+p\\nαt−1βt\\n1−αtx,β t(1−αt−1)#\\n.(18.27)\\n两个正态分布之间的 KL散度有一个封闭形式的表达式。此外，这个表达式中的许\\n多项不依赖于 ϕ（见问题 18.8） ，表达式简化为均值之间的平方差加上一个常数 C：\\nDKL[q(zt−1|zt,x)||Pr(zt−1|zt,ϕt)] =\\n1\\n2σ2\\nt\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c(1−αt−1)\\n1−αt−r\\nβt\\n1−αtzt+r\\nαt−1βt\\n1−αtx−ft[zt,ϕ]\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c2\\n+C. (18.28)\\n18.4.4 扩散损失函数\\n为了拟合模型，我们需要最大化 ELBO，并将其通过参数 ϕ1...T来实现。我们将这\\n个过程转化为最小化问题，方法是乘以负一，并用样本来近似期望值，以此来定义损失\\n函数：\\nL(ϕ1...T) =IX\\ni=1\\x00\\n−logNorm xi[f1[zi1,ϕ1],σ2\\n1]\\x01\\n+TX\\nt=21\\n2σ2\\nt\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c1−αt−1\\n1−αt−r\\nαt−1βt\\n1−αtzit+r\\nαt−1βt\\n1−αtxi−ft[zit,ϕt]\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c2\\n),(18.29)\\n其中xi代表第i个数据点， zit是在第t步扩散过程中的关联潜变量。\\n18.4.5 训练过程\\n这个损失函数被用于在各个扩散时间步训练网络，其目的是最小化前一时间步隐藏'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 333}, page_content='),(18.29)\\n其中xi代表第i个数据点， zit是在第t步扩散过程中的关联潜变量。\\n18.4.5 训练过程\\n这个损失函数被用于在各个扩散时间步训练网络，其目的是最小化前一时间步隐藏\\n变量估计值 ft[zt,ϕt]与基于去噪数据 x的最可能值之间的差距。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 334}, page_content='18.5.损失函数的重新参数化 319\\n图18.7和图18.8显示了对简单一维示例的逆过程拟合。这个模型的训练过程包括：\\n(i)从原始分布中获取大量样本 x，(ii)利用扩散核在各个时间点 t为潜变量zt预测多个\\n相应值，然后 (iii)训练模型ft[zt,ϕt]以最小化方程 18.29中定义的损失函数。这些模型\\n虽然是非参数的（即一维输入到一维输出的查找表） ，但更常见的是使用深度神经网络。\\n图 18.7:拟合模型。 a)通过首先从标准正态分布 Pr(zT)采样 （底部行） ， 然后根据 Pr(zT−1|zT) =\\nNorm zT−1[fT(zT, ϕT), σ2\\nTI]逐步采样 zT−1等，可以生成个体样本，直至获得 x（展示了五条路\\n径） 。估计的边缘密度（热图）是这些样本的集合，与图 18.4中的真实边缘密度相似。 b)估计\\n分布 Pr(zt−1|zt)（棕色曲线）是扩散模型的真实后验 q(zt−1|zt)（图 18.5中的青色曲线）的合理\\n近似。估计的和真实的边缘分布 Pr(zt)和q(zt)（分别是深蓝色和灰色曲线）也相似。\\n图 18.8:拟合模型结果。青色和棕色曲线分别代表原始和估计密度，并分别对应于图 18.4和\\n18.7顶部的行。垂直条形代表模型生成的分箱样本，这些样本是通过从 P r(zT ) 采样并通过图\\n18.7所示的五条路径向后传播 zT−1、zT−2等变量得到的。\\n18.5损失函数的重新参数化\\n虽然方程 18.29中的损失函数是可行的，但研究发现，对扩散模型采用不同的参数\\n化方式能够获得更好的效果；损失函数经修改，目标是使模型预测出与原始数据混合生'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 335}, page_content='320 CHAPTER 18. 扩散模型\\n成当前变量的噪声。第 18.5.1节讨论了如何重新参数化目标（方程 18.29第二行的前两\\n项） ，第 18.5.2节讨论了如何重新参数化网络（方程 18.29第二行的最后一项） 。\\n18.5.1 目标的重参数化\\n原始的扩散更新由下式给出：\\nzt=√αt·x+√\\n1−αt·ϵ. (18.30)\\n因此，在方程 18.28中的数据项 x可以表示为扩散图像减去其上添加的噪声：\\nx=1√αt·zt−√1−αt√αt·ϵ. (18.31)\\n将这个表示代入方程 18.29中的目标项，我们得到：\\n(1−αt−1)\\n1−αtp\\n1−βtzt+√αt−1βt\\n1−αtx\\n=(1−αt−1)\\n1−αtp\\n1−βtzt+√αt−1βt\\n1−αt\\x121√αtzt−√1−αt√αtϵ\\x13\\n=(1−αt−1)\\n1−αtp\\n1−βtzt+βt\\n1−αt\\x121√1−βtzt−√1−αt√1−βtϵ\\x13\\n,\\n(18.32)\\n这里我们利用了从第二行到第三行√αt/√αt−1=√1−βt的关系。进一步简化，可\\n以得到：\\n(1−αt−1)\\n1−αtp\\n1−βtzt+p\\nαt−1βt\\n1−αtx\\n=\\x12(1−αt−1)√1−βt\\n1−αt+βt\\n(1−αt)√1−βt\\x13\\nzt−βt√1−αt√1−βtϵ\\n=\\x12(1−αt−1)(1−βt) +βt\\n(1−αt)√1−βt\\x13\\nzt−βt√1−αt√1−βtϵ\\n=1−αt−1−βt+βt\\n(1−αt)√1−βtzt−βt√1−αt√1−βtϵ\\n=1−αt−1\\n(1−αt)√1−βtzt−βt√1−αt√1−βtϵ\\n=1√1−βtzt−βt√1−αt√1−βtϵ, (18.33)\\n这个过程包括了在第二行和第三行间对第一项的分子和分母乘以√1−βt，展开这\\n些项，并在第三行和第四行间简化第一项的分子。\\n最后，将这个结果代回损失函数（方程 18.29） ，我们得到：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 336}, page_content='18.5.损失函数的重新参数化 321\\nL(ϕ1...T) =IX\\ni=1−logNorm xi[f1[zi1,ϕ1],σ2\\n1]\\n+TX\\nt=21\\n2σ2\\nt\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x121√1−βtzit−βt√1−αt√1−βtϵit\\x13\\n−ft[zit,ϕt]\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c\\x0c2\\n,(18.34)\\n18.5.2 网络的重参数化\\n现在我们用新模型 ˆϵ=gt[zt,ϕt]替换原有的模型中的 ˆzt−1=ft[zt,ϕt]部分，这个新\\n模型用于预测与 x混合生成zt的噪声ϵ：\\nft[zt,ϕt] =1√1−βtzt−βt√1−αt√1−βtgt[zt,ϕt]. (18.35)\\n将这个新模型代入方程 18.34，我们得到以下准则：\\nL(ϕ1...T) =IX\\ni=1−log\\x02\\x00\\nNorm xi[f1(zi1,ϕ1),σ2\\n1I]\\x01\\x03\\n+TX\\nt=2β2\\nt\\n(1−αt)(1−βt)2σ2\\nt∥gt[zit,ϕt]−ϵit∥2. (18.36)\\n对数正态分布的表达可以被转换为一个最小二乘损失加上常数 Ci（参见5.3.1节） ：\\nL(ϕ1...T) =IX\\ni=11\\n2σ2\\n1∥xi−f1(zi1,ϕ1)∥2+TX\\nt=2β2\\nt\\n(1−αt)(1−βt)2σ2\\nt∥gt[zit,ϕt]−ϵit∥2+Ci.\\n将方程18.31和18.35中的x和f1[z1,ϕ1]的定义代入后，第一项可以简化为：\\n1\\n2σ2\\n1∥xi−f1[zi1,ϕ1]∥2=1\\n2σ2\\n1\\r\\r\\r\\rβ1√1−α1√1−β1g1[zi1,ϕ1]−β1√1−α1√1−β1ϵi1\\r\\r\\r\\r2\\n.\\n(18.37)\\n把这个结果加回最终的损失函数，我们得到：\\nL(ϕ1...T) =IX\\ni=1TX\\nt=1β2\\nt\\n(1−αt)(1−βt)2σ2\\nt∥gt[zit,ϕt]−ϵit∥2, (18.38)\\n这里我们忽略了加性常数 Ci。\\n在实际应用中，通常会忽略不同时间步骤可能不同的缩放因子，从而得到一个更简\\n单的公式：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 337}, page_content='322 CHAPTER 18. 扩散模型\\nL(ϕ1...T) =IX\\ni=1TX\\nt=1∥gt[zit,ϕt]−ϵit∥2\\n=IX\\ni=1TX\\nt=1\\r\\rgt\\x02√αt·xi+√\\n1−αt·ϵit,ϕt\\x03\\n−ϵit\\r\\r2,(18.39)\\n其中我们在第二行使用扩散核（方程 18.30）重写了zt。\\n18.6实现\\n这导致我们为模型训练（算法 18.1）和采样（算法 18.2）分别得出了直观的算法。\\n训练算法的优点在于： (i)实现简单， (ii)能够自然地扩充数据集；我们可以在每个时间\\n步反复利用每个原始数据点 xi，每次配合不同的噪声实例 ϵ使用。而采样算法的不足之\\n处在于，它需要顺序处理多个神经网络 gt[zt,ϕt]，因此比较耗时。\\n图 18.9: Figure18.8\\n18.6.1 应用于图像\\n扩散模型在图像数据的建模方面取得了巨大成功。这里，我们需构建的模型能够\\n处理带噪声的图像，并预测每个步骤中添加的噪声。在进行这种图像到图像的映射时，\\nU-Net（图11.10）是一个理想的选择。然而，可能存在大量的扩散步骤，训练和存储众\\n多的U-Net十分低效。一个解决办法是训练一个能够同时接受表示时间步骤的预定向\\n量作为输入的单一 U-Net（图18.9） 。实际上，这个向量会被调整大小，以便在 U-Net\\n的每个阶段与通道数匹配，并用来在每个空间位置调整和 /或缩放表示。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 338}, page_content='18.6.实现 323\\n由于超参数 βt接近零时，条件概率 q(zt−1|zt)趋近于正态分布，与解码器分布\\nPr(zt−1|zt,ϕt)的形式相匹配，因此需要很多时间步骤。但这会导致采样过程缓慢。我们\\n可能需要让 U-Net模型经历高达 1000个步骤，才能生成高质量的图像。\\n图 18.10:在图像扩散模型中使用的 U-Net。网络目标是预测加入到图像中的噪声。它包括一个\\n编码器，用于降低图像尺寸并增加通道数，以及一个解码器，用于增加图像尺寸并减少通道数。\\n编码器和解码器中的对应层通过连接结合在一起。这些连接由残差块构成，并且包括周期性的\\n全局自注意力机制，使得每个空间位置能与其他位置相互作用。通过将正弦时间嵌入通过浅层\\n神经网络处理并将其结果添加到 U-Net的每个阶段的每个空间位置的通道中，这种单一网络被\\n用于处理所有时间步。\\n18.6.2 提高生成速度\\n损失函数（方程 18.39）兼容的扩散核形式为 q(zt|x) =Norm [√αtx,√1−αtI]。这\\n种损失函数对任何前向过程都有效。\\n在此关系基础上，有一系列相容的过程。这些过程虽然优化标准相同，但前向过程\\n的规则和逆过程中如何利用估计噪声 g[zt,ϕt]预测zt−1的规则各不相同（见图 18.10） 。\\n这一系列中包括 *去噪扩散隐式模型 *，在从x到z1的第一步后不再随机，以及 *\\n加速采样模型 *，后者的前向过程仅在时间步骤的子序列中定义。这使得逆过程可以跳\\n过某些时间步骤，从而显著提高采样效率；当前向过程非随机时，仅需 50个时间步骤\\n就能产生优质样本。这比以往快了不少，但与大多数其他生成模型相比，速度仍较慢。\\n18.6.3 条件生成\\n如果数据有关联标签 c，我们可以利用这些标签来控制生成过程。在生成对抗网络\\n（GANs）中，这有时能够改进生成的结果，我们有理由相信，在扩散模型中也能达到类\\n似的效果；如果我们对图像包含的内容有所了解，去除噪声就更加容易。在扩散模型中\\n进行条件合成的一种方法是 *分类器引导 *。这种方法调整了从 zt到zt−1的去噪步骤，\\n以包含类别信息 c。实际操作中，这意味着在算法 18.2的最终更新步骤中增加了一个额\\n外的项：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 339}, page_content='324 CHAPTER 18. 扩散模型\\n图 18.11:与同一模型兼容的不同扩散过程。 a)重新参数化模型的五个采样轨迹叠加在真实边缘\\n分布上。顶部行表示 Pr(x)，其后的行表示 q(xt)。b)从重新参数化模型生成的样本的直方图与\\n真实密度曲线 Pr(x)并列显示。这个训练过的模型与包括去噪扩散隐式（ DDIM）模型在内的扩\\n散模型系列兼容， DDIM是一种确定性模型，在每一步不添加噪声。 c) DDIM 模型的五条轨迹。\\nd) DDIM 模型的样本直方图。这个模型还与那些跳过某些推理步骤以提高采样速度的加速扩散\\n模型兼容。 e)加速模型的五条轨迹。 f)加速模型的样本直方图。\\nzt−1= ˆzt−1+ασ2\\nt\\nσ2\\nϵ∇ztlogPr(c|zt) +σϵ·ϵ. (18.40)\\n这个新项取决于基于潜变量 zt的分类器Pr(c|zt)的梯度。它将 U-Net的下采样部\\n分的特征映射到类别 c。如同U-Net，这通常贯穿所有时间步，并将时间作为输入。现\\n在，从zt更新到zt−1更有可能得到类别 c。\\n*无分类器引导 *不需要学习一个独立的分类器 Pr(c|zt)，而是将类别信息直接整\\n合到主模型 gθ(zt,c,ϕ c)中。这通常通过类似于时间步骤添加方式，在 U-Net的各层中\\n加入基于 c的嵌入来实现（参见图 18.9） 。这个模型通过在训练期间随机省略类别信息，\\n对条件和非条件目标进行联合训练。因此，它可以在测试时生成无条件或有条件的数据\\n示例，或者两者的任意加权组合。这带来了意外的优势；如果过度强调条件信息，模型\\n会倾向于生成质量非常高但略显典型的示例。这有点类似于生成对抗网络中使用的截断\\n技术（参见图 15.10） 。\\n18.6.4 提高生成质量\\n就像其他生成模型一样，通过对基础模型实施各种技巧和扩展，可以得到最高质量\\n的结果。首先，估计反向过程的方差 σ2\\nt以及均值（即图 18.7中棕色正态分布的宽度）\\n被认为是有益的，这在减少采样步骤时尤其能提高生成质量。其次，可以调整正向过程\\n的噪声计划，使得每步的 βt发生变化，这同样有助于优化结果。\\n第三，为生成高分辨率的图像，采用了扩散模型级联。首个模型生成低分辨率图像\\n（可能受类别信息的引导） 。随后的模型逐步生成更高分辨率的图像，通过调整低分辨率'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 340}, page_content='18.6.实现 325\\n图像的大小并将其及相关类别信息融入到 U-Net的各层实现条件化处理（见图 18.11） 。\\n图 18.12:基于文本提示的级联条件生成。 a)使用一系列 U-Nets的扩散模型生成 64×64分辨率\\n的图像。 b)生成过程基于由语言模型计算得到的句子嵌入。 c)接着生成更高分辨率的 256×256\\n图像，这一过程依赖于较小图像和文本编码。 d)通过重复这个过程生成 1024×1024 分辨率的图\\n像。 e)最终图像序列。据 Saharia等人（ 2022b）改编。\\n综合这些技术可以生成极高质量的图像。图 18.12展示了基于 ImageNet 类别条件\\n化的模型生成的图像示例，该模型能生成极其多样化的类别，这一点尤其令人印象深刻。\\n图18.13则展示了一个训练以根据文本标题条件化的模型生成的图像，这些标题通过类\\n似BERT的语言模型编码，并以类似时间步的方式嵌入模型中（参见图 18.9和18.11） 。\\n结果是非常逼真的图像，与标题高度匹配。由于扩散模型的随机性，它能够根据同一标\\n题生成多个不同的图像。\\n图 18.13:使用分类器引导的条件生成。这里展示了根据不同 ImageNet 类别条件化的图像样本。\\n同一个模型能够生成各种类别的高质量图像样本。改编自 Dhariwal & Nichol （2021） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 341}, page_content='326 CHAPTER 18. 扩散模型\\n18.7总结\\n扩散模型将数据示例通过一系列潜变量映射，这个过程涉及将当前的数据表示与随\\n机噪声反复混合。在进行足够多的步骤后，数据的表示将变得无法与白噪声区分。因为\\n这些步骤较小，每一步的逆去噪过程都可以近似为正态分布，并且可以通过深度学习模\\n型来预测。损失函数建立在证据下界（ ELBO）之上，并最终简化为最小二乘法公式。\\n在图像生成方面， 每一个去噪步骤都采用 U-Net来实施， 因此相较于其他生成模型，\\n其采样速度较慢。为了提升生成速度，可以把扩散模型转换为确定性公式，这样少量的\\n采样步骤就能够取得良好效果。已经提出了几种方法，用以根据类别信息、图像和文本\\n信息来调节生成过程。结合这些方法可以得到令人印象深刻的文本到图像的合成效果。\\n18.8笔记\\n去噪扩散模型最早由 Sohl-Dickstein 等人于2015年提出，随后 Song & Ermon 在\\n2019年基于得分匹配进行了早期相关研究。 Ho等人于2020年生成的图像样本能够与\\nGANs相竞争，引发了对这一领域的广泛兴趣。本章的主要内容，包括最初的公式和参\\n数重新设定，源自他们的工作。 Dhariwal & Nichol 在2021年进一步提升了结果的质量，\\n并首次证明扩散模型在 Fréchet Inception Distance 方面量化优于 GAN模型。截至目前，\\nKarras等人在2022年实现了条件图像合成的最新进展。关于去噪扩散模型的综述可见\\nCroitoru 等人（2022） 、Cao等人（2022） 、Luo（2022）和Yang等人（2022）的研究。\\n图像应用 ：扩散模型在图像领域的应用广泛，包括文本到图像生成、图像到图像的\\n转换任务（如上色、修复、去裁剪和恢复） 、超分辨率、图像编辑、去除对抗性扰动、语\\n义分割和医学成像。在这些应用中，扩散模型有时用作生成过程的先验知识。\\n不同数据类型 ：扩散模型还应用于视频数据的生成、帧预测和插值，以及 3D形状\\n生成。最近，还开发了一种新技术，通过 2D文本到图像扩散模型生成 3D模型。此外，\\n扩散模型也被应用于音频数据的处理。\\n去噪的替代方法 ：虽然本章的扩散模型通过与数据混合噪声逐步去噪，但还有其他\\n非随机退化方法，如遮蔽、变形、模糊和像素化，可以逐步模糊图像，而不必使用噪声。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 341}, page_content='扩散模型也被应用于音频数据的处理。\\n去噪的替代方法 ：虽然本章的扩散模型通过与数据混合噪声逐步去噪，但还有其他\\n非随机退化方法，如遮蔽、变形、模糊和像素化，可以逐步模糊图像，而不必使用噪声。\\n与其他生成模型的比较 ：与其他生成模型相比，扩散模型能够生成更高质量的图像，\\n并且训练简单。它们可视为具有固定编码器和数据大小相同潜空间的分层 VAE的特例。\\n虽然它们是概率模型，但基本形式下只能为数据点的可能性提供下界估计。 Kingma等\\n人（2021）指出，扩散模型的这种下界在测试数据上优于归一化流和自回归模型的精确\\n对数可能性。扩散模型的可能性可以通过转换为普通微分方程或训练基于扩散标准的连\\n续归一化流模型来计算。扩散模型的主要缺点是处理速度慢，且潜空间缺乏语义解释。\\n提高质量 ：为了改进图像质量，提出了众多技术。其中包括第 18.5节所述的网络重\\n新参数化和随后术语的等权重处理（ Ho等人，2020） 。Choi等人（2022）进一步研究了\\n损失函数中不同术语的权重分配。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 342}, page_content='18.8.笔记 327\\nKingma等人（2021）通过学习去噪权重 βt提升了模型的测试对数似然度。另一方\\n面，Nichol & Dhariwal （2021）通过除了均值之外还学习每个时间步的去噪估计方差 σ2，\\n来增强了模型性能。 Bao等人（2022）则展示了在模型训练后如何学习方差。\\nHo等人（2022a）开发了产生极高分辨率图像的级联方法（见图 18.11） 。为防止\\n低分辨率图像的瑕疵扩散到高分辨率，他们引入了噪声条件增强技术，即在每个训练步\\n骤中通过添加噪声来降低低分辨率条件图像的质量。这降低了对低分辨率图像细节的依\\n赖，并且在推理时也采用了这种方法，通过对不同噪声水平进行评估来确定最优噪声水\\n平。\\n提高速度 ：扩散模型的主要缺点之一是其训练和采样耗时长。稳定扩散模型（ Rom-\\nbach等人，2022）通过传统自编码器将原始数据映射到一个较小的潜在空间，然后在这\\n个小空间内执行扩散过程。这种方法的优势在于减少了扩散过程中训练数据的维数，并\\n使得扩散模型能够描述文本、图形等其他数据类型。 Vahdat等人（2021）也采用了类似\\n的方法。\\nSong等人（2021a）证明了一个整体的扩散过程家族（ diffusion process ）与训练目\\n标相兼容。其中大部分过程是非马尔可夫的（ non-Markovian ） ，即扩散步骤不只是依赖\\n前一步的结果。在去噪扩散隐式模型（ DDIM）中，更新过程是确定性的（见图 18.10b） 。\\n该模型能够执行较大的步骤（见图 18.10b） ，而不会产生大的误差，并有效地将其转换\\n为常微分方程（ ODE） ，使轨迹曲率较低，并允许使用高效的数值方法解常微分方程。\\nSong等人（2021c）提出将基础的随机微分方程转换成具有与原过程相同边际分布\\n的概率流常微分方程（ probability flow ODE ） 。Vahdat等人（2021） 、Xiao等人（2022b）\\n和Karras等人（2022）都采用了解常微分方程的技术以加快合成速度。 Karras等人\\n（2022）找到了采样过程中最优的时间离散化方法，并对不同的采样计划进行了评估，从\\n而显著降低了合成所需的步骤数。\\n由于需要多个小扩散步骤来确保后验分布 q(zt−1|zt) 接近高斯分布（见图 18.5） ， 采'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 342}, page_content='而显著降低了合成所需的步骤数。\\n由于需要多个小扩散步骤来确保后验分布 q(zt−1|zt) 接近高斯分布（见图 18.5） ， 采\\n样过程变得缓慢，这也就是解码器中使用高斯分布的合理性。如果使用的模型能够在每\\n个去噪步骤描述更复杂的分布，就可以减少扩散步骤的数量。为此， Xiao等人（2022b）\\n研究了条件 GAN（Generative Adversarial Network ）模型的使用，而 Gao等人（2021）\\n则研究了条件能量基模型（ conditional energy-based model ）的应用。虽然这些模型不\\n能完全描述原始数据分布，但它们足以准确预测更为简单的逆扩散步骤。\\nSalimans 和Ho（2022）将去噪过程中的连续步骤简化为单一步骤以加快合成速度。\\nDockhorn 等人（2022）在扩散过程中引入了动量，这使得轨迹更加平滑，因而更适合进\\n行粗略采样。\\n条件生成 ：Dhariwal 和Nichol（2021）提出了分类器指导（ classifier guidance ）方法，\\n其中分类器在每一步学习识别被合成对象的类别，并将这一信息用于偏向去噪更新以靠\\n近该类别。虽然这种方式效果显著，但单独训练分类器成本高。 Ho和Salimans （2022）\\n提出的无分类器指导（ classifier-free guidance ）通过在训练过程中以一定比例随机丢弃\\n类别信息，同时训练条件和非条件的去噪模型，类似于 dropout技术。这种方法允许调'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 343}, page_content='328 CHAPTER 18. 扩散模型\\n节条件成分和非条件成分的相对重要性，过分强调条件成分可以让模型生成更典型、更\\n逼真的样本。\\n在图像上进行条件化的标准做法是将（调整尺寸的）图像附加到 U-Net的各个层。\\n例如，Ho等人（2022a）在超分辨率的级联生成过程中采用了此方法。 Choi等人（2021）\\n提出了一种方法，在无条件扩散模型中通过匹配潜变量与条件图像的潜变量来实现基于\\n图像的条件化。对于文本的条件化，标准做法是将文本嵌入线性变换至与 U-Net层同样\\n大小，然后以引入时间嵌入的方式加入到模型表示中（参见图 18.9） 。\\n现有扩散模型还可以微调， 通过一个称为控制网络（ control network ）的神经网络结\\n构，使其能够基于边缘图、关节位置、分割、深度图等进行条件化（ Zhang & Agrawala,\\n2023） 。\\n文本到图像 ：在扩散模型出现之前，基于 Transformer 的系统是最先进的文本到图\\n像解决方案（例如 Ramesh 等人，2021） 。GLIDE（Nichol等人，2022）和Dall·E 2\\n（Ramesh等人，2022）都是基于 CLIP模型（Radford 等人，2021）的嵌入条件化，该\\n模型为文本和图像数据生成联合嵌入。 Imagen（Saharia等人，2022b）展示了来自大\\n语言模型的文本嵌入能产生更优结果（见图 18.13） 。这些作者还提出了一个基准测试\\nDrawBench ，用于评估模型在渲染颜色、对象数量、空间关系等方面的能力。 Feng等人\\n（2022）开发了一种中文文本到图像模型。\\n与其他模型的连接 ：本章将扩散模型描述为层次化变分自编码器，这种视角与本书\\n的其他部分紧密相关。然而，扩散模型也与随机微分方程（参考图 18.5中的路径）和\\n得分匹配（ Song & Ermon, 2019, 2020 ）关系密切。 Song等人（2021c）基于随机微分方\\n程提出了一个框架，涵盖了去噪和得分匹配的理论。扩散模型还与规范化流（ Zhang &\\nChen, 2021 ）有紧密联系。 Yang等人（2022）总结了扩散模型与其他生成方法之间的关\\n系。\\n图 18.14:使用文本提示的条件生成。这些图像是在一个级联生成框架下合成的，依赖于由大语'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 343}, page_content='Chen, 2021 ）有紧密联系。 Yang等人（2022）总结了扩散模型与其他生成方法之间的关\\n系。\\n图 18.14:使用文本提示的条件生成。这些图像是在一个级联生成框架下合成的，依赖于由大语\\n言模型编码的文本提示进行条件化。该随机模型能生成多种与文本提示相匹配的图像。模型具\\n有对象计数能力，并能将文本内容融入生成的图像中。改编自 Saharia等人（ 2022b） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 344}, page_content='18.9.习题 329\\n18.9习题\\n问题 18.1证明如果Var[xt−1] = 1并且我们使用更新：\\nxt=p\\n1−βt·xt−1+p\\nβt·ϵt, (18.41)\\n那么Var[xt] = 1，所以方差保持不变。\\n问题 18.2考虑变量：\\nz=a·ϵ1+b·ϵ2, (18.42)\\n其中ϵ1和ϵ2都是从独立的标准正态分布中抽取的，这个分布的平均值为零，方差\\n为单位。证明：\\nE[z] = 0\\nVar[z] =a2+b2, (18.43)\\n因此，我们可以等价地计算 z=√\\na2+b2·ϵ，其中ϵ也是从标准正态分布中抽取的。\\n问题 18.3继续等式 18.5中的过程以显示：\\nz3=p\\n(1−β3)(1−β2)(1−β1)·x+p\\n1−(1−β3)(1−β2)(1−β1)·ϵ′,(18.44)\\n其中ϵ′是从标准正态分布中抽取的。\\n问题 18.4证明关系：\\nNorm [Aw,B]or Norm\\x02\\n(ATB−1A)−1ATB−1v,(ATB−1A)−1\\x03\\n. (18.45)\\n问题 18.5证明关系：\\nNorm [x,a]Norm [x,b]∝Norm x\\x02\\n(A−1+B−1)−1(A−1a+B−1b),(A−1+B−1)−1\\x03\\n.(18.46)\\n问题 18.6导出公式 18.15。\\n问题 18.7从等式18.25的第二行推导出第三行。\\n问题 18.8两个正态分布在 D维空间中的 KL散度，均值分别为 a和b，协方差矩\\n阵分别为 A和B，其给出为：\\nDKL[Norm [w,A]∥Norm [w,B ]] =1\\n2\\x12\\ntr[B−1A]−d+ (a−b)TB−1(a−b) +log|B|\\n|A|\\x13\\n.\\n(18.47)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 345}, page_content='330 CHAPTER 18. 扩散模型\\n将等式18.27的定义代入这个表达式，并显示参数 ϕ依赖的唯一项是等式 18.28的\\n第一项。\\nProblem 18.9 如果αt=Qt\\ns=1(1−βs),则:\\nrαt\\nαt−1=p\\n1−βt. (18.48)\\n问题 18.10如果αt=Qt\\ns=1(1−βs),则:\\n(1−αt−1)(1−βt) +βt\\n(1−αt)√1−βt=1√1−βt. (18.49)\\n问题 18.11证明等式 18.37。\\n问题 18.12无分类器指导允许我们创建给定类别的更加典型的“标准”图像。当我\\n们描述Transformer 解码器、生成对抗网络和 GLOW算法时，我们也讨论了减少变异\\n量并产生更加典型输出的方法。这些方法是什么？你认为我们应该以这种方式限制生成\\n模型的输出吗？'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 346}, page_content='Chapter 19\\n深度强化学习\\n强化学习（ RL）是一个序贯决策框架，智能体在此框架中通过在环境内执行动作来\\n学习，旨在最大化获得的奖励。例如， RL算法可以控制视频游戏中角色（智能体）的\\n移动（动作） ，以最大化分数（奖励） 。在机器人领域， RL算法能控制机器人（智能体）\\n在现实世界（环境）内的活动，执行特定任务以赚取奖励。在金融领域， RL算法或许\\n会控制一个虚拟交易员（智能体） ，在交易平台（环境）上进行资产买卖（动作） ，以最\\n大化利润（奖励） 。\\n以学习下棋为例，游戏结束时，根据智能体的胜、负或平，奖励分别为 +1、-1或\\n0，而在游戏的其他时间步骤中奖励为 0。这体现了 RL的挑战。首先，奖励是稀疏的，\\n即只有在完成整场游戏后才能获得反馈。其次，奖励与导致其发生的动作之间存在时间\\n上的延迟，如在获得胜利的三十步之前可能就已获得决定性优势，这要求将奖励与关键\\n动作关联起来，这种情况称为时间信用分配问题。第三，环境具有随机性，对手的每次\\n移动不总是相同的，这使得判断一个动作是真正有效还是仅仅依赖运气变得困难。最后，\\n智能体需要在探索环境（例如，尝试新的开局方式）与利用已有知识（例如，使用之前\\n成功的开局）之间做出平衡，这种平衡称为探索与利用的权衡。\\n强化学习是一个广泛的框架，不必须依赖深度学习。然而，在实际应用中，先进的\\n系统通常会使用深度网络，这些网络对环境（如视频游戏画面、机器人传感器、金融时\\n间序列或棋盘）进行编码，并将其直接或间接映射到下一步动作（图 1.13） 。\\n19.1马尔可夫决策过程、回报与策略\\n强化学习将环境观察转化为动作，其目标是最大化与所获奖励相关的数值。通常，\\n我们通过学习一个策略来最大化马尔科夫决策过程中的预期回报。本节将解释这些术\\n语。\\n331'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 347}, page_content='332 CHAPTER 19. 深度强化学习\\n19.1.1 马尔科夫过程\\n马尔科夫过程是一种假设，认为世界总是存在于一系列可能的状态中。马尔科夫性\\n指的是，一个状态的出现概率只与其前一个状态有关，而与更早的状态无关。状态之间\\n的转变通过转移概率 Pr(st+1|st)描述，即从当前状态 st转移到下一个状态 st+1的概率，\\n这里的t表示时间步。因此，马尔科夫过程是不断演化的，它生成一系列状态 s1,s2,s3\\n...（图19.1） 。\\n图 19.1:马尔可夫过程。马尔可夫过程由一组状态和定义从当前状态 st转移到状态 st+1的概\\n率的转移概率 P r(st+1|st)组成。 a)企鹅可以在冰面上访问 16个不同的位置（状态） 。 b)冰面\\n很滑，所以企鹅每次都有相同的概率移动到任一相邻状态。例如，在位置 6，它分别有 25%的\\n概率移动到状态 2、5、7和 10。从这个过程中得到的轨迹 τ={s1, s2, s3, . . .}是一个状态序列\\n19.1.2 马尔可夫奖励过程\\n*马尔科夫奖励过程 *包含一个分布 Pr(rt+1|st)，用以确定在状态 st下，下\\n一时间步骤可能获得的奖励 rt+1。这构建了一个由状态和其对应奖励组成的序列\\nr1,s1,r2,s2,r3,s3,r4...（图19.2） 。\\n图 19.2:马尔可夫奖励过程。它把一个奖励分布 P r(rt+1|st)与每个状态 st相关联。 a)这里，奖\\n励是确定的：企鹅如果落在鱼上获得 +1奖励，否则为 0。轨迹 τ现在是状态和奖励交替的序列\\ns1, r2, s2, r3, s3, r4. . .，在八步后终止。序列的总回报 Gt是折扣后未来奖励的总和，此处的折扣\\n因子为 γ= 0.9。b-c)随着企鹅沿轨迹前进逐渐靠近奖励，其回报逐步增加。\\n在马尔科夫奖励过程中，还引入了一个 *折扣因子 *γ∈(0,1)来计算在时间点 t\\n的*回报*Gt：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 348}, page_content='19.1.马尔可夫决策过程、回报与策略 333\\nGt=∞X\\nk=0γkrt+k+1. (19.1)\\n回报是对未来奖励进行累积折扣计算后的总和，用于评估沿此轨迹的未来收益。折\\n扣因子小于一意味着越近期的奖励比远期的奖励更有价值。\\n19.1.3 马尔科夫决策过程\\n*马尔科夫决策过程 *（MDP）为每一个时间步增加了一组可能的 *动作*。\\n这些动作at会改变转移概率，现在表示为 Pr(st+1|st,at)。奖励同样可能受到动作\\n的影响，现表示为 Pr(rt+1|st,at)。MDP描述了一个由状态、动作及奖励组成的序列\\ns1,a1,r2,s2,a2,r3,s3,a3,r4...（图19.3） 。进行这些动作的实体称为 *智能体*。\\n图 19.3:马尔可夫决策过程。 a)智能体（企鹅）可以在每个状态中选择一组动作之一执行。动\\n作会影响到转移到下一状态的概率及获得奖励的可能性。 b)在这里，四个动作分别对应上、右、\\n下、左移动。 c)在任何状态下（如状态 6） ，动作会改变到下一个状态的转移概率。企鹅有 50%\\n的概率向预定方向移动，但由于冰面滑，它也可能以相同的概率滑到其他相邻位置。因此，在面\\n板 (a)中，实际采取的动作（灰色箭头）不一定与轨迹（橙色线）一致。这里的动作并不影响奖\\n励，因此 P r(rt+1|st, at) =P r(rt+1|st)。MDP的轨迹 τ是由状态 st、动作 at和奖励 rt+1交\\n替构成的序列。请注意，在此，企鹅在离开有鱼的状态时获得奖励，即通过鱼的格子即可获得奖\\n励，无论是故意还是偶然。\\n19.1.4 部分可观测马尔可夫决策过程\\n在*部分可观测马尔科夫决策过程 *（POMDP）中，状态并不直接显现给\\n智能体（图 19.4） 。智能体得到的是观测值 ot，这个观测值根据 Pr(ot|st)的概\\n率分布得出。因此， POMDP 创造了一个由状态、观测、动作和奖励组成的序列\\ns1,o1,a1,r2,s2,o2,a2,r3,s3,o3,a3,r4...。一般而言，每个观测值与某些状态更为匹配，但\\n不足以精确确定具体的状态。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 349}, page_content='334 CHAPTER 19. 深度强化学习\\n图 19.4:部分可观测马尔可夫决策过程（ POMDP ） 。在 POMDP 中，智能体无法完全知晓状态。\\n例如，企鹅在状态三时只能看到虚线框内的区域，这与其在状态九的视角无异。在前者中，向右\\n移动将导致掉入冰洞（奖励为 -2） ，而在后者中，则可获得鱼（奖励为 +3） 。\\n19.1.5 策略\\n*策略*（图19.5）是指导智能体在各个状态下采取何种行动的规则。策略可以是\\n随机的，即为每个状态定义一系列动作的概率分布；也可以是确定性的，即智能体在特\\n定状态下总是执行相同的动作。随机策略 π(a|s)对于状态s下的每个可能动作提供一\\n个概率分布，用于抽样决定新的动作。确定性策略 π(a|s)对于状态s下选定的动作 a\\n返回一，对其他动作返回零。 *静态*策略仅与当前状态相关，而 *非静态*策略还考\\n虑了时间步的变化。\\n图 19.5:策略。 a)确定性策略在每个状态下总是采取相同的动作（箭头指示） 。虽然有些策略优\\n于其他策略，但这种策略能够基本引导企鹅从左上角向右下角移动以获取奖励。 b)此策略更具\\n随机性。 c)随机策略为每个状态设定一个动作的概率分布（概率由箭头大小表示） ，这有助于智\\n能体更全面地探索状态，这在部分可观测的马尔可夫决策过程中可能是必要的以达到最优表现。\\n环境与智能体之间形成一个交互循环 （图 19.6） 。 智能体接收上一时间步的状态 st和\\n奖励rt， 并依此来调整策略 π(a|st)， 选择下一步的动作 at。 随后， 环境根据 Pr(st+1|st,at)\\n确定下一个状态，并根据 Pr(rt+1|st,at)确定奖励。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 350}, page_content='19.2.预期回报 335\\n图 19.6:强化学习循环。智能体在时间点 t根据策略 π[at|st]和当前状态 st执行动作 at，引发\\n新的状态 st+1（通过状态转移函数）和奖励 rt+1（通过奖励函数）的产生。这两者随后被反馈\\n给智能体，促使其选择下一个动作。\\n19.2预期回报\\n上一节我们介绍了马尔科夫决策过程，以及智能体如何根据策略进行动作。我们的\\n目标是找到一个最大化预期回报的策略。在本节中，我们将对这一概念进行数学上的精\\n确定义。为了做到这点，我们给每个状态 st和每对状态 -动作{st,at}赋予一个 *数值\\n*。\\n19.2.1 状态与动作价值\\n回报Gt取决于状态 st和策略π(a|s)。智能体将从这个状态出发，经历一系列状\\n态的变迁，执行动作并收获奖励。由于策略 π(a|st)、状态转移 Pr(st+1|st,at)以及奖励\\nPr(rt+1|st,at)都具有随机性，即使是从同一起点出发，智能体经历的序列也会每次不\\n同。\\n在特定策略 π下，通过考虑预期回报 v(st|π)，我们可以评估一个状态的价值。这\\n是从该状态开始，遵循策略所得到的平均回报，称为 *状态价值 *或*状态价值函数 *\\n（图19.7a） ：\\nv(st|π) =E[Gt|st,π]. (19.2)\\n状态价值反映了从某一状态出发，长期遵循特定策略所能期待的平均奖励。在后续\\n状态转移可能快速获得较大奖励的情况下，这一价值尤为显著（假定折扣因子 γ小于\\n一） 。\\n同样，*动作价值 *或*状态-动作价值函数 *q(st,at|π)表示在状态 st中执行动\\n作at的预期回报（图 19.7b） ：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 351}, page_content='336 CHAPTER 19. 深度强化学习\\n图 19.7:状态和动作价值。 a)状态 st的价值 v(st|π)（每个位置的数值）代表在策略 π（灰色箭\\n头）下，从该状态出发可获得的预期回报，即多条轨迹的折扣奖励平均值。这里，靠鱼越近的状\\n态价值越高。 b)在状态 st中采取动作 at的价值 q(st, at, π)（每个位置 /状态对应的四个数值分\\n别对应四种动作）反映了采取该动作所期望的回报。这个价值会随着接近鱼而增加，并且朝鱼的\\n方向的动作价值更高。 c)如果我们了解某状态的动作价值，策略就可以调整为选择这些价值中\\n的最大者（面板 b的红色数字表示） 。\\nq(st,at|π) =E[Gt|st,at,π]. (19.3)\\n动作价值显示了从一个状态出发，采取某动作并遵循特定策略之后，长期所能获取\\n的平均奖励。强化学习算法利用这个指标将当前动作与未来的奖励相连接，从而解决时\\n间信用分配问题。\\n19.2.2 最优策略\\n我们追求的策略目标是最大化预期回报。在 MDP中（POMDP 则不适用） ，总能\\n找到一个既确定性又静态的策略，以最大化所有状态的价值。如果我们掌握了这一最优\\n策略，我们便能获得最优状态价值函数 v∗(st)：\\nv∗(st) =max\\nπE[Gt|st,π]. (19.4)\\n同理，最优状态 -动作价值函数可以在最优策略下得到：\\nq∗(st,at) =max\\nπE[Gt|st,at,π]. (19.5)\\n进一步地，如果我们知道了最优动作价值 q∗(st,at)，就可以通过选取最高价值的动\\n作at来确定最优策略（图 19.7c） ：\\nπ(at|st) =argmax atq∗(st,at). (19.6)\\n事实上，有些强化学习算法就是基于动作价值和策略的交替估计来实现的（参见第\\n19.3节） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 352}, page_content='19.2.预期回报 337\\n19.2.3 贝尔曼方程\\n对于任何策略，我们可能无法准确知道状态价值 v(st)或动作价值 q(st,at)。但是，\\n这些价值需要相互协调一致，我们可以容易地确定它们之间的关系。状态价值 v(st)由\\n动作价值q(st,at)的加权和构成，权重由策略 π(at|st)决定动作的概率（图 19.8） ：\\nv(st) =X\\natπ(at|st)q(st,at). (19.7)\\n图 19.8:状态值与动作值的关系。状态六的值 v[st= 6]是其动作值 q[st= 6, at]的加权和，权\\n重是采取各动作的策略概率 π[at|st= 6]。\\n同理，动作的价值等于执行该动作所获得的即时奖励 rt+1=r(st,at)，加上下一状\\n态st+1的价值v(st+1)经过折扣γ后的结果（图 19.9） 。因为状态 st+1的确定不是一成\\n不变的，我们需要根据转移概率 Pr(st+1|st,at)来加权v(st+1)：\\nq(st,at) =r(st,at) +γX\\nst+1Pr(st+1|st,at)v(st+1). (19.8)\\n将方程19.8代入方程 19.7，我们可以得到时间 t和t+ 1之间状态价值的关系：\\nv(st) =X\\natπ(at|st)\"\\nr(st,at) +γX\\nst+1Pr(st+1|st,at)v(st+1)#\\n. (19.9)\\n同样，将方程 19.7代入方程 19.8，我们可以得到时间 t和t+ 1之间动作价值的关\\n系：\\nq(st,at) =r(st,at) +γX\\nst+1Pr(st+1|st,at)\"X\\nat+1π(at+1|st+1)q(st+1,at+1)#\\n.(19.10)\\n这两个关系构成了 *贝尔曼方程 *，它们是许多强化学习方法的基础。简言之，它\\n们要求状态价值和动作价值之间保持一致性。因此，当我们更新某个状态或动作价值的\\n估计时，会引起其他所有价值的连锁调整。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 353}, page_content='338 CHAPTER 19. 深度强化学习\\n图 19.9:动作值与状态值的关系。在状态六采取动作二的价值 q[st= 6, at= 2]等于采该动作获\\n得的奖励 r[st= 6, at= 2]加上后继状态的折扣价值 v[st+ 1]的加权和，其中权重为转移概率\\nP r(st+1|st= 6, at= 2)。通过贝尔曼方程，这种关系与图 19.8的状态值和动作值关系相连，形\\n成了当前与下一个状态值和动作值之间的联系。\\n19.3表格式强化学习\\n表格型强化学习算法，也就是不依赖函数逼近技术的算法，分为基于模型和无模型\\n两种方法。基于模型的方法利用 MDP结构来明确寻找最佳策略，通过分析转移矩阵\\nPr(st+1|st,at)和奖励结构 r[s, a]实现。若这些信息已知，问题则转化为可通过动态规划\\n解决的直接优化问题。如果未知，就需要先基于观测到的 MDP轨迹进行估计。\\n无模型方法则不依赖于 MDP的具体模型，分为两种： 1.值估计方法，旨在估计最\\n优状态-动作价值函数，然后为每个状态指定最大价值动作的策略；\\n2.策略估计方法，通过梯度下降直接估计最优策略，无需经过模型或价值的估计阶\\n段。\\n在这两个方法系列中，蒙特卡洛方法通过模拟多个给定策略的 MDP轨迹来积累信\\n息，进而优化策略。然而，在策略更新前模拟众多轨迹有时既不可行也不实际。时序差\\n分（TD）方法允许在智能体遍历 MDP过程中实时更新策略。\\n接下来简述动态规划、蒙特卡洛值估计和 TD值估计方法。第 19.4节将介绍深度\\n网络如何用于 TD值估计方法，而第 19.5节继续讨论策略估计。\\n19.3.1 动态规划\\n动态规划算法基于完整了解转移和奖励结构的前提。与大多数强化学习算法不同，\\n后者依靠观测智能体与环境的交互来间接获得这些数据。\\n状态价值v(s)通常初始化为零，而确定性策略 π(a|s)则通过为每个状态随机选择\\n一个动作来初始化。接下来，算法交替执行对当前策略的状态价值计算（策略评估）和\\n策略的优化（策略改进） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 354}, page_content='19.3.表格式强化学习 339\\n策略评估： 遍历各状态 st，根据贝尔曼方程更新它们的价值：\\nv(st)←X\\natπ(at|st)\"\\nr(st,at) +γX\\nst+1Pr(st+1|st,at)v(st+1)#\\n,(19.11)\\n其中st+1是后继状态， Pr(st+1|st,at)表示状态转移概率。更新使 v(st)与后继状态\\nst+1的价值保持一致，这个过程称为自举。\\n策略改进： 更新策略时，我们贪心地选择能使每个状态价值最大化的动作：\\nπ(at|st)←argmax at\"\\nr(st,at) +γX\\nst+1Pr(st+1|st,at)v(st+1)#\\n. (19.12)\\n根据策略改进定理，这种方法能够保证策略的持续优化。这两个步骤持续迭代，直\\n到策略稳定（图 19.10） 。\\n图 19.10:动态规划。 a)最初，状态值设为零，策略随机选定（箭头表示） 。 b)状态值根据其邻\\n近值进行更新（经过两次迭代后的方程 19.11） 。策略调整为指向价值最高的状态（方程 19.12） 。\\nc)经过多次迭代，算法逐步优化至最佳策略，此时企鹅会尽量避开洞并寻找鱼。\\n这种方法有多种变体。在策略迭代中，会先将策略评估迭代至收敛，然后再进行策\\n略改进。值的更新可以在每次扫描时就地或同步进行。值迭代中，策略评估只进行一次\\n扫描就直接进入策略改进。异步动态规划算法无需每步都系统地遍历所有状态，而是可\\n以任意顺序地就地更新部分状态。\\n19.3.2 蒙特卡洛方法\\n与动态规划算法不同， 蒙特卡洛方法不需要预先知道 MDP的转移概率和奖励结构。\\n它们通过重复采样 MDP的轨迹并观察奖励来积累经验。这些方法在计算行动价值（基\\n于累积的经验）和更新策略（基于行动价值）之间交替进行。\\n为了估计行动价值 q(s,a)，会运行一系列轮次。每个轮次从给定状态和行为开始，\\n随后按照当前策略执行，产生一连串的行为、状态和收益（图 19.11a） 。给定状态 -行为\\n对的行动价值，在当前策略下，通过平均每次观察到此对后获得的实证回报来估计（图\\n19.11b） 。然后，通过选择每个状态下价值最大的行为来更新策略（图 19.11c） ：\\nπ(a|s)←argmax aq(s,a). (19.13)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 355}, page_content='340 CHAPTER 19. 深度强化学习\\n图 19.11:蒙特卡洛方法。 a)初始时，策略（箭头）是随机设置的。通过反复模拟 MDP，记录下\\n各次模拟的轨迹（橙色和棕色路径表示两个轨迹） 。 b)通过对这些轨迹观测到的回报进行平均，\\n经验性地估计动作价值。这里，所有动作价值起初都是零，后根据观测到的动作进行更新。 c)接\\n下来可以根据获得最优（或较优）奖励的动作来更新策略。\\n这是一种在策略学习方法；使用当前最优策略来指导智能体穿行于环境中。这个策\\n略是基于每个状态观察到的行动价值确定的，但是未使用的行为的价值是无法估计的，\\n同时没有机制促使算法去探索这些未知行为。一种解决方法是采用探索初始法。在此方\\n法中，每种可能的状态 -行为对都会启动一个轮次，确保每种组合至少被观察一次。然而，\\n如果状态数量庞大或起始点无法控制，则这种方法不切实际。另一种方法是采用 ϵ-贪婪\\n策略，即以 ϵ的概率采取随机行动，而将剩余的概率分配给最优行动。 ϵ的选择实现了\\n利用与探索之间的权衡。在这种情况下，基于 ϵ-贪婪策略的在策略学习方法会寻找最佳\\n策略，但这通常不是最佳的整体策略。\\n相反，在离策略学习方法中，通过不同的行为策略 π′生成的轮次来学习最优策略\\nπ（目标策略） 。通常目标策略是确定性的，而行为策略是随机的（例如， ϵ-贪婪策略） 。\\n因此，行为策略能够探索环境，而学到的目标策略则保持高效。某些离策略方法明确采\\n用重要性采样（第 17.8.1节）来估计在策略 π下的行动价值，使用来自 π′的样本。其\\n他方法，如 Q学习（将在下一节描述） ，则基于最优行动来估计价值，即便实际选择的\\n行动可能并非如此。\\n19.3.3 时序差分学习\\n动态规划方法采用自举方法来更新数值，确保它们在当前策略下自洽。蒙特卡洛方\\n法通过对 MDP的采样来获得信息。时序差异 (Temporal Difference, TD) 方法融合了自\\n举和采样。不过，与蒙特卡洛方法不同的是， TD方法在智能体遍历 MDP状态的过程\\n中就更新数值和策略，而不是之后。\\n*SARSA* （状态-行动-奖励-状态-行动）是一种在策略 (on-policy) 算法，其更新公\\n式为：\\nq(st,at)←q(st,at) +α[r(st+1,at) +γq(st+1,at+1)−q(st,at)], (19.14)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 355}, page_content='式为：\\nq(st,at)←q(st,at) +α[r(st+1,at) +γq(st+1,at+1)−q(st,at)], (19.14)\\n其中，α∈R+表示学习率。方括号内的项称为 *TD误差*，用于衡量经过单步操\\n作后，估计的行动价值 q(st,at)与其后的估计值 r(st,at) +γq(st+1,at+1)之间的一致性。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 356}, page_content='19.4.拟合 Q-LEARNING 341\\n相对而言， *Q-学习*是一种离策略 (off-policy) 算法，其更新公式如下（图 19.12） ：\\nq(st,at)←q(st,at) +αh\\nr(st,at) +γmax\\na[q(st+1,a)]−q(st,at)i\\n, (19.15)\\n图 19.12: Q-learning ：a)智能体在状态 st处开始，并按策略采取动作 at=2。它未在冰面上滑\\n倒，并向下移动，在离开原始状态时获得奖励 r[st,at]=0 。b)找到新状态下的最大动作价值（此\\n处为 0.43） 。 c)基于对后续状态的最大动作价值的当前估计、奖励、折现因子 γ= 0.9和学习率\\nα= 0.1，原始状态的动作 2的价值被更新为 1.12。这导致原始状态的最高动作价值发生变化，\\n因而策略也随之改变。\\n其中，每一步的行动选择是基于不同的行为策略 π′来确定的。\\n在这两种情况下， 策略通过在每个状态下取行动价值的最大值来更新（方程 19.13） 。\\n可以证明，这些更新是收敛映射（参见方程 16.20） ；只要每个状态 -行动对被访问无限\\n次，行动价值就会最终收敛。\\n19.4拟合 Q-learning\\n上文描述的表格式 Monte Carlo 和TD (时序差分 )算法反复遍历整个马尔科夫决策\\n过程(MDP)并更新动作价值。但是，只有当状态 -动作空间较小时，这种方法才是可行\\n的。遗憾的是，这种情况并不常见；即便是在棋盘这样的限制环境中，也存在超过 1040\\n个可能的动作价值。\\n在拟合Q-学习中，法定状态的离散表示 q(st,at)被替换为机器学习模型 q(st,at;θ)，\\n现在状态由向量 st表示，而不仅仅是一个索引。接着我们定义了一个基于相邻动作价\\n值一致性的最小二乘法损失（类似于 Q-学习中的做法，见方程 19.15） ：\\nL(ϕ) =h\\nr(st,at) +γmax\\naq(st+1,a;ϕ)−q(st,at;ϕ)i2\\n, (19.16)\\n这进而引导了以下更新公式：\\nϕ←ϕ+αh\\nr(st,at) +γ·max\\na[q(st+1,a,ϕ )]−q(st,at,ϕ)i∂q(st,at,ϕ)\\n∂ϕ(19.17)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 357}, page_content='342 CHAPTER 19. 深度强化学习\\n拟合Q-学习与Q-学习的区别在于它不再保证收敛性。参数的改变可能会同时影响\\n目标r(st,at) +γmax aq(st+1,at+1;ϕ)（最大值可能发生变化）和预测 q(st,at;ϕ)，这在\\n理论和实践上都被证明会对收敛性产生不利影响。\\n19.4.1 深度 Q-网络在 A T ARI 游戏中的应用\\n深度网络非常适合于从高维状态空间进行预测，因此在拟合 Q-学习中成为模型的\\n自然选择。理论上，它们能够同时处理状态和动作作为输入以预测值，但实践中，网络\\n只接收状态作为输入，并同时预测各个动作的值。\\n图 19.13:阿塔里基准。阿塔里基准包含了 49款阿塔里 2600游戏，如突破、乒乓及多种射击、\\n平台等类型的游戏。 a-d)单屏幕游戏的状态无法仅通过一个画面完全确定，因为物体的速度信\\n息不可见。因此，通常用几个连续帧（此处为四帧）来表达状态。 e)通过操纵杆模拟用户的动\\n作输入。 f)共有十八种动作，对应八个方向的移动或停止，并且对这九种状态，按钮可按下或不\\n按。\\nDeep Q-Network 是一个突破性的强化学习架构，它利用深度网络学会了玩 ATARI\\n2600游戏。观测数据包括 220×160 像素的图像，每个像素拥有 128种可能的颜色（见\\n图19.13） 。这些图像被重塑为 84×84像素，并且只保留了亮度值。不幸的是，单一帧\\n图像无法展现完整的状态。例如，游戏中物体的速度未知。为解决这个问题，网络在每\\n个时间步骤摄取最后四帧图像，组成 st。网络通过三个卷积层及一个全连接层处理这些\\n帧，以预测每个动作的价值（见图 19.14） 。\\n对标准训练过程进行了数项修改。首先，根据游戏得分驱动的奖励被限制在 −1到\\n+1之间，这种做法旨在平衡不同游戏间得分的巨大差异，并允许使用统一的学习率。其\\n次，系统采用了经验回放机制。不是仅基于当前步骤的 <s t,at,rt+1,st+1>元组或最近\\nI个元组的批处理来更新网络，而是将所有近期的元组都保存在一个缓冲区内。这个缓\\n冲区被随机采样以在每一步生成一个批量，这种方法使得数据样本被多次重用，并降低\\n了批次中样本间因相邻帧的相似性而产生的相关性。\\n最终，通过固定目标参数到 ϕ−值并定期更新，解决了拟合 Q-网络中的收敛问题，\\n给出了以下更新公式：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 358}, page_content='19.4.拟合 Q-LEARNING 343\\n图 19.14:深度 Q-网络架构。输入 st为阿塔里游戏的四帧连续画面，每帧调整至 84×84像素\\n并转为灰度图。这些帧作为四通道输入，先经过 8×8卷积处理（步长为 4） ，然后是 4×4卷积\\n（步长为 2） ，最后通过两个全连接层。最终输出为此状态下 18个动作的动作价值 q[st, at]预测。\\nϕ←ϕ+αh\\nr(st,at) +γ·max\\na[q(st+1,a,ϕ )]−q(st,at,ϕ)i∂q(st,at,ϕ)\\n∂ϕ(19.18)\\n现在网络不再追逐不断变化的目标，从而减少了振荡的倾向。\\n利用这些和其他启发式方法，结合 ϵ-贪婪策略， Deep Q-Networks 在49个游戏的\\n集合上达到了与专业游戏测试者相媲美的水平，每个游戏都使用单独训练的同一网络。\\n值得注意的是，训练过程非常耗费数据，学习每款游戏约需要 38天的完整体验。在某\\n些游戏中，该算法的性能超越了人类水平。而在如“ Montezuma’s Revenge ”这样的游\\n戏中，进展几乎寥寥无几，因为该游戏的奖励稀疏，且包含多个外观差异显著的屏幕。\\n19.4.2 双 Q-学习与双深度 Q-网络\\nQ-学习的一个潜在问题是，在进行更新时对动作执行最大化操作：\\nq(st,at)←q(st,at) +αh\\nr(st,at) +γmax\\na[q(st+1,a)]−q(st,at)i\\n(19.19)\\n这导致估计的状态价值 q(st,at)出现系统性偏差。假设两个动作提供相同的平均奖\\n励，但一个动作的奖励是随机的，而另一个是确定性的。随机奖励在约一半的时间里会\\n超过平均值并被最大化操作选中，从而导致对应的动作价值 q(st,at)被过高估计。网络\\n输出q(st,at;ϕ)的随机误差或 q-函数的随机初始化也可能导致类似的问题。\\n这个问题的核心在于同一个网络同时负责选择目标（通过最大化操作）和更新值。\\n双重Q-学习通过同时训练两个模型 q1(st,at,ϕ1)和q2(st,at,ϕ2)来解决这一挑战：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 359}, page_content='344 CHAPTER 19. 深度强化学习\\nq1(st,at)←q1(st,at) +α[r(st,at) +γ·q2(st+1,argmax a[q1(st+1,a,ϕ 1)])−q1(st,at)]\\nq2(st,at)←q2(st,at) +α[r(st,at) +γ·q1(st+1,argmax a[q2(st+1,a,ϕ 2)])−q2(st,at)]\\n(19.20)\\n如此一来，目标的选择与目标本身被分开，有助于避免这些偏见。在实际应用中，\\n新的元组< s,a,r,s′>会被随机分配到其中一个模型进行更新，这种方法被称为双重\\nQ-学习。双重深度 Q-网络（Double DQNs ）利用深度网络 q(st,at;ϕ1)和q(st,at;ϕ2)来\\n估计动作价值，更新过程变为：\\nϕ1←ϕ1+α[r(st,at) +γ·q(st+1,argmaxa[q(st+1,a,ϕ 1)],ϕ2)−q(st,at,ϕ1)]∂q(st,at,ϕ1)\\n∂ϕ1\\nϕ2←ϕ2+α[r(st,at) +γ·q(st+1,argmaxa[q(st+1,a,ϕ 2)],ϕ1)−q(st,at,ϕ2)]∂q(st,at,ϕ2)\\n∂ϕ2\\n(19.21)\\n19.5策略梯度方法\\nQ-学习首先估计动作价值，然后利用这些价值来更新策略。与之相反，策略基方法\\n直接学习一个随机策略 π(at|st,θ)。这是一个带有可训练参数 θ的函数，能将状态 st映\\n射到动作at的分布Pr(at|st)上，我们可以从这个分布中进行抽样。在 MDPs中，总存\\n在一个最优的确定性策略。但是，采用随机策略有三个理由：\\n1.随机策略有助于自然探索空间；我们不需要在每个时间步采取最优动作。 2.当我\\n们调整随机策略时，损失函数会平滑变化。这意味着我们可以使用梯度下降法，即使奖\\n励是离散的。这与在离散分类问题中使用最大似然估计类似。模型参数的变化使得真实\\n类别变得更有可能，从而使损失平滑变化。 3. MDP 的假设通常是不准确的；我们通常\\n不具有对状态的完全了解。例如，考虑一个代理只能观察到其附近位置的导航环境（如\\n图19.4） 。如果两个位置外观相同，但附近的奖励结构不同，随机策略就能允许采取不\\n同的行动，直至解决这种歧义。\\n19.5.1 梯度更新推导'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 359}, page_content='图19.4） 。如果两个位置外观相同，但附近的奖励结构不同，随机策略就能允许采取不\\n同的行动，直至解决这种歧义。\\n19.5.1 梯度更新推导\\n考虑通过马尔科夫决策过程 (MDP)的一条轨迹 τ= [s1,a1,s2,a2,...,s T,aT]。这条\\n轨迹的概率 Pr(τ|θ)取决于状态演化函数 Pr(st+1|st,at)和当前的随机策略 π(at|st,θ)：\\nPr(τ|θ) =Pr(s1)TY\\nt=1π(at|st,θ)Pr(st+1|st,at). (19.22)\\n策略梯度算法旨在最大化许多此类轨迹上的期望回报 r(τ)：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 360}, page_content='19.5.策略梯度方法 345\\nθ=argmax θEτ[r(τ)] =argmax θ\\x14Z\\nPr(τ|θ)r(τ)dτ\\x15\\n, (19.23)\\n其中回报是沿轨迹获取的所有奖励之和。\\n为了最大化这个量，我们采用梯度上升法更新：\\nθ←θ+α·∂\\n∂θZ\\nPr(τ|θ)r(τ)dτ=θ+α·Z∂Pr(τ|θ)\\n∂θr(τ)dτ. (19.24)\\n我们希望通过经验观察到的轨迹的总和来近似这个积分。这些轨迹来源于分布\\nPr(τ|θ)，因此为了进展，我们用这个分布乘除被积函数：\\n图 19.15:策略梯度。同一策略下的五次模拟（亮度高表示奖励大） 。轨迹 1、2和 3持续获得高\\n奖励，但这种轨迹在当前策略下已频繁出现，故无需变动。相反，轨迹 4奖励较低，策略需调整\\n以避免生成类似轨迹。轨迹 5奖励高且不常见，根据方程 19.25，它将引起策略的最大改变。\\nθ←θ+α·Z∂Pr(τ|θ)\\n∂θr(τ)dτ\\n=θ+α·Z\\nPr(τ|θ)1\\nPr(τ|θ)∂Pr(τ|θ)\\n∂θr(τ)dτ\\n≈θ+α·1\\nIIX\\ni=11\\nPr(τi|θ)∂Pr(τi|θ)\\n∂θr(τi). (19.25)\\n这个方程简单来说，就是通过增加观察到的轨迹 τi的可能性Pr(τi|θ)来调整参数，\\n与该轨迹的奖励 r(τi)成比例。但同时，它通过首次观察到该轨迹的概率进行归一化，以\\n补偿某些轨迹更频繁观察到的事实。如果一个常见且高奖励的轨迹已存在，则无需大幅\\n改变。最大的更新将源自那些不常见但能带来大量奖励的轨迹。\\n我们可以使用“似然比恒等式”简化这个表达式：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 361}, page_content='346 CHAPTER 19. 深度强化学习\\n∂log[f(z)]\\n∂z=1\\nf(z)∂f(z)\\n∂z, (19.26)\\n产生如下更新：\\nθ←θ+α·1\\nIIX\\ni=1∂log[Pr(τi|θ)]\\n∂θr[τi]. (19.27)\\n轨迹的对数概率 log[Pr(τ|θ)]可以表示为：\\nlog[Pr(τ|θ)] =log[Pr(s1)]TY\\nt=1π(at|st,θ)Pr(st+1|st,at)\\n=log[Pr(s1)] +TX\\nt=1log[π(at|st,θ)] +TX\\nt=1log[Pr(st+1|st,at)],(19.28)\\n由于只有中间项依赖于 θ，我们可以根据方程 19.27重新写更新式为：\\nθ←θ+α·1\\nIIX\\ni=1TX\\nt=1∂log[π(at|sit,θ)]\\n∂θr[τi], (19.29)\\n其中sit是第i集中时间t的状态，ait是第i集中时间t执行的动作。由于与状态\\n演化Pr(st+1|st,at)相关的项消失了，这种参数更新不需要假设马尔科夫时间演化过程。\\n进一步简化这个表达，我们注意到：\\nr[τi] =TX\\nt=1rit=t−1X\\nk=1rik+TX\\nk=trik, (19.30)\\n其中rit是第i集中时间t的奖励。时间 t之前的奖励（第一项）不影响时间 t的\\n更新，因此我们可以表示为：\\nθ←θ+α·1\\nIIX\\ni=1TX\\nt=1∂log[π(at|sit,θ)]\\n∂θTX\\nk=trik. (19.31)\\n19.5.2 REINFORCE 算法\\nREINFORCE 是一种初期策略梯度算法， 该算法利用了前述结果并加入了折现因素。\\n它采用蒙特卡罗方法，根据当前策略 π(a|s,θ)生成轨迹τi= [si1,ai1,ri2,si2,ai2,...,r iT]。\\n在离散动作情况下，可以通过神经网络 π(s|θ)来确定这一策略，该网络接受当前状态 s\\n并为每种可能动作输出一个值。这些输出值通过 softmax函数转换成动作的分布，每一\\n时间步都从这个分布中进行抽样。\\n对于每个轨迹 i，我们遍历其每个时间步 t，计算从该时间步开始的部分轨迹 τit的\\n实际折扣回报：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 362}, page_content='19.5.策略梯度方法 347\\nr[τit] =TX\\nk=t+1γk−t−1rik, (19.32)\\n接着，我们在每个轨迹的每个时间步更新参数：\\nθ←θ+α·γt∂log[π(at|sit,θ)]\\n∂θr[τit]∀i,t, (19.33)\\n其中π(at|st,θ)是神经网络给定当前状态 st和参数θ时产生动作 at的概率，α为学习\\n率。额外的 γt项确保奖励根据序列起点进行折扣，因为我们在整个序列中最大化回报\\n的对数概率（参见方程 19.23） 。\\n19.5.3 Baselines\\n策略梯度方法存在高方差的问题，可能需要多个轮次才能获得稳定的导数更新。降\\n低方差的一个方法是用基线 b减去轨迹回报 r[τ]：\\nθ←θ+α·1\\nIIX\\ni=1TX\\nt=1∂log[π(at|sit,θ)]\\n∂θ(r[τit]−b). (19.34)\\n只要基线b不与动作相关联：\\nEτ\"TX\\nt=1∂log[πait[sit,θ]]\\n∂θ·b#\\n= 0, (19.35)\\n图 19.16:使用控制变量降低估计方差。 a)考虑基于少量样本估计 E[a]。估计值（样本均值）会\\n因样本数和方差的不同而变化。 b)接着观察一个与 a共变的变量 b，其期望值 E[b] = 0且方差\\n与a相同。 c)a−b的样本方差明显低于 a的方差，但其期望值 E[a−b] =E[a]，因此我们得\\n到了一个方差更低的估计器。\\n期望值就不会改变。然而，如果基线与其他无关且增加不确定性的因素相关联，那\\n么减去基线就能减少方差（见图 19.16） 。这是控制变量方法的一个特殊情况（参见问题\\n19.7） 。\\n这就引出了如何选择 b的问题。我们可以通过构建方差的表达式，对 b进行求导，\\n将结果置为零，并解出方程来找到使方差最小的 b值：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 363}, page_content='348 CHAPTER 19. 深度强化学习\\nb=P\\niPT\\nt=1(∂log[πait[sit,θ]]\\n∂θ)2r[τit]\\nP\\niPT\\nt=1(∂log[πait[sit,θ]]\\n∂θ)2. (19.36)\\n实际操作中，这通常被近似为：\\nb=1\\nIX\\nir[τi]. (19.37)\\n通过减去这个基线，可以消除由于所有轨迹的回报 r[τi]超出平均水平仅因它们通\\n过的状态具有高于平均回报的特性引起的方差。\\n19.5.4 依赖当前状态的 baselines\\n更佳的方案是使用依赖于当前状态 sit的基线b[sit]。\\nθ←θ+α·1\\nIIX\\ni=1TX\\nt=1∂log[πait[sit,θ]]\\n∂θ(r[τit]−b[sit]). (19.38)\\n这里，我们正在对一些状态比其他状态具有更高总回报而引入的方差进行补偿，不\\n论采取何种行动。\\n一个合理的选择是基于当前状态的预期未来奖励，即状态值 v[s]。在这种情况下，\\n经验观察到的奖励与基线之间的差异称为优势估计（ advantage estimate ） 。鉴于我们处\\n于蒙特卡罗环境，这可以通过参数为 ϕ的神经网络 b[s] =v[s,ϕ]来参数化，并使用最小\\n二乘损失对观测到的回报进行拟合：\\nL[ϕ] =IX\\ni=1TX\\nt=1 \\nv[sit,ϕ]−TX\\nj=trij!2\\n. (19.39)\\n19.6 Actor-Critic 方法\\nActor-critic 算法属于时间差分 (TD)策略梯度算法，能够在每一步骤更新策略网络\\n的参数。这与必须等待一个或多个轮次结束才能更新参数的蒙特卡罗 REINFORCE 算\\n法形成对比。\\n在TD方法中，我们不能获取到沿此轨迹的未来奖励 r[τt] =PT\\nk=trk。Actor-critic\\n算法通过观测的当前奖励加上下一个状态的折扣值来近似计算所有未来奖励的总和：\\nTX\\nk=1r[τik]≈rit+γ·v[si,t+1,ϕ]. (19.40)\\n其中，值v[si,t+1,ϕ]通过参数为 ϕ的第二个神经网络进行估计。\\n将其代入方程 19.38，我们得到如下更新：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 364}, page_content='19.7.离线强化学习 349\\nθ←θ+α·1\\nIIX\\ni=1TX\\nt=1∂log[Pr(ait|sit,θ)]\\n∂θ(rit+γ·v[si,t+1,ϕ]−v[sit,ϕ]).(19.41)\\n同时，我们利用损失函数对参数 ϕ进行自举更新：\\nL[ϕ] =IX\\ni=1TX\\nt=1(rit+γ·v[si,t+1,ϕ]−v[sit,ϕ])2. (19.42)\\n预测Pr(a|st)的策略网络 π[st,θ]称为actor，值网络v[st,ϕ]称为critic。常见的是，同\\n一网络同时充当 actor和critic，它具有两套输出，分别预测策略和值。虽然 actor-critic\\n方法理论上可以在每步更新策略参数，但实际上这种操作较为罕见。通常，智能体会在\\n多个时间步之后累积一定的经验，再进行策略更新。\\n19.7离线强化学习\\n强化学习的核心是与环境的交互。但在某些情况下，例如自动驾驶车辆的驾驶或进\\n行金融交易，由于环境中的不稳定行为可能危险，或数据收集过程耗时且成本高昂，让\\n未经训练的智能体进入环境进行探索是不现实的。\\n然而，在这两种情况下，我们可以从人类操作者那里收集历史数据。离线强\\n化学习 (Offline RL) 或批量强化学习 (Batch RL) 旨在通过观察过去的行为序列\\ns1,a1,r2,s2,a2,r3,...来学习如何采取行动，以便在未来的轮次中最大化奖励，而不需\\n要与环境直接交互。这与模仿学习不同，后者没有奖励信息，只是尝试复制历史操作者\\n的行为而不是改善它。\\n虽然存在基于 Q-Learning 和策略梯度的离线 RL方法，但这一领域开启了新的可\\n能性。特别地，我们可以将其视作一个序列学习问题，目的是在给定状态、奖励和行动\\n的历史下预测下一个行动。决策变换器（ Decision Transformer ）采用Transformer 解码\\n器框架（见第 12.7节）进行预测（见图 19.17） 。\\n但目标是基于 *未来奖励 *预测行动，这些在标准的 s,a,r序列中无法体现。因\\n此，决策变换器用 *剩余回报 *Rt:T=PT\\nt′=trt′（即未来奖励的累积和）来替换当\\n前奖励rt。剩余部分的框架与标准的 Transformer 解码器非常相似。状态、行动和剩余\\n回报通过学习得到的映射转换成固定大小的嵌入。对于 Atari游戏，状态嵌入可能通过'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 364}, page_content='前奖励rt。剩余部分的框架与标准的 Transformer 解码器非常相似。状态、行动和剩余\\n回报通过学习得到的映射转换成固定大小的嵌入。对于 Atari游戏，状态嵌入可能通过\\n类似图19.14中的卷积网络进行转换。行动和剩余回报的嵌入可类似于单词嵌入（见图\\n12.9）进行学习。 Transformer 通过带掩码的自注意力和位置嵌入进行训练。\\n这种方法在训练时自然有效，但在推理时会遇到问题，因为我们不知道剩余回报。\\n这可以通过在第一步设定目标总回报，并随着奖励的获得逐步减少这个值来解决。例如，\\n在Atari游戏中，目标总回报可能是赢得比赛所需的总分。\\n决策变换器还可以从在线经验中进行微调， 并逐渐学习。 它们的优势在于摒弃了大部\\n分强化学习的机制及其相关的不稳定性，转而采用了标准的监督学习方法。 Transformer'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 365}, page_content='350 CHAPTER 19. 深度强化学习\\n图 19.17:决策变换器。决策变换器把离线强化学习处理为序列预测问题。输入是状态、动作和\\n剩余回报的序列，每个元素都被转换为固定大小的嵌入。每一步，网络预测下一动作。在测试阶\\n段，剩余回报未知；实际中，通常从一个初始估计出发，逐渐扣除观测到的奖励。\\n能够处理大量数据，并在广阔的时间范围内整合信息，使时间信用分配问题变得更易于\\n处理。这为强化学习开辟了一条新的、令人兴奋的道路。\\n19.8总结\\n增强学习 (Reinforcement Learning) 是针对马尔科夫决策过程 (Markov Decision\\nProcesses) 及其类似系统的序贯决策框架。本章介绍了增强学习的表格方法，包括动态\\n规划（环境模型已知） 、蒙特卡罗方法（通过运行多个回合并根据获得的奖励调整动作\\n值和策略）和时差分方法（在回合进行中更新这些值） 。\\n深度Q学习(Deep Q-Learning) 是一种时差分方法，使用深度神经网络预测每个状\\n态的动作价值，能够训练智能体在 Atari 2600 游戏中达到类似人类的水平。策略梯度方\\n法直接对策略进行优化，而非对动作进行价值赋值。这些方法生成的是随机策略，在部\\n分可观测的环境中尤其重要。这些更新过程含有噪声，为减少其方差已经引入了多种改\\n进措施。\\n当无法直接与环境互动而必须依赖历史数据学习时，就会使用离线增强学习。决策\\n变换器(Decision Transformer) 利用深度学习的最新进展构建状态 -动作-奖励序列模型，\\n并预测能够最大化奖励的动作。\\n19.9笔记\\nSutton和Barto在2018年的作品中详细介绍了表格型增强学习方法。 Li (2017) 、\\nArulkumaran 等人(2017)、FranCois-Lavet 等人(2018)和Wang等人(2022c)分别提供\\n了深度增强学习领域的综述。 Graesser 和Keng的2019年作品是一本优秀的入门资源，\\n其中包含了 Python代码示例。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 366}, page_content='19.9.笔记 351\\n深度增强学习的里程碑 ：增强学习的重大成就主要在视频游戏或现实世界游戏中实\\n现，这些游戏提供了具有有限动作和固定规则的约束性环境。深度 Q学习（由 Mnih等\\n人在2015年提出）在 ATARI游戏的基准测试中达到了人类水平的表现。 AlphaGo （由\\nSilver等人在2016年提出）战胜了围棋的世界冠军，这是一个之前被认为计算机难以掌\\n握的游戏。 Berner等人在2019年构建的系统在 Dota 2（五对五玩家游戏）中击败了世\\n界冠军队，显示出了玩家间合作的必要性。 Ye等人在2021年开发的系统能够在有限的\\n数据下超越人类玩家在 Atari游戏中的表现，这与之前需要大量经验的系统形成鲜明对\\n比。最近， FAIR在2022年推出的 Cicero系统在需要自然语言协商和玩家协调的《外\\n交》游戏中展示了人类级别的表现。\\nRL还成功应用于组合优化问题， Mazyavkina 等人在2021年的研究中有所涉及。\\n例如，Kool等人在2019年开发的模型在解决旅行商问题上与最佳启发式方法表现相当。\\n最近，Fawzi等人在2022年提出的 AlphaTensor 将矩阵乘法视作一种游戏，学会了用\\n更少的乘法操作更快地进行矩阵乘法，这一发现对深度学习领域，尤其是因其重度依赖\\n矩阵乘法的特性，意义重大，标志着 AI领域自我进化的重要里程碑。\\n经典增强学习方法 ： 关于马尔科夫决策过程 (MDPs)理论的早期贡献分别由 Thomp-\\nson在1933年和1935年作出。 Bellman 在1966年引入了 Bellman 递归，Howard在\\n1960年引入了策略迭代方法。 Sutton和Barto在2018年的研究中指出， Andreae 在\\n1969年的工作首次使用 MDP形式主义来描述增强学习。\\n现代增强学习的发展起源于 Sutton (1984) 和Watkins (1989) 的博士论文。 Sutton\\n在1988年引入时序差分学习， Watkins (1989) 和Watkins & Dayan (1992) 提出了Q学\\n习，并证明了它通过 Banach定理收敛到一个固定点，因为 Bellman 操作是收缩映射。\\nWatkins (1989) 首次明确地将动态规划和增强学习联系起来。 SARSA是由Rummery &'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 366}, page_content='习，并证明了它通过 Banach定理收敛到一个固定点，因为 Bellman 操作是收缩映射。\\nWatkins (1989) 首次明确地将动态规划和增强学习联系起来。 SARSA是由Rummery &\\nNiranjan (1994) 开发的。 Gordon (1995) 提出了拟合 Q学习，用机器学习模型预测每个\\n状态-动作对的价值。 Riedmiller (2005) 引入了神经拟合 Q学习，使用神经网络从一个\\n状态一次性预测所有动作的价值。 Singh & Sutton (1996) 对蒙特卡罗方法进行了早期研\\n究，探索启动算法则由 Sutton & Barto (1999) 提出。这是对五十多年工作的极简总结，\\nSutton & Barto (2018) 的著作中有更为全面的论述。\\n深度 Q网络：Mnih等人在2015年设计的深度 Q学习是神经拟合 Q学习的理论\\n衍生。它利用了当时卷积网络的进展，开发出一种拟合 Q学习方法，在 ATARI游戏基\\n准测试中达到人类水平的表现。深度 Q学习存在致命的三重问题，即训练在包含自举、\\n离策略学习和函数逼近的方案中可能不稳定（ Sutton & Barto, 2018 ） 。很多后续研究致\\n力于让训练过程更加稳定。 Mnih等人(2015)引入了经验回放机制（ Lin, 1992 ） ，Schaul\\n等人(2016)对其进行改进，优先考虑更重要的经验，从而加快学习速度，这就是所谓的\\n优先经验回放。\\n原始的Q学习论文使用四帧图像串联，以便网络观察到对象的速度，使底层过程更\\n接近完全可观测。 Hausknecht & Stone (2015) 引入了深度递归 Q学习，使用循环网络\\n架构，一次只处理一个帧图像，因为它能“记住”之前的状态。 Van Hasselt (2010) 指出'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 367}, page_content='352 CHAPTER 19. 深度强化学习\\n由于最大化操作导致的状态价值系统性过高估计，并提出了双 Q学习，通过同时训练两\\n个模型来解决这个问题。这种方法后来被应用于深度 Q学习（Van Hasselt 等人，2016） ，\\n虽然其有效性后来受到了质疑（ Hessel等人，2018） 。Wang等人(2016)引入了深度对\\n决网络，其中网络的两个部分分别预测状态的价值和每个动作的相对优势，这种解耦可\\n以提高稳定性，因为有时状态的价值更为重要，而具体采取哪种动作的影响不大。\\nFortunato 等人（2018）提出了噪声深度 Q-网络，其特点是 Q-网络中的部分权重乘\\n以噪声以增加预测的随机性并促进探索行为。该网络能够在逐步收敛到合理策略的过程\\n中学会减少噪声的强度。分布式 DQN（Bellemare 等人，2017a；Dabney等人，2018，继\\nMorimura 等人，2010）的目标是估计回报分布的更全面信息，而不仅仅是期望值。这使\\n得网络有可能减轻最坏情况下的影响，并且还可以通过预测更高阶矩来提高性能，因为\\n这为训练提供了更丰富的信号。 Rainbow（Hessel等人，2018）结合了六项对原始深度\\nQ-学习算法的改进，包括决策网络、分布式 DQN和噪声DQN，从而提高了在 ATARI\\n基准测试上的训练速度和最终性能。\\n策略梯度 ：Williams （1992）首次提出了 REINFORCE 算法。”策略梯度方法 ”一\\n词最早见于 Sutton等人（1999） 。Konda和Tsitsiklis （1999）引入了演员 -评论家算法。\\n使用不同的基准来降低方差在 Greensmith 等人（2004）和Peters & Schaal （2008）的\\n工作中被探讨。 Mei等人（2022）后来指出，价值基准主要是减少更新的激进性而非其\\n方差。\\n策略梯度已经被改进以产生确定性策略（ Silver等人，2014；Lillicrap 等人，2016；\\nFujimoto 等人，2018） 。最直接的方法是对所有可能的行动进行最大化，但如果行动空\\n间是连续的，则每一步都需要一个优化过程。深度确定性策略梯度算法（ Lillicrap 等人，\\n2016）按照行为价值梯度的方向调整策略，这表明使用了演员 -评论家方法。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 367}, page_content='间是连续的，则每一步都需要一个优化过程。深度确定性策略梯度算法（ Lillicrap 等人，\\n2016）按照行为价值梯度的方向调整策略，这表明使用了演员 -评论家方法。\\n现代策略梯度 ：我们之前提到，策略梯度可以从参数更新的角度进行介绍。但它们\\n也可以视为基于当前策略参数下预期奖励的重要性采样来优化一个代理损失。这种方法\\n允许我们合理地进行多次优化步骤。然而，这样做可能会导致很大的策略更新。在监督\\n学习中，过度更新只是一个较小的问题，因为后续可以对轨迹进行修正。但在强化学习\\n中，这会影响到未来的数据收集，可能造成极大的破坏。\\n为了缓和这些更新，提出了几种方法。自然策略梯度（ Kakade，2001）基于自然梯\\n度（Amari，1998） ，它通过 Fisher信息矩阵来调整下降方向，从而提供了更优的更新路\\n径，减少了陷入局部平稳区的可能。然而，对于参数众多的模型，计算 Fisher矩阵并不\\n实际。在信赖区域策略优化（ TRPO）中（Schulman 等人，2015） ，通过对旧策略和新\\n策略之间的 KL散度施加约束来最大化代理目标。 Schulman 等人（2017）提出了一种\\n更简化的方案，将 KL散度作为正则化项引入，其权重根据 KL散度与设定目标的距离\\n调整，以反映我们希望策略变化的程度。邻近策略优化（ PPO） （Schulman 等人，2017）\\n则是一种更简化的方法，通过剪裁损失来保证较小的更新幅度。\\n演员 -评论家模型 ：在第19.6节描述的演员 -评论家模型（ Konda & Tsitsiklis, 1999 ）\\n中，评论家部分使用了单步估计方法。此外，还可以使用 k步估计方法（在此方法中，'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 368}, page_content='19.9.笔记 353\\n我们观测 k个打折后的奖励，并使用状态值的估计来近似后续奖励） 。随着 k的增加，\\n估计的方差也增加，但偏差则减少。广义优势估计（ Schulman 等人，2016）将多步的\\n估计结果综合起来，并通过单个参数来调整偏差与方差之间的权衡。 Mnih等人（2016）\\n提出了异步演员 -评论家模型（ A3C） ，在该模型中，多个代理在并行环境中独立运行并\\n更新相同的参数。每隔 T时间步，策略和价值函数根据 k步回报的混合来更新。 Wang\\n等人（2017）引入了几种方法，使异步演员 -评论家模型更加高效。软演员 -评论家模型\\n（Haarnoja 等人，2018b）在成本函数中增加了一个熵项，以鼓励探索并减少过拟合，使\\n策略倾向于更加不自信。\\n离线强化学习 ：离线强化学习中，策略的学习是通过观察其他代理的行为及其获得\\n的奖励来实现的，而无需直接干预策略。这与模仿学习类似，后者旨在复制另一代理的\\n行为，但不需要奖励信息（参见 Hussein等人，2017） 。离线强化学习可被视为与离策略\\n强化学习相同的处理方式。然而，实践中，观测到的策略与实际应用的策略之间的分布\\n偏移可能导致对行动价值过于乐观的估计，进而影响性能（参见 Fujimoto 等人，2019；\\nKumar等人，2019a；Agarwal 等人，2020） 。保守 Q-学习（Kumar等人，2020b）通过\\n对Q-值进行正则化，学习价值函数的保守下界估计。决策变换器（ Chen等人，2021c）\\n是一种简便的离线学习方法，利用了广泛研究的自注意力架构。后续，它可以通过在线\\n训练进行进一步微调（ Zheng等人，2022） 。\\n强化学习和聊天机器人 ：聊天机器人的训练可以采用一种称为强化学习结合人类反\\n馈（RLHF）的技术（ Christiano 等人，2018；Stiennon 等人，2020） 。例如， InstructGPT\\n（ChatGPT 的前身， Ouyang等人，2022）起始于一个标准的 Transformer 解码器模型。\\n接着，基于人类注释者编写的提示 -响应对进行微调。在这一训练阶段，模型优化以预测\\n真实响应中的下一个词。\\n遗憾的是，产生足够的训练数据以保证高质量表现的成本非常高。为了解决这个问\\n题，人类注释者随后指出他们更偏好的模型响应。这些成本更低的数据用于训练奖励模'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 368}, page_content='真实响应中的下一个词。\\n遗憾的是，产生足够的训练数据以保证高质量表现的成本非常高。为了解决这个问\\n题，人类注释者随后指出他们更偏好的模型响应。这些成本更低的数据用于训练奖励模\\n型，即一个第二个 Transformer 网络，它根据提示和模型响应给出评分。最后，经过微\\n调的聊天机器人模型进一步训练，以根据奖励模型的监督产生高奖励。由于无法通过聊\\n天机器人输出的采样过程计算导数，因此无法使用标准的梯度下降法。于是，使用近似\\n策略优化（一种可计算导数的策略梯度方法）对模型进行训练，以产生更高的奖励。\\n强化学习的其他领域 ：强化学习是一个广阔的领域，足以单独编成一本书，而本文\\n的综述仅触及了表面。我们未涉及的强化学习的其他重要领域包括基于模型的强化学\\n习，在这个领域中，状态转移概率和奖励函数是被建模的（参见 Moerland 等人，2023） 。\\n这种方法支持前瞻性规划，并且具有可以针对不同奖励结构重用同一模型的优势。像\\nAlphaGo （Silver等人，2016）和MuZero（Schrittwieser 等人，2020）这样的混合方法\\n为状态的动态、策略和未来位置的价值分别建立了模型。\\n本章只简要讨论了如 epsilon-greedy 方法、噪声 Q-学习和添加熵项以惩罚过度自信\\n策略等探索方法。内在动机是指为探索增加奖励的方法，这样做可以赋予智能体“好奇\\n心” （参见 Barto，2013；Aubret等人，2019） 。 层次化强化学习（参见 Pateria等人，2021）'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 369}, page_content='354 CHAPTER 19. 深度强化学习\\n是指将最终目标分解成子任务的方法。多智能体强化学习（参见 Zhang等人，2021a）探\\n讨了多个智能体在共享环境中共存的情况，这可以是竞争性或合作性的情境。\\n19.10习题\\n图 19.18:通过 MDP的一条轨迹。企鹅在到达第一个鱼位置时获得 +1奖励，掉入洞时失去 -2\\n奖励，到达第二个鱼位置时再获得 +1奖励。折扣因子 γ设定为 0.9。\\n问题 19.1在图19.18展示的MDP示例中考虑一条特定的轨迹。假设折扣因子 γ\\n为0.9，请计算该轨迹中每一步的回报。\\n问题 19.2证明策略改进定理。假设从策略 π更改为策略 π′，在状态st时新策略\\nπ′选择能够最大化期望回报的动作：\\nπ′[at|st] =argmax\\nat\"\\nr(st,at) +γ·X\\nst+1Pr(st+1|st,at)v[st+1|π]#\\n. (19.43)\\n对于所有其他状态，两个策略保持一致。证明原始策略 π下的值vπ(st)必须小于或\\n等于新策略 π′下的值vπ′(st) =qπ(st,π′(st))：\\nv[st|π]≤q[st,π′[at|st]|π]\\n=Eπ′[rt+1+γ·v[st+1|π]]. (19.44)\\n提示：首先尝试用新策略 π′来表达vπ(st+1)。\\n问题 19.3假设状态值和策略按图 19.10a初始化，展示它们在进行两次迭代后变成\\n图19.10b中的状态。迭代包括： (i)策略评估（其中所有状态基于当前值进行更新，然\\n后替换前一个值） ，和 (ii)策略改进。状态转移给策略指示的方向分配一半的概率，其'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 370}, page_content='19.10.习题 355\\n余概率平均分配给其他有效动作。无论采取何种动作，当企鹅离开洞穴时奖励函数返回\\n-2；当企鹅离开鱼瓦片且剧情结束时，奖励函数返回 +3，因此鱼瓦片的价值为 +3。\\n问题 19.4Boltzmann 策略通过基于当前状态 -动作奖励函数 q[s,a]来决定动作概率\\nπ[a|s]，从而在探索和利用之间实现平衡：\\nπ[a|s] =exp(q[s,a]/τ)P\\na′exp(q[s,a′]/τ). (19.45)\\n讨论如何通过调整温度参数 τ来偏向探索或利用。\\n问题 19.5当学习率α为1时，Q-Learning 的更新公式为：\\nf[q(s,a)] =r[s,a] +γ·max\\na′q[s′,a′]. (19.46)\\n证明这是一个压缩映射（参照方程 16.30） ，所以：\\n∥f[q1(s,a)]−f[q2(s,a)]∥∞≤γ∥q1(s,a)−q2(s,a)∥∞∀q1,q2. (19.47)\\n其中∥·∥ ∞表示ℓ∞范数。根据 Banach定理，存在一个固定点，且更新最终会收\\n敛。\\n问题 19.6证明：\\nEτ\\x14∂\\n∂θlog[Pr(τ|θ)]b\\x15\\n= 0, (19.48)\\n所以添加基线更新不改变策略梯度更新的期望值。\\n问题 19.7*假设我们要根据样本 a1,a2...a I估计量 E[a]。同时，我们有与 a相关\\n联的样本对 b1,b2...b I，其平均值为 E[b] =µb。定义新变量：\\na′=a−c(b−µb). (19.49)\\n证明当恰当选择常数 c时，Var[a′]≤Var[a]成立，并给出 c的最优值表达式。\\n问题19.8在方程19.34中，梯度的估计可表示为：\\nEτ[g(θ)(r[τ]−b)], (19.50)\\n其中\\ng(θ) =TX\\nt=1∂\\n∂θlog[Pr(at|st,θ)], (19.51)\\n且\\nr[τ] =TX\\nk=trk. (19.52)\\n证明最小化梯度估计方差的 b值由以下式子给出：\\nb=E[g(θ)2r[τ]]\\nE[g(θ)2]. (19.53)'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 371}, page_content='356 CHAPTER 19. 深度强化学习'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 372}, page_content='Chapter 20\\n为什么深度学习有效？\\n本章不同于前面的章节。它不展示已确立的结果，而是探讨了深度学习为何和如何\\n取得显著成功的问题，这些问题在教科书里很少被提及。然而，需明白（尽管本书的标\\n题所示） ，我们对深度学习的理解还很有限。\\n我们发现，深度网络之所以易于训练及其泛化能力强，都是令人惊异的现象。接下\\n来，我们将逐一分析这些议题。我们将探讨影响训练成功的各种因素，并讨论深度网络\\n损失函数的已知信息。接着，我们分析影响泛化能力的因素。最后，我们讨论网络是否\\n需要过度参数化和深化的问题。\\n20.1深度学习的质疑\\nMNIST-1D 数据集（图 8.1）只有40个输入维度和 10个输出维度。在每层具有足\\n够的隐藏单元的情况下，一个两层全连接网络能够完美分类 10000个MNIST-1D 训练\\n数据点，并合理泛化到未见样本（图 8.10a） 。实际上，我们已经习以为常，认为只要隐\\n藏单元足够，深度网络几乎可以完美分类任意训练集，并预期这样的模型会对新数据具\\n有泛化能力。然而，训练过程的成功和模型的泛化能力并非不言自明。本节将阐述为何\\n这两个现象令人意外。\\n20.1.1 训练\\n在每层有 43个隐藏单元（约 4000参数）的情况下，两层全连接网络在 10000个\\nMNIST-1D 训练样本上的表现是完美的。然而，寻找任意非凸函数的全局最小值是 NP-\\n困难问题（ Murty & Kabadi, 1987 ） ，这同样适用于特定的神经网络损失函数（ Blum &\\nRivest, 1992 ） 。算法避免陷入局部最小值或鞍点，有效利用模型剩余容量拟合未解释的\\n训练数据，这非常显著。\\n参数远超训练数据时，这种成功似乎不足为奇。但这种情况是否普遍存在还有待商\\n榷。AlexNet 拥有6000万参数，训练了约 100万个数据点，且每个训练样本增加了 2048\\n357'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 373}, page_content='358 CHAPTER 20. 为什么深度学习有效？\\n个变换。 GPT-3则有1750亿参数，训练了 3000亿个token。这两个模型是否过参数化\\n尚无定论，但它们的训练都取得了成功。\\n总之，我们能够可靠且高效地拟合深度网络，这本身就值得惊讶。数据、模型、训\\n练算法或它们的某种组合，一定有些特殊的属性，才使这成为可能。\\n20.1.2 泛化\\n神经网络的高效拟合已经足够令人惊讶，而它们对新数据的泛化能力则更是难以理\\n解。首先，典型数据集是否足以描述输入 /输出映射并不是显然的。维数灾难告诉我们，\\n训练数据集与可能的输入相比简直微不足道；例如，若 MNIST-1D 数据的每个输入都\\n有10种可能值，将产生 1040个可能的输入，这是训练样本数量的 1035倍。\\n其次，深度网络能描述极其复杂的函数。一个具有 400个单元的两层全连接网络可\\n以为MNIST-1D 创建多达 1042个线性区域，大约为每个训练样本 1037个区域，训练\\n阶段的大部分区域都不包含数据；但是，包含数据点的区域会限制其他区域，使之表现\\n合理。\\n第三，模型的泛化能力随着参数数量增加而提高（图 8.10）。前面提到的模型有\\n177,201个参数，假定每个参数可以拟合一个训练样例，它有 167,201个额外自由度。这\\n种参数过剩让模型在训练数据间的行为几乎无拘无束，但它依然表现得很合理。\\n20.1.3 深度学习的不合理效果\\n总结来说，深度网络的拟合与泛化能力并不是自明的。从理论上讲，深度学习本不\\n应有效，但实际却大有成效。本章将探讨这背后的原因。 20.2至20.3节将阐述我们对\\n深度网络拟合及其损失函数的理解； 20.4至20.6节将讨论泛化问题。\\n20.2影响拟合性能的因素\\n图6.4展示了非线性模型的损失函数具有局部最小值和鞍点。尽管如此，我们能\\n够可靠地训练深度网络以适应复杂的训练集，如图 8.10所示，MNIST-1D 、MNIST和\\nCIFAR-100 上的训练表现均达到完美。本节将探讨可能化解这种矛盾的因素。\\n20.2.1 数据集\\n我们需要认识到，并非所有函数都能被学习。以将每个可能的 28×28二进制图像\\n随机映射到十个类别中的一个为例，这样的函数没有固定结构，因此唯一的方法是记住\\n2784的映射。然而，在包含 60,000个标记为十类之一的 28×28图像的MNIST数据集'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 373}, page_content='随机映射到十个类别中的一个为例，这样的函数没有固定结构，因此唯一的方法是记住\\n2784的映射。然而，在包含 60,000个标记为十类之一的 28×28图像的MNIST数据集\\n上进行训练却相对容易（见图 8.10和15.15） 。这种矛盾可能因为我们试图近似的现实\\n世界函数相对简单，更容易找到全局最小值。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 374}, page_content='20.2.影响拟合性能的因素 359\\n这一假设由 Zhang等人在2017年的研究中得到验证，他们对 CIFAR-10 图像分类\\n数据集进行了实验，其中一是将每个图像替换为高斯噪声，二是随机置换了十个类别的\\n标签（见图 20.1） 。这些变化降低了学习速度，但网络仍然能够很好地适应这个有限的\\n数据集。这表明数据集的特性并非决定性因素。\\n图 20.1:拟合随机数据。训练在 CIF AR-10 数据集上的 AlexNet 架构所得的损失。当像素从一\\n个与原始数据有相同均值和方差的高斯随机分布中抽取时，尽管速度更慢，但模型仍然能够拟\\n合。当标签随机化后，模型的拟合过程进一步放缓。改编自 Zhang et al. (2017a) 。\\n20.2.2 正则化\\n模型易于训练的另一个原因可能是某些正则化方法，例如 L2正则化（权重衰减） ，\\n让损失函数的表面变得更加平滑和接近凸形。但是， Zhang等人（2017a）的研究发现，\\n无论是L2正则化还是 Dropout 都不是拟合随机数据所必需的。这不排除由拟合算法的\\n有限步长带来的隐式正则化（见第 9.2节） 。尽管这种影响随学习率增大而加剧（参见\\n公式9.9） ，模型拟合的难度并未因较大的学习率而减小。\\n20.2.3 随机训练算法\\n第6章提到， SGD算法可能使优化过程在训练期间穿越不同的“谷” 。但 Keskar\\n等人（2017）证明了，使用大批量（ 5000-6000 图像）的方法，多个模型（包括全连接和\\n卷积网络）可以在多个数据集（包括 CIFAR-100 和MNIST）上几乎完美地拟合。这大\\n大减少了随机性，但训练依然取得了成功。\\n图20.2展示了四个全连接模型使用全批量（非随机）梯度下降，在 4000个带随机\\n标签的MNIST-1D 示例上的训练结果。过程中没有使用显式正则化，学习率被设定为\\n较小的恒定值 0.0025，以尽量减少隐式正则化的影响。尽管数据到标签的映射没有固定\\n结构，训练是确定性的，未经正则化，训练误差还是降到了零。这暗示这些损失函数可\\n能确实不存在局部最小值。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 375}, page_content='360 CHAPTER 20. 为什么深度学习有效？\\n图 20.2: MNIST-1D 训练。利用完全批量梯度下降、 He初始化（ He initialization ） 、无动量或正\\n则化，以及 0.0025的学习率，四个全连接网络被用来拟合 4000个带有随机标签的 MNIST-1D\\n示例。 1、2、3、4层的模型分别具有 298、100、75、63个隐藏单元，以及 15208、15210、15235、\\n15139个参数。所有模型均成功训练，但深层模型需要的训练周期更少。\\n20.2.4 过参数化\\n过参数化无疑是促进训练简化的一个关键因素。这表明存在一个庞大的等效解集\\n合，因此几乎总能找到一个方向来调整参数以减少损失。 Sejnowski （2020）指出， “ ...\\n解的等效性改变了问题本质，从海量的稻草堆中找到一根针变成了找到一个充满针的稻\\n草堆。 ”\\n在实际应用中，网络常常被过度参数化至一个或两个数量级（如图 20.3所示） 。然\\n而，数据增强的使用使得精确陈述变得复杂。数据增强可能将数据量增加数个数量级，\\n但这些仅是对现有示例的变换，而非新增独立数据点。此外，如图 8.10所示，即使参数\\n数量与数据点数量相当或更少，神经网络有时也能很好地拟合训练数据，这可能归因于\\n相同基础函数下训练样本的冗余性。\\n多项理论研究结果表明， 在特定条件下， 如果网络过度参数化， 随机梯度下降 （ SGD）\\n能收敛至全局最小值。例如， Du等人（2019b）发现，对于具有足够隐层单元的浅层全\\n连接ReLU网络，随机初始化的 SGD能够收敛至最小二乘损失的全局最小值。类似地，\\nDu等人（2019a）研究了当激活函数是平滑且 Lipschitz 连续时的深度残差网络和卷积\\n网络。Zou等人（2020）分析了在使用铰链损失函数的深层全连接网络上梯度下降的收\\n敛性。Allen-Zhu 等人（2019）考察了使用 ReLU激活函数的深层网络。\\n如果神经网络过度参数化到可以记忆任意固定大小的数据集，那么所有静止点将成\\n为全局最小值（ Livni等人，2014；Nguyen & Hein ，2017, 2018 ） 。其他研究结果表明，\\n如果网络足够宽，则高于全球最小值的局部最小值很少出现（参见 Choromanska 等人，'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 375}, page_content='如果网络足够宽，则高于全球最小值的局部最小值很少出现（参见 Choromanska 等人，\\n2015；Pascanu 等人，2014；Pennington & Bahri ，2017） 。Kawaguchi 等人（2019）证明，\\n随着网络变得更深、更宽或两者兼有，局部最小值处的损失会趋近于全局最小值，特别\\n是对于平方损失函数而言。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 376}, page_content='20.2.影响拟合性能的因素 361\\n图 20.3:过参数化。作为卷积网的过参数化（相对于数据集大小的倍数）的函数， ImageNet 的\\n性能展示了大部分模型的参数是训练样例的 10至 100倍。比较的模型包括 ResNet (He et al.,\\n2016a,b)、DenseNet (Huang et al., 2017b) 、Xception (Chol let, 2017) 、EﬀicientNet (T an & Le,\\n2019)、Inception (Szegedy et al., 2017) 、ResNeXt (Xie et al., 2017) 和 AmoebaNet (Cubuk et\\nal., 2019) 。\\n这些理论成果令人兴奋，但它们通常基于对网络结构的不切实际假设。例如， Du等\\n人（2019a）发现，当网络宽度 D（即隐层单元数）为 Ω[I4K2]时，残差网络能够收敛\\n到零训练损失，其中 I是训练数据量， K是网络深度。类似地， Nguyen & Hein （2017）\\n的假设认为网络宽度超过数据集大小，这在大多数实践情境中并不现实。过参数化显然\\n很重要，但当前的理论还不能完全解释实证的拟合性能。\\n20.2.5 激活函数\\n激活函数的选择显著影响训练难度。相比 ReLU（其变化覆盖了半个输入范围）和\\nLeaky ReLU （覆盖整个输入范围） ，在输入范围的小部分内变化的激活函数使得网络更\\n难以拟合；例如， sigmoid和tanh函数（如图 3.13a所示）在其尾部具有较浅的梯度，\\n在激活函数近似常数的区域，训练梯度接近零，因此无法有效改善模型。\\n20.2.6 初始化\\nXavier/He 初始化将参数设置为易于优化的值，这是另一个可能的解释。显然，对\\n于更深层的网络，这种初始化是避免梯度爆炸和消失不可或缺的，因此在一定意义上，\\n初始化对训练的成功至关重要。但对于较浅的网络，权重的初始方差就显得不那么重要。\\nLiu等人（2023c）在1000个MNIST数据点上训练了一个三层全连接网络，每层有 200\\n个隐藏单元。他们发现，随着方差从 He建议的值增加，拟合训练数据所需的迭代次数'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 377}, page_content='362 CHAPTER 20. 为什么深度学习有效？\\n也随之增加（如图 20.4所示） ，但这并未最终阻碍拟合。因此，虽然爆炸 /消失的梯度揭\\n示了使训练困难的初始化条件，初始化并没有完全解释拟合神经网络为何较为容易。\\n图 20.4:初始化和拟合。一个具有每层 200个隐藏单元的三层全连接网络在使用 AdamW、一\\n位热目标（ one-hot targets ）和均方误差损失（ mean-squared error loss ）训练的 1000个 MNIST\\n示例上进行了训练。使用较大倍数的 He初始化时，虽然拟合网络需要更长时间，但最终结果不\\n受影响。这可能仅仅反映了权重需要移动更长的距离。改编自 Liu et al. (2023c) 。\\n20.2.7 网络深度\\n由于梯度爆炸和消失（如图 7.7所示）以及碎裂梯度（如图 11.3所示） ，深层神经\\n网络更加难以拟合。但这些主要是实际的数值问题，并无确凿证据表明随着网络深度增\\n加，底层损失函数的凸性会有本质的增减。图 20.2显示，在使用 He初始化的 MNIST\\n数据上，更深的网络在更少的迭代次数内完成训练。这可能是因为更深网络的梯度更为\\n陡峭，或者 He初始化使得宽而浅的网络从更远离最优参数的点开始训练。\\nFrankle & Carbin （2019）通过对小型网络如 VGG的研究，展示了通过先训练网\\n络，再剪裁幅度最小的权重，并从相同的初始权重重新训练，可以获得相同或更优的性\\n能。如果权重随机重新初始化，则此方法不适用。他们认为，原始的过参数化网络含有\\n可训练的小型子网络，足以提供所需的性能，这种现象被称为彩票假设，这些高效的子\\n网络被视为“获胜彩票” 。这表明，在拟合过程中，有效子网络的数量可能具有关键作\\n用。尽管如此，对于固定的参数数量，这种作用可能随网络深度而变化，但目前还缺乏\\n对这一现象的精确描述。\\n20.3损失函数的属性\\n前一部分讨论了促使神经网络易于训练的因素。参数的数量（过参数化程度）和激\\n活函数的选择都是关键因素。然而，数据集的选择、拟合算法的随机性以及正则化的应'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 378}, page_content='20.3.损失函数的属性 363\\n用似乎并不那么重要。目前还没有明确的证据表明（对于给定的参数数量）网络的深度\\n（除了因梯度爆炸 /消失/碎裂而引起的数值问题外）具有重要影响。本节从损失函数的\\n经验属性这一不同角度探讨了相同的主题。大多数证据来源于全连接网络和卷积神经网\\n络（CNN） ；而对 Transformer 网络的损失函数了解较少。\\n20.3.1 多个全局最小值\\n我们期待深层网络的损失函数存在大量等价的全局最小值。在全连接网络中，可以\\n改变每层隐藏单元及其相关权重的排列而不改变输出。在卷积网络中，适当改变通道和\\n卷积核的排列也不会改变输出。在任何 ReLU函数前乘以权重，在其后除以一个正数，\\n同样不会改变输出。引入批量归一化（ BatchNorm ）会产生额外的冗余，因为它重置了\\n每个隐藏单元或通道的均值和方差。\\n这些修改对每个输入都产生相同的输出。然而，全局最小值仅取决于训练数据点上\\n的输出。在过参数化网络中，还存在着一些在数据点上行为相同但在其间行为不同的解\\n集合，这些也都属于全局最小值。\\n20.3.2 到达最小值的路径\\nGoodfellow 等人（2015b）研究了从初始参数到最终值之间的直线路径。他们发现，\\n沿此路径的损失函数通常呈单调递减（尽管有时起始处会有小幅波动） 。这一现象在不\\n同类型的网络和激活函数中都有观察到（如图 20.5a所示） 。\\n图 20.5:通过损失函数的线性切片。 a)一个在 MNIST上训练的两层全连接 ReLU网络，其损\\n失沿着从初始参数 (δ= 0)到训练参数 (δ= 1)的直线单调下降。 b)然而，在 MNIST上的这个\\n两层全连接 MaxOut 网络中，损失在一个解 (δ= 0)和另一个解 (δ= 1)之间的直线上却有所增\\n加。改编自 Goodfel low et al. (2015b) 。\\n当然，实际的优化路径并非直线。然而， Li等人（2018b）发现，它们实际上位于\\n低维子空间中。这归因于损失景观中存在大而近乎凸的区域，这些区域在早期捕捉到优\\n化轨迹，并将其朝几个关键方向引导。有趣的是， Li等人（2018a）发现，即使将优化\\n限制在一个随机的低维子空间中，网络的训练仍然表现良好（如图 20.6所示） 。\\nLi & Liang （2018）研究表明，随着网络宽度增加，训练中参数的相对变化减少；对'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 378}, page_content='限制在一个随机的低维子空间中，网络的训练仍然表现良好（如图 20.6所示） 。\\nLi & Liang （2018）研究表明，随着网络宽度增加，训练中参数的相对变化减少；对\\n于更宽的网络，参数起始值较小，相对变化幅度也较小，并且在更少的步骤内收敛。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 379}, page_content='364 CHAPTER 20. 为什么深度学习有效？\\n图 20.6:子空间训练。一个包含两个隐藏层、每层 200个单元的全连接网络在 MNIST上进行\\n训练。参数通过标准方法（如 He初始化）初始化后，被限制在一个随机子空间内。在这个子空\\n间为 750D（即内在维度）时，性能可达到无约束模型性能的 90%，仅占原始参数的 0.4%。改\\n编自 Li et al. (2018a) 。\\n20.3.3 极小值间的关联\\nGoodfellow 等人（2015b）考察了两个独立确定的最小值间直线路径上的损失函数\\n变化，发现在这两点之间损失显著增加（见图 20.5b） ，表明良好的最小值通常不直接线\\n性连接。然而， Frankle等人（2020）发现，如果网络在最初相同的训练条件下开始，后\\n来允许通过不同的 SGD噪音和增强策略分开发展，这种损失增加会消失。这说明解决\\n方案在训练初期就受到约束，而且某些最小值族可以线性连接。\\nDraxler等人（2018）在CIFAR-10 数据集上找到了表现良好但不同的最小值，并证\\n明可以构建一条从一个最小值到另一个最小值的路径，在该路径上损失函数保持较低。\\n他们得出结论，存在一条连续的低损失流形（如图 20.7所示） 。随着网络宽度和深度的\\n增加，这一现象变得更加明显。 Garipov 等人（2018）和Fort & Jastrzębski （2019）也\\n提出了连接最小值的不同方法。\\n20.3.4 损失表面的曲率\\n随机高斯函数的一个有趣特性是：对于梯度为零的点，当这些点的损失值较低时，\\n函数向下弯曲的方向比例会减小（参见 Bahri等人，2020） 。Dauphin 等人（2014）研究\\n了神经网络损失函数中的鞍点，发现损失与负特征值数量之间存在相关性（见图 20.8） 。\\nBaldi & Hornik （1989）分析了浅层网络的误差表面，发现除了鞍点外没有局部最小值。\\n这些研究表明，网络中不良的局部最小值较少或不存在。\\nFort & Scherlis （2019）研究了神经网络损失表面上随机点的曲率，发现当权重的 l2\\n范数处于某个特定范围内时，损失表面的曲率异常正向（见图 20.9） ，他们将这个范围\\n称为“刚刚好区域” 。 He和Xavier初始化方法都处于这一范围之内。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 380}, page_content='20.4.决定泛化能力的因素 365\\n图 20.7:极小值之间的连接。对 CIF AR-10 上 DenseNet 的损失函数进行切片分析。参数 ϕ1和\\nϕ2代表两个独立发现的极小值。这些参数之间的线性插值展示了一个能量障碍（虚线所示） 。但\\n是，在足够深且宽的网络中，能够在两个极小值间找到一条低能量的曲线路径（显示为青色线） 。\\n改编自 Draxler et al. (2018) 。\\n图 20.8:损失函数的临界点。 a)在随机高斯函数中，函数在零梯度点下降的方向数随函数值的\\n增加而减少，从而所有极小值都位于较低的函数值。 b) Dauphin et al. (2014) 在神经网络的损\\n失面上找到了临界点（即零梯度的点） 。研究表明，负特征值（指向下方的方向）的比例随损失\\n的增加而减少，这表明所有的极小值（零梯度且没有向下指向的点）均对应于较低的损失。改编\\n自 Dauphin et al. (2014) 和 Bahri et al. (2020) 。\\n20.4决定泛化能力的因素\\n最近两节分析了影响网络训练成功的因素和神经网络损失函数的相关知识。本节将\\n探讨影响网络泛化能力的因素，这对于理解第 9章讨论的正则化（旨在促进泛化）非常\\n有补充意义。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 381}, page_content='366 CHAPTER 20. 为什么深度学习有效？\\n图 20.9:适中区域。在一个随机子空间内，对于一个应用了 ReLU函数、有两层全连接的网络，\\n在 MNIST上相对于 Xavier初始化的参数平方半径 r2，Hessian 的正特征值（反映正曲率 /凸\\n性）比例显示了一个明显的正曲率区域，称为适中区域。改编自 F ort & Scherlis (2019) 。\\n20.4.1 训练算法\\n鉴于深度网络通常是过参数化的，训练过程的细节决定了算法收敛到哪个解集中的\\n特定最小值。这些细节中的一些被证明能有效提升泛化能力。\\nLeCun等人（2012）发现，相比于全批量梯度下降，随机梯度下降（ SGD）具有更\\n优的泛化效果。虽然有观点认为 SGD的泛化能力超过 Adam（如Wilson等人，2017；\\nKeskar & Socher ，2017） ，但最新研究指出，如果仔细调整超参数，二者之间的差异并不\\n明显（Choi等人，2019） 。Keskar等人（2017）发现，在不使用其他形式正则化的情况\\n下，使用较小批量大小的深度网络能实现更好的泛化。已知较大的学习率通常能带来更\\n好的泛化效果（如图 9.5） 。Jastrzebski 等人（2018） 、Goyal等人（2018）以及He等人\\n（2019）强调批量大小与学习率的比值对泛化非常关键。 He等人（2019）还证明了这一\\n比值与网络泛化程度存在显著的正相关性，并且为神经网络的泛化能力确立了界限，这\\n一界限与该比值正相关（如图 20.10所示） 。\\n这些发现支持了随机梯度下降（ SGD）会隐式地向损失函数添加正则化项的观点\\n（见第9.2节） ，而这些正则化项的大小取决于学习率。这种正则化改变了参数的更新轨\\n迹，使得它们趋向于泛化良好的损失函数区域。\\n20.4.2 极小点的平坦性\\n自Hochreiter & Schmidhuber （1997a）以来，人们推测损失函数中的平坦最小值比\\n尖锐最小值具有更佳的泛化能力（见图 20.11） 。简而言之，最小值越平坦，对模型参数\\n的小误差影响越小。这一点也得到了各种理论的支持，比如最小描述长度理论表明，由\\n更少比特定义的模型能更好地泛化（ Rissanen ，1983） 。对于宽广的最小值，存储权重所'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 382}, page_content='20.4.决定泛化能力的因素 367\\n图 20.10:批大小与学习率的比率。在 CIF AR-10 数据库上，两种模型的泛化性依赖于批大小与\\n学习率的比例。随着批大小的增加，泛化性下降；随着学习率的增加，泛化性提升。改编自 He\\net al. (2019) 。\\n图 20.11:平坦与尖峭极小值。平坦极小值通常具有更好的泛化能力。在估计参数或训练和测试\\n损失函数的对齐时，小误差在平坦区域中的影响较小。改编自 Keskar et al. (2017) 。\\n需的精度更低，因此泛化能力应该更强。\\n平坦性可以通过几种方法来衡量：一是最小值周围训练损失相似的连通区域的大小\\n（Hochreiter & Schmidhuber ，1997a） ，二是最小值附近的二阶曲率（ Chaudhari et al.,\\n2019） ，三是最小值邻域内的最大损失（ Keskar et al., 2017 ） 。但是，需要注意的是，由\\n于ReLU函数的非负同质性，对网络的简单重新参数化可能会影响平坦性的估计（ Dinh\\net al., 2017 ） 。\\n然而，Keskar等人（2017）通过改变批量大小和学习率发现，平坦性与泛化能力存\\n在相关性。 Izmailov 等人（2018）通过平均学习轨迹中多个点的权重，不仅使最小值处\\n的测试和训练表面更平坦，也提高了模型的泛化性。其他正则化技术也可以从这个视角\\n进行理解，例如模型输出的平均化（集成方法）可以使测试损失表面更平坦。 Kleinberg'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 383}, page_content='368 CHAPTER 20. 为什么深度学习有效？\\n等人（2018）指出，训练过程中较大的梯度方差有助于避免尖锐区域，这解释了为什么\\n减小批量大小和增加噪声能够促进泛化。\\n以上研究主要考虑了单个模型和训练集的平坦性。然而，尖锐度并不是一个能够预\\n测不同数据集间泛化性能的可靠标准；例如，当 CIFAR数据集的标签被随机化（导致\\n泛化不可能）时，最小值的平坦度并没有相应地减少（ Neyshabur et al., 2017 ） 。\\n20.4.3 架构\\n网络的归纳偏置是由其结构所决定的，而恰当地选择模型可以大幅度提高泛化。第\\n10章介绍了卷积网络，这些网络专为处理规则网格上的数据而设计；它们假定输入的统\\n计特性在各处都相同，因此在不同位置共享参数。同理， Transformers 适用于对置换不\\n变的数据建模，而图神经网络适合于不规则图上的数据表示。架构与数据属性的匹配优\\n于泛化的通用全连接架构（参见图 10.8） 。\\n20.4.4 权重的范数\\n第20.3.4节回顾了 Fort & Scherlis （2019）的发现，即权重的 l2范数在特定范围内\\n时，损失表面的曲率异常正向。该研究还表明，在这个所谓的金发姑娘区域内， l2权重\\n范数与良好的泛化性能有关（见图 20.12） 。权重范数与模型的 Lipschitz 常数间接相关，\\n影响泛化能力：范数过小，模型变化不足以捕捉底层函数的波动；范数过大，则模型在\\n训练点间变化过度，无法平滑插值。\\n图 20.12:在超球面上进行泛化。一个具有两个隐藏层、每层 200个单元（ 198,450个参数）的\\n全连接网络在 MNIST数据库上进行了训练。参数被初始化到一个给定的 l2范数，并被限制在\\n这个范数下维持在一个子空间（垂直方向） 。这个网络在由 Xavier初始化定义的半径 r的小范\\n围内表现出良好的泛化能力（青色虚线表示） 。改编自 F ort & Scherlis (2019) 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 384}, page_content='20.4.决定泛化能力的因素 369\\nLiu等人（2023c）利用这一发现解释了 grokking 现象（Power等人，2022） ，即在训\\n练误差已降至零后的许多轮次中， 泛化性能可能会突然显著提升（见图 20.13） 。grokking\\n发生于权重范数起初过大的情况下；尽管训练数据拟合良好，但模型在数据点间的变化\\n较大。随时间推移，隐式或显式正则化减小权重范数，直至进入金发姑娘区域，此时泛\\n化能力得以突然提高。\\n图 20.13: Grokking 现象。当参数初始化使其 l2范数（半径）远大于 He初始化所指定的时，训\\n练需要更长时间（表示为虚线） ，泛化过程则更加缓慢（表示为实线） 。泛化的滞后归因于权重的\\n范数减少回到“适中区”所需的时间。改编自 Liu et al. (2023c) 。\\n20.4.5 过参数化\\n图8.10展示了泛化性能随过参数化程度的增加而提升的趋势。结合偏差 /方差权衡\\n曲线后，可以观察到双重下降现象。这种提升的可能解释是，在模型过参数化的情况下，\\n网络在训练数据点之间变得更平滑的自由度更高。\\n因此，权重的范数同样可以用来解释双重下降现象。当参数数量接近数据点数量时\\n（模型此时会扭曲自己以精确拟合这些点） ，权重的范数会增大，进而降低泛化性能。随\\n着网络加宽和权重数量的增加，这些权重的总范数开始减小；权重采用与网络宽度成反\\n比的方差进行初始化（即使用 He或Glorot初始化方法） ，权重从其初始值变化甚微。\\n20.4.6 超出数据流形\\n迄今为止，我们探讨了模型对从训练数据相同分布中提取的新数据的泛化能力。这\\n在实验中是一个合理假设。但是，实际部署的系统可能会遇到由噪声、数据统计特征随\\n时间变化或故意攻击引起的意外数据。显然，在这种情况下做出明确的判断更为困难，\\n但D’Amour等人(2020)的研究表明，在损坏数据上用不同种子训练的相同模型的变\\n异性可能非常大且不可预测。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 385}, page_content='370 CHAPTER 20. 为什么深度学习有效？\\nGoodfellow 等人(2015a)的研究证实了深度学习模型对对抗性攻击的脆弱性。想象\\n一下对一个网络正确识别为“狗”的图像进行扰动，以便尽可能快地减少正确类别的概\\n率直到类别改变。如果这幅图像现在被识别为飞机，人们可能会预期扰动后的图像看上\\n去是狗和飞机的混合物。 然而， 实际上， 扰动后的图像与原始的狗图像几乎毫无区别（见\\n图20.14） 。\\n图 20.14:对抗样本。在每个例子中，左侧图像被 AlexNet 正确分类。通过考虑网络输出对输入\\n的梯度，可以找到一个小的扰动（中间图，为了可见性放大了 10倍） ，这个扰动加到原始图像\\n（右侧）上时，会使网络错误地将其分类为鸵鸟。这是尽管原始图像和扰动图像对人类来说几乎\\n无法区分的情况下。改编自 Szegedy et al. (2014) 。\\n我们得出的结论是，有些位置虽接近但不位于数据流形上，却会被误分类，这些位\\n置就是所谓的对抗性示例。它们的存在令人意外；如此细微的网络输入变化如何能引起\\n输出的剧烈变化？目前最合理的解释是，对抗性示例并非因为缺乏对训练数据流形外数\\n据的鲁棒性。而是因为它们利用了训练数据中的某种信息，这种信息虽然范数小且对人\\n不可察觉，但却足以造成影响（ Ilyas等人，2019） 。\\n20.5真的需要这么多参数吗？\\n第20.4节讨论了模型在过参数化（ Over-parameterized ）情况下更易于泛化的观点。\\n实际上，在处理复杂数据集时，极少有模型的参数数量明显低于训练数据点数却能达到\\n顶尖水平的例子。\\n然而，第 20.2节回顾了证据表明，随着参数数量的增加，训练过程变得更加容易。\\n因此，目前还不清楚是小模型固有属性的限制导致它们表现不佳，还是训练算法未能为\\n小模型找到有效的解决方案。模型修剪（ Pruning）和蒸馏（ Distilling ）是两种用于缩减'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 386}, page_content='20.5.真的需要这么多参数吗？ 371\\n训练模型大小的方法。本节将探讨这些方法是否能够生成既小又保持过参数化模型性能\\n的欠参数化模型。\\n20.5.1 剪枝\\n图 20.15:神经网络剪枝。目标是在不影响性能的前提下尽可能剪枝权重。这通常基于权重的幅\\n值来进行。剪枝后，网络通常需要进行细微调整。 a)示例全连接网络。 b)剪枝后。\\n通过修剪训练模型可以减小模型大小，进而降低存储需求（图 20.15） 。最简单的修\\n剪方法是去除个别权重，可以根据损失函数的二阶导数（ LeCun等人，1990；Hassibi &\\nStork，1993）或更实用地，根据权重的绝对值来进行（ Han等人，2016, 2015 ） 。还有研\\n究通过修剪隐藏单元（ Zhou等人，2016a；Alvarez & Salzmann ，2016） 、卷积网络的通\\n道（Li等人，2017a；Luo等人，2017b；He等人，2017；Liu等人，2019a）或残差网络\\n的整层（ Huang & Wang ，2018）来减小模型。修剪后，通常会对网络进行微调，有时这\\n一过程还需重复。\\n举例来说， Han等人（2016）在只保留 8%权重的情况下， VGG网络在ImageNet\\n分类任务上仍然保持了良好的性能。这显著降低了模型大小，但还不足以证明非过参数\\n化模型不可行； VGG网络的参数数量是 ImageNet 训练数据的约 100倍（未计入数据\\n增强） 。\\n修剪本质上是一种架构搜索过程。 Frankle & Carbin （2019）在其关于彩票假说的研\\n究（见第 20.2.7节）中，首先训练网络，然后修剪幅度最小的权重，并从相同初始权重\\n开始对剩余网络进行重新训练。通过重复这个过程，他们在 CIFAR-10 数据集（ 60,000\\n样本）上将 VGG-19 网络（原有 1.38亿参数）的大小减少了 98.5%，同时维持了良好的\\n性能。对于 ResNet-50 （有2,560万参数） ，他们在不损失 ImageNet （1,280万样本）上\\n的性能的情况下，将参数减少了 80%。这些成果虽然印象深刻，但即使是修剪后（不考\\n虑数据增强） ，这些网络仍然过参数化。\\n20.5.2 知识蒸馏\\n通过训练一个较小的网络（学生）模仿一个较大网络（教师）的性能，也可以减少'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 386}, page_content='虑数据增强） ，这些网络仍然过参数化。\\n20.5.2 知识蒸馏\\n通过训练一个较小的网络（学生）模仿一个较大网络（教师）的性能，也可以减少\\n模型参数。这种方法称为知识蒸馏，最早由 Buciluǎ等人（2006）提出。 Hinton等人\\n（2015）发现，不同输出类别间的信息模式很重要，并且他们训练了一个小型网络以近似\\n大型网络的 Softmax 函数前的 logits（图20.16） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 387}, page_content='372 CHAPTER 20. 为什么深度学习有效？\\n图 20.16:知识蒸馏。 a)教师网络用于图像分类，按照常规方法进行训练，采用多类交叉熵作为\\n分类损失。 b)学生网络则使用相同的损失进行训练，并额外增加了蒸馏损失，该损失鼓励学生\\n网络在 softmax操作前的激活值与教师网络的相同。\\nZagoruyko & Komodakis （2017）进一步推动了学生网络的激活空间图与教师网络\\n在多个点上的相似性。他们利用这种注意力转移方法来模拟一个 34层残差网络（大约\\n6300万参数）与一个 18层残差网络（大约 1100万参数）在 ImageNet 分类任务上的性\\n能。然而，这个参数数量仍然超过了训练样本的数量（大约 100万图像） 。尽管现代方\\n法（例如 Chen等人，2021a）取得了一定进展，但目前为止，知识蒸馏还没有确凿证据\\n证明欠参数化模型能够有良好的表现。\\n20.5.3 讨论\\n目前的证据显示，至少对于当前使用的数据集大小和复杂度来说，过参数化对于模\\n型的泛化是必要的。目前尚无证据显示，在复杂数据集上能用远少于训练样本的参数实\\n现顶尖性能。尽管尝试通过修剪或蒸馏已训练的网络来减小模型的规模，但这并未改变\\n过参数化的必要性。\\n此外，最近的理论研究发现模型的 Lipschitz 常数与过参数化之间存在一种权衡关\\n系。Bubeck & Sellke （2021）的研究表明，在 D维空间中，要实现平滑插值，所需的参\\n数数量是仅进行插值所需参数的 D倍。他们认为，目前用于大型数据集（如 ImageNet ）\\n的模型过参数化程度还不够，进一步增加模型容量可能是提升性能的关键。\\n20.6网络必须深吗？\\n第3章探讨了通用逼近定理，定理指出只要隐藏单元足够多，浅层神经网络能以任\\n意精度逼近任何函数。这就引出了一个明显的问题：神经网络是否必须要深层结构。\\n首先，我们需要考虑支持深度必要性的证据。从历史上看，性能与网络深度之间存'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 388}, page_content='20.6.网络必须深吗？ 373\\n在明确的相关性。比如，最初在 ImageNet 基准测试上的性能随着网络深度的增加而提\\n升，直至训练遇到困难。此后，引入残差连接和批量归一化（第 11章）使得更深层次网\\n络的训练成为可能，并带来了性能的显著提升。截至目前，几乎所有的顶尖应用，如图\\n像分类（例如视觉 Transformer ） 、文本生成（例如 GPT3）和文本引导的图像合成（例\\n如DALL·E-2） ，都是基于拥有数十甚至数百层的深度网络。\\n尽管趋势如此，也有研究尝试使用浅层网络。 Zagoruyko & Komodakis （2016）构\\n建了较浅但较宽的残差神经网络，性能与 ResNet相当。近期， Goyal等人（2021）设计\\n了一个仅有 12层的网络，通过并行卷积通道达到了与深层网络相似的性能。 Veit等人\\n（2016）的研究显示，在残差网络中，通常是 5至17层的较短路径决定了网络性能。\\n然而，总体证据表明深度至关重要；即使是性能优良的图像分类网络也需要超过 10\\n层。目前还没有明确解释为什么会这样。可能的原因包括： （ i）深度网络能表示更为复\\n杂的函数， （ ii）深度网络更易训练， （ iii）深度网络能提供更好的归纳偏好。\\n20.6.1 建模函数的复杂度\\n第4章显示，与浅层网络相比，深层网络在相同参数量下可以形成更多的线性分\\n割区域。我们还注意到，一些特殊的“病态”函数被识别出来，相比于深层网络，使用\\n浅层网络来建模这些函数需要远多的隐藏单元（如 Eldan & Shamir ，2016；Telgarsky ，\\n2016） 。事实上， Liang & Srikant （2016）发现了一些由深层网络更有效建模的广泛函数\\n族。然而， Nye & Saxe （2018）发现，这些函数中的一些在实践中并不易于被深层网络\\n拟合。此外，几乎没有证据显示我们试图逼近的现实世界函数具有这种特殊属性。\\n20.6.2 训练的可行性\\n另一个解释是，尽管拥有实际数量的隐藏单元的浅层网络理论上可以支持顶尖性\\n能，但找到一个既能良好拟合训练数据又能合理进行插值的有效解决方案非常困难。\\n一个验证这一点的方法是将成功的深层网络蒸馏成较浅但更宽的学生模型，并检验\\n是否能保持性能。 Urban等人（2017）将CIFAR-10 数据集上的 16个卷积网络集成体'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 388}, page_content='一个验证这一点的方法是将成功的深层网络蒸馏成较浅但更宽的学生模型，并检验\\n是否能保持性能。 Urban等人（2017）将CIFAR-10 数据集上的 16个卷积网络集成体\\n蒸馏到不同深度的学生模型中。他们发现，浅层网络无法复制更深的教师网络的性能，\\n学生模型的性能随着深度的增加而在固定的参数量下提高。\\n20.6.3 归纳偏见\\n当前多数模型依赖于卷积块或 Transformer 。这些网络对输入数据的局部区域共享\\n参数，并且常常逐步将这些信息融合到整个输入中。这种设计限制了网络能够表示的函\\n数类型，并不具有普遍性。因此，深度网络之所以优越，部分原因是它们具有合适的归\\n纳偏置，而且让浅层网络遵循这些限制相当困难。\\n多层卷积架构似乎天生就有益处，即便是在未经训练的情况下也是如此。 Ulyanov\\n等（2018）证明了未经训练的 CNN结构可以作为低级任务，如去噪和超分辨率的先验。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 389}, page_content='374 CHAPTER 20. 为什么深度学习有效？\\nFrankle等（2021）通过随机初始化核，固定它们的值，仅训练批归一化的偏移和缩放因\\n子，就在图像分类任务中达到了良好的性能。 Zhang等（2017a）发现，随机初始化的卷\\n积滤波器的特征可以支持后续使用核模型的图像分类。\\n来自Urban等（2017）的进一步证据显示，卷积网络提供了有用的归纳偏置，他们\\n试图将卷积网络转换为更浅的网络。研究发现，与转换到全连接网络相比，向卷积架构\\n的转换系统地表现更佳，说明卷积架构具有某些内在优势。由于卷积网络的序贯局部处\\n理不易被更浅的网络模仿，这强调了深度的重要性。\\n20.7 Summary\\n本章论述了深度学习的成功令人意外的论点。我们探讨了优化高维损失函数的挑\\n战，并认为过参数化和激活函数选择是使深度网络可行的两个关键因素。我们观察到，\\n在训练过程中，参数在低维子空间中移动，趋向于一系列相连的全局最小值，并且局部\\n最小值并不显著。\\n神经网络的泛化能力也随着过参数化而增强，但最小值的平坦度和架构的归纳偏置\\n也同样重要。尽管原因尚不明确，但看来，要实现良好的泛化，大量的参数和多层网络\\n都是必需的。\\n仍有许多问题未得到解答。我们目前没有确切的理论来预测训练和泛化何时会成功\\n或失败。我们还不了解深度网络学习的极限，也不清楚是否存在更高效的模型。我们不\\n确定在同一模型中是否存在能更好泛化的参数。深度学习的研究依旧依赖于经验示范，\\n这些成果虽然印象深刻，但我们对深度学习机制的理解尚未达到相匹配的水平。\\n20.8习题\\n问题20.1在ImageNet 图像分类任务中，输入图像的分辨率为 224×224 像素，每个\\n像素点包含 RGB三通道的颜色值。如果将这些 RGB值粗略地量化到每个通道十个等\\n级，并且用大约 1000万个训练样本进行训练，每个训练数据点会有多少种可能的输入？\\n问题20.2考虑图20.1。为什么当像素被随机化时，相比于标签被随机化，算法能\\n更快地拟合数据呢？\\n问题20.3图20.2展示了使用固定学习率的非随机拟合过程成功地拟合了随机数据。\\n这是否表明损失函数没有局部最小值？这是否意味着该函数是凸形的？请对你的回答进\\n行证明，并且如果你认为以上任何一种说法是错误的，请给出反例。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 390}, page_content='Chapter 21\\n深度学习与伦理\\n*本章由Travis LaCroix 和Simon J.D. Prince 编写。*\\n人工智能 (AI)正在成为改变社会的力量，这种改变可能带来好处也可能带来弊端。\\n这些技术在促进社会福祉方面拥有巨大的潜力（ Taddeo & Floridi, 2018; Tomašev et al.,\\n2020） ，尤其体现在医疗保健（ Rajpurkar et al., 2022 ）和抗击气候变化（ Rolnick et al.,\\n2023）的重要作用。然而，它们也存在被误用和造成无意伤害的风险。这催生了 AI伦\\n理学这一领域的发展。\\n深度学习的现代纪元始于 2012年的AlexNet，但AI伦理的关注并未随之立即兴\\n起。事实上， 一个关于机器学习公平性的研讨会在 2013年的NeurIPS 被拒绝， 原因是缺\\n乏相关材料。直到 2016年，随着 ProPublica 对COMPAS 再犯预测模型中的偏见进行\\n揭露（Angwin et al., 2016 ）和Cathy O’Neil出版的《数学毁灭武器》 （ O’Neil, 2016 ） ，\\nAI伦理学才迎来了其“ AlexNet”时刻。自那以后，对此领域的兴趣急剧增长；自 2018\\n年首次举办以来，提交给公平、问责和透明会议 (FAccT) 的论文数量增加了近十倍。\\n同时，许多组织提出了负责任的 AI政策建议。 Jobin等人(2019)发现了84份包\\n含AI伦理原则的文件，其中 88%是自2016年以来发布的。这些非立法的政策协议大\\n量增加，主要依赖自愿的、非强制性的合作，这让人质疑它们的有效性（ McNamara et\\nal., 2018; Hagendorff, 2020; LaCroix & Mohseni, 2022 ） 。总的来说， AI伦理学仍处于发\\n展初期，其伦理考量往往是事后反应而非主动预防。\\n本章将探讨由 AI系统的设计和使用所引发的潜在危害，包括算法偏见、缺乏可解\\n释性、数据隐私侵犯、军事化、欺诈和环境问题。我们的目标不是提供如何更加伦理的\\n建议，而是通过在哲学、政治学和更广泛的社会科学领域受到关注的关键区域内表达观\\n点和开展对话，来启发思考和讨论。\\n21.1价值观对齐\\n当我们设计人工智能 (AI)系统时，我们希望它们的价值观（目标）与人类的价值观'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 390}, page_content='点和开展对话，来启发思考和讨论。\\n21.1价值观对齐\\n当我们设计人工智能 (AI)系统时，我们希望它们的价值观（目标）与人类的价值观\\n保持一致。这通常被称作价值对齐问题（ Russell, 2019; Christian, 2020; Gabriel, 2020 ） 。\\n375'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 391}, page_content='376 CHAPTER 21. 深度学习与伦理\\n这项挑战主要有三个原因：首先，完整且准确地定义我们的价值观本身就是困难的；其\\n次，把这些价值观转化为 AI模型的具体目标是一项艰巨的任务；第三，确保模型真正\\n学会实现这些目标也不容易。\\n在机器学习模型中，损失函数作为我们真实目标的代理指标。当损失函数与真实目\\n标不一致时，我们称之为外部对齐问题（ Hubinger et al., 2019 ） 。如果这种代理指标不\\n够完善，系统可能会找到“漏洞” ，通过最小化损失函数来达成目标，但实际上却未能\\n满足真正的预期目标。例如，在训练强化学习（ RL）智能体玩国际象棋的过程中，如果\\n智能体因捕获棋子而获得奖励，可能导致很多平局而非赢得比赛，这就是我们期望的行\\n为。而内部对齐问题则是确保即使损失函数被准确定义， AI系统的行为也不会偏离既\\n定目标。如果学习算法未能找到全局最优解，或者训练数据不具备代表性，那么训练可\\n能会收敛于一个与真实目标不一致的解，从而导致不良行为（ Goldberg, 1987; Mitchell\\net al., 1992; Lehman & Stanley, 2008 ） 。\\nGabriel (2020) 将价值对齐问题分为技术和规范两部分。技术层面关注的是如何将\\n价值观编码进模型，确保它们可靠地执行既定任务。某些具体问题，比如避免奖励操纵\\n和安全探索，可能存在技术层面的解决方案（ Amodei et al., 2016 ） 。而规范层面则关注\\n什么是正确的价值观。考虑到不同文化和社会的价值多样性，这个问题可能没有统一的\\n答案。重要的是，所编码的价值观应代表所有人，而非仅仅是占主导地位的文化群体。\\n价值对齐也可以被视为一种结构问题，出现在人类主体将任务委托给人工代理的情\\n况中（LaCroix, 2022 ） 。这与经济学中的委托代理问题（ Laffont & Martimort, 2002 ）相\\n似，后者指出任何一方期望另一方代表其最佳利益行事的关系中都存在着内在的竞争激\\n励。在AI的背景下，当目标设定不当或当主体与代理之间存在信息不对称时，就可能\\n产生利益冲突（图 21.1） 。\\n图 21.1:值对齐问题的结构描述。 a)问题源于 a)目标不匹配（如偏差）或 b)信息不对称，这'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 391}, page_content='产生利益冲突（图 21.1） 。\\n图 21.1:值对齐问题的结构描述。 a)问题源于 a)目标不匹配（如偏差）或 b)信息不对称，这\\n种不对称存在于人类委托人与人工代理之间（例如，缺乏可解释性） 。据 LaCroix (2023) 改编。\\nAI伦理的许多议题都可以从价值对齐的结构视角来理解。接下来的部分将讨论偏\\n见与公平、人工道德代理（这两者与目标设定有关） 、透明度与可解释性（这两者与信\\n息不对称相关）等问题。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 392}, page_content='21.1.价值观对齐 377\\n21.1.1 偏见和不公正\\n从科学的角度来看，偏见指的是与某个规范的统计偏离。在 AI领域，当这种偏离\\n基于非法因素而影响输出时，它便成为了一种恶劣的现象。例如，性别与工作表现无关，\\n因此用性别作为招聘依据是不合理的。同样，种族与犯罪行为无关，所以使用种族作为\\n再犯预测的依据同样是不合理的。\\nAI模型中的偏见可能通过以下途径引入（ Fazelpour & Danks, 2021 ） ：\\n-问题定义 ： 选择模型的目标需要进行价值判断， 这可能导致偏见的产生（ Fazelpour\\n& Danks, 2021 ） 。如果我们无法成功实施这些选择，并且问题定义未能准确反映我们的\\n预期目标，进一步的偏见就可能产生（ Mitchell et al., 2021 ） 。\\n-数据：当数据集不具代表性或不完整时，算法偏见就可能形成（ Danks & London,\\n2017） 。例如， PULSE面部超分辨率算法（ Menon et al., 2020 ）是基于主要是白人名人\\n的照片数据库训练的。当它用于处理低分辨率的奥巴马肖像时，生成了一张白人男性的\\n照片（Vincent, 2020 ） 。\\n如果生产训练数据的社会结构对边缘化群体存在偏见，那么即使数据集完整且具有\\n代表性，也会引入偏见（ Mayson, 2018 ） 。比如，在美国，黑人相比白人更频繁地遭到警\\n察执法和监禁。因此，用于训练再犯预测模型的历史数据对黑人社群已存在偏见。\\n-建模和验证 ：选择数学定义来衡量模型的公平性需要进行价值判断。存在多种直\\n观但逻辑不一致的公平性定义（ Kleinberg et al., 2017; Chouldechova, 2017; Berk et al.,\\n2017） 。这暗示我们需要从纯数学的公平性定义转向更实质性的评估，即算法在实际应\\n用中是否促进了正义（ Green, 2022 ） 。\\n-部署：部署的算法可能与社会中的其他算法、结构或机构相互作用，形成复杂的反\\n馈循环，加剧现有偏见（ O’Neil, 2016 ） 。例如，大型语言模型如 GPT-3（Brown et al.,\\n2020）是基于网络数据训练的。然而，当 GPT-3的输出内容被发布到网络上时，未来模'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 392}, page_content='2020）是基于网络数据训练的。然而，当 GPT-3的输出内容被发布到网络上时，未来模\\n型的训练数据质量可能下降， 这可能会加剧偏见并产生新的社会伤害（ Falbo & LaCroix,\\n2022） 。\\n不公正的情况可能因交叉性的因素而加剧；不同的社会类别可以交织在一起，形成\\n重叠且相互依存的压迫体系。例如，有色女同性恋者所遭遇的歧视并不仅仅是她因同性\\n恋、性别或种族身份可能遭遇的歧视之和（ Crenshaw, 1991 ） 。在AI领域，Buolamwini\\n& Gebru （2018）的研究显示，主要针对浅肤色面孔训练的面部分析算法在处理深肤色\\n面孔时性能较差。更严重的是，当考虑皮肤颜色和性别等特征组合时，它们的性能甚至\\n比单独考虑这些特征时还要差。\\n当然，我们可以采取措施确保数据的多样性、代表性和完整性。但如果生成训练数\\n据的社会本质上对边缘化群体存在结构性偏见，即使数据集再准确，也无法避免引入\\n偏见。鉴于上述算法偏见潜力和训练数据集中的代表性不足，有必要考虑这些系统的\\n输出错误率如何可能加剧对已边缘化群体的歧视（ Buolamwini & Gebru, 2018; Raji &\\nBuolamwini, 2019; Raji et al., 2022 ） 。结果产生的模型可能会固化和加深包括资本主义、\\n阶级主义、性别歧视、厌女症、父权制、殖民主义、帝国主义、种族主义、白人至上主'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 393}, page_content='378 CHAPTER 21. 深度学习与伦理\\n义、能力主义以及顺性别和异性恋规范性在内的权力和压迫体系。从维持对权力动态敏\\n感的偏见视角来看，需要考虑数据中编码的历史不公和劳动条件（ Micelli et al., 2022 ） 。\\n为防止这种情况，我们必须积极确保算法的公平性。一种简单的方法是通过无知实\\n现公平，即从输入特征中删除受保护的属性（例如，种族、性别） 。但不幸的是，这种方\\n法并不有效；剩余特征仍然可以反映出受保护的属性信息。更实际的方法是首先定义一\\n个数学公平性标准。例如，在二元分类中，分离度量要求预测结果 ŷ在给定真实标签 y\\n的条件下，与受保护变量 a（例如，种族）独立。然后通过各种方式干预，以最小化与\\n该公平性度量的偏差（图 21.2） 。\\n图 21.2:缓解偏见。已提出多种方法，在训练流程的各个阶段对偏见进行补偿，从数据收集到对\\n已训练模型的后处理。参考 Barocas等人 (2023)和 Mehrabi 等人 (2022)。\\n一个进一步的复杂因素是，除非我们能够确认社群成员身份，否则我们无法判断算\\n法对某个社群是否不公平或采取避免这种情况的措施。大多数关于算法偏见和公平性的\\n研究都集中在训练数据中可能存在的明显可观察特征上（例如，性别） 。然而，边缘化社\\n群的特征可能是不可观察的，这使得减轻偏见变得更加困难。这些特征包括酷儿性、残\\n疾状态、神经多样性、社会阶层和宗教信仰。当从训练数据中移除可观察特征以阻止模\\n型利用它们时，会出现类似的问题。\\n21.1.2 人工道德代理\\n许多决策领域并不涉及具有道德意义的行为。例如，选择下一步国际象棋走法并无\\n明显的道德影响。然而，在某些情况下，行为可能具有重要的道德意义。这包括自动驾\\n驶汽车中的决策（ Awad et al., 2018; Evans et al., 2020 ） 、致命自主武器系统（ Arkin,\\n2008a,b）以及用于儿童保育、老年护理和医疗护理的专业服务机器人（ Anderson &\\nAnderson, 2008; Sharkey & Sharkey, 2012 ） 。随着这些系统变得更加自主，它们可能需\\n要独立于人类输入做出道德决定。\\n这引入了人工道德代理的概念，即一个能够独立作出道德判断的自主 AI系统。道\\n德代理可以按复杂性递增分为几类（ Moor, 2006 ） ：'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 393}, page_content='要独立于人类输入做出道德决定。\\n这引入了人工道德代理的概念，即一个能够独立作出道德判断的自主 AI系统。道\\n德代理可以按复杂性递增分为几类（ Moor, 2006 ） ：\\n1.伦理影响代理，其行为具有伦理影响，因此几乎所有部署在社会中的技术都可以\\n视为伦理影响代理。 2.隐含伦理代理，除了具有伦理影响外，还包括一些内置的安全功\\n能。3.显式伦理代理，能够根据情境遵循一般的道德原则或伦理行为规则。 4.完全伦\\n理代理，具有信仰、欲望、意图、自由意志，并对其行为具有自觉认识。\\n机器伦理学领域致力于寻找创建人工道德代理的方法。这些方法可以分为自上而\\n下、自下而上或混合型（ Allen et al., 2005 ） 。自上而下（理论驱动）方法直接基于某种'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 394}, page_content='21.1.价值观对齐 379\\n道德理论实施并层级排列具体规则来指导伦理行为。阿西莫夫的“机器人三定律”是这\\n种方法的一个简单例证。\\n在自下而上 （学习驱动） 方法中， 模型通过数据学习道德规律， 无需显式编程 （ Wallach\\net al., 2008 ） 。例如， Noothigattu et al. （2018）设计了一个基于投票的伦理决策系统，\\n通过从道德困境中收集的人类偏好数据来学习社会偏好；然后该系统总结并汇总这些结\\n果，以做出“伦理”决策。混合方法结合了自上而下和自下而上的策略。\\n一些研究人员对人工道德代理的可行性提出了质疑，并主张道德代理对确保安全并\\n非必需（ van Wynsberghe & Robbins, 2019 ） 。Cervantes et al. （2019）对人工道德代理\\n进行了最新的调查研究，而 Tolmeijer et al. （2020）则对人工道德代理的技术方法进行\\n了最新的调查研究。\\n21.1.3 透明与不透明\\n当一个复杂的计算系统的运作细节全部明晰时，我们称之为透明。如果人们能够理\\n解它如何做决策，那么这个系统便是可解释的。透明性或可解释性的缺失导致用户与 AI\\n系统间的信息不对称，这使得确保价值对齐变得困难。\\nCreel（2020）从不同的粒度级别对透明性进行了阐述。功能性透明性关乎系统算法\\n功能的知擂（即输入与输出间的逻辑规则） 。本书所述方法即在此层面详细介绍。结构\\n透明性则是指了解程序如何执行算法，在高级编程语言编写的命令被机器码执行时，这\\n种透明性可能受到阻碍。而运行透明性要求理解程序在特定情况下如何运行，对于深度\\n网络而言，这涉及对硬件、输入数据、训练数据及其互动的了解，这些细节无法仅通过\\n审查代码来获取。\\n以GPT3为例，其在功能上是透明的，其架构已在 Brown等人（2020）的研究中\\n描述。然而，由于无法访问代码，它在结构上不透明，同样，由于无法获取到学习过的\\n参数、硬件或训练数据，它在运行上也不透明。其后续产品 GPT4则完全缺乏透明性，\\n这个商业产品的运作细节尚不为外界所知。\\n21.1.4 可解释性与可解读性\\n即使系统透明，我们也不一定能理解其决策如何形成，或决策依据何种信息。深度\\n网络含有数十亿参数，单凭检查无法完全明了其工作机制。然而，在某些地区，公众有'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 394}, page_content='21.1.4 可解释性与可解读性\\n即使系统透明，我们也不一定能理解其决策如何形成，或决策依据何种信息。深度\\n网络含有数十亿参数，单凭检查无法完全明了其工作机制。然而，在某些地区，公众有\\n权获取决策解释。例如，欧盟通用数据保护条例第 22条指出，在决策完全基于自动化\\n过程时，所有数据主体都应享有获得决策解释的权利。\\n这种挑战催生了解释性 AI的子领域。在这一领域内， 局部解释取得了一定成效。虽\\n然无法对整个系统进行解释， 但我们可以解释特定输入如何被分类。比如， LIME（Local\\ninterpretable model-agnostic explanations, Ribeiro 等，2016）通过采样模型在临近输入\\n上的输出，构建一个简化模型（图 21.3） ，为分类决策提供了洞见，哪怕原模型不透明\\n且难以解释。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 395}, page_content='380 CHAPTER 21. 深度学习与伦理\\n图 21.3: LIME 。深度网络的输出函数非常复杂；在高维情况下，很难知道决策的形成原因或在\\n无法接触模型的情况下如何修改输入以改变结果。 a)尝试理解在白色十字处 Pr(y = 1|x) 为何\\n较低。 LIME通过探测临近点来分析网络，查看这些点是否被识别为 Pr(y = 1|x) < 0.5 （青色\\n点）或 P r(y= 1|x)≥0.5（灰色点） ，并根据与关注点的接近度对这些点进行加权（权重由圆圈\\n大小表示） 。 b)这些加权点用于训练一个更简单的模型（此处为逻辑回归——一个通过 sigmoid\\n函数的线性函数） 。 c)在白色十字附近，这个近似值接近于 d)原始函数。虽然我们无法接触原\\n始模型，但我们可以通过这个近似模型的参数推断，增加 x1或减少 x2将使 Pr(y = 1|x) 增加，\\n进而改变输出类别。根据 Prince (2022) 改编。\\n复杂决策系统是否能对用户乃至其创造者完全可理解，目前尚无定论。对于系统何\\n为可解释、可理解或可诠释，学界仍有持续讨论（ Erasmus 等，2021） ；目前这些概念尚\\n无确切定义。关于这一主题的更多信息，可参考 Molnar（2022） 。\\n21.2故意误用\\n上文提到的问题主要是由于目标不明确和信息不对称造成的。但即使在系统正常运\\n行的情况下，也可能出现不道德的行为或被有意滥用。这一节将着重探讨由于 AI系统\\n被滥用而引发的一些特别的伦理问题。\\n21.2.1 人脸识别与分析\\n面部识别技术极易被滥用。例如，威权国家可能利用这项技术识别和镇压抗议者，\\n危及民主的核心价值，如言论自由和抗议权。 Smith & Miller （2022）指出，自由民主的\\n价值观（如安全、隐私、自治和问责）与这些技术的潜在应用场景（如边境安全、刑事\\n侦查、国家安全和个人数据商业化）之间存在冲突。因此，不少研究人员、活动家和政\\n策制定者开始质疑这项技术的存在合理性（ Barrett，2020） 。\\n而且，这些技术经常未能实现它们所宣称的功能（ Raji et al., 2022 ） 。比如纽约大\\n都会交通局在面部识别的概念验证试验中 100%失败率的情况下，仍推进并扩大了该技\\n术的使用（ Berger，2019） 。类似地，面部分析工具常常夸大其能力，如声称能推断个人'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 395}, page_content='都会交通局在面部识别的概念验证试验中 100%失败率的情况下，仍推进并扩大了该技\\n术的使用（ Berger，2019） 。类似地，面部分析工具常常夸大其能力，如声称能推断个人\\n的性取向（ Leuner，2019） 、情感（ Stark & Hoey ，2021） 、聘用潜力（ Fetscherin et al.,'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 396}, page_content='21.2.故意误用 381\\n2020）或犯罪可能性（ Wu & Zhang ，2016） 。Stark & Hutson （2022）强调，计算机视\\n觉系统已促使面相学和颅相学这些无科学依据、被广泛驳斥的伪科学领域重新浮现。\\n21.2.2 军事化与政治干涉\\n政府因国家安全和国家建设的需要而投资 AI研究，这种做法可能引起国家间的武\\n器竞赛，导致高投资、透明度低、相互猜疑和恐惧，以及抢先部署的倾向（ Sisson等人，\\n2020） 。\\n致命的自主武器系统因其容易被想象并且多个系统正在开发中而成为关注焦点\\n（Heikkilä，2022）。同时， AI也加剧了网络攻击和虚假信息活动的风险，即传播意图\\n欺骗的不准确或误导性信息。 AI系统使得制作极其逼真的假内容成为可能，并有助于\\n信息的针对性传播（ Akers等人，2018）和大规模传播（ Bontridder & Poullet ，2021） 。\\nKosinski 等人（2013）研究表明，通过社交媒体上的“点赞”就能预测包括性取向、\\n种族、宗教和政治观点、个性特征、智力、幸福度、使用成瘾物质、父母分离情况、年\\n龄和性别在内的敏感信息。这些信息可以被用来进行操纵，例如影响选民的投票行为。\\n21.2.3 欺诈\\n遗憾的是， AI常被用作自动化各类欺诈活动的工具，例如发送钓鱼电子邮件或短\\n信，诱骗人们泄露敏感信息或汇款。生成式 AI能制造假象，让人误以为自己在与真实\\n实体交互，或产生能误导和欺骗人们的虚假文件。此外， AI还能提高网络攻击的复杂\\n性，比如制作更加逼真的钓鱼邮件或对抗目标组织的防御措施。\\n这揭示了机器学习系统透明度呼声的潜在弊端：系统越开放透明，它们就可能越容\\n易遭受安全风险或被恶意行为者利用。例如，像 ChatGPT 这样的生成式语言模型，已\\n经被用于编写软件和电子邮件，这些软件和邮件可能用于间谍活动、勒索软件及其他恶\\n意软件（ Goodin，2023） 。\\n人们倾向于将计算机行为人性化，并将意义投射到符号串上，这种现象称为 ELIZA\\n效应（Hofstadter ，1995） 。这种倾向使人在与高级聊天机器人交互时产生错误的安全感，\\n从而更容易陷入文本欺诈，如网络恋情骗局或商业电子邮件欺诈（ Abrahams ，2023） 。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 396}, page_content='效应（Hofstadter ，1995） 。这种倾向使人在与高级聊天机器人交互时产生错误的安全感，\\n从而更容易陷入文本欺诈，如网络恋情骗局或商业电子邮件欺诈（ Abrahams ，2023） 。\\nVélez（2023）指出， 一些聊天机器人使用表情符号本质上是利用人的情感反应进行操纵。\\n21.2.4 数据隐私\\n现代深度学习依赖的大规模众包数据集可能涉及敏感或私人信息。即便移除了敏感\\n信息， 借助辅助知识和冗余编码， 仍可实现数据集的去匿名化（ Narayanan & Shmatikov ，\\n2008） 。例如， 1997年，马萨诸塞州州长威廉·韦尔德的健康记录被一名研究生通过公\\n开选民名单解密，尽管这些记录已删除了诸如患者姓名和地址的直接个人信息。\\n因此，在医疗和金融等高风险领域应用深度学习技术时，采用以隐私为先的设计策\\n略极为重要。可以采用差分隐私和语义安全（如同态加密或安全多方计算）技术来保障'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 397}, page_content='382 CHAPTER 21. 深度学习与伦理\\n模型训练过程中的数据安全（见 Mireshghallah 等，2020；Boulemtafes 等，2020） 。\\n21.3其它社会、伦理及专业议题\\n上一节讨论了 AI可能被有意滥用的情形。这一节将探讨 AI大规模应用可能带来\\n的其他副作用。\\n21.3.1 知识产权\\n知识产权（ IP）被视为非物理财产，是原创思维的产物（ Moore & Himma, 2022 ） 。\\n实际上，许多 AI模型的训练基于版权材料。因此，这些模型的部署可能引发法律和道\\n德风险，甚至触犯知识产权（ Henderson et al., 2023 ） 。\\n有时，这些问题非常明显。例如，当语言模型以版权材料的摘录作为输入时，其\\n输出可能直接包含版权文本。在扩散模型中生成图像的情境中，也面临着相似的问题\\n（Henderson et al., 2023; Carlini et al., 2022, 2023 ） 。即便这种训练属于“合理使用” ，也\\n可能在某些情况下侵犯内容创作者的道德权利（ Weidinger et al., 2022 ） 。\\n更为微妙的是，生成模型（章节 12,14–18）引发了关于 AI与知识产权的新问题。例\\n如，机器学习模型的输出（如艺术、音乐、代码、文本）能否获得版权或专利保护？基\\n于特定艺术家的作品对模型进行微调以复制该艺术家风格的行为，在道德上或法律上是\\n否可接受？知识产权法凸显出现有立法未能预见到机器学习模型的发展。虽然政府和法\\n院可能会在不久的将来建立先例，但在撰写本文时，这些问题仍然未有定论。\\n21.3.2 自动化偏见与道德技能退化\\n随着社会对 AI系统依赖程度的增加，自动化偏见的风险也随之增加，人们期望模\\n型输出是正确的，因为它们被认为是“客观的” 。这种情况促使人们认为定量方法优于\\n定性方法。然而，如 21.5节所示，那些自称客观的努力很少不带有价值判断。\\n社会学的技能退化概念指的是，在自动化的背景下，人类技能变得冗余和贬值\\n（Braverman, 1974 ）。例如，把记忆等认知技能外包给技术可能导致我们记忆能力的\\n衰退。同样，在道德重要性高的决策中采用 AI自动化，可能会削弱我们的道德判断能\\n力（Vallor, 2015 ） 。例如，在战争中，自动化武器系统的使用可能使战争受害者被非人'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 397}, page_content='衰退。同样，在道德重要性高的决策中采用 AI自动化，可能会削弱我们的道德判断能\\n力（Vallor, 2015 ） 。例如，在战争中，自动化武器系统的使用可能使战争受害者被非人\\n化（Asaro, 2012; Heyns, 2017 ） 。类似地，老年、儿童或医疗保健领域中的护理机器人的\\n使用可能削弱我们互相照顾的能力（ Vallor, 2011 ） 。\\n21.3.3 环境影响\\n训练深度网络耗能巨大。 Strubell 等人（2019, 2020 ）估计，训练一个拥有 2.13亿\\n参数的Transformer 模型会产生约 284吨二氧化碳排放。 Luccioni 等人（2022）对训练'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 398}, page_content='21.4.案例研究 383\\nBLOOM 语言模型产生的排放也给出了相似的估算。遗憾的是，封闭和专有模型的增加\\n意味着我们对其环境影响所知甚少（ Luccioni, 2023 ） 。\\n21.3.4 就业与社会\\n技术创新历来伴随着工作岗位的取代。麦肯锡全球研究所在 2018年估计，到 2030\\n年，AI可能使经济产出增加约 13万亿美元，主要通过自动化替代人力（ Bughin et al.,\\n2018） 。麦肯锡全球研究所的另一项研究显示，从 2016年到2030年间，全球多达 30%\\n的劳动力（ 1亿到8亿人）可能因 AI而失去工作（ Manyika et al., 2017; Manyika &\\nSneader, 2018 ） 。\\n然而，预测固然充满挑战，虽然 AI的自动化可能导致短期失业，但技术失业被视\\n为“短暂的不适应阶段” （ Keynes, 2010 ） 。因为财富增长可以通过增加对产品和服务的\\n需求来抵消生产力的增长所带来的收益，而且新技术能够创造新型工作岗位。\\n即使自动化最终不会导致长期总就业的净损失，短期内可能仍需推出新的社会计\\n划。因此，不论对 AI带来的失业可能性持乐观（ Brynjolfsson & McAfee, 2016; Danaher,\\n2019） 、中性（ Metcalf et al., 2016; Calo, 2018; Frey, 2019 ）还是悲观（ Frey & Osborne,\\n2017）看法，显然，社会将经历重大变革。\\n21.3.5 权力集中\\n随着深度网络的规模扩大，训练这些模型所需的数据和计算能力也随之增长。在这\\n种情况下，小型公司和初创企业可能难以与大型、成熟的科技公司竞争。这可能会形\\n成一个使权力和财富越来越集中于少数公司手中的循环。最近的一项研究发现，在主\\n要AI会议上，大型科技公司和“精英”大学与中等或低等大学之间的发表差距在扩大\\n（Ahmed & Wahed, 2016 ） 。从多个角度看，这种财富和权力的集中与社会公正分配原则\\n不符（Rawls, 1971 ） 。\\n这促使了对 AI民主化的呼声， 目标是让每个人都能创建此类系统 （ Li, 2018; Knight,\\n2018; Kratsios, 2019; Riedl, 2020 ） 。这个过程需要通过开源和开放科学使深度学习技术'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 398}, page_content='2018; Kratsios, 2019; Riedl, 2020 ） 。这个过程需要通过开源和开放科学使深度学习技术\\n更广泛可用和更易于使用，让更多人从中受益。这降低了进入门槛，并提高了 AI的可\\n获取性，同时降低了成本，确保了模型的准确性，并提高了参与度和包容性（ Ahmed et\\nal., 2020） 。\\n21.4案例研究\\n我们接下来介绍一个案例研究，它关联到本章讨论的多个问题。 2018年，主流媒体\\n报道了一种引发争议的面部分析模型——被昵称为“同性恋识别 AI” （Wang & Kosinski,\\n2018）——其标题颇为耸动，例如 AI能判断你是否为同性恋：人工智能从一张照片预测\\n性取向， 准确度惊人 （ Ahmed, 2017 ） ； 一种令人惊恐的 AI能以91%的准确率判断一个人'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 399}, page_content='384 CHAPTER 21. 深度学习与伦理\\n是否为同性恋（ Matsakis, 2017 ） ；以及人工智能系统能判断你是否为同性恋（ Fernandez,\\n2017） 。\\n这项工作有若干问题。首先，其训练数据集存在严重偏差，不具有代表性，主要由\\n白人图像构成。其次，鉴于性别和性取向的多样性，其建模和验证过程也存在疑问。第\\n三，这种模型最直接的应用场景是在将同性恋定罪的国家中针对 LGBTQ+ 个体进行有\\n针对性的歧视和迫害。第四，在透明度、可解释性和价值一致性方面，据称， “同性恋识\\n别”模型似乎捕捉到了基于个人打扮、表现和生活方式的表面相关性，而非作者声称的\\n面部结构（ Agüera y Arcas et al., 2018 ） 。第五，关于数据隐私，从约会网站上获取“公\\n开”照片和性取向标签的伦理性引发了争议。最后，在科学传播方面，研究者的表达方\\n式明显旨在吸引媒体头条，甚至论文的标题也过于夸大了模型的能力：深度神经网络能\\n够通过面部特征判断性取向。 （事实并非如此。 ）\\n显然，用于判断性取向的面部分析模型对 LGBTQ+ 社群没有任何正面影响。如果\\n它真要造福社会，最关键的问题是特定的研究、实验、模型、应用或技术是否真正符合\\n所涉及社群的利益。\\n21.5科学的价值中立理想\\n本章列举了多种情况，展示了 AI系统的目标可能无意中或通过误用偏离了人类的\\n价值观。我们进而认为，科学家并非中立的参与者；他们的价值观不可避免地影响到了\\n他们的研究工作。\\n这可能令人意外。普遍存在一种观点，认为科学是或应当是客观的，这一观点被科\\n学的无价值观理念所体现。许多人认为，机器学习之所以客观，是因为算法本质上是数\\n学。然而，与算法偏见（第 21.1.1节）相似， AI实践者的价值观可能在以下四个阶段影\\n响其工作（ Reiss & Sprenger, 2017 ） ：\\n1.研究问题的选择。 2.收集与研究问题相关的证据。 3.将某一科学假设接受为问\\n题的解答。 4.应用科学研究结果。\\n在这些阶段中，价值观在第一和最后阶段发挥着重要作用是较为普遍接受的。研究\\n问题的初选和随后应用的选择，受到科学家、机构和资助机构利益的影响。然而，科学\\n的无价值观理念主张在科学过程中尽量减少道德、个人、社会、政治和文化价值观的影'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 399}, page_content='问题的初选和随后应用的选择，受到科学家、机构和资助机构利益的影响。然而，科学\\n的无价值观理念主张在科学过程中尽量减少道德、个人、社会、政治和文化价值观的影\\n响。这种理念基于价值中立的假设，认为科学家可以（至少在原则上）在处理第（ 2）和\\n（3）阶段时，避免做出这些价值判断。\\n然而，无论是有意还是无意，价值观都已融入机器学习研究。这些价值观多数被视\\n为认知价值（例如，性能、泛化能力、基于过去工作、效率、创新性） 。但决定这些价\\n值观本身就是一个带有价值倾向的决策；很少有研究明确讨论社会需求，更不用说潜在\\n的负面影响了（ Birhane et al., 2022b ） 。科学哲学家质疑科学的无价值理念是否可行或\\n者理想。例如， Longino（1990, 1996 ）认为这些认知价值并非完全是认知性的。 Kitcher\\n（2011a,b）则认为，科学家通常不是单纯追求真理；而是追求与他们的目标和兴趣相关'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 400}, page_content='21.6.将负责任的 AI研究视为集体行动的问题 385\\n的真理。\\n机器学习依赖于归纳推理，因此容易承担归纳风险。模型只能在训练数据点上受到\\n约束，而维度的诅咒意味着这只是输入空间的一小部分；无论我们使用多少数据来训练\\n模型，输出结果总有可能是错误的。因此，选择接受或拒绝一个模型的预测本身就涉及\\n价值判断：即接受错误的风险是否低于拒绝错误的风险。\\n因此，归纳推理的使用意味着机器学习模型本质上包含了价值观（ Johnson, 2022 ） 。\\n实际上，如果不包含价值观，它们就无法发挥作用：它们之所以有用，正是因为它们包\\n含了价值观。因此，认识到算法在现实世界中被用于排名、分类、过滤、推荐、标记、预\\n测等，意味着这些过程将对现实世界产生影响。随着机器学习系统越来越多地商业化和\\n应用，它们在我们关心的领域中的影响也越来越深。\\n这些见解对于那些认为算法比人类决策者更客观（因此，在我们认为客观性重要的\\n领域应取代人类决策者）的研究者有重要启示。\\n21.6将负责任的 AI研究视为集体行动的问题\\n推卸责任很容易。读过这一章的学生和专业人士可能会认为，他们的工作与现实世\\n界相去甚远，或仅是庞大体系中的一小部分，认为他们的行为无法产生影响。然而，这\\n种想法是错误的。研究者通常可以选择他们投入时间的项目、为之工作的公司或机构、\\n追求的知识、他们交流的社交及智力圈子，以及他们的沟通方式。\\n做正确的事情，无论这涉及什么，往往会呈现为一个社会难题；最好的结果需要依\\n靠合作，尽管对任何个人来说合作不一定符合其个人利益：负责任的 AI研究是一个集\\n体性的行动难题。\\n21.6.1 科学交流\\n一个积极的措施是负责任地进行交流。在多种社交网络中，错误信息比真相传播得\\n更快、更容易持久化（ LaCroix et al., 2021; Ceylan et al., 2023 ） 。因此，不夸大机器学习\\n系统的能力（参见上述案例研究）并避免误导性的拟人化非常重要。同样重要的是意识\\n到机器学习技术可能被误用的风险。例如，颅相学和面相学这样的伪科学实践在 AI领\\n域意外复兴（ Stark & Hutson, 2022 ） 。\\n21.6.2 多样性和异质性\\n鼓励多样性是第二个积极措施。当社会群体同质化（主要由相似成员构成）或趋\\n同（成员倾向于与相似者交往）时，主导群体往往会巩固并稳定其习俗（ O’Connor &'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 400}, page_content='21.6.2 多样性和异质性\\n鼓励多样性是第二个积极措施。当社会群体同质化（主要由相似成员构成）或趋\\n同（成员倾向于与相似者交往）时，主导群体往往会巩固并稳定其习俗（ O’Connor &\\nBruner, 2019 ） 。一种减轻压迫系统的方法是确保考虑多样化的观点。这可以通过机构层\\n面的公平、多样性、包容性和可访问性举措，研究层面的参与式和基于社区的研究方法，\\n以及个人层面对社会、政治和道德问题的深入了解来实现。'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 401}, page_content='386 CHAPTER 21. 深度学习与伦理\\n立场认识论（ Harding, 1986 ）认为，知识是受社会位置影响的。技术圈子的同质性\\n可能导致技术偏见（ Noble, 2018; Eubanks, 2018; Benjamin, 2019; Broussard, 2023 ） 。缺\\n乏多样性意味着创建技术的个体视角将默认地渗透到数据集、算法和代码中。 Broussard\\n（2023）指出，因为许多技术是由健康的白人、顺性别、美国男性开发的，这些技术最\\n优化地服务于这一群体，其视角成为默认标准。确保技术惠及历史上被边缘化的社区，\\n要求研究人员理解这些社区的需求、愿望和视角（ Birhane et al., 2022a ） 。设计正义和\\n参与式及基于社区的 AI研究方法主张，受技术影响的社区应积极参与技术的设计过程\\n（Constanza-Chock, 2020 ） 。\\n21.7前行之道\\n毫无疑问，人工智能 (AI)将从正面或负面根本改变社会。然而，我们应该谨慎对待\\n那些乐观的、由 AI驱动的乌托邦式未来社会愿景，并进行深思熟虑的批判性反思。许\\n多所谓的 AI带来的好处，实际上只在特定情境下对部分社会群体有利。例如， Green\\n(2019)强调，有项目利用 AI来提升警察问责制和寻找监禁的替代方案，还有项目旨在\\n通过预测性警务增强安全性，这些都被宣称为“社会良善的 AI” 。这种标签的使用实际\\n上是一种缺乏基础原则的价值判断；对一个社区可能是利益，对另一个则可能造成伤害。\\n在考虑新兴技术对社会潜在益处时，我们必须深入思考这些益处是否能够公平或均\\n等地分配。人们往往误认为最先进的技术方案就是最佳选择，这种观点被称为技术优越\\n主义(technochauvinism, Broussard, 2018) 。但实际上，许多社会问题根源于深层的社会\\n问题，它们并不适合用技术手段解决。\\n本章讨论了一些共通主题，我们希望向读者强调以下四个关键点：\\n1.机器学习 (Machine Learning) 研究无法回避伦理问题。历史上，研究者可以在受\\n控实验室环境中专注于其工作的基本方面。但现在，由于将 AI商业化的巨大经济激励，\\n以及学术工作受到行业资金的影响（参见 Abdalla & Abdalla, 2021 ） ，这种奢侈正在消'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 401}, page_content='控实验室环境中专注于其工作的基本方面。但现在，由于将 AI商业化的巨大经济激励，\\n以及学术工作受到行业资金的影响（参见 Abdalla & Abdalla, 2021 ） ，这种奢侈正在消\\n失；即使是理论研究也可能带来社会影响，因此研究者必须考虑他们工作的社会和伦理\\n维度。2.纯技术决策亦充满价值判断。尽管普遍认为 AI基本上是数学，因此是“客观\\n的” ，与伦理无关，但这种观点在我们考虑 AI系统的创建或部署时并不成立。 3.我们应\\n质疑AI工作所处的结构环境。大量关于 AI伦理的研究仅聚焦于具体案例，却未对 AI\\n将运作的更广泛的社会结构提出质疑。例如，确保算法公正性引起了广泛关注，但要在\\n现行的社会和政治结构中实现公正、正义或平等的理念可能并非总是可行的。因此，技\\n术本质上具有政治属性。 4.社会和伦理问题并非总需要技术方案来解决。围绕 AI技术\\n的众多潜在伦理问题主要是社会和结构性的，技术创新本身不能解决这些问题；如果科\\n学家想通过新技术带来积极变革，他们必须持有政治和道德立场。\\n对于普通科学家，这意味着什么？或许他们需要深思自己工作的道德和社会维度。\\n这可能意味着积极参与那些最有可能受到新技术影响的社区，建立研究人员与社区间的\\n联系，并赋权给这些社区。同样，这也可能涉及到跨越自己专业领域的文献研究。对于'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 402}, page_content='21.8.总结 387\\n哲学问题而言，斯坦福哲学百科全书是极为宝贵的资源。跨学科会议在此也大有裨益，\\n尤其是在公平、问责和透明度会议 (FAccT) 和AI、伦理与社会会议 (AIES)上发表的领\\n先工作。\\n21.8总结\\n本章探讨了深度学习和人工智能 (AI)的伦理含义。价值对齐问题关乎确保 AI系统\\n的目标与人类目标保持一致。偏见、可解释性、人工道德代理性以及其它相关主题均可\\n从这个角度进行考量。 AI可能被有意地误用，本章详细介绍了这种情况可能发生的一\\n些途径。 AI的发展对知识产权法、气候变化等多个领域都产生了深远的影响。\\n伦理AI是一个集体的行动难题。本章最后呼吁科学家们深思他们的工作对道德和\\n伦理的影响。每一个伦理问题并非每个计算机科学家都能掌控。然而，这并不意味着研\\n究人员就完全无需考虑或尽力减少他们所开发的系统可能被误用的风险。\\n/section习题问题 21.1通常认为 AI的价值对齐问题可以定义为“确保 AI系统的\\n价值观与人类价值观保持一致” 。讨论这种问题描述的不足之处。讨论资料来自 LaCroix\\n(2023)。\\n问题 21.2古德哈特法则指出，当一个衡量指标变成了追求的目标，它就不再是一\\n个好的衡量指标。考虑这个法则如何针对 AI的价值对齐问题进行改编，特别是当损失\\n函数只是我们真实目标的一个近似时。\\n问题 21.3假设一所大学利用过去学生的数据建模，预测“学生成功” ，以便支持政\\n策和实践的知情决策。思考在这个模型的开发和部署的四个阶段中，偏见可能如何产生\\n影响。讨论资料来自 Fazelpour & Danks (2021) 。\\n问题 21.4功能透明性、结构透明性和运行透明性可以被视为相互独立的。举例说\\n明，在某一透明度方面的增加可能不会导致另一方面透明度的相应增加。讨论资料来自\\nCreel (2020) 。\\n问题 21.5如果一位计算机科学家撰写了一篇关于 AI的研究论文或将代码推送到\\n公开仓库，你认为他们应对其工作未来可能的误用负责吗？\\n问题 21.6你认为AI军事化的程度有多大的不可避免性？\\n问题 21.7考虑到第 21.2节所强调的 AI可能的误用问题，分析深度学习研究中开\\n源文化的利弊。\\n问题 21.8有观点认为，个人数据是其所有者的一种力量来源。讨论个人数据对于'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 402}, page_content='问题 21.7考虑到第 21.2节所强调的 AI可能的误用问题，分析深度学习研究中开\\n源文化的利弊。\\n问题 21.8有观点认为，个人数据是其所有者的一种力量来源。讨论个人数据对于\\n采用深度学习的公司的价值，并考虑这种观点：隐私的损失是集体而不是个体所经历的。\\n讨论资源： Véliz (2020) 。\\n问题 21.9生成式AI（Generative AI ）将如何影响创意产业？你认为应该如何修改\\n知识产权法以应对这一新变化？\\n问题 21.10有效的预测必须（ i）足够具体，以便知道何时判断错误， （ ii）顾及可\\n能的认知偏误，并（ iii）允许理性更新信念。分析最近媒体关于 AI未来的任何预测，并'),\n",
       " Document(metadata={'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf', 'page': 403}, page_content='388 CHAPTER 21. 深度学习与伦理\\n讨论它是否符合这些标准。 讨论资源： T etlock & Gardner (2016) 。\\n问题 21.11有批评者认为， 呼吁 AI民主化过分强调了民主的参与性， 这可能增加在\\n集体感知、 推理和行动中犯错的风险， 导致道德上的负面结果。 思考下列问题： AI的哪些\\n方面应该民主化？ 为什么要民主化 AI？ 如何实现 AI的民主化？ 讨论资源： Himmelreich\\n(2022)。\\n问题 21.122023年3月，未来生活研究所发表了一封题为“暂停巨型 AI实验”的\\n公开信，呼吁所有 AI实验室至少暂停六个月训练超过 GPT-4的强大AI系统。分析作\\n者发此信的动机、公众反应及此类暂停的影响，并将此事件与 AI伦理被视为一种集体\\n行动问题的观点（第 21.6节）联系起来。 讨论资源： Gebru et al. (2023) 。\\n问题 21.13讨论第21.7节提出的四个观点的优点。你对这些观点持何看法？')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['56f74b11-7917-44d4-b51b-5dfa3d76aad5',\n",
       " '1a84c25d-1ff7-493b-8258-06aac5711ce6',\n",
       " 'dfae6e63-309a-4893-bcba-31c73c2f0a86',\n",
       " '0d0b438a-ed2b-4a2b-9912-3e422bec8908',\n",
       " '7a479cbc-c2fe-468e-808c-5a49e54d283f',\n",
       " '225a6e9a-3130-4de7-8e7e-3efae9d05d78',\n",
       " 'ea8bf32a-acb3-480d-8391-1f36c969dc84',\n",
       " 'fc9af2cb-6d79-45b7-9d96-ee53e638db3a',\n",
       " 'a093848e-595b-43be-8f97-13df3a53f109',\n",
       " 'f9e17048-0bf5-4a72-820c-7cc57613fdd1',\n",
       " '2f76b11d-3ffc-4dd6-88fc-e17453523f83',\n",
       " '77204da6-3574-485a-ad11-915df4e95aaa',\n",
       " '58d33213-8317-4fdd-93c5-dab88c98a304',\n",
       " '64e91136-b6b3-4006-b0d3-cadc5375ee00',\n",
       " 'e1c4ff99-13fa-4503-89ed-6593568ed11b',\n",
       " 'ec3fd155-c374-462f-be74-37b61899bbd0',\n",
       " 'b3c52a43-349e-4b42-8179-f55c738133e5',\n",
       " 'aa3f0c6c-16b1-4e61-a53b-233da2ad4b72',\n",
       " 'cd347bab-a7b1-403e-a3ca-cd27f6491ebf',\n",
       " 'bf8ccee5-34c3-432c-a4bb-aa92343b2a16',\n",
       " '815f11de-4bd8-41f2-8588-fc676b0ad044',\n",
       " 'e8014f40-8342-40e4-a95b-f18580835a91',\n",
       " '31a222a2-b5a7-4a2e-a65c-64a749363e57',\n",
       " '2ea5d4f6-2a65-4d3c-92e4-2e112bc01bf6',\n",
       " '164dc632-0ded-4277-a4a5-3c11a7ad000b',\n",
       " 'aeb53487-6cd0-4dfc-b61b-530197f9970c',\n",
       " '32665e63-df87-4bf2-ae69-bf0ef206d3a1',\n",
       " 'f63162ee-78ce-410e-8602-cb53af6c048c',\n",
       " '454e0ea8-8997-4487-b787-317806548f26',\n",
       " '1bffd48b-7203-4d8c-a0b5-a065af59677e',\n",
       " '97ece111-d5b7-4b07-a066-49a05394c5fa',\n",
       " '7a5106f2-b77c-4cd9-bb04-ebe01fec29da',\n",
       " '3bf52069-c9ea-4ccf-af34-f12066f7d90b',\n",
       " '454b790f-6195-43cc-a16d-b386323d7051',\n",
       " 'f56080e7-8979-4ab5-89a1-362a7b78f363',\n",
       " '0203bf5c-2ce5-4768-9f8f-86a3142933d5',\n",
       " '5fe2e361-119a-42a4-882d-f7eaa55c366b',\n",
       " '264c069c-586c-4818-81ae-25a1aa8fe109',\n",
       " '760c640f-b56c-4eac-bf80-504a1ab751a6',\n",
       " 'fce32b54-20ad-493a-9100-abd80f5c0e2e',\n",
       " '61bf4661-7106-45d4-83a8-3dcfae362fd3',\n",
       " '758d4a4b-9d5d-489a-82de-d698029488df',\n",
       " '3d21e86a-a5af-4d2f-8f41-bf46b45c6c92',\n",
       " '2693b3da-e9ff-48b7-9493-6ad6e5cf6c9b',\n",
       " '64be0867-ceac-476d-9253-6271cc4a9e56',\n",
       " '489e6a22-a86e-42d5-9df9-cd2da1978e9b',\n",
       " 'fc73b08f-8308-48f8-87a7-55068df62922',\n",
       " '7b4a9a20-87c6-46e2-a0b9-a2fda45b33e4',\n",
       " '6f61562d-0604-4ae3-a9f8-fc2bba1b0a07',\n",
       " '859ed8f2-e4c1-46e2-995d-4269eaf86b40',\n",
       " 'b4ce5d7d-48df-4506-99a8-ed60e591fda8',\n",
       " '48fffbe2-2b55-4f0d-9afa-0642089179d6',\n",
       " '0e6a724d-13c3-4791-8e77-5ac725b7e5f0',\n",
       " 'f1fae55d-7ccc-4832-b853-7028b7b80c60',\n",
       " 'dacf2edc-fb3f-4d7a-a54c-32a2fb8545e7',\n",
       " 'aeb2767b-f203-48c3-b718-7fd1cabd0b1e',\n",
       " '85e22ec9-062a-4fef-984f-078cd2051c76',\n",
       " '3d20b321-07b2-4744-94de-64e5a4f3c9cc',\n",
       " '729d8906-cb27-4f65-a142-704844578208',\n",
       " '82947030-ecfc-4963-9267-3f676b1dcbaf',\n",
       " '9487e2cf-f54d-4ca1-982d-8a443c86a358',\n",
       " 'ac3057ee-eb40-4234-8f4c-e1503cf26327',\n",
       " '88dfbd7a-0186-4ef3-9089-92065ad037db',\n",
       " '02590391-7e18-4d63-8199-f118054d610e',\n",
       " 'ae1a024b-b2a9-4d7f-af42-73823d9fb441',\n",
       " '5206403c-e416-47ff-abfc-f90f7fa3f4ac',\n",
       " 'f472d1a2-bf54-460b-a152-02c131eedd8a',\n",
       " '4c6e342a-aba4-475a-a841-c4957697ca65',\n",
       " '86ebf840-2659-4953-8510-892e343029fe',\n",
       " '2bd08d85-f566-46e2-81c0-c3b2436a50f3',\n",
       " '571e8ea2-00d8-45f4-bdd3-1d07028f77d5',\n",
       " 'f7c243ac-ae3d-4ca6-90d7-ab8b87d45652',\n",
       " '5a7a0dad-0509-4298-bac2-92d561561a6e',\n",
       " 'df5d19c4-9c75-4baf-9a9d-e0a3c86a5c56',\n",
       " '15f3f69f-bc38-40d5-9721-8eda092ffd0b',\n",
       " '35ccec1a-540a-49e7-b896-62e7f6e58e20',\n",
       " 'f2ec0fe9-1d03-49a5-a471-259223a9269f',\n",
       " '0581ebb4-0e6a-4e24-a11c-46fbb4069f5b',\n",
       " 'e8953888-9cb5-44d0-8ed4-4eed0f4f57a6',\n",
       " 'a6579f57-0473-4667-9359-8f843fa06855',\n",
       " '77a9820f-b3f8-49ef-b681-51b0fc55bd11',\n",
       " '50e898d0-cac4-4f07-a63c-f6899a5b86dd',\n",
       " 'e61d7393-82ea-4912-ab45-1e08c7e9de8c',\n",
       " '0a31986b-909e-4a26-9781-21535567e8ba',\n",
       " '14ed32ce-e161-4fcf-995e-80ef49c5bc72',\n",
       " 'de048ea5-1f3e-4954-b83c-1b098f3ef81c',\n",
       " '890ab85a-0425-4a42-b9ef-d366a21510fb',\n",
       " '5c444eca-06af-4d92-a9b1-9f0b7e0d4cd2',\n",
       " '8110f8ca-652d-43f7-a64e-e9fb90d2d10a',\n",
       " '98b7cf19-d9e0-4722-8871-512b394725f7',\n",
       " '6c708811-5367-4e47-969a-16bd94469825',\n",
       " '5231cc0a-0e67-4608-975c-d05cc56f328b',\n",
       " '4ef54c1a-d857-4624-ba72-c19fec2db6b9',\n",
       " '626195e7-32af-4341-a783-f821bff0b066',\n",
       " 'e231ccbe-e26c-44be-a465-fed649babd9e',\n",
       " '8017f793-48e9-4fec-8f40-be35d9f97b33',\n",
       " 'fb5a02cb-ba81-426b-8924-956fd7a2f446',\n",
       " '92770b3b-b6a4-42b9-8b14-fe86dfe9b594',\n",
       " '6f15841a-d88b-4aa4-becd-93e619aee993',\n",
       " 'e46d5234-0d71-4289-b0fb-187746b1aaba',\n",
       " '06a28a46-9fbf-4722-a3bb-d94c789998a4',\n",
       " '63f2e53d-2704-41ab-8778-127f156351d3',\n",
       " '4adaab90-6002-4936-907e-aefc3279fa20',\n",
       " '8ca58a53-0ea7-45c5-a651-932e36bf5ca4',\n",
       " '6ad27450-506a-413e-bbe3-d37d5857e3be',\n",
       " '3e65c1e8-2777-4bf0-b606-cce20bb04f83',\n",
       " '16b85649-0a0e-47d8-a4db-91da5be87561',\n",
       " '21636369-810f-4d65-8d52-6db59a47cfbf',\n",
       " '09a642d6-7cb7-4c13-ad2f-5e72a4dc9ee5',\n",
       " 'e54e2538-b575-49b3-82c7-7c4ecd2246a8',\n",
       " 'd80592ff-5c9a-4281-9a0c-bc7e1f9bcfb3',\n",
       " '7a13b541-ff7c-45dd-bbd5-f909e47898fc',\n",
       " '477ce479-8196-4432-a9f8-f2c6a31fe77d',\n",
       " '4df9702e-3cdc-40dc-ad7a-eb55e0936651',\n",
       " '48494e74-c278-4127-93c5-89d135c832fc',\n",
       " 'c4f2059f-1255-4432-81e0-0b4563f966fd',\n",
       " '681ce1b9-cbd6-4b96-9572-049bc0cbd179',\n",
       " '4e3ef6a8-321d-4608-97ee-e81722894fc9',\n",
       " '1ec5cfdf-c61a-48b4-896e-272ba618cb2f',\n",
       " 'b1aecdd0-1dc8-47ab-86ae-59bd348311a6',\n",
       " 'f78118fa-d788-4dc2-a22a-34fdda108ec8',\n",
       " 'ed77f1ad-65a8-4336-89c7-0e1601854823',\n",
       " '92678e9e-da1f-4bf2-8217-090ac6578b1f',\n",
       " '2a0ecf7e-3454-4993-9547-1d0ed229156d',\n",
       " '64791c28-3361-4efb-b91c-ff35dbd3c605',\n",
       " '9e039aee-e189-4542-81a7-9c7ddff659aa',\n",
       " '1e566586-911e-406e-9912-6bb9844b2955',\n",
       " '1ffa0fe2-aeda-472c-871d-50feb07bab76',\n",
       " '1b02d47b-6bdb-463b-b2ee-1586854edc5b',\n",
       " 'b6afc98b-7d6e-4713-9fc7-f52ce20fd19a',\n",
       " 'e14140ce-bcdf-418f-b43c-755b1e95df51',\n",
       " 'd04c3171-4a98-4c6d-a944-bf54c77e6153',\n",
       " '080a4a2f-af0b-4b28-9a59-db927fecb5ac',\n",
       " 'a7b10d30-da32-4580-b49d-1685a2dd2071',\n",
       " 'fbfd9770-e2c2-4d13-af51-59cadf8615b6',\n",
       " 'ce3c8c22-db01-4bfa-82a6-dcd99bc3a0e8',\n",
       " '6442c9ad-ef75-42db-9400-43f473c54e6c',\n",
       " '96434ced-93d4-484a-8a05-a3f47611d33e',\n",
       " '231206a8-1d6a-4af7-aba7-3d89055a3119',\n",
       " '4ecccf36-a67d-4148-a7ee-26732e8b07f7',\n",
       " 'a615a245-abe9-4c4a-9e67-94d673595f23',\n",
       " '557a3abc-5cae-45a0-8df1-0ee769c9ecb3',\n",
       " '64ff1853-460d-48a2-9515-846b1bd94c96',\n",
       " 'ab70b1d3-90f8-4cdb-a025-0259e7869f4b',\n",
       " '151d6713-3c97-4ea1-bb09-52f6a02a6c5c',\n",
       " '545c3a92-ce91-44b1-83a8-ee22e482c424',\n",
       " '2861de09-8434-430c-ba17-02bcd40dd4a1',\n",
       " 'b97c96c9-fa9b-4ef8-8858-6a1e47df8c9e',\n",
       " '5fb72839-a31c-441b-92b1-2846cd6f98cb',\n",
       " 'b254075f-6627-4fea-ac19-623aacd38aef',\n",
       " '02307e96-ab81-4be7-8901-c8c26f1213de',\n",
       " '32b86517-fe1e-40cb-96ad-53f035b13ef8',\n",
       " '41a473c1-dc51-4370-ba4f-d47ead11b6ed',\n",
       " 'cf148f52-7614-49e8-a612-cc2106183fdf',\n",
       " '2e43a44f-ef43-4897-b3ce-fe5c7cb98b2c',\n",
       " '9ed8b122-9ee6-4870-8ef2-40db900ae700',\n",
       " 'c3efd5c3-d74a-4861-9af9-32acee2f38a3',\n",
       " '831718be-3aab-40df-88fe-ee01a7a2b128',\n",
       " 'a9fa2976-f915-4cd3-85b1-c8fd79169a47',\n",
       " 'd448a924-8bfb-4d77-8f82-d785168358ca',\n",
       " 'cc62b804-e843-40f3-972c-970dae6e025f',\n",
       " '9eda956c-f607-4c4d-9136-54953b84e8bf',\n",
       " 'b923bca4-40d3-4e74-887b-92755bb932a3',\n",
       " '41d68ecb-051b-489e-9f3c-8505762de843',\n",
       " '88a1ad55-c8ca-4edc-aaf0-0ea73ac20677',\n",
       " '59d1ba00-da52-4ccb-89ee-793012a2d173',\n",
       " 'e1d89d13-3e2a-45ca-81d1-4553d753d5bc',\n",
       " '1b11ed65-e09e-4287-ad0b-104a0b06826b',\n",
       " '41756c4c-2270-409d-967c-711e83155e89',\n",
       " '0bde8dbe-1deb-40c0-96e3-231bb67e2f97',\n",
       " '786f3e35-6dcd-451a-b7ff-27ec4aa71a81',\n",
       " '2af8487f-4ed1-4c95-ac65-d4f0364963d0',\n",
       " '306c4185-2e41-477c-9d01-3f5fca37a753',\n",
       " 'd560cecf-607c-4259-a2fc-1d7f72b32e31',\n",
       " '8184dc39-e333-44cc-b252-430e0138911d',\n",
       " '8d0539cc-a9db-4883-8b89-3d2ab5d32e5a',\n",
       " 'eaa6cd0e-4dc2-4a4f-946f-f3627982b88d',\n",
       " '67cf4832-9e3a-4470-938a-a1cc71850283',\n",
       " '2d8c2ad2-4618-4ca5-9b94-22a8d686c5fc',\n",
       " '23e0b736-658d-4b66-84b0-439cb45469c4',\n",
       " '38cb5db9-80c0-4e52-b27b-133eba528528',\n",
       " 'd27b7deb-f437-4930-88f3-7e2da9db6ea5',\n",
       " '1c320264-f40b-4f5d-8c3d-3c7b3de43c4d',\n",
       " '50e0300f-0971-4023-bf35-c33c6490e88b',\n",
       " 'ea0f7b00-0958-404c-b554-70a9a4866947',\n",
       " '37e0436d-a509-433e-b9d7-27bd40a3e4c5',\n",
       " '65eb81fe-46da-4b78-99ef-d96fb516d8e0',\n",
       " '3dbf3ce4-5efe-4175-b866-5bdac3a38598',\n",
       " 'c3c290c2-5fd6-4525-8894-20d5a8443f09',\n",
       " 'ed833c77-1ee9-4876-8a6d-8229b3ff551d',\n",
       " '60f00fe2-7c7e-41ba-be7d-740bb11a1c28',\n",
       " '03a67789-fa53-4aaf-a4c0-88f549bb1c78',\n",
       " '4bf7896a-753c-4d48-9f70-f9adccb49e6e',\n",
       " '455571f7-e8c2-4171-a116-9d1b2e8b5af3',\n",
       " 'ee708c2e-3429-4765-8342-f2444550b2eb',\n",
       " 'fd383b68-5e7e-457b-b0b0-5f3e30e11430',\n",
       " 'c21ccee7-ebfa-4dca-9601-87176f481206',\n",
       " '4ff5ea7d-6f0c-42a2-8184-f5f9ec5dda4d',\n",
       " '2a67ff60-f4f0-423a-a571-3127ca5c9b69',\n",
       " '39c6528f-da1c-41a1-b857-ce97a9e77614',\n",
       " 'a5ca2354-c38b-4256-a7e6-c84960eb6b29',\n",
       " 'd1e05bc3-5d56-4c30-939e-2f035a2fbd52',\n",
       " 'd693b54b-e8cc-4d3b-aeb5-8cce2d282631',\n",
       " 'f019229a-8324-420c-9613-4d4c57341c78',\n",
       " '9aa7de01-f553-4f55-8fc3-ec1abfb792e1',\n",
       " '4b60466d-3552-4f1e-951b-ab46de953435',\n",
       " 'c4cfb5fc-12c3-4c9b-859a-fc00355e41e4',\n",
       " '3ad32cdc-fe64-4a68-bfdc-7815f461cb77',\n",
       " '3f5b744e-bd0e-4e4a-953c-b4864fc1b192',\n",
       " 'dc94ea53-caf8-4318-bacc-18e19ac84019',\n",
       " '222c751f-3fc1-4d6f-8df1-97e2f6186c06',\n",
       " 'b6947276-b4b1-4fb7-a901-a19b4629378d',\n",
       " '57104701-7835-4a8d-8421-b747372b6bb3',\n",
       " 'ec88dc6b-9e14-4121-a763-91676d043a12',\n",
       " '7c02ac29-77d9-4ec8-bb4a-4cbfc0729bc2',\n",
       " '5187b325-4536-4080-8406-9a9efb7b5d98',\n",
       " 'ca591b33-938c-4936-bf8b-454b4df5e380',\n",
       " 'f1fa63e3-e3a3-48be-904d-4db1b4f823ac',\n",
       " '0884521f-cf46-4131-b73f-a76b2adb8f28',\n",
       " '4277f884-638a-410a-87b0-5a8a561ab28c',\n",
       " '6b1d4356-fa2d-48b5-943f-f7dcf316bbfa',\n",
       " '00fb9809-a4bd-4b50-91f7-52eb5130b208',\n",
       " '45b058fb-e017-403e-8b8f-fff563ffab04',\n",
       " '24d50167-4c23-4081-a4ca-89f1f70be9c2',\n",
       " 'd75322c6-27d2-4e43-a69c-e8d01f2ecef8',\n",
       " '39695e75-851f-4de4-a73b-4e0bc30149bf',\n",
       " '1cf32e72-0222-4e88-8fe5-9974a5dbdac7',\n",
       " '3bff8a0a-76ae-4eea-a259-d21d0056035a',\n",
       " 'a15583f1-7cd0-40f3-967c-a739eeadc01c',\n",
       " 'c7648427-1d99-4357-b634-a6f2c9b788ac',\n",
       " 'cdceed57-b1d3-46c3-9040-8d9cabc86005',\n",
       " 'f0ca8c6c-0a8e-4993-8374-a705d260f31c',\n",
       " 'a1b42fad-ceef-4a11-846a-65f99e6ae3aa',\n",
       " '05bbcb3a-384e-4c6d-9dd6-c70a487d31cc',\n",
       " '948210c2-29ae-4cd5-a721-c23c88886bcd',\n",
       " 'f727425b-7668-4458-9995-1a6a5bc6f438',\n",
       " '05f62efd-1fd4-4876-b839-87e27570f14f',\n",
       " '23535360-45f4-492b-b45c-98a11166c549',\n",
       " '7d5591b5-fc7e-4753-9633-7fa2010c0610',\n",
       " '0f403ab4-8a40-49dc-be84-56cf40c32cae',\n",
       " '652a2bc2-f904-4903-9e68-023f80a689f2',\n",
       " '7bfa0c09-aee9-43fa-bb8c-3f1e374b24e1',\n",
       " 'f287bc73-65ca-4898-b142-3194b88d1f2a',\n",
       " '4a6ae19f-7614-4a50-9d10-5962612055f1',\n",
       " '6e6a7e53-7430-454a-b6b8-971b514ee143',\n",
       " '0b10d9a6-2948-4888-9f32-84ad08c49c1a',\n",
       " '8e4511da-9d0e-407b-b040-4dcf2e5555ce',\n",
       " 'c7616ae7-94bc-45d3-a4dc-a7e48cb6f9b7',\n",
       " '20003ebd-0194-4bf5-a140-99fce554eadf',\n",
       " 'd6d29e54-15c5-40f7-836d-c35e4f40a31e',\n",
       " '2bbbbb25-4a7d-420e-8de6-622c675beddc',\n",
       " '52e0576f-29c2-47c9-b54d-fda62b620502',\n",
       " 'ce7eb810-1ca1-4338-9397-8a2a195a4cdb',\n",
       " '95c48e4a-956f-45bd-b8be-de090f5064c4',\n",
       " '5df6e1a4-25d4-478a-bf93-5c46caae0a3a',\n",
       " '77b3a069-1932-45f3-80b9-0f587cb0227b',\n",
       " '7de884ef-8f7c-44d8-a0d0-c7c848013922',\n",
       " 'f71fde10-2c58-403c-a847-d7562b6836a3',\n",
       " '4ac5deb0-8280-4732-89b3-b0e5fa1555f2',\n",
       " '546575a0-3fa9-466f-8974-9d39b7b9ee6c',\n",
       " '740eceed-d41d-40a1-b150-b721886f71cd',\n",
       " 'ed3df673-49de-4b37-ba32-545f2de7dfef',\n",
       " '6f47a4e0-8220-4895-8d9b-abc07377600b',\n",
       " 'e07ea45f-9f29-4492-8754-b5842db31a0d',\n",
       " '030ad172-2006-4189-8a11-0552e84298e0',\n",
       " '13d54204-ed65-4dc7-a8ee-ad3aff0d7eeb',\n",
       " '8f298810-7008-46af-8781-5f3c3febded2',\n",
       " '35888cda-400c-49bf-a020-9c9167d8197b',\n",
       " '8e81d42f-f4cb-445c-a2eb-a3d6875eb5ca',\n",
       " 'f0301e94-8c1e-4486-9cf2-87b270d0dc13',\n",
       " '328808d5-227f-4f6e-89c0-8e956593d7ba',\n",
       " 'c710d886-9532-4d7a-b3bf-41ca4192ea26',\n",
       " '8c2e9ab4-26bc-4eed-abb1-b8cb22be14ae',\n",
       " 'c67312f9-48ac-4c9d-b619-194dbe013142',\n",
       " '0b5fad12-ecf3-4a45-9c82-54aca466e14d',\n",
       " 'c3339a9b-1a93-4102-bc63-8b9465dda4fb',\n",
       " '890c2144-d099-4b73-abbe-8d77916a6c48',\n",
       " 'f56e04e3-0b9f-4d15-89f9-68bd40351ba4',\n",
       " '32a8daaa-845e-4640-a3f0-ee42a2ca41bf',\n",
       " '3cac247b-5f3b-4cd9-bab4-7d3377893fb4',\n",
       " '82bc183f-227f-4905-a1ff-f266f993fc25',\n",
       " '8c5f97ce-67b2-4556-a636-de6ceabc73d1',\n",
       " '778c20bb-e842-4078-a16c-b0d03250cd7a',\n",
       " 'fd3b5d45-1359-48a3-8009-744c71b71f6e',\n",
       " '441de9d3-5fdb-4108-9677-fb00e84e0cbf',\n",
       " '0b106ae8-f8fa-4a38-b21b-f90c454eb4e3',\n",
       " '830514e8-24e0-4b4a-b02b-7e637540089a',\n",
       " '1fb7ee69-a6b3-4e36-829d-53525f02b3f7',\n",
       " 'b7686efb-2b49-46dc-9726-76fa36ee3810',\n",
       " 'ea214cbd-c2f1-4046-a89f-d0a37fb78837',\n",
       " '95f84390-b158-41eb-a282-dd7df72d5e03',\n",
       " 'cdc0c1af-1dab-47e0-b0fa-69ba3a0cd0e3',\n",
       " '3d19cba3-f022-4771-add4-88957cd4327a',\n",
       " '7d5f99d3-143d-47ce-903d-c5f92506fb5d',\n",
       " '16340dbc-f263-4872-9fcb-41e558deba86',\n",
       " '2b39e9ec-74c5-4ccd-9003-744c081fc41d',\n",
       " '4d19f289-cd17-4f51-a2e5-e8e11df7805d',\n",
       " 'b01b82de-8f8a-4744-8895-d58b415c1786',\n",
       " '9408b7aa-9f5c-4a61-bbf7-cbaf403055cd',\n",
       " '3a540fac-bf6b-4906-8096-a29a6e87a590',\n",
       " '3804d8f9-241f-4aa5-aaa1-3c75c8b618f6',\n",
       " '28d35a69-4eaa-4e20-8ec4-d70299532678',\n",
       " 'ac2e44c0-9437-4c94-88be-82a23cdb5e8b',\n",
       " '4a27adfe-c038-4bc5-9c39-f04d5aeffce3',\n",
       " '7aa76981-4c7e-4ff3-acbb-22232b2e91c1',\n",
       " 'e2efc469-ebc3-469f-8577-74accc5cbe48',\n",
       " '0c500e3f-d732-47fe-ac48-69e2a47c3a86',\n",
       " 'd5671a52-6529-475f-80fd-7eb7b0981c76',\n",
       " 'f8ff706b-8e55-493e-91f9-1cbf7c770da4',\n",
       " '79c7da57-09ad-4d6d-8938-56b4d5d73aa4',\n",
       " '934296e7-0e2d-4668-a12e-b5d86d6d8b20',\n",
       " 'ef339fe8-b68e-43a6-8e74-9585452c6a53',\n",
       " '9f7de404-7c79-4999-8544-1da9b39d8d38',\n",
       " '9e1dd51c-488e-489f-a70d-d505377fedf7',\n",
       " '82b5bb24-d99b-49e1-92dd-722f5fb64df8',\n",
       " 'ac370581-d3c3-48cd-ab8d-b315ada07dbc',\n",
       " '6925c536-f5c3-4e82-b2b1-7a141cff0098',\n",
       " '10c5726f-7186-4806-9422-a23d9c0769b1',\n",
       " '483f8fc4-8246-4e36-b660-8304f1fc782d',\n",
       " 'f0760a8c-3311-4864-8f3d-9b81c8bf91ef',\n",
       " '44b6d736-5401-4913-a8be-a44c89fae8a9',\n",
       " '0541bb35-8dbd-49e4-ad5b-79af1e13599f',\n",
       " 'bd2a6388-9299-49b1-813b-d7fb2627bcee',\n",
       " 'b313e814-c918-40c9-88e8-d267f9f99b3d',\n",
       " '43ca472f-0c8f-47fd-ab9f-7eb478386460',\n",
       " '0fa3da53-a7d5-4639-a28f-759ad8d84f12',\n",
       " 'f93b3d32-e43a-46df-9f75-e846e3c81cd8',\n",
       " '5a4aad0f-7ffd-4838-8428-4a547624cbbd',\n",
       " '5840920c-93a0-464d-8d4d-83f66f48101c',\n",
       " '499517cc-1cb2-445b-a711-5fabf7e3d155',\n",
       " '34875f72-ed5a-458a-8673-92087bb78a27',\n",
       " '910e627f-09ad-4458-b2dd-e1c213d63d9d',\n",
       " '1b03ebc7-2f10-497f-91db-46c9af99f9e2',\n",
       " '627f8692-ff51-446c-8ee9-b2e9ae108475',\n",
       " '5ffced4b-79e1-4c9e-a25a-3c004c3a588e',\n",
       " '169cc7db-aa18-4c37-aed9-d0cf08085cc7',\n",
       " 'eca7b46d-814f-42c4-8ff4-2e6da8be7580',\n",
       " '39e3596a-58c4-4557-b8c2-ab6cc352e0c2',\n",
       " '9d08dc67-27a3-4b75-96c5-f19eb9a27f74',\n",
       " '78b27dad-3ebe-4ffc-a654-31fca4663611',\n",
       " 'c9fe17d5-066a-4c43-a481-70b514274cbe',\n",
       " 'af06d520-7929-475d-85fe-c162509ad935',\n",
       " 'e67712c2-6eec-49e0-b166-547f2d65b436',\n",
       " '8da40a04-9a7b-4068-afd6-9af31b651bb0',\n",
       " '2fc4f31f-3b65-4c01-953e-b00343e0cb47',\n",
       " 'f497f876-9895-4146-a483-5923c417d96e',\n",
       " '1f598e94-7876-4859-bf8a-6fd915e178bb',\n",
       " 'e327c5bf-beea-4e38-9b4e-a1dd08eaceb2',\n",
       " '9208fef9-3e4c-4bec-b656-538c21ce067f',\n",
       " 'f698e852-5384-4461-a3c2-8a61825ab5f0',\n",
       " 'b6d2114b-c4de-47b9-8da2-d427d6dca4f5',\n",
       " '83977c4c-9bcc-4b2b-b3fb-0ed111748ca3',\n",
       " '5ea9c3fd-b262-4bcb-b9c5-e54d265d08da',\n",
       " '98a95402-8caa-48fd-a5bd-9143c309cef5',\n",
       " '120937d6-1c24-44c5-8197-16cb59c01e10',\n",
       " '28b533be-0bf2-4755-94e3-6471101447bc',\n",
       " '8caf4183-47b6-4b1d-b67a-9d9b0ca507f9',\n",
       " '05044102-f5a8-4791-b5fe-3a8bb91ae6e7',\n",
       " '8b1e04d1-a7a0-447a-846e-ae41cf40dedb',\n",
       " '11e8b3d2-dc56-4a2a-99a2-b223caff86dd',\n",
       " '6280f4b6-96e0-4446-b93e-77791c1e27d3',\n",
       " 'dbb4a0cd-2244-4fc2-9634-0e9da3b73888',\n",
       " 'a068e6d7-4d59-4ae1-bc09-b19cd0e46d79',\n",
       " '041f35a4-a076-42f7-923d-e6697eedc96b',\n",
       " '6b1fa2d2-4171-44c6-901b-330dc2d3af3c',\n",
       " '556521ca-e92c-45d4-8a38-5154d4f9cdcc',\n",
       " '436b6be0-5a76-4e18-8618-81861eb8a588',\n",
       " 'baf6e9cb-7767-44dd-a255-1907334c5417',\n",
       " '7291208c-705c-4be0-b735-4b24b689c077',\n",
       " '73d44b90-9c2b-41e0-a0c3-627924799280',\n",
       " 'f1acc5b9-bf9a-4438-b2ac-1ab70abdf004',\n",
       " '9ec64f64-5044-4182-9708-4d5905aa7371',\n",
       " '0f37f23d-8819-4194-b62a-fd5707690f93',\n",
       " '97c3c460-5060-4af4-a1ff-22457368e8c0',\n",
       " '203cc57e-3a0a-48fd-ac61-aff325c708ab',\n",
       " '2a58a594-bb84-48e4-8365-c5e21330560d',\n",
       " 'c6081d11-2bad-48b3-8e22-858e88fdbddd',\n",
       " '3be502bf-284f-4661-971e-82f2d9244089',\n",
       " '5e783b86-f6c4-4282-b8aa-5850b829123a',\n",
       " '7b4e04da-6072-4e16-bac9-f15d12ab13e2',\n",
       " '1b827998-9a24-4c53-8a32-4e9ff2333d9d',\n",
       " '459903c3-a5f2-443d-8de4-61f23b6669c6',\n",
       " 'ef7f25eb-1b69-43e5-b0db-661f9bd9b256',\n",
       " 'ccbe05a7-4f6e-4286-9319-f8693001ba82',\n",
       " '478328d3-d92c-46a9-b7dd-ed0ab82eb81b',\n",
       " '0b0be404-6267-45f9-b319-1edf7aea6a01',\n",
       " 'd13254f0-67ef-4f1c-9a21-c1af22cc0b12',\n",
       " 'c2bf8b8f-6b42-42df-89f3-99718368c450',\n",
       " 'f3a36153-0fc9-49c1-9d5a-aae17fb74478',\n",
       " '3ac5e488-7b50-4b53-ba6c-111152d9d788',\n",
       " 'f2406bae-c269-4239-8c13-516feb90e04e',\n",
       " 'bb089993-4bc5-4ecb-8bae-51638d4f8fcf',\n",
       " '7e9472e0-cd83-44bf-96ce-1b29a161933b',\n",
       " '32db00da-a65e-47db-96d2-7b0bbdf49d59',\n",
       " 'fb35b602-697d-4a26-968f-b1c4a58b8aa5',\n",
       " '2f85abec-f7cf-4b16-bf09-7bc8ba9be2fa',\n",
       " 'ce73194b-1fa8-4d12-a3e1-f8f6e6ca90b4',\n",
       " '056c8e74-4301-45e8-bc7b-46a81bde3697',\n",
       " 'c75890c0-df7a-4daf-936d-67e81a12e009',\n",
       " '6be50e63-e108-466c-9696-a8d84db2d489',\n",
       " 'e4a82c29-0f2a-4e0a-930a-6545b4c0e046',\n",
       " 'f2d87c32-2f37-4fef-8108-0d8e311c5564',\n",
       " '4db35f3e-69c8-4fdf-84f7-9a4bd7195b5f',\n",
       " '2f69020d-28e7-4375-ba89-adb06ed657d9',\n",
       " '25175568-49ad-4108-92c0-49a2dc480f78',\n",
       " 'b90e20a5-5db0-42f4-9620-5a130d06678f',\n",
       " 'de28d510-f1ed-4e8e-96bd-b734fef20386',\n",
       " '80585fdb-00c0-45c4-9eab-a5afec6ddc58',\n",
       " '2965b694-fe0c-48ad-b1c4-d30a380b32d9',\n",
       " '9b77e8fa-d6f0-46d7-b5b6-b7273f522637',\n",
       " '9c7a39e9-a12f-4049-b12c-141fdf8c713f',\n",
       " 'ffb00c66-d485-4e32-b7c0-e4224790edc3',\n",
       " '53cf3723-f4d1-448b-99fb-cfc8bb6e268e',\n",
       " '38bdbb20-f891-46dd-8812-261dd93ad162',\n",
       " 'bfb36847-9d5e-4fdb-beb6-0885b762849c',\n",
       " '52822aae-afaa-4f03-b5f0-23f431fb17be',\n",
       " '88eea302-4de0-479c-b9a4-28ee6bd62869',\n",
       " 'ad84e783-fd1d-4552-aa0d-9eeba700a96a',\n",
       " '6035f9bd-25d1-4239-8c80-c152f59c8c4b',\n",
       " '512029c4-be2f-4ea7-8140-e944eddd091a',\n",
       " '06d03b1f-59c2-4d21-9a1f-7f82c967df09',\n",
       " '5d8ddcc3-6c65-4401-8500-4c1419fcff23',\n",
       " 'c0b2a1ae-da57-42b6-bfb8-615c2405944f',\n",
       " '234c7eda-688e-45a2-a33f-67f5f5c3a1ca',\n",
       " '887fc771-9682-4973-841f-6b733488b815',\n",
       " '4cec12b4-3521-4e15-8a16-09d1a9bc7a3a',\n",
       " '09da775e-06cc-425d-9f85-de84cb4adb93',\n",
       " '2680a6f9-2681-41cc-a4fb-01dac0dd83ac',\n",
       " 'cf319b3d-16cb-4a6a-8408-7195b6524491',\n",
       " 'f3f7b0dc-787f-4dbd-bdd3-56f13c3cf452',\n",
       " '2c6785d7-cb99-4bb2-96e3-d21dd6ff09e6',\n",
       " 'd8773dc9-a699-444b-90c3-a6031a91738b',\n",
       " '1b8ddeac-0040-479e-99bd-ea58e9eee3cc',\n",
       " 'cf85ecff-d0c9-48fa-b63f-6d1cc5d3cbb6',\n",
       " 'ff265d76-1bf7-45a5-9074-2450612abd95',\n",
       " '6ff8ff2d-9abb-4b9c-ab7c-cc307be79bd7',\n",
       " '5648689c-d62b-419b-aac5-8295c45ce9b0',\n",
       " 'd4a49301-1c68-480e-a0ab-34ce208661f6',\n",
       " '8048ef47-d778-4163-9aa3-c13d7a5d628d',\n",
       " 'f279e7bb-c271-428c-a570-c65d1378f580',\n",
       " '1b412eb9-8391-4cc7-bda8-b00e0c5afc36',\n",
       " '8c060adc-7fd0-4a8c-9f66-7c341cba3f66',\n",
       " '1f8d62d9-e474-4496-8b05-b6b246eae25d',\n",
       " '7ed1535e-39e1-4e83-9295-a35f396c7fcb',\n",
       " '85e2503c-8009-4956-93e3-3518cc7b6781',\n",
       " '84c0f561-a35d-42f4-a911-3e113662f166',\n",
       " '4bc511bc-5522-4943-861d-6727a903c228',\n",
       " 'eb9bbcc5-4152-446e-b51b-e1264cea9387',\n",
       " '877d2011-6116-4bca-879b-7cbdca98d9f6',\n",
       " 'd8bda6d2-854b-493a-9467-fb79589f1b65',\n",
       " '8a2c8d05-6b3d-4c24-b794-132f17711c8c',\n",
       " 'ec62ce14-fac8-43c2-b44c-fa832256420c',\n",
       " '9c13248e-e349-4e7c-a657-f16999fab575',\n",
       " 'cd00918e-7aee-4223-81e2-9855c0fda6ed',\n",
       " '16ddbc9f-9033-4595-b6ec-000e691c1b12',\n",
       " '907c8303-10d8-40ef-abc5-21a75a2a67ae',\n",
       " 'd14bab34-4979-425e-b2ef-637ffbc8ead1',\n",
       " '6bcf351b-6c6b-4521-8117-0d87380e4dfe',\n",
       " 'db8c8fdf-7db6-4f57-b8ad-94dc8d58ddef',\n",
       " 'c9ad5e2c-9732-4b93-af73-05a874b0b21a',\n",
       " '2268c25b-0dbd-4ec7-92d6-268b0b05f709',\n",
       " '74e5923a-b5d2-4849-92d3-d93e67617ca0',\n",
       " '15c9aa83-65ca-4f3d-8c1d-79542d584af8',\n",
       " '6880c421-a337-479f-83c3-ff3288df850e',\n",
       " '26ea7bef-d533-420a-b4b5-e7f340391d00',\n",
       " '544c579f-2c53-454a-b7cd-b50e780f8ffa',\n",
       " 'e941aa1f-5ebd-45af-a54d-5d6473200dd2',\n",
       " '9f11ef96-b224-4f3c-8edb-48911f867c8d',\n",
       " '8fb56268-e839-4ba0-9cce-0b3646ca86db',\n",
       " '5327ae65-542d-42d6-99a4-459c5e0b1e62',\n",
       " 'ca0c7145-aca9-4a4d-a203-daab1f4e4430',\n",
       " '4c677cac-1165-4997-9887-2716c387ed4e',\n",
       " '3630810d-03c8-481b-ba63-90636d001ef4',\n",
       " '6db7e62f-aedb-4587-ac36-eb280c79b78b',\n",
       " 'd91fbcde-b21b-4d2a-b805-ee77293f3dcd',\n",
       " '356f2389-5b26-461d-b0e1-d80eccc8286b',\n",
       " '43b4180b-2f54-499a-aca7-07a57b3e8406',\n",
       " '849890db-d77d-4352-ba88-ec440e9c7d1d',\n",
       " 'cb4e27ad-9756-4e8e-9b9d-f2f25bfebeff',\n",
       " '7fb9aab2-0719-4ce4-bd73-81557eb5e142',\n",
       " 'cb448eb2-10fd-471d-84b1-2e51debefed1',\n",
       " '35dfe56e-1215-4b1a-9ad5-02d257a21542',\n",
       " '8383cfff-5b2c-4485-ac23-6030e27d69e9',\n",
       " 'c5198d94-f2e4-4192-aa4b-a6d4aa8fb643',\n",
       " 'f33b3456-bec3-406e-83b8-0627f1331437',\n",
       " '04b592be-df1b-4610-8524-cd9867ce1156',\n",
       " '6e500e22-3d53-4b0a-bcd2-c200d7f26a06',\n",
       " '229d99bb-3ba9-4da4-929d-73fdbcbbebeb',\n",
       " 'df570513-5414-443e-9ad3-912010dc2fb1',\n",
       " '16caeb05-5cd1-4946-a984-baa8fe880055',\n",
       " 'a13da07c-e3ef-4114-9193-93af0a387b48',\n",
       " '05f72885-753e-494b-b229-5feb038130ba',\n",
       " 'd2fcd993-2389-4c12-9386-a9aba2d26bc7',\n",
       " '0e95134e-02b6-4cb7-9d68-c859427e05f3',\n",
       " 'a1ddb024-d64f-4d1f-9036-cfaeaf64acfc',\n",
       " '85715f42-4364-428a-bda8-ff4fbc49bf1b',\n",
       " 'b6e4bbd3-b6ef-49ac-8be5-66cfa35cad59',\n",
       " 'e004d24b-3b61-4788-876e-8fd652f8c19d',\n",
       " 'a105f8fe-f9f0-4035-a837-76fe9ed73d74',\n",
       " '6afd6c7d-b62c-4f09-b1e7-3beedd43c02e',\n",
       " 'ae445bd3-8624-4dfd-b691-4efe39a86b56',\n",
       " '629c922c-10ed-4dc3-9b17-bf0d3099f080',\n",
       " '60290343-24c9-4fe8-863b-b1c54793c788',\n",
       " '4dedc1d2-7157-48c3-97f8-745b490290f9',\n",
       " '0f5fb7c9-0524-4f72-8dde-c33aa0f32fe9',\n",
       " 'f7073155-9809-4d20-99e2-e1eabef69371',\n",
       " 'c1915232-548b-4afe-916d-dbecdad6b0c1',\n",
       " '058c67c5-74eb-4474-bcb4-f835a64777b6',\n",
       " 'e3a8b084-752d-48a6-8c2a-3b8d41a65804',\n",
       " 'a241569c-9fb0-42f3-b0e3-45bba635065e',\n",
       " '4ae118fe-aff7-4aeb-a4a5-2cebf96c6567',\n",
       " 'a4a67a6d-9b37-455f-b248-9e75441197a9',\n",
       " '331353bd-5d5f-4f94-825b-a17111aea6a4',\n",
       " '5a0115c6-8f84-47c7-8d98-b05c65ae2ac2',\n",
       " 'c48ea313-39e8-4bb0-9869-1904f98c4375',\n",
       " 'f1551aef-86ad-474f-b755-9834479af176',\n",
       " 'fcd97c80-623a-4de0-a3f1-48f160c732f6',\n",
       " 'c6dcc0ad-4427-46f6-88c8-bdca7d966511',\n",
       " 'd3b1047d-544a-4da7-aaaf-a147ea7cd20b',\n",
       " 'a079f1ff-58b9-46a2-8113-b0a46b5541af',\n",
       " 'c9ff059b-e319-4ab9-8872-27939a857af0',\n",
       " '1eb8472e-c0a3-4873-9b41-6a0ee120106e',\n",
       " '2ba28fda-ed2a-4e1e-b91c-8bcb486752cf',\n",
       " '3df2159a-c254-43cf-82a3-fa3f2c87b029',\n",
       " '036b41cd-d4e2-41bf-84cd-0a6ef53a616d',\n",
       " '6ccdafe4-a566-4a1c-b7bf-0bf68f001fc2',\n",
       " '5d133588-d6e5-45e8-8a7c-52a063634a98',\n",
       " '51cda251-223b-4a7c-9be0-4c59f5f71688',\n",
       " '66a95e61-2b83-4fea-9a99-dc1ed06fb5e2',\n",
       " 'a6b367a0-28cc-42bc-ac61-16260864018c',\n",
       " '6107c12f-6404-44c3-9d1b-09169af7015b',\n",
       " '6ab6bf38-8381-4217-a4c4-e120b2f8b4cb',\n",
       " 'a0cf4fa9-9906-4c20-9254-d64d9cf3aa85',\n",
       " '40f94fed-06b3-4181-b0e9-c0de9b0aadee',\n",
       " 'f014a7d0-b56a-4577-92f1-ec91f809adb4',\n",
       " 'e6bbc4d0-27b4-4107-8343-254035fcfcc8',\n",
       " '73353fca-2f65-4060-bd53-7a1ea96878df',\n",
       " '87426b91-749a-4eae-bd57-0f9bcf99e3af',\n",
       " '2be60029-ee06-4af4-9126-7ea9c6d20b6c',\n",
       " '2ceb0c9b-c6cd-4fed-91bf-1a74b89ac21a',\n",
       " '048153b4-7335-4af9-97ef-c6b4132a2fa5',\n",
       " 'b6dd80cb-8437-4adf-ac79-01fdef2e54ca',\n",
       " 'd21992db-4a56-481b-bec0-d6676623bc81',\n",
       " '2aeec539-203c-4197-bd23-2db1b80801bf',\n",
       " '00ee5176-3cfd-4d4f-84c9-a818c2aedb63',\n",
       " 'e43e229d-6a9b-4b5e-8a55-979e156cf654',\n",
       " '1cf0357c-2ba0-424d-b592-48eb2f606817',\n",
       " 'e8b0ca0d-9645-4c2e-92a7-c5c8b6879ba2',\n",
       " 'f75e872e-d8a3-4bf8-9098-ac6dba3b4e59',\n",
       " 'ceb25c19-9f22-4352-85a4-5ca56524295d']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(documents_chunks))]\n",
    "\n",
    "vector_store.add_documents(documents=documents_chunks, ids=uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.delete(ids=uuids[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 查询向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"深度强化学习有哪些一般的方法？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 352 CHAPTER 19. 深度强化学习\n",
      "由于最大化操作导致的状态价值系统性过高估计，并提出了双 Q学习，通过同时训练两\n",
      "个模型来解决这个问题。这种方法后来被应用于深度 Q学习（Van Hasselt 等人，2016） ，\n",
      "虽然其有效性后来受到了质疑（ Hessel等人，2018） 。Wang等人(2016)引入了深度对\n",
      "决网络，其中网络的两个部分分别预测状态的价值和每个动作的相对优势，这种解耦可\n",
      "以提高稳定性，因为有时状态的价值更为重要，而具体采取哪种动作的影响不大。\n",
      "Fortunato 等人（2018）提出了噪声深度 Q-网络，其特点是 Q-网络中的部分权重乘\n",
      "以噪声以增加预测的随机性并促进探索行为。该网络能够在逐步收敛到合理策略的过程\n",
      "中学会减少噪声的强度。分布式 DQN（Bellemare 等人，2017a；Dabney等人，2018，继\n",
      "Morimura 等人，2010）的目标是估计回报分布的更全面信息，而不仅仅是期望值。这使\n",
      "得网络有可能减轻最坏情况下的影响，并且还可以通过预测更高阶矩来提高性能，因为\n",
      "这为训练提供了更丰富的信号。 Rainbow（Hessel等人，2018）结合了六项对原始深度\n",
      "Q-学习算法的改进，包括决策网络、分布式 DQN和噪声DQN，从而提高了在 ATARI\n",
      "基准测试上的训练速度和最终性能。\n",
      "策略梯度 ：Williams （1992）首次提出了 REINFORCE 算法。”策略梯度方法 ”一\n",
      "词最早见于 Sutton等人（1999） 。Konda和Tsitsiklis （1999）引入了演员 -评论家算法。\n",
      "使用不同的基准来降低方差在 Greensmith 等人（2004）和Peters & Schaal （2008）的\n",
      "工作中被探讨。 Mei等人（2022）后来指出，价值基准主要是减少更新的激进性而非其\n",
      "方差。\n",
      "策略梯度已经被改进以产生确定性策略（ Silver等人，2014；Lillicrap 等人，2016；\n",
      "Fujimoto 等人，2018） 。最直接的方法是对所有可能的行动进行最大化，但如果行动空\n",
      "间是连续的，则每一步都需要一个优化过程。深度确定性策略梯度算法（ Lillicrap 等人，\n",
      "2016）按照行为价值梯度的方向调整策略，这表明使用了演员 -评论家方法。 \n",
      "\n",
      "**********\n",
      "\n",
      " [{'page': 367, 'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf'}] \n",
      "\n",
      "\n",
      "* 习，并证明了它通过 Banach定理收敛到一个固定点，因为 Bellman 操作是收缩映射。\n",
      "Watkins (1989) 首次明确地将动态规划和增强学习联系起来。 SARSA是由Rummery &\n",
      "Niranjan (1994) 开发的。 Gordon (1995) 提出了拟合 Q学习，用机器学习模型预测每个\n",
      "状态-动作对的价值。 Riedmiller (2005) 引入了神经拟合 Q学习，使用神经网络从一个\n",
      "状态一次性预测所有动作的价值。 Singh & Sutton (1996) 对蒙特卡罗方法进行了早期研\n",
      "究，探索启动算法则由 Sutton & Barto (1999) 提出。这是对五十多年工作的极简总结，\n",
      "Sutton & Barto (2018) 的著作中有更为全面的论述。\n",
      "深度 Q网络：Mnih等人在2015年设计的深度 Q学习是神经拟合 Q学习的理论\n",
      "衍生。它利用了当时卷积网络的进展，开发出一种拟合 Q学习方法，在 ATARI游戏基\n",
      "准测试中达到人类水平的表现。深度 Q学习存在致命的三重问题，即训练在包含自举、\n",
      "离策略学习和函数逼近的方案中可能不稳定（ Sutton & Barto, 2018 ） 。很多后续研究致\n",
      "力于让训练过程更加稳定。 Mnih等人(2015)引入了经验回放机制（ Lin, 1992 ） ，Schaul\n",
      "等人(2016)对其进行改进，优先考虑更重要的经验，从而加快学习速度，这就是所谓的\n",
      "优先经验回放。\n",
      "原始的Q学习论文使用四帧图像串联，以便网络观察到对象的速度，使底层过程更\n",
      "接近完全可观测。 Hausknecht & Stone (2015) 引入了深度递归 Q学习，使用循环网络\n",
      "架构，一次只处理一个帧图像，因为它能“记住”之前的状态。 Van Hasselt (2010) 指出 \n",
      "\n",
      "**********\n",
      "\n",
      " [{'page': 366, 'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf'}] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    query,\n",
    "    k=2,\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} \\n\\n**********\\n\\n [{res.metadata}] \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'> 0.8206568956375122\n",
      "<class 'float'> 0.8553059101104736\n",
      "<class 'float'> 0.8592807054519653\n",
      "<class 'float'> 0.8806620240211487\n",
      "<class 'float'> 0.892906904220581\n",
      "<class 'float'> 0.8954190611839294\n",
      "<class 'float'> 0.8960753083229065\n",
      "<class 'float'> 0.9018613696098328\n",
      "<class 'float'> 0.923303484916687\n",
      "<class 'float'> 0.9272459149360657\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    query, k=10\n",
    ")\n",
    "for res, score in results:\n",
    "    # print(f\"* [SIM={score:3f}] \\n\\n*********\\n\\n {res.page_content} \\n\\n##########\\n\\n [{res.metadata}] \\n\\n\")\n",
    "    print(type(score), score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 假如我们换一个collection_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取当前目录\n",
    "current_directory = os.getcwd()\n",
    "# 设置persist_directory为Advanced_RAG_From_Scratch文件夹\n",
    "persist_directory = os.path.join(current_directory, '..', 'ChromaVDB')\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"test\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=persist_directory,  # Where to save data locally, remove if not necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"深度强化学习有哪些一般的方法？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    query, k=10\n",
    ")\n",
    "for res, score in results:\n",
    "    # print(f\"* [SIM={score:3f}] \\n\\n*********\\n\\n {res.page_content} \\n\\n##########\\n\\n [{res.metadata}] \\n\\n\")\n",
    "    print(type(score), score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试写的ChromaManager "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')  # 会跳出tests文件夹到Advanced_RAG_From_Scratch文件夹里面找PineconeManager\n",
    "from ChromaManager import ChromaVectorStoreManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建ChromaVectorStore实例\n",
    "chroma_store = ChromaVectorStoreManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_chroma.vectorstores.Chroma"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_vector_store = chroma_store.get_vector_store()\n",
    "type(chroma_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上传PDF文档\n",
    "chroma_store.upload_pdf_file(\"../files/UnderstandingDeepLearning-ZH-CN-240721.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行相似性搜索\n",
    "query = \"深度强化学习有哪些一般的方法？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = chroma_store.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: 352 CHAPTER 19. 深度强化学习\n",
      "由于最大化操作导致的状态价值系统性过高估计，并提出了双 Q学习，通过同时训练两\n",
      "个模型来解决这个问题。这种方法后来被应用于深度 Q学习（Van Hasselt 等人，2016） ，\n",
      "虽然其有效性后来受到了质疑（ Hessel等人，2018） 。Wang等人(2016)引入了深度对\n",
      "决网络，其中网络的两个部分分别预测状态的价值和每个动作的相对优势，这种解耦可\n",
      "以提高稳定性，因为有时状态的价值更为重要，而具体采取哪种动作的影响不大。\n",
      "Fortunato 等人（2018）提出了噪声深度 Q-网络，其特点是 Q-网络中的部分权重乘\n",
      "以噪声以增加预测的随机性并促进探索行为。该网络能够在逐步收敛到合理策略的过程\n",
      "中学会减少噪声的强度。分布式 DQN（Bellemare 等人，2017a；Dabney等人，2018，继\n",
      "Morimura 等人，2010）的目标是估计回报分布的更全面信息，而不仅仅是期望值。这使\n",
      "得网络有可能减轻最坏情况下的影响，并且还可以通过预测更高阶矩来提高性能，因为\n",
      "这为训练提供了更丰富的信号。 Rainbow（Hessel等人，2018）结合了六项对原始深度\n",
      "Q-学习算法的改进，包括决策网络、分布式 DQN和噪声DQN，从而提高了在 ATARI\n",
      "基准测试上的训练速度和最终性能。\n",
      "策略梯度 ：Williams （1992）首次提出了 REINFORCE 算法。”策略梯度方法 ”一\n",
      "词最早见于 Sutton等人（1999） 。Konda和Tsitsiklis （1999）引入了演员 -评论家算法。\n",
      "使用不同的基准来降低方差在 Greensmith 等人（2004）和Peters & Schaal （2008）的\n",
      "工作中被探讨。 Mei等人（2022）后来指出，价值基准主要是减少更新的激进性而非其\n",
      "方差。\n",
      "策略梯度已经被改进以产生确定性策略（ Silver等人，2014；Lillicrap 等人，2016；\n",
      "Fujimoto 等人，2018） 。最直接的方法是对所有可能的行动进行最大化，但如果行动空\n",
      "间是连续的，则每一步都需要一个优化过程。深度确定性策略梯度算法（ Lillicrap 等人，\n",
      "2016）按照行为价值梯度的方向调整策略，这表明使用了演员 -评论家方法。\n",
      "\n",
      "Metadata: {'page': 367, 'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf'}\n",
      "\n",
      "Content: 习，并证明了它通过 Banach定理收敛到一个固定点，因为 Bellman 操作是收缩映射。\n",
      "Watkins (1989) 首次明确地将动态规划和增强学习联系起来。 SARSA是由Rummery &\n",
      "Niranjan (1994) 开发的。 Gordon (1995) 提出了拟合 Q学习，用机器学习模型预测每个\n",
      "状态-动作对的价值。 Riedmiller (2005) 引入了神经拟合 Q学习，使用神经网络从一个\n",
      "状态一次性预测所有动作的价值。 Singh & Sutton (1996) 对蒙特卡罗方法进行了早期研\n",
      "究，探索启动算法则由 Sutton & Barto (1999) 提出。这是对五十多年工作的极简总结，\n",
      "Sutton & Barto (2018) 的著作中有更为全面的论述。\n",
      "深度 Q网络：Mnih等人在2015年设计的深度 Q学习是神经拟合 Q学习的理论\n",
      "衍生。它利用了当时卷积网络的进展，开发出一种拟合 Q学习方法，在 ATARI游戏基\n",
      "准测试中达到人类水平的表现。深度 Q学习存在致命的三重问题，即训练在包含自举、\n",
      "离策略学习和函数逼近的方案中可能不稳定（ Sutton & Barto, 2018 ） 。很多后续研究致\n",
      "力于让训练过程更加稳定。 Mnih等人(2015)引入了经验回放机制（ Lin, 1992 ） ，Schaul\n",
      "等人(2016)对其进行改进，优先考虑更重要的经验，从而加快学习速度，这就是所谓的\n",
      "优先经验回放。\n",
      "原始的Q学习论文使用四帧图像串联，以便网络观察到对象的速度，使底层过程更\n",
      "接近完全可观测。 Hausknecht & Stone (2015) 引入了深度递归 Q学习，使用循环网络\n",
      "架构，一次只处理一个帧图像，因为它能“记住”之前的状态。 Van Hasselt (2010) 指出\n",
      "\n",
      "Metadata: {'page': 366, 'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf'}\n",
      "\n",
      "Content: 350 CHAPTER 19. 深度强化学习\n",
      "图 19.17:决策变换器。决策变换器把离线强化学习处理为序列预测问题。输入是状态、动作和\n",
      "剩余回报的序列，每个元素都被转换为固定大小的嵌入。每一步，网络预测下一动作。在测试阶\n",
      "段，剩余回报未知；实际中，通常从一个初始估计出发，逐渐扣除观测到的奖励。\n",
      "能够处理大量数据，并在广阔的时间范围内整合信息，使时间信用分配问题变得更易于\n",
      "处理。这为强化学习开辟了一条新的、令人兴奋的道路。\n",
      "19.8总结\n",
      "增强学习 (Reinforcement Learning) 是针对马尔科夫决策过程 (Markov Decision\n",
      "Processes) 及其类似系统的序贯决策框架。本章介绍了增强学习的表格方法，包括动态\n",
      "规划（环境模型已知） 、蒙特卡罗方法（通过运行多个回合并根据获得的奖励调整动作\n",
      "值和策略）和时差分方法（在回合进行中更新这些值） 。\n",
      "深度Q学习(Deep Q-Learning) 是一种时差分方法，使用深度神经网络预测每个状\n",
      "态的动作价值，能够训练智能体在 Atari 2600 游戏中达到类似人类的水平。策略梯度方\n",
      "法直接对策略进行优化，而非对动作进行价值赋值。这些方法生成的是随机策略，在部\n",
      "分可观测的环境中尤其重要。这些更新过程含有噪声，为减少其方差已经引入了多种改\n",
      "进措施。\n",
      "当无法直接与环境互动而必须依赖历史数据学习时，就会使用离线增强学习。决策\n",
      "变换器(Decision Transformer) 利用深度学习的最新进展构建状态 -动作-奖励序列模型，\n",
      "并预测能够最大化奖励的动作。\n",
      "19.9笔记\n",
      "Sutton和Barto在2018年的作品中详细介绍了表格型增强学习方法。 Li (2017) 、\n",
      "Arulkumaran 等人(2017)、FranCois-Lavet 等人(2018)和Wang等人(2022c)分别提供\n",
      "了深度增强学习领域的综述。 Graesser 和Keng的2019年作品是一本优秀的入门资源，\n",
      "其中包含了 Python代码示例。\n",
      "\n",
      "Metadata: {'page': 365, 'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(f\"Content: {result['content']}\\n\\nMetadata: {result['metadata']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: 352 CHAPTER 19. 深度强化学习\n",
      "由于最大化操作导致的状态价值系统性过高估计，并提出了双 Q学习，通过同时训练两\n",
      "个模型来解决这个问题。这种方法后来被应用于深度 Q学习（Van Hasselt 等人，2016） ，\n",
      "虽然其有效性后来受到了质疑（ Hessel等人，2018） 。Wang等人(2016)引入了深度对\n",
      "决网络，其中网络的两个部分分别预测状态的价值和每个动作的相对优势，这种解耦可\n",
      "以提高稳定性，因为有时状态的价值更为重要，而具体采取哪种动作的影响不大。\n",
      "Fortunato 等人（2018）提出了噪声深度 Q-网络，其特点是 Q-网络中的部分权重乘\n",
      "以噪声以增加预测的随机性并促进探索行为。该网络能够在逐步收敛到合理策略的过程\n",
      "中学会减少噪声的强度。分布式 DQN（Bellemare 等人，2017a；Dabney等人，2018，继\n",
      "Morimura 等人，2010）的目标是估计回报分布的更全面信息，而不仅仅是期望值。这使\n",
      "得网络有可能减轻最坏情况下的影响，并且还可以通过预测更高阶矩来提高性能，因为\n",
      "这为训练提供了更丰富的信号。 Rainbow（Hessel等人，2018）结合了六项对原始深度\n",
      "Q-学习算法的改进，包括决策网络、分布式 DQN和噪声DQN，从而提高了在 ATARI\n",
      "基准测试上的训练速度和最终性能。\n",
      "策略梯度 ：Williams （1992）首次提出了 REINFORCE 算法。”策略梯度方法 ”一\n",
      "词最早见于 Sutton等人（1999） 。Konda和Tsitsiklis （1999）引入了演员 -评论家算法。\n",
      "使用不同的基准来降低方差在 Greensmith 等人（2004）和Peters & Schaal （2008）的\n",
      "工作中被探讨。 Mei等人（2022）后来指出，价值基准主要是减少更新的激进性而非其\n",
      "方差。\n",
      "策略梯度已经被改进以产生确定性策略（ Silver等人，2014；Lillicrap 等人，2016；\n",
      "Fujimoto 等人，2018） 。最直接的方法是对所有可能的行动进行最大化，但如果行动空\n",
      "间是连续的，则每一步都需要一个优化过程。深度确定性策略梯度算法（ Lillicrap 等人，\n",
      "2016）按照行为价值梯度的方向调整策略，这表明使用了演员 -评论家方法。\n",
      "Metadata: {'page': 367, 'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf'}\n",
      "Score: 0.8190323710441589\n",
      "\n",
      "Content: 习，并证明了它通过 Banach定理收敛到一个固定点，因为 Bellman 操作是收缩映射。\n",
      "Watkins (1989) 首次明确地将动态规划和增强学习联系起来。 SARSA是由Rummery &\n",
      "Niranjan (1994) 开发的。 Gordon (1995) 提出了拟合 Q学习，用机器学习模型预测每个\n",
      "状态-动作对的价值。 Riedmiller (2005) 引入了神经拟合 Q学习，使用神经网络从一个\n",
      "状态一次性预测所有动作的价值。 Singh & Sutton (1996) 对蒙特卡罗方法进行了早期研\n",
      "究，探索启动算法则由 Sutton & Barto (1999) 提出。这是对五十多年工作的极简总结，\n",
      "Sutton & Barto (2018) 的著作中有更为全面的论述。\n",
      "深度 Q网络：Mnih等人在2015年设计的深度 Q学习是神经拟合 Q学习的理论\n",
      "衍生。它利用了当时卷积网络的进展，开发出一种拟合 Q学习方法，在 ATARI游戏基\n",
      "准测试中达到人类水平的表现。深度 Q学习存在致命的三重问题，即训练在包含自举、\n",
      "离策略学习和函数逼近的方案中可能不稳定（ Sutton & Barto, 2018 ） 。很多后续研究致\n",
      "力于让训练过程更加稳定。 Mnih等人(2015)引入了经验回放机制（ Lin, 1992 ） ，Schaul\n",
      "等人(2016)对其进行改进，优先考虑更重要的经验，从而加快学习速度，这就是所谓的\n",
      "优先经验回放。\n",
      "原始的Q学习论文使用四帧图像串联，以便网络观察到对象的速度，使底层过程更\n",
      "接近完全可观测。 Hausknecht & Stone (2015) 引入了深度递归 Q学习，使用循环网络\n",
      "架构，一次只处理一个帧图像，因为它能“记住”之前的状态。 Van Hasselt (2010) 指出\n",
      "Metadata: {'page': 366, 'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf'}\n",
      "Score: 0.8553059101104736\n",
      "\n",
      "Content: 350 CHAPTER 19. 深度强化学习\n",
      "图 19.17:决策变换器。决策变换器把离线强化学习处理为序列预测问题。输入是状态、动作和\n",
      "剩余回报的序列，每个元素都被转换为固定大小的嵌入。每一步，网络预测下一动作。在测试阶\n",
      "段，剩余回报未知；实际中，通常从一个初始估计出发，逐渐扣除观测到的奖励。\n",
      "能够处理大量数据，并在广阔的时间范围内整合信息，使时间信用分配问题变得更易于\n",
      "处理。这为强化学习开辟了一条新的、令人兴奋的道路。\n",
      "19.8总结\n",
      "增强学习 (Reinforcement Learning) 是针对马尔科夫决策过程 (Markov Decision\n",
      "Processes) 及其类似系统的序贯决策框架。本章介绍了增强学习的表格方法，包括动态\n",
      "规划（环境模型已知） 、蒙特卡罗方法（通过运行多个回合并根据获得的奖励调整动作\n",
      "值和策略）和时差分方法（在回合进行中更新这些值） 。\n",
      "深度Q学习(Deep Q-Learning) 是一种时差分方法，使用深度神经网络预测每个状\n",
      "态的动作价值，能够训练智能体在 Atari 2600 游戏中达到类似人类的水平。策略梯度方\n",
      "法直接对策略进行优化，而非对动作进行价值赋值。这些方法生成的是随机策略，在部\n",
      "分可观测的环境中尤其重要。这些更新过程含有噪声，为减少其方差已经引入了多种改\n",
      "进措施。\n",
      "当无法直接与环境互动而必须依赖历史数据学习时，就会使用离线增强学习。决策\n",
      "变换器(Decision Transformer) 利用深度学习的最新进展构建状态 -动作-奖励序列模型，\n",
      "并预测能够最大化奖励的动作。\n",
      "19.9笔记\n",
      "Sutton和Barto在2018年的作品中详细介绍了表格型增强学习方法。 Li (2017) 、\n",
      "Arulkumaran 等人(2017)、FranCois-Lavet 等人(2018)和Wang等人(2022c)分别提供\n",
      "了深度增强学习领域的综述。 Graesser 和Keng的2019年作品是一本优秀的入门资源，\n",
      "其中包含了 Python代码示例。\n",
      "Metadata: {'page': 365, 'source': '../files/UnderstandingDeepLearning-ZH-CN-240721.pdf'}\n",
      "Score: 0.8592807054519653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 执行带分数的相似性搜索\n",
    "results_with_score = chroma_store.similarity_search_with_score(query)\n",
    "for result in results_with_score:\n",
    "    print(f\"Content: {result['content']}\\nMetadata: {result['metadata']}\\nScore: {result['score']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chroma检索出来的信息是根据score升序排列的，这与pinecoe不同，需要注意一下 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
