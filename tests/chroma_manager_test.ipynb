{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') \n",
    "from src.vdb_managers.chroma_manager import ChromaManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_store = ChromaManager() # 自定义的chroma类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"files/论文 - GraphRAG.pdf\"\n",
    "# file_path = \"files/上奇实习报告.pdf\"\n",
    "auto_extract_metadata = True\n",
    "metadata = {\n",
    "    'keywords': \"实习\", # 必须是str，好像bool等也行，不记得了，反正不能是list\n",
    "    \"from\": \"上齐实习\"\n",
    "}\n",
    "collection_name = \"RAG\"\n",
    "similarity_metric = \"cosine\"\n",
    "dense_weight = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上传PDF文档\n",
    "chroma_store.upload_pdf_file(file_path = file_path, collection_name = collection_name)\n",
    "# chroma_store.upload_pdf_file(file_path = file_path, metadata=metadata, collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the general methods of deep reinforcement learning?\"\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = chroma_store.dense_search(collection_name=collection_name, query=query, k=k)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = chroma_store.hybrid_search(collection_name=collection_name, query=query, k=k, dense_weight=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Recursive abstractive processing for tree-organized retrieval. arXiv preprint arXiv:2401.18059 .\\nScott, K. (2024). Behind the Tech. https://www .microsoft .com/en-us/behind-the-tech.\\nShao, Z., Gong, Y ., Shen, Y ., Huang, M., Duan, N., and Chen, W. (2023). Enhancing retrieval-\\naugmented large language models with iterative retrieval-generation synergy. arXiv preprint\\narXiv:2305.15294 .\\nSu, D., Xu, Y ., Yu, T., Siddique, F. B., Barezi, E. J., and Fung, P. (2020). Caire-covid: A ques-\\ntion answering and query-focused multi-document summarization system for covid-19 scholarly\\ninformation management. arXiv preprint arXiv:2005.03975 .\\nTang, Y . and Yang, Y . (2024). MultiHop-RAG: Benchmarking retrieval-augmented generation for\\nmulti-hop queries. arXiv preprint arXiv:2401.15391 .\\nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y ., Bashlykov, N., Batra, S.,\\nBhargava, P., Bhosale, S., et al. (2023). Llama 2: Open foundation and fine-tuned chat models.',\n",
       "  'metadata': {'category': 'artifical_intelligence',\n",
       "   'keywords': 'retrieval',\n",
       "   'page': 13,\n",
       "   'source': 'files/论文 - GraphRAG.pdf'},\n",
       "  'score': 0.305845749572931},\n",
       " {'content': 'Baek, J., Aji, A. F., and Saffari, A. (2023). Knowledge-augmented language model prompting for\\nzero-shot knowledge graph question answering. arXiv preprint arXiv:2306.04136 .\\nBan, T., Chen, L., Wang, X., and Chen, H. (2023). From query tools to causal architects: Harnessing\\nlarge language models for advanced causal discovery from data.\\nBaumel, T., Eyal, M., and Elhadad, M. (2018). Query focused abstractive summarization: Incorpo-\\nrating query relevance, multi-document coverage, and summary length constraints into seq2seq\\nmodels. arXiv preprint arXiv:1801.07704 .\\nBlondel, V . D., Guillaume, J.-L., Lambiotte, R., and Lefebvre, E. (2008). Fast unfolding of\\ncommunities in large networks. Journal of statistical mechanics: theory and experiment ,\\n2008(10):P10008.\\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam,\\nP., Sastry, G., Askell, A., et al. (2020). Language models are few-shot learners. Advances in',\n",
       "  'metadata': {'category': 'artifical_intelligence',\n",
       "   'keywords': 'language model',\n",
       "   'page': 11,\n",
       "   'source': 'files/论文 - GraphRAG.pdf'},\n",
       "  'score': 0.28943433436355614},\n",
       " {'content': 'represent similar semantics. Queries are then embedded into the same vector space, with the text\\nchunks of the nearest kvectors used as context. More advanced variations exist, but all solve the\\nproblem of what to do when an external dataset of interest exceeds the LLM’s context window.\\nAdvanced RAG systems include pre-retrieval, retrieval, post-retrieval strategies designed to over-\\ncome the drawbacks of Na ¨ıve RAG, while Modular RAG systems include patterns for iterative and\\ndynamic cycles of interleaved retrieval and generation (Gao et al., 2023). Our implementation of\\nGraph RAG incorporates multiple concepts related to other systems. For example, our community\\nsummaries are a kind of self-memory (Selfmem, Cheng et al., 2024) for generation-augmented re-\\ntrieval (GAR, Mao et al., 2020) that facilitates future generation cycles, while our parallel generation\\nof community answers from these summaries is a kind of iterative (Iter-RetGen, Shao et al., 2023)',\n",
       "  'metadata': {'category': 'artifical_intelligence',\n",
       "   'keywords': 'RAG',\n",
       "   'page': 9,\n",
       "   'source': 'files/论文 - GraphRAG.pdf'},\n",
       "  'score': 0.2862438149079758}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = chroma_store.search(collection_name=collection_name, query=query, k=k, dense_weight=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[文档片段 1]\\nDataset Example activity framing and generation of global sensemaking questions Podcast transcriptsUser : A tech journalist looking for insights and trends in the tech industry Task: Understanding how tech leaders view the role of policy and regulation Questions : 1. Which episodes deal primarily with tech policy and government regulation? 2. How do guests perceive the impact of privacy laws on technology development? 3. Do any guests discuss the balance between innovation and ethical considerations? 4. What are the suggested changes to current policies mentioned by the guests? 5. Are collaborations between tech companies and governments discussed and how? News articlesUser : Educator incorporating current affairs into curricula Task: Teaching about health and wellness Questions : 1. What current topics in health can be integrated into health education curricula? 2. How do news articles address the concepts of preventive medicine and wellness?\\n\\n---\\n\\n[文档片段 2]\\nof data sensemaking, i.e., the process though which people inspect, engage with, and contextualize data within the broader scope of real-world activities (Koesten et al., 2021). Similarly, methods for extracting latent summarization queries from source texts also exist (Xu and Lapata, 2021), but such extracted questions can target details that betray prior knowledge of the texts. To evaluate the effectiveness of RAG systems for more global sensemaking tasks, we need questions that convey only a high-level understanding of dataset contents, and not the details of specific texts. We used an activity-centered approach to automate the generation of such questions: given a short description of a dataset, we asked the LLM to identify Npotential users and Ntasks per user, then for each (user, task) combination, we asked the LLM to generate Nquestions that require understanding of the entire corpus. For our evaluation, a value of N= 5 resulted in 125 test questions\\n\\n---\\n\\n[文档片段 3]\\n2. How do news articles address the concepts of preventive medicine and wellness? 3. Are there examples of health articles that contradict each other, and if so, why? 4. What insights can be gleaned about public health priorities based on news coverage? 5. How can educators use the dataset to highlight the importance of health literacy? Table 1: Examples of potential users, tasks, and questions generated by the LLM based on short descriptions of the target datasets. Questions target global understanding rather than specific details. 3 Evaluation 3.1 Datasets We selected two datasets in the one million token range, each equivalent to about 10 novels of text and representative of the kind of corpora that users may encounter in their real world activities: •Podcast transcripts . Compiled transcripts of podcast conversations between Kevin Scott, Microsoft CTO, and other technology leaders (Behind the Tech, Scott, 2024). Size: 1669'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_context = chroma_store.get_formatted_context(collection_name=collection_name, query=query, k=k, dense_weight=dense_weight)\n",
    "formatted_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv # type: ignore\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('ZETATECHS_API_KEY')\n",
    "base_url = os.getenv('ZETATECHS_API_BASE')\n",
    "\n",
    "import chromadb # type: ignore\n",
    "import chromadb.utils.embedding_functions as embedding_functions # type: ignore\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"ChromaVDB\")\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=api_key,\n",
    "    api_base=base_url,\n",
    "    model_name=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "collection = client.get_or_create_collection(name=\"test\", embedding_function=openai_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(collection.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(client.get_or_create_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(collection.add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(client.create_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
