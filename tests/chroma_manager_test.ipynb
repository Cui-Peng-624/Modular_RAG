{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') \n",
    "from src.vdb_managers.chroma_manager import ChromaManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_store = ChromaManager() # 自定义的chroma类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"files/论文 - GraphRAG.pdf\"\n",
    "file_path = \"files/上奇实习报告.pdf\"\n",
    "auto_extract_metadata = True\n",
    "metadata = {\n",
    "    'keywords': \"实习\", # 如果有keywords关键字，必须使用[]包裹\n",
    "    \"from\": \"上齐实习\"\n",
    "}\n",
    "collection_name = \"RAG\"\n",
    "similarity_metric = \"cosine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上传PDF文档\n",
    "# chroma_store.upload_pdf_file(file_path = file_path, collection_name = collection_name)\n",
    "chroma_store.upload_pdf_file(file_path = file_path, metadata=metadata, collection_name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the general methods of deep reinforcement learning?\"\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = chroma_store.dense_search(collection_name=collection_name, query=query, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['85d3db5c-29df-447b-b2a5-9fccc1772b18',\n",
       "   '115f6050-ab41-4da5-be1b-6c22cf5e6871',\n",
       "   '1a70213d-a622-4e47-be25-43f475d8fc5b']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Recursive abstractive processing for tree-organized retrieval. arXiv preprint arXiv:2401.18059 .\\nScott, K. (2024). Behind the Tech. https://www .microsoft .com/en-us/behind-the-tech.\\nShao, Z., Gong, Y ., Shen, Y ., Huang, M., Duan, N., and Chen, W. (2023). Enhancing retrieval-\\naugmented large language models with iterative retrieval-generation synergy. arXiv preprint\\narXiv:2305.15294 .\\nSu, D., Xu, Y ., Yu, T., Siddique, F. B., Barezi, E. J., and Fung, P. (2020). Caire-covid: A ques-\\ntion answering and query-focused multi-document summarization system for covid-19 scholarly\\ninformation management. arXiv preprint arXiv:2005.03975 .\\nTang, Y . and Yang, Y . (2024). MultiHop-RAG: Benchmarking retrieval-augmented generation for\\nmulti-hop queries. arXiv preprint arXiv:2401.15391 .\\nTouvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y ., Bashlykov, N., Batra, S.,\\nBhargava, P., Bhosale, S., et al. (2023). Llama 2: Open foundation and fine-tuned chat models.',\n",
       "   'Baek, J., Aji, A. F., and Saffari, A. (2023). Knowledge-augmented language model prompting for\\nzero-shot knowledge graph question answering. arXiv preprint arXiv:2306.04136 .\\nBan, T., Chen, L., Wang, X., and Chen, H. (2023). From query tools to causal architects: Harnessing\\nlarge language models for advanced causal discovery from data.\\nBaumel, T., Eyal, M., and Elhadad, M. (2018). Query focused abstractive summarization: Incorpo-\\nrating query relevance, multi-document coverage, and summary length constraints into seq2seq\\nmodels. arXiv preprint arXiv:1801.07704 .\\nBlondel, V . D., Guillaume, J.-L., Lambiotte, R., and Lefebvre, E. (2008). Fast unfolding of\\ncommunities in large networks. Journal of statistical mechanics: theory and experiment ,\\n2008(10):P10008.\\nBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam,\\nP., Sastry, G., Askell, A., et al. (2020). Language models are few-shot learners. Advances in',\n",
       "   'represent similar semantics. Queries are then embedded into the same vector space, with the text\\nchunks of the nearest kvectors used as context. More advanced variations exist, but all solve the\\nproblem of what to do when an external dataset of interest exceeds the LLM’s context window.\\nAdvanced RAG systems include pre-retrieval, retrieval, post-retrieval strategies designed to over-\\ncome the drawbacks of Na ¨ıve RAG, while Modular RAG systems include patterns for iterative and\\ndynamic cycles of interleaved retrieval and generation (Gao et al., 2023). Our implementation of\\nGraph RAG incorporates multiple concepts related to other systems. For example, our community\\nsummaries are a kind of self-memory (Selfmem, Cheng et al., 2024) for generation-augmented re-\\ntrieval (GAR, Mao et al., 2020) that facilitates future generation cycles, while our parallel generation\\nof community answers from these summaries is a kind of iterative (Iter-RetGen, Shao et al., 2023)']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[{'category': 'artifical_intelligence',\n",
       "    'keywords': 'retrieval-augmented',\n",
       "    'page': 13,\n",
       "    'source': 'files/论文 - GraphRAG.pdf'},\n",
       "   {'category': 'artifical_intelligence',\n",
       "    'keywords': 'language models',\n",
       "    'page': 11,\n",
       "    'source': 'files/论文 - GraphRAG.pdf'},\n",
       "   {'category': 'artifical_intelligence',\n",
       "    'keywords': 'RAG',\n",
       "    'page': 9,\n",
       "    'source': 'files/论文 - GraphRAG.pdf'}]],\n",
       " 'distances': [[0.6933481884752979, 0.7107481870163558, 0.7139820134613135]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv # type: ignore\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('ZETATECHS_API_KEY')\n",
    "base_url = os.getenv('ZETATECHS_API_BASE')\n",
    "\n",
    "import chromadb # type: ignore\n",
    "import chromadb.utils.embedding_functions as embedding_functions # type: ignore\n",
    "\n",
    "client = chromadb.PersistentClient(path=\"ChromaVDB\")\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=api_key,\n",
    "    api_base=base_url,\n",
    "    model_name=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "collection = client.get_or_create_collection(name=\"test\", embedding_function=openai_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(collection.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(client.get_or_create_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(collection.add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(client.create_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
